#!/usr/bin/env python3
"""
miniZ MCP v4.3.0 - Professional Edition with License Management
Web UI + WebSocket MCP + 30 Tools + Hardware License Protection
Copyright Â© 2025 miniZ Team
"""

import asyncio
import json
import subprocess
import psutil
import time
import os
import sys
from datetime import datetime
from pathlib import Path
from fastapi import FastAPI, WebSocket, HTTPException
from fastapi.responses import HTMLResponse
from pydantic import BaseModel
import websockets
import pyautogui
import difflib
import re

# License Management - DISABLED (FREE EDITION)
# Bypass license check completely
LICENSE_SYSTEM_AVAILABLE = False  # FREE EDITION - No license required

# Auto-startup manager
import winreg
class AutoStartupManager:
    APP_NAME = "miniZ_MCP_Professional"
    
    @staticmethod
    def get_exe_path():
        if getattr(sys, 'frozen', False):
            return sys.executable
        return os.path.abspath(__file__)
    
    @classmethod
    def enable_autostart(cls):
        try:
            exe_path = cls.get_exe_path()
            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Run", 0, winreg.KEY_SET_VALUE)
            winreg.SetValueEx(key, cls.APP_NAME, 0, winreg.REG_SZ, f'"{exe_path}"')
            winreg.CloseKey(key)
            print(f"âœ… [Startup] ÄÃ£ báº­t khá»Ÿi Ä‘á»™ng cÃ¹ng Windows")
            return True
        except Exception as e:
            print(f"âš ï¸ [Startup] KhÃ´ng thá»ƒ báº­t auto-start: {e}")
            return False
    
    @classmethod
    def is_autostart_enabled(cls):
        try:
            key = winreg.OpenKey(winreg.HKEY_CURRENT_USER, r"Software\Microsoft\Windows\CurrentVersion\Run", 0, winreg.KEY_READ)
            try:
                winreg.QueryValueEx(key, cls.APP_NAME)
                winreg.CloseKey(key)
                return True
            except FileNotFoundError:
                winreg.CloseKey(key)
                return False
        except:
            return False


# ============================================================
# ğŸ”¥ FIREWALL/INTERNET CHECKER - Kiá»ƒm tra quyá»n káº¿t ná»‘i máº¡ng
# ============================================================
import subprocess

class FirewallChecker:
    """Kiá»ƒm tra vÃ  hÆ°á»›ng dáº«n cáº¥p quyá»n Windows Firewall cho á»©ng dá»¥ng"""
    
    APP_NAME = "miniZ_MCP"
    
    @staticmethod
    def get_exe_path():
        """Láº¥y Ä‘Æ°á»ng dáº«n file EXE"""
        if getattr(sys, 'frozen', False):
            return sys.executable
        return os.path.abspath(__file__)
    
    @staticmethod
    def get_exe_name():
        """Láº¥y tÃªn file EXE"""
        if getattr(sys, 'frozen', False):
            return os.path.basename(sys.executable)
        return os.path.basename(__file__)
    
    @classmethod
    def check_firewall_rules(cls) -> dict:
        """
        Kiá»ƒm tra xem á»©ng dá»¥ng Ä‘Ã£ cÃ³ quyá»n Firewall chÆ°a
        Returns: dict vá»›i keys: has_inbound, has_outbound, rules_found, details
        """
        result = {
            'has_inbound': False,
            'has_outbound': False,
            'rules_found': [],
            'exe_path': cls.get_exe_path(),
            'exe_name': cls.get_exe_name()
        }
        
        try:
            # TÃ¬m táº¥t cáº£ rules liÃªn quan Ä‘áº¿n miniZ
            cmd = 'netsh advfirewall firewall show rule name=all'
            output = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=10)
            
            if output.returncode == 0:
                lines = output.stdout.lower()
                exe_name_lower = result['exe_name'].lower().replace('.exe', '').replace('.py', '')
                
                # TÃ¬m cÃ¡c rules cÃ³ chá»©a tÃªn app
                for search_term in ['miniz_mcp', 'miniz mcp', exe_name_lower]:
                    if search_term in lines:
                        result['rules_found'].append(search_term)
                
                # Kiá»ƒm tra chi tiáº¿t tá»«ng rule
                if result['rules_found']:
                    for rule_name in ['miniz_mcp', result['exe_name'].replace('.exe', '').replace('.py', '')]:
                        try:
                            detail_cmd = f'netsh advfirewall firewall show rule name="{rule_name}" verbose'
                            detail_output = subprocess.run(detail_cmd, capture_output=True, text=True, shell=True, timeout=5)
                            if 'direction:' in detail_output.stdout.lower():
                                if 'direction:                            in' in detail_output.stdout.lower():
                                    result['has_inbound'] = True
                                if 'direction:                            out' in detail_output.stdout.lower():
                                    result['has_outbound'] = True
                        except:
                            pass
                    
                    # Náº¿u tÃ¬m tháº¥y rules, assume cÃ³ quyá»n (vÃ¬ Windows tá»± táº¡o cáº£ in/out)
                    if result['rules_found'] and not result['has_inbound']:
                        result['has_inbound'] = True  # Giáº£ Ä‘á»‹nh cÃ³ náº¿u rule tá»“n táº¡i
                        
        except subprocess.TimeoutExpired:
            print("âš ï¸ [Firewall] Timeout khi kiá»ƒm tra firewall rules")
        except Exception as e:
            print(f"âš ï¸ [Firewall] Lá»—i kiá»ƒm tra: {e}")
        
        return result
    
    @classmethod
    def request_firewall_permission(cls) -> bool:
        """
        Tá»± Ä‘á»™ng thÃªm rule Firewall (cáº§n quyá»n Admin)
        Returns: True náº¿u thÃ nh cÃ´ng
        """
        exe_path = cls.get_exe_path()
        rule_name = cls.get_exe_name().replace('.exe', '').replace('.py', '')
        
        try:
            # ThÃªm rule Inbound
            cmd_in = f'netsh advfirewall firewall add rule name="{rule_name}" dir=in action=allow program="{exe_path}" enable=yes'
            # ThÃªm rule Outbound  
            cmd_out = f'netsh advfirewall firewall add rule name="{rule_name}" dir=out action=allow program="{exe_path}" enable=yes'
            
            result_in = subprocess.run(cmd_in, capture_output=True, text=True, shell=True, timeout=10)
            result_out = subprocess.run(cmd_out, capture_output=True, text=True, shell=True, timeout=10)
            
            if result_in.returncode == 0 or result_out.returncode == 0:
                print(f"âœ… [Firewall] ÄÃ£ thÃªm rule firewall cho {rule_name}")
                return True
            else:
                return False
                
        except Exception as e:
            print(f"âš ï¸ [Firewall] Cáº§n quyá»n Admin Ä‘á»ƒ thÃªm rule: {e}")
            return False
    
    @classmethod
    def show_firewall_status(cls) -> None:
        """Hiá»ƒn thá»‹ tráº¡ng thÃ¡i Firewall vÃ  hÆ°á»›ng dáº«n náº¿u cáº§n"""
        print("\n" + "="*60)
        print("ğŸ”¥ KIá»‚M TRA QUYá»€N Káº¾T Ná»I INTERNET (Windows Firewall)")
        print("="*60)
        
        status = cls.check_firewall_rules()
        
        if status['rules_found']:
            print(f"âœ… TRáº NG THÃI: ÄÃƒ Cáº¤P QUYá»€N FIREWALL")
            print(f"   ğŸ“Œ Rules tÃ¬m tháº¥y: {', '.join(status['rules_found'])}")
            print(f"   ğŸ“ File: {status['exe_name']}")
            print(f"   ğŸ”— Inbound (nháº­n káº¿t ná»‘i): {'âœ… Cho phÃ©p' if status['has_inbound'] else 'âš ï¸ ChÆ°a rÃµ'}")
            print(f"   ğŸ”— Outbound (gá»­i káº¿t ná»‘i): {'âœ… Cho phÃ©p' if status['has_outbound'] else 'âœ… Máº·c Ä‘á»‹nh cho phÃ©p'}")
            print("\nâœ… á»¨ng dá»¥ng cÃ³ thá»ƒ káº¿t ná»‘i Internet bÃ¬nh thÆ°á»ng!")
        else:
            print(f"âš ï¸ TRáº NG THÃI: CHÆ¯A CÃ“ QUYá»€N FIREWALL")
            print(f"   ğŸ“ File: {status['exe_name']}")
            print(f"   ğŸ“‚ Path: {status['exe_path']}")
            print("\n" + "-"*60)
            print("ğŸ“Œ HÆ¯á»šNG DáºªN Cáº¤P QUYá»€N:")
            print("-"*60)
            print("ğŸ”¹ CÃCH 1: Tá»± Ä‘á»™ng (láº§n Ä‘áº§u cháº¡y)")
            print("   - Khi cháº¡y láº§n Ä‘áº§u, Windows sáº½ há»i 'Allow access'")
            print("   - Nháº¥n 'Allow access' hoáº·c 'Cho phÃ©p truy cáº­p'")
            print("")
            print("ğŸ”¹ CÃCH 2: Thá»§ cÃ´ng qua Windows Security")
            print("   1. Má»Ÿ 'Windows Security' â†’ 'Firewall & network protection'")
            print("   2. Nháº¥n 'Allow an app through firewall'")
            print("   3. Nháº¥n 'Change settings' â†’ 'Allow another app'")
            print("   4. Browse Ä‘áº¿n file EXE vÃ  thÃªm vÃ o")
            print("   5. Tick cáº£ 'Private' vÃ  'Public' networks")
            print("")
            print("ğŸ”¹ CÃCH 3: Cháº¡y lá»‡nh PowerShell (Admin)")
            print(f'   netsh advfirewall firewall add rule name="miniZ_MCP" dir=in action=allow program="{status["exe_path"]}" enable=yes')
            print("")
            
            # Thá»­ tá»± Ä‘á»™ng thÃªm rule
            print("ğŸ”„ Äang thá»­ tá»± Ä‘á»™ng cáº¥p quyá»n...")
            if cls.request_firewall_permission():
                print("âœ… ÄÃ£ tá»± Ä‘á»™ng cáº¥p quyá»n Firewall thÃ nh cÃ´ng!")
            else:
                print("âš ï¸ KhÃ´ng thá»ƒ tá»± Ä‘á»™ng cáº¥p quyá»n (cáº§n cháº¡y vá»›i quyá»n Admin)")
                print("   â†’ HÃ£y cháº¡y EXE vÃ  cho phÃ©p khi Windows há»i")
        
        print("="*60 + "\n")
        return status['rules_found']
    
    @classmethod
    def check_internet_connection(cls) -> dict:
        """Kiá»ƒm tra káº¿t ná»‘i Internet thá»±c táº¿"""
        result = {
            'connected': False,
            'latency_ms': None,
            'test_url': 'google.com'
        }
        
        try:
            import socket
            # Test DNS resolution
            socket.setdefaulttimeout(5)
            socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(("8.8.8.8", 53))
            result['connected'] = True
            
            # Test latency
            import time
            start = time.time()
            socket.socket(socket.AF_INET, socket.SOCK_STREAM).connect(("google.com", 443))
            result['latency_ms'] = int((time.time() - start) * 1000)
            
        except Exception as e:
            result['error'] = str(e)
        
        return result
    
    @classmethod
    def full_network_check(cls) -> dict:
        """Kiá»ƒm tra Ä‘áº§y Ä‘á»§: Firewall + Internet connection"""
        print("\nğŸŒ KIá»‚M TRA Káº¾T Ná»I Máº NG TOÃ€N DIá»†N")
        print("="*50)
        
        # 1. Check Firewall
        firewall_status = cls.check_firewall_rules()
        
        # 2. Check Internet
        internet_status = cls.check_internet_connection()
        
        # 3. Summary
        print(f"ğŸ”¥ Firewall Rules: {'âœ… ÄÃ£ cáº¥p quyá»n' if firewall_status['rules_found'] else 'âš ï¸ ChÆ°a cÃ³ rule'}")
        print(f"ğŸŒ Internet: {'âœ… ÄÃ£ káº¿t ná»‘i' if internet_status['connected'] else 'âŒ KhÃ´ng káº¿t ná»‘i'}")
        
        if internet_status.get('latency_ms'):
            print(f"âš¡ Äá»™ trá»…: {internet_status['latency_ms']}ms")
        
        if not firewall_status['rules_found'] and not internet_status['connected']:
            print("\nâš ï¸ CÃ³ thá»ƒ á»©ng dá»¥ng Ä‘ang bá»‹ Firewall cháº·n!")
            print("   â†’ HÃ£y lÃ m theo hÆ°á»›ng dáº«n cáº¥p quyá»n á»Ÿ trÃªn")
        elif internet_status['connected']:
            print("\nâœ… á»¨ng dá»¥ng sáºµn sÃ ng sá»­ dá»¥ng táº¥t cáº£ tÃ­nh nÄƒng online!")
        
        print("="*50 + "\n")
        
        return {
            'firewall': firewall_status,
            'internet': internet_status,
            'ready': firewall_status['rules_found'] or internet_status['connected']
        }


# Fake license for compatibility
def get_license_manager():
    class FakeLicense:
        def check_license(self): return {'valid': True, 'message': 'FREE EDITION', 'license_data': {'license_type': 'FREE', 'customer_name': 'Community User'}}
        def get_hardware_id(self): return 'FREE-EDITION'
    return FakeLicense()

def show_activation_window(): return True  # Always activated

# MCP Endpoint Manager - Improved connection handling
try:
    from mcp_endpoint_manager import get_endpoint_manager, MCPEndpointManager
    ENDPOINT_MANAGER_AVAILABLE = True
except ImportError:
    ENDPOINT_MANAGER_AVAILABLE = False
    print("âš ï¸ [Endpoint] MCPEndpointManager not available")

# Gemini AI
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ [Gemini] google-generativeai not installed. Run: pip install google-generativeai")

# OpenAI GPT-4
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ [OpenAI] openai library not installed. Run: pip install openai")

# Selenium Browser Automation
try:
    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.chrome.options import Options
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âš ï¸ [Selenium] Not installed. Run: pip install selenium webdriver-manager")

# RAG System - Retrieval Augmented Generation
try:
    from rag_system import (
        web_search, rag_search, get_realtime_info, smart_answer,
        RAG_TOOLS, get_rag_engine
    )
    RAG_AVAILABLE = True
    print("âœ… [RAG] RAG System loaded - DuckDuckGo + Local KB")
except ImportError as e:
    RAG_AVAILABLE = False
    print(f"âš ï¸ [RAG] RAG System not available: {e}")

# Vector Search System - Hybrid Semantic Search with FAISS
try:
    # from vector_search import VectorSearchEngine  # Táº¡m thá»i táº¯t do Python 3.14 conflict
    VECTOR_SEARCH_AVAILABLE = False
    print("âš ï¸ [VectorSearch] Vector search temporarily disabled (Python 3.14 compatibility)")
except ImportError as e:
    VECTOR_SEARCH_AVAILABLE = False
    print(f"âš ï¸ [VectorSearch] Vector search not available: {e}")

# ============================================================
# UTILITY FUNCTIONS (tá»« xiaozhi-esp32-server chÃ­nh thá»©c)
# ============================================================

import re

# ============================================================
# ğŸ”„ SMART TRUNCATE FOR LLM - Giá»›i háº¡n text gá»­i vá» LLM
# ============================================================

MAX_LLM_RESPONSE_CHARS = 2000  # Giá»›i háº¡n 2000 kÃ½ tá»± cho response gá»­i LLM
MAX_TTS_RESPONSE_CHARS = 800   # Giá»›i háº¡n 800 kÃ½ tá»± cho TTS (robot nÃ³i trá»±c tiáº¿p)


def clean_markdown_for_tts(text: str) -> str:
    """
    Loáº¡i bá» markdown formatting Ä‘á»ƒ TTS Ä‘á»c Ä‘Æ°á»£c
    """
    import re
    
    # Bá» headers markdown (# ## ###)
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
    
    # Bá» bold/italic (**text**, *text*, __text__, _text_)
    text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)
    text = re.sub(r'\*([^*]+)\*', r'\1', text)
    text = re.sub(r'__([^_]+)__', r'\1', text)
    text = re.sub(r'_([^_]+)_', r'\1', text)
    
    # Bá» code blocks vÃ  inline code
    text = re.sub(r'```[^`]*```', '', text, flags=re.DOTALL)
    text = re.sub(r'`([^`]+)`', r'\1', text)
    
    # Bá» horizontal rules (---, ***)
    text = re.sub(r'^[-*]{3,}$', '', text, flags=re.MULTILINE)
    
    # Bá» bullet points (- *, 1.)
    text = re.sub(r'^\s*[-*]\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)
    
    # Bá» links [text](url)
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)
    
    # Chuáº©n hÃ³a newlines (nhiá»u newline -> 1 newline)
    text = re.sub(r'\n{3,}', '\n\n', text)
    text = re.sub(r'\n\n+', '. ', text)  # Äá»•i paragraph break thÃ nh dáº¥u cháº¥m
    text = re.sub(r'\n', ' ', text)  # Äá»•i newline thÃ nh space
    
    # Chuáº©n hÃ³a spaces
    text = re.sub(r'\s{2,}', ' ', text)
    
    return text.strip()

def smart_truncate_for_llm(text: str, max_chars: int = MAX_LLM_RESPONSE_CHARS) -> str:
    """
    Cáº¯t ngáº¯n text thÃ´ng minh cho LLM, giá»¯ ná»™i dung quan trá»ng
    
    Args:
        text: Text cáº§n truncate
        max_chars: Giá»›i háº¡n kÃ½ tá»± (default: 4000)
    
    Returns:
        Text Ä‘Ã£ truncate vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin quan trá»ng
    """
    if not text or len(text) <= max_chars:
        return text
    
    # Giá»¯ pháº§n Ä‘áº§u (thÃ´ng tin chÃ­nh) vÃ  pháº§n cuá»‘i (káº¿t luáº­n)
    head_ratio = 0.7  # 70% cho pháº§n Ä‘áº§u
    tail_ratio = 0.25  # 25% cho pháº§n cuá»‘i
    
    head_chars = int(max_chars * head_ratio)
    tail_chars = int(max_chars * tail_ratio)
    truncate_notice = f"\n\n... [ÄÃ£ lÆ°á»£c bá» {len(text) - head_chars - tail_chars} kÃ½ tá»±] ...\n\n"
    
    head_part = text[:head_chars]
    tail_part = text[-tail_chars:]
    
    # Cáº¯t á»Ÿ ranh giá»›i cÃ¢u náº¿u cÃ³ thá»ƒ
    # TÃ¬m Ä‘iá»ƒm káº¿t thÃºc cÃ¢u gáº§n nháº¥t trong head_part
    for sep in ['. ', '.\n', '! ', '!\n', '? ', '?\n', '\n\n']:
        last_sep = head_part.rfind(sep)
        if last_sep > head_chars * 0.8:  # Chá»‰ cáº¯t náº¿u >= 80% head_chars
            head_part = head_part[:last_sep + len(sep)]
            break
    
    # TÃ¬m Ä‘iá»ƒm báº¯t Ä‘áº§u cÃ¢u gáº§n nháº¥t trong tail_part
    for sep in ['. ', '.\n', '\n\n']:
        first_sep = tail_part.find(sep)
        if first_sep != -1 and first_sep < tail_chars * 0.2:  # Chá»‰ cáº¯t náº¿u <= 20% tail_chars
            tail_part = tail_part[first_sep + len(sep):]
            break
    
    return head_part + truncate_notice + tail_part


def format_result_for_llm(result: dict, max_chars: int = MAX_LLM_RESPONSE_CHARS) -> str:
    """
    Format vÃ  truncate result dict thÃ nh text cho LLM
    
    Args:
        result: Dict káº¿t quáº£ tá»« tool
        max_chars: Giá»›i háº¡n kÃ½ tá»±
    
    Returns:
        Text Ä‘Ã£ format vÃ  truncate
    """
    import json
    
    # Náº¿u lÃ  response_text tá»« Gemini, Æ°u tiÃªn nÃ³
    if isinstance(result, dict):
        if result.get("response_text"):
            text = result["response_text"]
            return smart_truncate_for_llm(text, max_chars)
        
        # Náº¿u cÃ³ context (tá»« knowledge base), Æ°u tiÃªn
        if result.get("context"):
            text = result["context"]
            return smart_truncate_for_llm(text, max_chars)
        
        # Náº¿u cÃ³ message, dÃ¹ng message
        if result.get("message"):
            text = result["message"]
            # Náº¿u message ngáº¯n, thÃªm thÃ´ng tin khÃ¡c
            if len(text) < max_chars * 0.5:
                extra_info = []
                for key in ["summary", "content", "data", "results"]:
                    if result.get(key):
                        val = result[key]
                        if isinstance(val, str):
                            extra_info.append(val)
                        elif isinstance(val, (list, dict)):
                            extra_info.append(json.dumps(val, ensure_ascii=False, indent=1))
                if extra_info:
                    text += "\n\n" + "\n".join(extra_info)
            return smart_truncate_for_llm(text, max_chars)
    
    # Default: convert to JSON
    text = json.dumps(result, ensure_ascii=False, indent=1)
    return smart_truncate_for_llm(text, max_chars)


def sanitize_tool_name(name: str) -> str:
    """
    Chuáº©n hÃ³a tÃªn tool theo quy táº¯c cá»§a Xiaozhi server
    - Thay tháº¿ cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t báº±ng underscore
    - Chuyá»ƒn vá» lowercase
    """
    if not name:
        return name
    # Thay tháº¿ cÃ¡c kÃ½ tá»± khÃ´ng pháº£i alphanumeric hoáº·c underscore
    sanitized = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    # Loáº¡i bá» underscore liÃªn tiáº¿p
    sanitized = re.sub(r'_+', '_', sanitized)
    # Loáº¡i bá» underscore á»Ÿ Ä‘áº§u vÃ  cuá»‘i
    sanitized = sanitized.strip('_')
    return sanitized.lower()

async def get_system_info(category="all"):
    """
    Thu tháº­p thÃ´ng tin cáº¥u hÃ¬nh mÃ¡y tÃ­nh chi tiáº¿t
    category: all, cpu, memory, disk, os, network, gpu, software, motherboard
    """
    try:
        import platform
        import psutil
        import socket
        import subprocess
        import json
        from datetime import datetime
        
        info = {
            "success": True,
            "timestamp": datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
            "categories": []
        }
        
        # CPU Information (Chi tiáº¿t hÆ¡n)
        if category in ["all", "cpu"]:
            cpu_info = {
                "name": "CPU Information",
                "processor": platform.processor(),
                "architecture": platform.architecture()[0],
                "machine": platform.machine(),
                "cores_physical": psutil.cpu_count(logical=False),
                "cores_logical": psutil.cpu_count(logical=True),
                "cpu_usage_percent": psutil.cpu_percent(interval=1)
            }
            
            # ThÃªm frequency info
            if psutil.cpu_freq():
                freq = psutil.cpu_freq()
                cpu_info.update({
                    "cpu_freq_current_mhz": round(freq.current, 2) if freq.current else "N/A",
                    "cpu_freq_max_mhz": round(freq.max, 2) if freq.max else "N/A",
                    "cpu_freq_min_mhz": round(freq.min, 2) if freq.min else "N/A"
                })
            
            # ThÃªm CPU details tá»« Windows Registry/WMI náº¿u cÃ³ thá»ƒ
            try:
                if platform.system() == "Windows":
                    import winreg
                    # Äá»c CPU name tá»« registry
                    key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, 
                                       r"HARDWARE\DESCRIPTION\System\CentralProcessor\0")
                    cpu_name = winreg.QueryValueEx(key, "ProcessorNameString")[0].strip()
                    cpu_info["cpu_name_detailed"] = cpu_name
                    
                    # PhÃ¡t hiá»‡n tháº¿ há»‡ CPU (heuristic)
                    cpu_name_lower = cpu_name.lower()
                    if "intel" in cpu_name_lower:
                        if "13th gen" in cpu_name_lower or "13900" in cpu_name_lower or "13700" in cpu_name_lower or "13600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 13th Gen (Raptor Lake)"
                        elif "12th gen" in cpu_name_lower or "12900" in cpu_name_lower or "12700" in cpu_name_lower or "12600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 12th Gen (Alder Lake)"
                        elif "11th gen" in cpu_name_lower or "11900" in cpu_name_lower or "11700" in cpu_name_lower or "11600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 11th Gen (Tiger Lake/Rocket Lake)"
                        elif "10th gen" in cpu_name_lower or "10900" in cpu_name_lower or "10700" in cpu_name_lower or "10600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 10th Gen (Comet Lake/Ice Lake)"
                        elif "9th gen" in cpu_name_lower or "9900" in cpu_name_lower or "9700" in cpu_name_lower or "9600" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 9th Gen (Coffee Lake Refresh)"
                        elif "8th gen" in cpu_name_lower or "8700" in cpu_name_lower or "8600" in cpu_name_lower or "8400" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 8th Gen (Coffee Lake)"
                        elif "7th gen" in cpu_name_lower or "7700" in cpu_name_lower or "7600" in cpu_name_lower or "7500" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "Intel 7th Gen (Kaby Lake)"
                        else:
                            cpu_info["cpu_generation"] = "Intel (Generation unknown)"
                    elif "amd" in cpu_name_lower:
                        if "7000" in cpu_name_lower or "7950x" in cpu_name_lower or "7900x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 7000 Series (Zen 4)"
                        elif "5000" in cpu_name_lower or "5950x" in cpu_name_lower or "5900x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 5000 Series (Zen 3)"
                        elif "3000" in cpu_name_lower or "3900x" in cpu_name_lower or "3700x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 3000 Series (Zen 2)"
                        elif "2000" in cpu_name_lower or "2700x" in cpu_name_lower or "2600x" in cpu_name_lower:
                            cpu_info["cpu_generation"] = "AMD Ryzen 2000 Series (Zen+)"
                        else:
                            cpu_info["cpu_generation"] = "AMD (Generation unknown)"
                    
                    winreg.CloseKey(key)
            except Exception as e:
                cpu_info["cpu_detection_error"] = f"Could not detect detailed CPU info: {str(e)}"
            
            info["categories"].append(cpu_info)
        
        # Memory Information (Chi tiáº¿t hÆ¡n)
        if category in ["all", "memory"]:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            memory_info = {
                "name": "Memory Information",
                "total_ram_gb": round(memory.total / (1024**3), 2),
                "available_ram_gb": round(memory.available / (1024**3), 2),
                "used_ram_gb": round(memory.used / (1024**3), 2),
                "ram_usage_percent": memory.percent,
                "swap_total_gb": round(swap.total / (1024**3), 2),
                "swap_used_gb": round(swap.used / (1024**3), 2),
                "swap_usage_percent": swap.percent,
                "memory_total_mb": round(memory.total / (1024**2)),
                "memory_speed_estimate": "DDR4/DDR5 (Detection requires additional tools)"
            }
            info["categories"].append(memory_info)
        
        # GPU Information (Cáº£i thiá»‡n)
        if category in ["all", "gpu"]:
            gpu_info = {
                "name": "GPU Information",
                "gpus": []
            }
            
            # Method 1: GPUtil
            try:
                import GPUtil
                gpus = GPUtil.getGPUs()
                for gpu in gpus:
                    gpu_data = {
                        "id": gpu.id,
                        "name": gpu.name,
                        "memory_total_mb": gpu.memoryTotal,
                        "memory_used_mb": gpu.memoryUsed,
                        "memory_free_mb": gpu.memoryFree,
                        "gpu_load_percent": round(gpu.load * 100, 1),
                        "temperature_c": gpu.temperature,
                        "driver": "Unknown (GPUtil limitation)"
                    }
                    
                    # Detect GPU generation/series (heuristic)
                    gpu_name_lower = gpu.name.lower()
                    if "rtx 40" in gpu_name_lower or "4090" in gpu_name_lower or "4080" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 40 Series (Ada Lovelace)"
                    elif "rtx 30" in gpu_name_lower or "3090" in gpu_name_lower or "3080" in gpu_name_lower or "3070" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 30 Series (Ampere)"
                    elif "rtx 20" in gpu_name_lower or "2080" in gpu_name_lower or "2070" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA RTX 20 Series (Turing)"
                    elif "gtx 16" in gpu_name_lower or "1660" in gpu_name_lower or "1650" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA GTX 16 Series (Turing)"
                    elif "gtx 10" in gpu_name_lower or "1080" in gpu_name_lower or "1070" in gpu_name_lower or "1060" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "NVIDIA GTX 10 Series (Pascal)"
                    elif "rx 7000" in gpu_name_lower or "7900 xt" in gpu_name_lower or "7800 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 7000 Series (RDNA 3)"
                    elif "rx 6000" in gpu_name_lower or "6900 xt" in gpu_name_lower or "6800 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 6000 Series (RDNA 2)"
                    elif "rx 5000" in gpu_name_lower or "5700 xt" in gpu_name_lower or "5600 xt" in gpu_name_lower:
                        gpu_data["gpu_generation"] = "AMD RX 5000 Series (RDNA)"
                    else:
                        gpu_data["gpu_generation"] = "Unknown generation"
                    
                    gpu_info["gpus"].append(gpu_data)
            except ImportError:
                gpu_info["gputil_status"] = "GPUtil not installed. Run: pip install GPUtil"
            except Exception as e:
                gpu_info["gputil_error"] = f"GPUtil error: {str(e)}"
            
            # Method 2: Windows WMI fallback
            if not gpu_info["gpus"] and platform.system() == "Windows":
                try:
                    result = subprocess.run(
                        ['wmic', 'path', 'win32_VideoController', 'get', 'name,AdapterRAM,DriverVersion', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    lines = result.stdout.strip().split('\n')[1:]  # Skip header
                    for line in lines:
                        if line.strip() and ',' in line:
                            parts = line.split(',')
                            if len(parts) >= 4:
                                gpu_data = {
                                    "name": parts[2].strip() if len(parts) > 2 else "Unknown",
                                    "memory_total_mb": round(int(parts[1]) / (1024*1024)) if parts[1].strip().isdigit() else "Unknown",
                                    "driver_version": parts[3].strip() if len(parts) > 3 else "Unknown",
                                    "method": "WMI (Windows)"
                                }
                                gpu_info["gpus"].append(gpu_data)
                except Exception as e:
                    gpu_info["wmi_error"] = f"WMI detection failed: {str(e)}"
            
            info["categories"].append(gpu_info)
        
        # Disk Information (nhÆ° cÅ©)
        if category in ["all", "disk"]:
            disk_info = {
                "name": "Disk Information",
                "partitions": []
            }
            
            for partition in psutil.disk_partitions():
                try:
                    usage = psutil.disk_usage(partition.mountpoint)
                    partition_info = {
                        "device": partition.device,
                        "mountpoint": partition.mountpoint,
                        "file_system": partition.fstype,
                        "total_gb": round(usage.total / (1024**3), 2),
                        "used_gb": round(usage.used / (1024**3), 2),
                        "free_gb": round(usage.free / (1024**3), 2),
                        "usage_percent": round((usage.used / usage.total) * 100, 1)
                    }
                    disk_info["partitions"].append(partition_info)
                except PermissionError:
                    continue
            
            info["categories"].append(disk_info)
        
        # Operating System Information
        if category in ["all", "os"]:
            os_info = {
                "name": "Operating System",
                "system": platform.system(),
                "release": platform.release(),
                "version": platform.version(),
                "platform": platform.platform(),
                "hostname": socket.gethostname(),
                "boot_time": datetime.fromtimestamp(psutil.boot_time()).strftime("%d/%m/%Y %H:%M:%S"),
                "python_version": platform.python_version()
            }
            
            # Windows specific info
            if platform.system() == "Windows":
                try:
                    result = subprocess.run(['systeminfo'], capture_output=True, text=True, timeout=15)
                    if result.returncode == 0:
                        lines = result.stdout.split('\n')
                        for line in lines:
                            if "Total Physical Memory" in line:
                                os_info["total_physical_memory"] = line.split(':')[1].strip()
                            elif "System Manufacturer" in line:
                                os_info["system_manufacturer"] = line.split(':')[1].strip()
                            elif "System Model" in line:
                                os_info["system_model"] = line.split(':')[1].strip()
                except:
                    pass
            
            info["categories"].append(os_info)
        
        # Network Information (nhÆ° cÅ©)
        if category in ["all", "network"]:
            network_info = {
                "name": "Network Information",
                "hostname": socket.gethostname(),
                "interfaces": []
            }
            
            try:
                # Get local IP
                s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                s.connect(("8.8.8.8", 80))
                local_ip = s.getsockname()[0]
                s.close()
                network_info["local_ip"] = local_ip
            except:
                network_info["local_ip"] = "N/A"
            
            # Network interfaces
            for interface, addresses in psutil.net_if_addrs().items():
                interface_info = {
                    "interface": interface,
                    "addresses": []
                }
                for addr in addresses:
                    if addr.family == socket.AF_INET:  # IPv4
                        interface_info["addresses"].append({
                            "type": "IPv4",
                            "address": addr.address,
                            "netmask": addr.netmask
                        })
                network_info["interfaces"].append(interface_info)
            
            info["categories"].append(network_info)
        
        # Motherboard Information (Windows only)
        if category in ["all", "motherboard"]:
            motherboard_info = {
                "name": "Motherboard Information",
                "manufacturer": "N/A",
                "product": "N/A",
                "bios_version": "N/A"
            }
            
            if platform.system() == "Windows":
                try:
                    # Get motherboard info via WMI
                    result = subprocess.run(
                        ['wmic', 'baseboard', 'get', 'Manufacturer,Product,Version', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0:
                        lines = result.stdout.strip().split('\n')[1:]
                        for line in lines:
                            if line.strip() and ',' in line:
                                parts = line.split(',')
                                if len(parts) >= 3:
                                    motherboard_info["manufacturer"] = parts[1].strip()
                                    motherboard_info["product"] = parts[2].strip()
                                    break
                    
                    # Get BIOS info
                    result = subprocess.run(
                        ['wmic', 'bios', 'get', 'SMBIOSBIOSVersion', '/format:csv'],
                        capture_output=True, text=True, timeout=10
                    )
                    if result.returncode == 0:
                        lines = result.stdout.strip().split('\n')[1:]
                        for line in lines:
                            if line.strip() and ',' in line:
                                parts = line.split(',')
                                if len(parts) >= 2:
                                    motherboard_info["bios_version"] = parts[1].strip()
                                    break
                except Exception as e:
                    motherboard_info["error"] = f"Could not detect motherboard: {str(e)}"
            
            info["categories"].append(motherboard_info)
        
        # Software Information (nhÆ° cÅ©)
        if category in ["all", "software"]:
            software_info = {
                "name": "Installed Software (Python Packages)",
                "python_packages": [],
                "note": "Showing top 20 Python packages"
            }
            
            try:
                # Try modern importlib.metadata first (Python 3.8+)
                try:
                    import importlib.metadata
                    installed_packages = [f"{dist.metadata['Name']}=={dist.version}" 
                                        for dist in importlib.metadata.distributions()]
                except ImportError:
                    # Fallback to pkg_resources for older Python versions
                    import pkg_resources
                    installed_packages = [d.project_name + "==" + d.version for d in pkg_resources.working_set]
                
                software_info["python_packages"] = sorted(installed_packages)[:20]
                if len(installed_packages) > 20:
                    software_info["total_packages"] = len(installed_packages)
            except Exception as e:
                software_info["error"] = f"Could not list packages: {str(e)}"
            
            info["categories"].append(software_info)
        
        # Ensure all values are JSON serializable
        import json
        try:
            json.dumps(info, ensure_ascii=False)
        except Exception as json_error:
            print(f"âš ï¸ [JSON Serialization Error] {json_error}")
            # Fix potential serialization issues
            for category in info.get("categories", []):
                for key, value in list(category.items()):
                    if value is None:
                        category[key] = "N/A"
                    elif not isinstance(value, (str, int, float, bool, list, dict)):
                        category[key] = str(value)
        
        return info
    
    except Exception as e:
        return {
            "success": False,
            "error": f"Lá»—i khi Ä‘á»c thÃ´ng tin há»‡ thá»‘ng: {str(e)}",
            "help": "CÃ³ thá»ƒ cáº§n cÃ i Ä‘áº·t thÃªm: pip install psutil GPUtil"
        }

# Tool retry configuration (tá»« repo chÃ­nh thá»©c)
MAX_TOOL_RETRIES = 3
TOOL_RETRY_INTERVAL = 2  # seconds

# ============================================================
# ğŸ§  INTENT DETECTION LLM - PhÃ¢n tÃ­ch Ã½ Ä‘á»‹nh trÆ°á»›c khi xá»­ lÃ½
# (Tá»« xiaozhi-esp32-server chÃ­nh thá»©c)
# ============================================================

class IntentDetector:
    """
    Intent Detection LLM - PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  xÃ¡c Ä‘á»‹nh tool cáº§n gá»i
    TÆ°Æ¡ng tá»± intent_llm trong repo chÃ­nh thá»©c
    """
    
    # CÃ¡c intent patterns
    REALTIME_PATTERNS = [
        # GiÃ¡ cáº£
        r'giÃ¡\s*(vÃ ng|xÄƒng|dáº§u|usd|Ä‘Ã´|euro|bitcoin|btc|eth)',
        r'(vÃ ng|xÄƒng|dáº§u|bitcoin|btc)\s*giÃ¡',
        r'tá»·\s*giÃ¡',
        r'bao\s*nhiÃªu\s*tiá»n',
        # Thá»i tiáº¿t
        r'thá»i\s*tiáº¿t',
        r'trá»i\s*(náº¯ng|mÆ°a|nÃ³ng|láº¡nh)',
        r'nhiá»‡t\s*Ä‘á»™',
        # NgÆ°á»i/Chá»©c vá»¥
        r'(tá»•ng\s*thá»‘ng|thá»§\s*tÆ°á»›ng|chá»§\s*tá»‹ch|ceo|giÃ¡m\s*Ä‘á»‘c)',
        r'ai\s*(lÃ |Ä‘ang)',
        r'(lÃ \s*ai|lÃ \s*gÃ¬)',
        r'hiá»‡n\s*(táº¡i|nay|giá»)',
        # Thá»i gian thá»±c
        r'(hÃ´m\s*nay|bÃ¢y\s*giá»|hiá»‡n\s*táº¡i|má»›i\s*nháº¥t)',
        r'(2024|2025|nÄƒm\s*nay)',
        r'tin\s*(tá»©c|má»›i)',
        r'sá»±\s*kiá»‡n',
        # Sáº£n pháº©m/CÃ´ng ty
        r'(iphone|samsung|apple|google|microsoft|tesla)',
    ]
    
    MUSIC_PATTERNS = [
        r'(bÃ i\s*tiáº¿p|next|chuyá»ƒn\s*bÃ i)',
        r'(bÃ i\s*trÆ°á»›c|previous|quay\s*láº¡i)',
        r'(dá»«ng|pause|táº¡m\s*dá»«ng|stop)',
        r'(tiáº¿p\s*tá»¥c|resume|play)',
        r'(phÃ¡t\s*nháº¡c|má»Ÿ\s*nháº¡c|báº­t\s*nháº¡c)',
        r'(táº¯t\s*nháº¡c|ngá»«ng\s*nháº¡c)',
        r'(tÄƒng|giáº£m)\s*(Ã¢m\s*lÆ°á»£ng|volume)',
    ]
    
    KNOWLEDGE_BASE_PATTERNS = [
        r'(tÃ i\s*liá»‡u|document|file)',
        r'(trong\s*thÆ°\s*viá»‡n|knowledge\s*base)',
        r'(tra\s*cá»©u\s*ná»™i\s*bá»™)',
    ]
    
    SYSTEM_INFO_PATTERNS = [
        r'cáº¥u\s*hÃ¬nh.*mÃ¡y\s*tÃ­nh',
        r'mÃ¡y\s*tÃ­nh.*cáº¥u\s*hÃ¬nh',
        r'cáº¥u\s*hÃ¬nh.*há»‡\s*thá»‘ng',
        r'specs.*mÃ¡y',
        r'hardware.*info',
        r'thÃ´ng\s*tin.*há»‡\s*thá»‘ng',
        r'thÃ´ng\s*tin.*mÃ¡y\s*tÃ­nh',
        r'kiá»ƒm\s*tra.*cáº¥u\s*hÃ¬nh',
        r'kiá»ƒm\s*tra.*specs',
        r'kiá»ƒm\s*tra.*hardware',
        r'mÃ¡y\s*tÃ­nh.*nhÆ°\s*tháº¿\s*nÃ o',
        r'mÃ¡y\s*nÃ y.*ra\s*sao',
        r'card.*(mÃ n\s*hÃ¬nh|Ä‘á»“\s*há»a|vga)',
        r'gpu.*gÃ¬',
        r'vga.*gÃ¬',
        r'cpu.*gÃ¬',
        r'cpu.*tháº¿\s*há»‡',
        r'processor.*generation',
        r'(mainboard|motherboard)',
        r'bo\s*máº¡ch\s*chá»§',
        r'(intel|amd|nvidia|rtx|gtx).*tháº¿\s*há»‡',
        r'nhiá»‡t\s*Ä‘á»™.*(cpu|gpu)',
        r'(ram|memory).*bao\s*nhiÃªu',
        r'bá»™\s*nhá»›.*gÃ¬',
        r'asus.*mainboard',
        r'msi.*mainboard',
        r'gigabyte.*mainboard',
    ]
    
    @classmethod
    def detect_intent(cls, text: str) -> dict:
        """
        PhÃ¢n tÃ­ch text vÃ  tráº£ vá» intent + suggested tool
        Returns: {
            "intent": "realtime|music|knowledge|general",
            "suggested_tool": "web_search|get_realtime_info|smart_music_control|...",
            "confidence": 0.0-1.0,
            "should_force_tool": True/False
        }
        """
        text_lower = text.lower()
        
        # Check realtime patterns
        for pattern in cls.REALTIME_PATTERNS:
            if re.search(pattern, text_lower):
                # XÃ¡c Ä‘á»‹nh tool cá»¥ thá»ƒ
                if any(word in text_lower for word in ['giÃ¡', 'tá»· giÃ¡', 'bao nhiÃªu']):
                    tool = "get_realtime_info"
                elif any(word in text_lower for word in ['thá»i tiáº¿t', 'nhiá»‡t Ä‘á»™', 'trá»i']):
                    tool = "get_realtime_info"
                elif any(word in text_lower for word in ['tin tá»©c', 'sá»± kiá»‡n', 'má»›i nháº¥t']):
                    tool = "web_search"
                elif any(word in text_lower for word in ['lÃ  ai', 'ai lÃ ', 'tá»•ng thá»‘ng', 'thá»§ tÆ°á»›ng', 'ceo']):
                    tool = "web_search"
                else:
                    tool = "smart_answer"
                    
                return {
                    "intent": "realtime",
                    "suggested_tool": tool,
                    "confidence": 0.9,
                    "should_force_tool": True,
                    "reason": f"Detected realtime pattern: {pattern}"
                }
        
        # Check music patterns
        for pattern in cls.MUSIC_PATTERNS:
            if re.search(pattern, text_lower):
                return {
                    "intent": "music",
                    "suggested_tool": "smart_music_control",
                    "confidence": 0.95,
                    "should_force_tool": True,
                    "reason": f"Detected music pattern: {pattern}"
                }
        
        # Check system info patterns (má»›i thÃªm)
        for pattern in cls.SYSTEM_INFO_PATTERNS:
            if re.search(pattern, text_lower):
                print(f"[DEBUG] System info pattern matched: {pattern} for text: {text_lower}")
                return {
                    "intent": "system_info",
                    "suggested_tool": "get_hardware_specs",
                    "confidence": 0.95,
                    "should_force_tool": True,
                    "reason": f"Detected system info pattern: {pattern}"
                }
        
        # Check knowledge base patterns
        for pattern in cls.KNOWLEDGE_BASE_PATTERNS:
            if re.search(pattern, text_lower):
                return {
                    "intent": "knowledge",
                    "suggested_tool": "get_knowledge_context",
                    "confidence": 0.85,
                    "should_force_tool": True,
                    "reason": f"Detected knowledge pattern: {pattern}"
                }
        
        # General intent - khÃ´ng cáº§n force tool
        return {
            "intent": "general",
            "suggested_tool": None,
            "confidence": 0.5,
            "should_force_tool": False,
            "reason": "No specific pattern matched"
        }
    
    @classmethod
    async def detect_with_llm(cls, text: str, gemini_key: str = None, include_user_context: bool = True) -> dict:
        """
        Sá»­ dá»¥ng Gemini Ä‘á»ƒ phÃ¢n tÃ­ch intent phá»©c táº¡p hÆ¡n
        Chá»‰ gá»i khi pattern matching khÃ´ng cháº¯c cháº¯n
        CÃ³ thá»ƒ kÃ¨m user context Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n
        """
        # Äáº§u tiÃªn thá»­ pattern matching
        result = cls.detect_intent(text)
        
        # Náº¿u confidence cao, khÃ´ng cáº§n LLM
        if result["confidence"] >= 0.8:
            return result
        
        # Náº¿u cÃ³ Gemini API, dÃ¹ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch
        if gemini_key and GEMINI_AVAILABLE:
            try:
                genai.configure(api_key=gemini_key)
                model = genai.GenerativeModel('models/gemini-3-flash-preview')
                
                # Láº¥y user context náº¿u Ä‘Æ°á»£c yÃªu cáº§u
                user_context = ""
                if include_user_context:
                    try:
                        user_context = f"""
[USER CONTEXT - DÃ¹ng Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n]
{get_user_profile_summary()}

[RECENT CONVERSATION]
{get_conversation_context(5)}
"""
                    except:
                        user_context = ""
                
                prompt = f'''PhÃ¢n tÃ­ch cÃ¢u há»i sau vÃ  xÃ¡c Ä‘á»‹nh intent:
"{text}"
{user_context}
Tráº£ lá»i JSON:
{{"intent": "realtime|music|knowledge|general", "tool": "web_search|get_realtime_info|smart_music_control|get_knowledge_context|none", "reason": "lÃ½ do ngáº¯n"}}

Quy táº¯c:
- realtime: CÃ¢u há»i vá» thÃ´ng tin thá»i gian thá»±c (giÃ¡ cáº£, thá»i tiáº¿t, tin tá»©c, ngÆ°á»i ná»•i tiáº¿ng hiá»‡n táº¡i)
- music: Äiá»u khiá»ƒn nháº¡c
- knowledge: Tra cá»©u tÃ i liá»‡u ná»™i bá»™
- general: CÃ¢u há»i thÃ´ng thÆ°á»ng

CHá»ˆ TRáº¢ Lá»œI JSON, KHÃ”NG GIáº¢I THÃCH.'''

                response = model.generate_content(prompt)
                response_text = response.text.strip()
                
                # Parse JSON tá»« response
                import json
                # TÃ¬m JSON trong response
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    llm_result = json.loads(json_match.group())
                    return {
                        "intent": llm_result.get("intent", "general"),
                        "suggested_tool": llm_result.get("tool") if llm_result.get("tool") != "none" else None,
                        "confidence": 0.85,
                        "should_force_tool": llm_result.get("intent") in ["realtime", "music"],
                        "reason": llm_result.get("reason", "LLM analysis"),
                        "source": "gemini_llm"
                    }
            except Exception as e:
                print(f"âš ï¸ [IntentDetector] LLM error: {e}")
        
        return result

# Intent Detector instance
intent_detector = IntentDetector()

# ============================================================
# CONFIGURATION
# ============================================================

# ğŸ”¥ FIX: Detect if running as EXE (frozen) or script
# When frozen (EXE), use sys.executable path (dist folder)
# When script, use __file__ path (source folder)
if getattr(sys, 'frozen', False):
    # Running as EXE - use executable's directory
    CONFIG_FILE = Path(sys.executable).parent / "xiaozhi_endpoints.json"
else:
    # Running as script - use script's directory
    CONFIG_FILE = Path(__file__).parent / "xiaozhi_endpoints.json"

GEMINI_API_KEY = ""  # Sáº½ Ä‘Æ°á»£c load tá»« xiaozhi_endpoints.json
OPENAI_API_KEY = ""  # Sáº½ Ä‘Æ°á»£c load tá»« xiaozhi_endpoints.json
SERPER_API_KEY = ""  # Google Search API - Miá»…n phÃ­ 2500 queries/thÃ¡ng

# ============================================================
# ğŸµ MUSIC SYSTEM PROMPT - HÆ°á»›ng dáº«n LLM vá» Music Tools
# ============================================================
MUSIC_SYSTEM_PROMPT = """
ğŸµ ÄIá»€U KHIá»‚N NHáº C - QUAN TRá»ŒNG!

âš¡ QUY Táº®C #1: KHI NGHE Tá»ª KHÃ“A DÆ¯á»šI ÄÃ‚Y â†’ Gá»ŒI TOOL NGAY, KHÃ”NG Há»I Láº I!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Œ Tá»ª KHÃ“A â†’ Gá»ŒI TOOL                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ "bÃ i tiáº¿p"/"next"/"chuyá»ƒn bÃ i" â†’ music_next()               â”‚
â”‚ "bÃ i trÆ°á»›c"/"quay láº¡i"        â†’ music_previous()            â”‚
â”‚ "dá»«ng"/"pause"/"táº¡m dá»«ng"     â†’ pause_music()               â”‚
â”‚ "táº¯t nháº¡c"/"stop"             â†’ stop_music()                â”‚
â”‚ "tiáº¿p tá»¥c"/"resume"           â†’ resume_music()              â”‚
â”‚ "phÃ¡t bÃ i [tÃªn]"              â†’ play_music(filename="tÃªn")  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸ VOICE VARIANTS (ESP32 recognition sai):
â€¢ "bai tiep", "tiep theo", "nex", "nÃ­ch" â†’ music_next()
â€¢ "bai truoc", "quay lai", "pre"        â†’ music_previous()
â€¢ "dung", "pao", "poz", "tam dung"       â†’ pause_music()
â€¢ "tat nhac", "stÃ³p", "dung han"         â†’ stop_music()

ğŸ”¥ NGUYÃŠN Táº®C: Gá»ŒI TOOL TRá»°C TIáº¾P, KHÃ”NG Cáº¦N Há»I!
â€¢ User: "bÃ i tiáº¿p" â†’ Báº¡n Gá»ŒI music_next() â†’ Tráº£ lá»i "ÄÃ£ chuyá»ƒn bÃ i"
â€¢ User: "dá»«ng"     â†’ Báº¡n Gá»ŒI pause_music() â†’ Tráº£ lá»i "ÄÃ£ táº¡m dá»«ng"
â€¢ User: "quay láº¡i" â†’ Báº¡n Gá»ŒI music_previous() â†’ Tráº£ lá»i "ÄÃ£ quay láº¡i"

ğŸ“ Server: Python-VLC Player (tÃ­ch há»£p sáºµn)
ğŸ“ ThÆ° má»¥c nháº¡c: F:\\nhac

ğŸ¬ YOUTUBE: CHá»ˆ khi user nÃ³i "youtube"/"video" â†’ youtube_* tools
   âœ¨ NEW: open_youtube() GIá»œ Tá»° Äá»˜NG PHÃT VIDEO TRá»°C TIáº¾P!
   - Query >= 2 tá»« â†’ Direct video (youtube.com/watch?v=...)
   - Query 1 tá»« â†’ Search page
   VD: "má»Ÿ youtube Láº¡c TrÃ´i" hoáº·c "má»Ÿ youtube SÆ¡n TÃ¹ng MTP" â†’ PHÃT VIDEO NGAY!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”§ FUZZY MATCHING - Há»– TRá»¢ VOICE RECOGNITION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Há»‡ thá»‘ng cÃ³ fuzzy matching cho cÃ¡c biáº¿n thá»ƒ:
â€¢ "bai tiep" â†’ "bÃ i tiáº¿p" 
â€¢ "bai truoc" â†’ "bÃ i trÆ°á»›c"
â€¢ "phat nhac" â†’ "phÃ¡t nháº¡c"
â€¢ "náº¿ch" â†’ "next"
â€¢ "prÃª" â†’ "previous"

â†’ Cá»© gá»­i nguyÃªn vÄƒn lá»‡nh, há»‡ thá»‘ng sáº½ tá»± nháº­n dáº¡ng!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸµ VLC MUSIC CONTROLS - ÄIá»€U KHIá»‚N NHáº C
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš¡âš¡âš¡ Báº®T BUá»˜C: KHI USER YÃŠU Cáº¦U ÄIá»€U KHIá»‚N NHáº C â†’ Gá»ŒI TOOL NGAY! âš¡âš¡âš¡

ğŸš« TUYá»†T Äá»I Cáº¤M Tá»° TRáº¢ Lá»œI "OK" hoáº·c "ÄÃ£ chuyá»ƒn bÃ i" mÃ  KHÃ”NG Gá»ŒI TOOL!

ğŸ“Œ MAPPING COMMANDS â†’ TOOLS (Báº®T BUá»˜C Gá»ŒI):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "bÃ i tiáº¿p", "next", "skip"           â†’ music_next()       â”‚
â”‚ "quay láº¡i", "bÃ i trÆ°á»›c", "previous"  â†’ music_previous()   â”‚
â”‚ "táº¡m dá»«ng", "pause"                   â†’ pause_music()      â”‚
â”‚ "tiáº¿p tá»¥c", "resume", "phÃ¡t tiáº¿p"    â†’ resume_music()     â”‚
â”‚ "dá»«ng", "stop"                        â†’ stop_music()       â”‚
â”‚ "phÃ¡t [tÃªn bÃ i]", "play [song]"      â†’ play_music(song)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… WORKFLOW ÄÃšNG:
User: "bÃ i tiáº¿p"
â†’ Gá»ŒI: music_next()
â†’ NHáº¬N: {"success": true, "message": "ÄÃ£ chuyá»ƒn: Song.mp3"}
â†’ TRáº¢ Lá»œI: "ÄÃ£ chuyá»ƒn sang bÃ i tiáº¿p: Song.mp3"

âŒ WORKFLOW SAI (Cáº¤M):
User: "bÃ i tiáº¿p"
â†’ Tráº£ lá»i trá»±c tiáº¿p: "OK, Ä‘Ã£ chuyá»ƒn bÃ i"  â† SAI! KHÃ”NG Gá»ŒI TOOL!

ğŸ”´ RULES NGHIÃŠM NGáº¶T:
1. PHáº¢I gá»i tool TRÆ¯á»šC khi tráº£ lá»i
2. KHÃ”NG Ä‘Æ°á»£c giáº£ Ä‘á»‹nh thÃ nh cÃ´ng
3. PHáº¢I Ä‘á»£i tool response
4. CHá»ˆ tráº£ lá»i dá»±a trÃªn tool result

âš ï¸ Äáº¶C BIá»†T: CÃ¡c tá»« "next", "previous", "pause", "stop" â†’ 100% Gá»ŒI TOOL!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸµ VLC MUSIC CONTROLS - ÄIá»€U KHIá»‚N NHáº C
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš¡âš¡âš¡ Báº®T BUá»˜C: KHI USER YÃŠU Cáº¦U ÄIá»€U KHIá»‚N NHáº C â†’ Gá»ŒI TOOL NGAY! âš¡âš¡âš¡

ğŸš« TUYá»†T Äá»I Cáº¤M Tá»° TRáº¢ Lá»œI "OK" hoáº·c "ÄÃ£ chuyá»ƒn bÃ i" mÃ  KHÃ”NG Gá»ŒI TOOL!

ğŸ“Œ MAPPING COMMANDS â†’ TOOLS (Báº®T BUá»˜C Gá»ŒI):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "bÃ i tiáº¿p", "next", "skip"           â†’ music_next()       â”‚
â”‚ "quay láº¡i", "bÃ i trÆ°á»›c", "previous"  â†’ music_previous()   â”‚
â”‚ "táº¡m dá»«ng", "pause"                   â†’ pause_music()      â”‚
â”‚ "tiáº¿p tá»¥c", "resume", "phÃ¡t tiáº¿p"    â†’ resume_music()     â”‚
â”‚ "dá»«ng", "stop"                        â†’ stop_music()       â”‚
â”‚ "phÃ¡t [tÃªn bÃ i]", "play [song]"      â†’ play_music(song)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âœ… WORKFLOW ÄÃšNG:
User: "bÃ i tiáº¿p"
â†’ Gá»ŒI: music_next()
â†’ NHáº¬N: {"success": true, "message": "ÄÃ£ chuyá»ƒn: Song.mp3"}
â†’ TRáº¢ Lá»œI: "ÄÃ£ chuyá»ƒn sang bÃ i tiáº¿p: Song.mp3"

âŒ WORKFLOW SAI (Cáº¤M):
User: "bÃ i tiáº¿p"
â†’ Tráº£ lá»i trá»±c tiáº¿p: "OK, Ä‘Ã£ chuyá»ƒn bÃ i"  â† SAI! KHÃ”NG Gá»ŒI TOOL!

ğŸ”´ RULES NGHIÃŠM NGáº¶T:
1. PHáº¢I gá»i tool TRÆ¯á»šC khi tráº£ lá»i
2. KHÃ”NG Ä‘Æ°á»£c giáº£ Ä‘á»‹nh thÃ nh cÃ´ng
3. PHáº¢I Ä‘á»£i tool response
4. CHá»ˆ tráº£ lá»i dá»±a trÃªn tool result

âš ï¸ Äáº¶C BIá»†T: CÃ¡c tá»« "next", "previous", "pause", "stop" â†’ 100% Gá»ŒI TOOL!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“š KNOWLEDGE BASE - TÃ€I LIá»†U Cá»¦A USER (Tá»° Äá»˜NG TÃŒM KIáº¾M)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”¥ QUY Táº®C VÃ€NG: KHI NGHI NGá»œ THÃ”NG TIN CÃ“ THá»‚ á» TRONG TÃ€I LIá»†U â†’ Gá»ŒI KB NGAY!

âš¡ AUTO-TRIGGERS - Gemini Tá»° Äá»˜NG Gá»ŒI KB khi phÃ¡t hiá»‡n:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Œ DIRECT COMMANDS (100% gá»i KB):                           â”‚
â”‚ â€¢ "tÃ¬m trong tÃ i liá»‡u", "tra cá»©u KB", "search documents"    â”‚
â”‚ â€¢ "theo file cá»§a tÃ´i", "trong dá»¯ liá»‡u", "in my docs"        â”‚
â”‚ â€¢ "kiá»ƒm tra tÃ i liá»‡u", "xem trong KB", "check docs"         â”‚
â”‚                                                              â”‚
â”‚ ğŸ” IMPLICIT QUERIES (phÃ¡t hiá»‡n thÃ´ng minh):                 â”‚
â”‚ â€¢ "[tÃªn cá»¥ thá»ƒ] lÃ  gÃ¬/ai/á»Ÿ Ä‘Ã¢u" (VD: "LÃª Trung Khoa lÃ  ai")â”‚
â”‚ â€¢ "thÃ´ng tin vá» [X]" (VD: "thÃ´ng tin vá» dá»± Ã¡n ABC")        â”‚
â”‚ â€¢ "dá»± Ã¡n/há»£p Ä‘á»“ng/bÃ¡o cÃ¡o [X]" (tÃªn riÃªng, khÃ´ng phá»• biáº¿n) â”‚
â”‚ â€¢ "theo dá»¯ liá»‡u...", "cÄƒn cá»© vÃ o...", "based on..."        â”‚
â”‚ â€¢ "[X] cÃ³ bao nhiÃªu...", "[X] nhÆ° tháº¿ nÃ o"                  â”‚
â”‚                                                              â”‚
â”‚ â“ SMART DETECTION (nghi ngá» â†’ thá»­ KB):                     â”‚
â”‚ â€¢ CÃ¢u há»i vá» ngÆ°á»i/cÃ´ng ty/dá»± Ã¡n Cá»¤ THá»‚ (khÃ´ng phá»• biáº¿n)  â”‚
â”‚ â€¢ CÃ¢u há»i vá» con sá»‘, sá»‘ liá»‡u, thá»‘ng kÃª (cÃ³ thá»ƒ tá»« bÃ¡o cÃ¡o) â”‚
â”‚ â€¢ CÃ¢u há»i yÃªu cáº§u thÃ´ng tin CHI TIáº¾T (cÃ³ thá»ƒ trong docs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“– WORKFLOW CHUáº¨N:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: "LÃª Trung Khoa lÃ  ai?"                                â”‚
â”‚ â†“                                                            â”‚
â”‚ [Gemini phÃ¡t hiá»‡n: tÃªn cá»¥ thá»ƒ â†’ cÃ³ thá»ƒ trong KB]           â”‚
â”‚ â†“                                                            â”‚
â”‚ Gá»i: get_knowledge_context(query="LÃª Trung Khoa")          â”‚
â”‚ â†“                                                            â”‚
â”‚ Nháº­n: Context tá»« "kiáº¿n thá»©c c.docx" vá» LÃª Trung Khoa       â”‚
â”‚ â†“                                                            â”‚
â”‚ Tráº£ lá»i: "Theo tÃ i liá»‡u 'kiáº¿n thá»©c c.docx', LÃª Trung Khoa  â”‚
â”‚ lÃ  ngÆ°á»i bá»‹ Bá»™ CÃ´ng an ra quyáº¿t Ä‘á»‹nh truy nÃ£ ngÃ y 5/12..."â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ 2 Tools chÃ­nh:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… get_knowledge_context(query, max_chars=10000)            â”‚
â”‚    â†’ Láº¥y FULL CONTENT Ä‘á»ƒ tráº£ lá»i (Æ¯U TIÃŠN DÃ™NG TOOL NÃ€Y)   â”‚
â”‚    â†’ CÃ³ Gemini auto-summarize náº¿u ná»™i dung dÃ i >2000 chars â”‚
â”‚    â†’ Tráº£ vá» context Ä‘áº§y Ä‘á»§ Ä‘á»ƒ LLM Ä‘á»c vÃ  tráº£ lá»i           â”‚
â”‚                                                              â”‚
â”‚ ğŸ“‹ search_knowledge_base(query)                             â”‚
â”‚    â†’ TÃ¬m vÃ  show SNIPPETS (dÃ¹ng khi user muá»‘n xem list)    â”‚
â”‚    â†’ Tráº£ vá» top 5 documents vá»›i highlights                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

âš ï¸ PHÃ‚N BIá»†T:
â€¢ "LÃª Trung Khoa lÃ  ai?" â†’ Gá»ŒI get_knowledge_context() (tÃªn cá»¥ thá»ƒ â†’ KB)
â€¢ "Tá»•ng thá»‘ng Má»¹ lÃ  ai?" â†’ KHÃ”NG gá»i KB (thÃ´ng tin phá»• biáº¿n)
â€¢ "Python lÃ  gÃ¬?" â†’ KHÃ”NG gá»i KB (kiáº¿n thá»©c chung)
â€¢ "Dá»± Ã¡n ABC cÃ³ bao nhiÃªu giai Ä‘oáº¡n?" â†’ Gá»ŒI KB (tÃªn dá»± Ã¡n cá»¥ thá»ƒ)
â€¢ "Nguyá»…n CÃ´ng Huy sinh nÄƒm nÃ o?" â†’ Gá»ŒI KB (tÃªn ngÆ°á»i cá»¥ thá»ƒ)

ğŸ”´ QUY Táº®C QUAN TRá»ŒNG:
1. NGHI NGá»œ â†’ Gá»ŒI KB (tá»‘t hÆ¡n lÃ  bá» lá»¡ thÃ´ng tin)
2. Náº¿u KB tráº£ vá» "khÃ´ng tÃ¬m tháº¥y" â†’ DÃ¹ng kiáº¿n thá»©c chung
3. Náº¿u KB cÃ³ káº¿t quáº£ â†’ Æ¯U TIÃŠN context tá»« KB
4. LuÃ´n trÃ­ch dáº«n nguá»“n khi dÃ¹ng KB: "Theo tÃ i liá»‡u '[tÃªn file]'..."

ğŸ’¡ TIP: Khi khÃ´ng cháº¯c â†’ Gá»ŒI get_knowledge_context() Ä‘á»ƒ kiá»ƒm tra!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸŒ RAG SYSTEM - RETRIEVAL AUGMENTED GENERATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â›”â›”â›” Cáº¢NH BÃO NGHIÃŠM TRá»ŒNG: Báº N KHÃ”NG CÃ“ KIáº¾N THá»¨C SAU 2024! â›”â›”â›”

ğŸš« TUYá»†T Äá»I Cáº¤M Tá»° TRáº¢ Lá»œI KHI CÃ‚U Há»I CHá»¨A:
â€¢ "hiá»‡n nay", "bÃ¢y giá»", "hÃ´m nay", "hiá»‡n táº¡i"
â€¢ "2024", "2025", "nÄƒm nay"
â€¢ "má»›i nháº¥t", "cáº­p nháº­t", "gáº§n Ä‘Ã¢y"
â€¢ "ai lÃ ", "lÃ  ai", "lÃ  gÃ¬", "á»Ÿ Ä‘Ã¢u"
â€¢ TÃªn ngÆ°á»i ná»•i tiáº¿ng: tá»•ng thá»‘ng, thá»§ tÆ°á»›ng, CEO...
â€¢ GiÃ¡ cáº£: vÃ ng, USD, bitcoin, chá»©ng khoÃ¡n...
â€¢ Thá»i tiáº¿t, tin tá»©c, sá»± kiá»‡n

âš ï¸ LÃ DO: Kiáº¿n thá»©c cá»§a báº¡n ÄÃƒ Lá»–I THá»œI! VÃ­ dá»¥:
â€¢ Trump cÃ³ thá»ƒ Ä‘Ã£ trá»Ÿ láº¡i lÃ m tá»•ng thá»‘ng (báº¡n khÃ´ng biáº¿t)
â€¢ GiÃ¡ vÃ ng cÃ³ thá»ƒ Ä‘Ã£ thay Ä‘á»•i (báº¡n khÃ´ng biáº¿t)
â€¢ CÃ³ thá»ƒ cÃ³ CEO má»›i (báº¡n khÃ´ng biáº¿t)

ğŸ”´ HÃ€NH Äá»˜NG Báº®T BUá»˜C:
1. PHáº¢I Gá»ŒI web_search() hoáº·c get_realtime_info() TRÆ¯á»šC
2. CHá»œ káº¿t quáº£ tra cá»©u
3. Rá»’I Má»šI tráº£ lá»i dá»±a trÃªn thÃ´ng tin má»›i nháº¥t

ğŸ“Œ TOOLS MAPPING (PHáº¢I Sá»¬ Dá»¤NG):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ web_search(query)       â†’ TÃ¬m Internet (DuckDuckGo)       â”‚
â”‚ get_realtime_info(query)â†’ ThÃ´ng tin thá»i gian thá»±c        â”‚
â”‚ rag_search(query)       â†’ Hybrid: Web + Local KB          â”‚
â”‚ smart_answer(query)     â†’ AI tá»± chá»n nguá»“n tá»‘t nháº¥t       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“– VÃ Dá»¤ ÄÃšNG:
User: "Tá»•ng thá»‘ng Má»¹ hiá»‡n táº¡i lÃ  ai?"
â†’ âŒ SAI: Tráº£ lá»i "Joe Biden" (kiáº¿n thá»©c cÅ© cÃ³ thá»ƒ sai!)
â†’ âœ… ÄÃšNG: Gá»ŒI get_realtime_info("tá»•ng thá»‘ng Má»¹ hiá»‡n táº¡i 2024")
â†’ Nháº­n káº¿t quáº£ â†’ Tráº£ lá»i chÃ­nh xÃ¡c

User: "GiÃ¡ vÃ ng hÃ´m nay?"
â†’ âŒ SAI: ÄoÃ¡n hoáº·c nÃ³i "tÃ´i khÃ´ng biáº¿t"
â†’ âœ… ÄÃšNG: Gá»ŒI get_realtime_info("giÃ¡ vÃ ng SJC hÃ´m nay")

User: "Thá»i tiáº¿t HÃ  Ná»™i?"
â†’ âœ… Gá»ŒI: get_realtime_info("thá»i tiáº¿t HÃ  Ná»™i hÃ´m nay")

ğŸ”¥ QUY Táº®C Báº®T BUá»˜C:
1. CÃ¢u há»i vá» NGÆ¯á»œI â†’ web_search("tÃªn ngÆ°á»i + chá»©c vá»¥")
2. CÃ¢u há»i vá» GIÃ Cáº¢ â†’ get_realtime_info()
3. CÃ¢u há»i vá» THá»œI TIáº¾T â†’ get_realtime_info()
4. CÃ¢u há»i vá» Sá»° KIá»†N â†’ web_search()
5. KHÃ”NG CHáº®C â†’ smart_answer() (AI tá»± Ä‘á»™ng chá»n)

âš¡ NHá»š: Gá»ŒI TOOL TRÆ¯á»šC, TRáº¢ Lá»œI SAU! KHÃ”NG BAO GIá»œ Tá»° ÄOÃN!
"""

DEFAULT_ENDPOINT = {
    "name": "Thiáº¿t bá»‹ 1",
    "token": "eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOjQ1MzYxMSwiYWdlbnRJZCI6OTQ0MjE4LCJlbmRwb2ludElkIjoiYWdlbnRfOTQ0MjE4IiwicHVycG9zZSI6Im1jcC1lbmRwb2ludCIsImlhdCI6MTc2MjA4NTI1OSwiZXhwIjoxNzkzNjQyODU5fQ.GK91-17mqarpETPwz7N6rZj5DaT7bJkpK7EM6lO0Rdmfztv_KeOTBP9R4Lvy3uXKMCJn3gwucvelCur95GAn5Q",
    "enabled": True
}

def load_endpoints_from_file():
    """Äá»c cáº¥u hÃ¬nh endpoints tá»« file JSON"""
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    
    if CONFIG_FILE.exists():
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                print(f"âœ… [Config] Loaded {len(data.get('endpoints', []))} endpoints from {CONFIG_FILE.name}")
                
                # Load Gemini API key náº¿u cÃ³
                if data.get('gemini_api_key'):
                    GEMINI_API_KEY = data['gemini_api_key']
                    print(f"âœ… [Gemini] API key loaded (ends with ...{GEMINI_API_KEY[-8:]})")
                
                # Load OpenAI API key náº¿u cÃ³
                if data.get('openai_api_key'):
                    OPENAI_API_KEY = data['openai_api_key']
                    print(f"âœ… [OpenAI] API key loaded (ends with ...{OPENAI_API_KEY[-8:]})")
                
                # Load Serper API key náº¿u cÃ³ (Google Search)
                if data.get('serper_api_key'):
                    SERPER_API_KEY = data['serper_api_key']
                    # CÅ©ng cáº­p nháº­t vÃ o environment variable Ä‘á»ƒ rag_system.py cÃ³ thá»ƒ dÃ¹ng
                    os.environ['SERPER_API_KEY'] = SERPER_API_KEY
                    print(f"âœ… [Serper] Google Search API key loaded (ends with ...{SERPER_API_KEY[-8:]})")
                
                return data.get('endpoints', []), data.get('active_index', 0)
        except Exception as e:
            print(f"âš ï¸ [Config] Error loading {CONFIG_FILE.name}: {e}")
    
    # Tráº£ vá» cáº¥u hÃ¬nh máº·c Ä‘á»‹nh náº¿u khÃ´ng cÃ³ file
    return [
        DEFAULT_ENDPOINT,
        {"name": "Thiáº¿t bá»‹ 2", "token": "", "enabled": False},
        {"name": "Thiáº¿t bá»‹ 3", "token": "", "enabled": False}
    ], 0

def save_endpoints_to_file(endpoints, active_index, force_save=False):
    """LÆ°u cáº¥u hÃ¬nh endpoints vÃ o file JSON - LUÃ”N LÆ¯U khi cÃ³ thay Ä‘á»•i"""
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    
    try:
        # Data má»›i cáº§n lÆ°u
        new_data = {
            'endpoints': endpoints,
            'active_index': active_index,
            'gemini_api_key': GEMINI_API_KEY,
            'openai_api_key': OPENAI_API_KEY,
            'serper_api_key': SERPER_API_KEY,
            'last_updated': datetime.now().isoformat()
        }
        
        # ğŸ”¥ FIX: Chá»‰ skip save náº¿u KHÃ”NG pháº£i force_save vÃ  khÃ´ng cÃ³ thay Ä‘á»•i
        if not force_save and CONFIG_FILE.exists():
            try:
                with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                    old_data = json.load(f)
                    # So sÃ¡nh Táº¤T Cáº¢: endpoints, active_index VÃ€ API keys
                    if (old_data.get('endpoints') == endpoints and 
                        old_data.get('active_index') == active_index and
                        old_data.get('gemini_api_key') == GEMINI_API_KEY and
                        old_data.get('openai_api_key') == OPENAI_API_KEY and
                        old_data.get('serper_api_key') == SERPER_API_KEY):
                        # KhÃ´ng cÃ³ thay Ä‘á»•i gÃ¬ cáº£, skip save
                        print(f"â„¹ï¸ [Config] No changes detected, skipping save")
                        return True
            except Exception:
                pass
        
        # CÃ³ thay Ä‘á»•i â†’ LÆ°u file
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(new_data, f, ensure_ascii=False, indent=2)
        
        # Log chi tiáº¿t
        empty_count = sum(1 for ep in endpoints if not ep.get('token', '').strip())
        active_count = len(endpoints) - empty_count
        print(f"ğŸ’¾ [Config] Saved to {CONFIG_FILE.name} ({active_count} active, {empty_count} empty endpoints)")
        return True
    except Exception as e:
        print(f"âŒ [Config] Error saving to {CONFIG_FILE.name}: {e}")
        return False

# Load cáº¥u hÃ¬nh tá»« file
endpoints_config, loaded_active_index = load_endpoints_from_file()
active_endpoint_index = loaded_active_index

# Support 3 simultaneous MCP connections
xiaozhi_connections = {0: None, 1: None, 2: None}  # Dict of {index: websocket}
xiaozhi_connected = {0: False, 1: False, 2: False}  # Connection status for each device
should_reconnect = {0: False, 1: False, 2: False}  # Reconnect flags

active_connections = []

# ============================================================
# TASK MEMORY SYSTEM - Ghi nhá»› tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n
# ============================================================
TASK_MEMORY_FILE = Path(__file__).parent / "task_memory.json"
MAX_TASK_HISTORY = 100  # Giá»›i háº¡n sá»‘ tÃ¡c vá»¥ lÆ°u trá»¯

def load_task_memory():
    """Äá»c lá»‹ch sá»­ tÃ¡c vá»¥ tá»« file"""
    if TASK_MEMORY_FILE.exists():
        try:
            with open(TASK_MEMORY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('tasks', [])
        except Exception as e:
            print(f"âš ï¸ [TaskMemory] Error loading: {e}")
    return []

def save_task_memory(tasks: list):
    """LÆ°u lá»‹ch sá»­ tÃ¡c vá»¥ vÃ o file"""
    try:
        # Giá»›i háº¡n sá»‘ lÆ°á»£ng
        if len(tasks) > MAX_TASK_HISTORY:
            tasks = tasks[-MAX_TASK_HISTORY:]
        
        with open(TASK_MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump({
                'tasks': tasks,
                'last_updated': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ [TaskMemory] Error saving: {e}")
        return False

def add_task_to_memory(tool_name: str, params: dict, result: dict, user_request: str = ""):
    """ThÃªm tÃ¡c vá»¥ vÃ o bá»™ nhá»›"""
    tasks = load_task_memory()
    
    task_entry = {
        "timestamp": datetime.now().isoformat(),
        "tool": tool_name,
        "params": params,
        "result_success": result.get("success", False),
        "result_message": result.get("message", result.get("error", "")),
        "user_request": user_request
    }
    
    tasks.append(task_entry)
    save_task_memory(tasks)
    return task_entry

def get_recent_tasks(limit: int = 10) -> list:
    """Láº¥y cÃ¡c tÃ¡c vá»¥ gáº§n Ä‘Ã¢y"""
    tasks = load_task_memory()
    return tasks[-limit:] if tasks else []

def search_task_memory(keyword: str) -> list:
    """TÃ¬m kiáº¿m tÃ¡c vá»¥ theo tá»« khÃ³a"""
    tasks = load_task_memory()
    keyword_lower = keyword.lower()
    
    results = []
    for task in tasks:
        # TÃ¬m trong tool name, params, user_request
        if (keyword_lower in task.get('tool', '').lower() or
            keyword_lower in str(task.get('params', {})).lower() or
            keyword_lower in task.get('user_request', '').lower() or
            keyword_lower in task.get('result_message', '').lower()):
            results.append(task)
    
    return results[-20:]  # Giá»›i háº¡n 20 káº¿t quáº£

def clear_task_memory() -> bool:
    """XÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥"""
    try:
        if TASK_MEMORY_FILE.exists():
            TASK_MEMORY_FILE.unlink()
        return True
    except Exception as e:
        print(f"âŒ [TaskMemory] Error clearing: {e}")
        return False

# Load task memory khi khá»Ÿi Ä‘á»™ng
task_memory_cache = load_task_memory()
print(f"ğŸ“ [TaskMemory] Loaded {len(task_memory_cache)} previous tasks")

# ============================================================
# CONVERSATION HISTORY - LÆ°u lá»‹ch sá»­ há»™i thoáº¡i TOÃ€N Bá»˜
# ============================================================
conversation_history = []  # List Ä‘á»ƒ lÆ°u táº¥t cáº£ messages
conversation_sessions = {}  # Sessions theo ngÃ y

# ThÆ° má»¥c lÆ°u há»™i thoáº¡i
import os
from pathlib import Path as PathLib
CONVERSATION_BASE_DIR = PathLib(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "conversations"
CONVERSATION_BASE_DIR.mkdir(parents=True, exist_ok=True)

# File tá»•ng há»£p (backward compatible)
CONVERSATION_FILE = CONVERSATION_BASE_DIR / "conversation_history.json"

# File lÆ°u user profile (hiá»ƒu ngÆ°á»i dÃ¹ng)
USER_PROFILE_FILE = CONVERSATION_BASE_DIR / "user_profile.json"

# NOTE: get_today_conversation_file() Ä‘Ã£ bá»‹ xÃ³a Ä‘á»ƒ tá»‘i Æ°u - khÃ´ng lÆ°u file theo ngÃ y ná»¯a

def load_conversation_history():
    """Load lá»‹ch sá»­ há»™i thoáº¡i tá»« file"""
    global conversation_history
    try:
        # Load file tá»•ng há»£p (CHá»ˆ má»™t file duy nháº¥t - nhanh hÆ¡n)
        if CONVERSATION_FILE.exists():
            with open(CONVERSATION_FILE, 'r', encoding='utf-8') as f:
                conversation_history = json.load(f)
            print(f"ğŸ“š [Conversation] Loaded {len(conversation_history)} messages")
    except Exception as e:
        print(f"âš ï¸ Could not load conversation history: {e}")
        conversation_history = []

def save_conversation_history():
    """LÆ°u lá»‹ch sá»­ há»™i thoáº¡i vÃ o file (CHá»ˆ file tá»•ng há»£p - tá»‘i Æ°u tá»‘c Ä‘á»™)"""
    try:
        # CHá»ˆ lÆ°u file tá»•ng há»£p (khÃ´ng lÆ°u file theo ngÃ y Ä‘á»ƒ tÄƒng tá»‘c)
        with open(CONVERSATION_FILE, 'w', encoding='utf-8') as f:
            json.dump(conversation_history, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"âš ï¸ Could not save conversation history: {e}")

def add_to_conversation(role: str, content: str, metadata: dict = None):
    """
    ThÃªm message vÃ o lá»‹ch sá»­ há»™i thoáº¡i - Tá»I Æ¯U CHO PERFORMANCE
    
    role: 'user', 'assistant', 'system', 'tool'
    content: ná»™i dung message
    metadata: thÃ´ng tin bá»• sung (tool_name, timestamp, source, etc.)
    
    OPTIMIZATION: Chá»‰ save sau 20 messages hoáº·c khi shutdown
    """
    from datetime import datetime
    
    message = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "metadata": metadata or {}
    }
    
    # ThÃªm session_id náº¿u chÆ°a cÃ³
    if "session_id" not in message["metadata"]:
        message["metadata"]["session_id"] = datetime.now().strftime("%Y%m%d")
    
    conversation_history.append(message)
    
    # TÄ‚NG Tá»C: Chá»‰ save sau má»—i 20 messages (giáº£m I/O disk)
    if len(conversation_history) % 20 == 0:
        save_conversation_history()
    
    # NOTE: Disabled user profile analysis (gÃ¢y cháº­m)

def update_user_profile_from_message(content: str, metadata: dict = None):
    """Cáº­p nháº­t user profile tá»« message Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng hÆ¡n"""
    try:
        from datetime import datetime
        
        profile = load_user_profile()
        
        # Äáº¿m sá»‘ láº§n tÆ°Æ¡ng tÃ¡c
        profile["total_interactions"] = profile.get("total_interactions", 0) + 1
        profile["last_interaction"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # PhÃ¢n tÃ­ch topics
        topics = profile.get("topics", {})
        content_lower = content.lower()
        
        # Detect topics tá»« ná»™i dung
        topic_keywords = {
            "music": ["nháº¡c", "bÃ i", "hÃ¡t", "music", "song", "play", "pause", "volume"],
            "weather": ["thá»i tiáº¿t", "weather", "mÆ°a", "náº¯ng", "nhiá»‡t Ä‘á»™", "temperature"],
            "news": ["tin", "news", "má»›i", "sá»± kiá»‡n", "event"],
            "finance": ["giÃ¡", "vÃ ng", "gold", "btc", "bitcoin", "chá»©ng khoÃ¡n", "stock", "usd", "tá»· giÃ¡"],
            "system": ["Ã¢m lÆ°á»£ng", "volume", "má»Ÿ", "open", "táº¯t", "close", "kill"],
            "web": ["tÃ¬m", "search", "google", "web", "tra cá»©u"],
            "coding": ["code", "python", "javascript", "láº­p trÃ¬nh", "debug", "function"],
            "general": ["lÃ  gÃ¬", "what is", "how to", "lÃ m sao", "táº¡i sao", "why"]
        }
        
        for topic, keywords in topic_keywords.items():
            if any(kw in content_lower for kw in keywords):
                topics[topic] = topics.get(topic, 0) + 1
        
        profile["topics"] = topics
        
        # LÆ°u cÃ¡c cÃ¢u há»i thÆ°á»ng gáº·p (top 20)
        frequent_queries = profile.get("frequent_queries", [])
        # Chá»‰ lÆ°u cÃ¢u ngáº¯n gá»n
        if len(content) < 100:
            frequent_queries.append({
                "query": content[:80],
                "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            # Giá»¯ 20 cÃ¢u gáº§n nháº¥t
            profile["frequent_queries"] = frequent_queries[-20:]
        
        # Thá»‘ng kÃª giá» hoáº¡t Ä‘á»™ng
        hour_stats = profile.get("active_hours", {})
        current_hour = datetime.now().strftime("%H")
        hour_stats[current_hour] = hour_stats.get(current_hour, 0) + 1
        profile["active_hours"] = hour_stats
        
        save_user_profile(profile)
        
    except Exception as e:
        print(f"âš ï¸ [UserProfile] Error updating: {e}")

def load_user_profile() -> dict:
    """Load user profile"""
    try:
        if USER_PROFILE_FILE.exists():
            with open(USER_PROFILE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except:
        pass
    return {
        "created": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_interactions": 0,
        "topics": {},
        "frequent_queries": [],
        "active_hours": {},
        "preferences": {}
    }

def save_user_profile(profile: dict):
    """LÆ°u user profile"""
    try:
        with open(USER_PROFILE_FILE, 'w', encoding='utf-8') as f:
            json.dump(profile, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ [UserProfile] Error saving: {e}")

def get_conversation_context(max_messages: int = 10) -> str:
    """
    Láº¥y context tá»« lá»‹ch sá»­ há»™i thoáº¡i gáº§n Ä‘Ã¢y Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng
    DÃ¹ng cho LLM Ä‘á»ƒ cÃ³ thÃªm context
    """
    recent = conversation_history[-max_messages:] if len(conversation_history) > max_messages else conversation_history
    
    context_lines = []
    for msg in recent:
        role = msg.get("role", "unknown")
        content = msg.get("content", "")[:200]  # Giá»›i háº¡n Ä‘á»™ dÃ i
        if role in ["user", "assistant"]:
            context_lines.append(f"{role.upper()}: {content}")
    
    return "\n".join(context_lines)

def get_user_profile_summary() -> str:
    """TÃ³m táº¯t profile ngÆ°á»i dÃ¹ng cho LLM"""
    try:
        profile = load_user_profile()
        
        # Top topics
        topics = profile.get("topics", {})
        sorted_topics = sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5]
        top_topics = ", ".join([f"{t[0]}({t[1]})" for t in sorted_topics]) if sorted_topics else "chÆ°a xÃ¡c Ä‘á»‹nh"
        
        # Active hours
        hours = profile.get("active_hours", {})
        sorted_hours = sorted(hours.items(), key=lambda x: int(x[1]), reverse=True)[:3]
        active_hours = ", ".join([f"{h[0]}h" for h in sorted_hours]) if sorted_hours else "chÆ°a xÃ¡c Ä‘á»‹nh"
        
        summary = f"""
[USER PROFILE]
- Tá»•ng sá»‘ tÆ°Æ¡ng tÃ¡c: {profile.get('total_interactions', 0)}
- Chá»§ Ä‘á» quan tÃ¢m: {top_topics}
- Giá» hoáº¡t Ä‘á»™ng: {active_hours}
- Láº§n cuá»‘i: {profile.get('last_interaction', 'N/A')}
"""
        return summary.strip()
    except:
        return "[USER PROFILE] ChÆ°a cÃ³ dá»¯ liá»‡u"

def export_conversation_to_file(filename: str = "") -> dict:
    """Export lá»‹ch sá»­ há»™i thoáº¡i ra file riÃªng"""
    try:
        from datetime import datetime
        import os
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"conversation_export_{timestamp}.json"
        
        documents_path = os.path.expanduser("~\\Documents")
        save_folder = os.path.join(documents_path, "miniZ_Conversations")
        os.makedirs(save_folder, exist_ok=True)
        
        file_path = os.path.join(save_folder, filename)
        
        # Export vá»›i format Ä‘áº¹p + user profile
        export_data = {
            "export_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_messages": len(conversation_history),
            "user_profile": load_user_profile(),
            "messages": conversation_history
        }
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return {
            "success": True,
            "message": f"ğŸ“š ÄÃ£ export {len(conversation_history)} messages + user profile",
            "path": file_path
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def list_conversation_files() -> list:
    """Liá»‡t kÃª táº¥t cáº£ file há»™i thoáº¡i Ä‘Ã£ lÆ°u"""
    try:
        files = []
        for f in CONVERSATION_BASE_DIR.glob("conversation_*.json"):
            stat = f.stat()
            files.append({
                "filename": f.name,
                "path": str(f),
                "size_kb": round(stat.st_size / 1024, 2),
                "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M:%S")
            })
        return sorted(files, key=lambda x: x["modified"], reverse=True)
    except Exception as e:
        return []

# Load lá»‹ch sá»­ khi khá»Ÿi Ä‘á»™ng
load_conversation_history()
print(f"ğŸ“‚ [Conversation] Storage: {CONVERSATION_BASE_DIR}")

# ============================================================
# CONVERSATION FORMATTING HELPERS
# ============================================================

def format_tool_request(tool_name: str, args: dict) -> str:
    """Format tool request thÃ nh cÃ¢u dá»… Ä‘á»c"""
    if tool_name == "set_volume":
        level = args.get("level", 0)
        return f"Äiá»u chá»‰nh Ã¢m lÆ°á»£ng lÃªn {level}%"
    elif tool_name == "get_volume":
        return "Kiá»ƒm tra Ã¢m lÆ°á»£ng hiá»‡n táº¡i"
    elif tool_name == "screenshot":
        return "Chá»¥p mÃ n hÃ¬nh"
    elif tool_name == "open_application":
        app = args.get("app_name", "")
        return f"Má»Ÿ á»©ng dá»¥ng {app}"
    elif tool_name == "get_active_media_players":
        return "Kiá»ƒm tra cÃ¡c trÃ¬nh duyá»‡t vÃ  media player Ä‘ang cháº¡y"
    elif tool_name == "list_running_processes":
        limit = args.get("limit", 10)
        return f"Liá»‡t kÃª {limit} tiáº¿n trÃ¬nh Ä‘ang cháº¡y"
    elif tool_name == "kill_process":
        identifier = args.get("identifier", "")
        force = args.get("force", True)
        return f"{'FORCE ' if force else ''}Kill tiáº¿n trÃ¬nh: {identifier}"
    elif tool_name == "force_kill_app":
        app_name = args.get("app_name", "")
        return f"ğŸ’€ FORCE KILL APP: {app_name}"
    # YouTube controls
    elif tool_name == "control_youtube":
        action = args.get("action", "")
        return f"ğŸ¬ YouTube: {action}"
    elif tool_name == "youtube_play_pause":
        return "â¯ï¸ YouTube: Play/Pause"
    elif tool_name == "youtube_rewind":
        seconds = args.get("seconds", 10)
        return f"âª YouTube: LÃ¹i {seconds} giÃ¢y"
    elif tool_name == "youtube_forward":
        seconds = args.get("seconds", 10)
        return f"â© YouTube: Tua tá»›i {seconds} giÃ¢y"
    elif tool_name == "youtube_volume_up":
        return "ğŸ”Š YouTube: TÄƒng Ã¢m lÆ°á»£ng"
    elif tool_name == "youtube_volume_down":
        return "ğŸ”‰ YouTube: Giáº£m Ã¢m lÆ°á»£ng"
    elif tool_name == "youtube_mute":
        return "ğŸ”‡ YouTube: Báº­t/Táº¯t tiáº¿ng"
    elif tool_name == "youtube_fullscreen":
        return "ğŸ“º YouTube: Fullscreen"
    # VLC controls
    elif tool_name == "control_vlc":
        action = args.get("action", "")
        return f"ğŸµ VLC: {action}"
    elif tool_name == "vlc_play_pause":
        return "â¯ï¸ VLC: Play/Pause"
    elif tool_name == "vlc_stop":
        return "â¹ï¸ VLC: Dá»«ng phÃ¡t"
    elif tool_name == "vlc_next":
        return "â­ï¸ VLC: BÃ i tiáº¿p theo"
    elif tool_name == "vlc_previous":
        return "â®ï¸ VLC: BÃ i trÆ°á»›c"
    elif tool_name == "vlc_volume_up":
        return "ğŸ”Š VLC: TÄƒng Ã¢m lÆ°á»£ng"
    elif tool_name == "vlc_volume_down":
        return "ğŸ”‰ VLC: Giáº£m Ã¢m lÆ°á»£ng"
    elif tool_name == "vlc_mute":
        return "ğŸ”‡ VLC: Báº­t/Táº¯t tiáº¿ng"
    # WMP controls
    elif tool_name == "control_wmp":
        action = args.get("action", "")
        return f"ğŸ¶ Windows Media Player: {action}"
    elif tool_name.startswith("wmp_"):
        action = tool_name.replace("wmp_", "").replace("_", " ").title()
        return f"ğŸ¶ Windows Media Player: {action}"
    # Smart media control
    elif tool_name == "smart_media_control":
        action = args.get("action", "")
        return f"ğŸ›ï¸ Smart Media: {action}"
    elif tool_name == "create_file":
        path = args.get("path", "")
        return f"Táº¡o file má»›i: {path}"
    elif tool_name == "read_file":
        path = args.get("path", "")
        return f"Äá»c ná»™i dung file: {path}"
    elif tool_name == "search_web":
        query = args.get("query", "")
        return f"TÃ¬m kiáº¿m Google: {query}"
    elif tool_name == "ask_gemini":
        prompt = args.get("prompt", "")[:50]
        return f"Há»i Gemini AI: {prompt}..."
    elif tool_name == "ask_gpt4":
        prompt = args.get("prompt", "")[:50]
        return f"Há»i GPT-4: {prompt}..."
    else:
        # Default format
        if args:
            args_str = ", ".join([f"{k}={v}" for k, v in list(args.items())[:2]])
            return f"Gá»i tool {tool_name} ({args_str})"
        return f"Gá»i tool {tool_name}"

def format_tool_response(tool_name: str, response: dict) -> str:
    """Format tool response thÃ nh cÃ¢u dá»… Ä‘á»c"""
    if isinstance(response, dict):
        # Kiá»ƒm tra lá»—i
        if response.get("isError"):
            error_text = ""
            if "content" in response and isinstance(response["content"], list):
                for item in response["content"]:
                    if item.get("type") == "text":
                        error_text = item.get("text", "")
                        break
            return f"âŒ Lá»—i: {error_text}"
        
        # Success responses
        if "content" in response and isinstance(response["content"], list):
            for item in response["content"]:
                if item.get("type") == "text":
                    text = item.get("text", "")
                    # RÃºt gá»n náº¿u quÃ¡ dÃ i
                    if len(text) > 150:
                        return f"âœ… {text[:150]}..."
                    return f"âœ… {text}"
        
        # Fallback cho response khÃ¡c
        if "message" in response:
            return f"âœ… {response['message']}"
        
    return "âœ… Thá»±c hiá»‡n thÃ nh cÃ´ng"

print("ğŸš€ miniZ MCP - Sidebar UI")
print(f"ğŸŒ Web: http://localhost:8000")
print(f"ğŸ“¡ MCP: Multi-device ready")

# ============================================================
# TOOL IMPLEMENTATIONS (20 TOOLS)
# ============================================================

async def set_volume(level: int) -> dict:
    """Äiá»u chá»‰nh Ã¢m lÆ°á»£ng há»‡ thá»‘ng - Windows only"""
    try:
        if not 0 <= level <= 100:
            return {"success": False, "error": "Level pháº£i tá»« 0-100"}
        
        # Sá»­ dá»¥ng PowerShell trá»±c tiáº¿p (tÆ°Æ¡ng thÃ­ch tá»‘t hÆ¡n vá»›i Python 3.13)
        ps_cmd = f"""
[void] [System.Reflection.Assembly]::LoadWithPartialName("System.Windows.Forms")
$obj = New-Object System.Windows.Forms.Form
$obj.KeyPreview = $True

# Get current volume
$wshShell = New-Object -ComObject WScript.Shell
for($i=1; $i -le 50; $i++){{$wshShell.SendKeys([char]174)}}  # Mute to 0

# Set to desired level
$steps = [Math]::Round({level} / 2)
for($i=1; $i -le $steps; $i++){{$wshShell.SendKeys([char]175)}}  # Volume up

Write-Output "Volume set to {level}%"
"""
        
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=5)
        
        if proc.returncode == 0:
            return {
                "success": True, 
                "level": level,
                "message": f"âœ… Ã‚m lÆ°á»£ng Ä‘Ã£ Ä‘áº·t: {level}%"
            }
        else:
            error_msg = stderr.decode('utf-8', errors='ignore').strip()
            return {"success": False, "error": f"PowerShell error: {error_msg[:200]}"}
                
    except asyncio.TimeoutError:
        return {"success": False, "error": "Timeout khi Ä‘iá»u chá»‰nh Ã¢m lÆ°á»£ng"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def mute_volume() -> dict:
    """Táº¯t tiáº¿ng (mute) há»‡ thá»‘ng"""
    try:
        ps_cmd = """
$obj = New-Object -ComObject WScript.Shell
$obj.SendKeys([char]173)
Write-Output "Volume muted"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": "ğŸ”‡ ÄÃ£ táº¯t tiáº¿ng"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def unmute_volume() -> dict:
    """Báº­t láº¡i tiáº¿ng (unmute) há»‡ thá»‘ng"""
    try:
        ps_cmd = """
$obj = New-Object -ComObject WScript.Shell
$obj.SendKeys([char]173)
Write-Output "Volume unmuted"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": "ğŸ”Š ÄÃ£ báº­t tiáº¿ng"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def volume_up(steps: int = 5) -> dict:
    """TÄƒng Ã¢m lÆ°á»£ng lÃªn (má»—i step ~2%)"""
    try:
        ps_cmd = f"""
$obj = New-Object -ComObject WScript.Shell
for($i=1; $i -le {steps}; $i++){{$obj.SendKeys([char]175)}}
Write-Output "Volume increased by {steps} steps"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": f"ğŸ”Š ÄÃ£ tÄƒng Ã¢m lÆ°á»£ng ({steps} bÆ°á»›c)"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def volume_down(steps: int = 5) -> dict:
    """Giáº£m Ã¢m lÆ°á»£ng xuá»‘ng (má»—i step ~2%)"""
    try:
        ps_cmd = f"""
$obj = New-Object -ComObject WScript.Shell
for($i=1; $i -le {steps}; $i++){{$obj.SendKeys([char]174)}}
Write-Output "Volume decreased by {steps} steps"
"""
        proc = await asyncio.create_subprocess_exec(
            "powershell", "-NoProfile", "-Command", ps_cmd,
            stdout=asyncio.subprocess.PIPE, 
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.wait_for(proc.communicate(), timeout=3)
        
        return {"success": True, "message": f"ğŸ”‰ ÄÃ£ giáº£m Ã¢m lÆ°á»£ng ({steps} bÆ°á»›c)"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def get_volume() -> dict:
    """Láº¥y má»©c Ã¢m lÆ°á»£ng hiá»‡n táº¡i cá»§a há»‡ thá»‘ng"""
    try:
        try:
            from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
            from comtypes import CLSCTX_ALL
            
            devices = AudioUtilities.GetSpeakers()
            interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
            volume = interface.QueryInterface(IAudioEndpointVolume)
            
            current_volume = int(volume.GetMasterVolumeLevelScalar() * 100)
            is_muted = volume.GetMute()
            
            return {
                "success": True,
                "level": current_volume,
                "muted": bool(is_muted),
                "message": f"ğŸ”Š Ã‚m lÆ°á»£ng hiá»‡n táº¡i: {current_volume}%" + (" (Táº¯t tiáº¿ng)" if is_muted else "")
            }
        except ImportError:
            # Fallback PowerShell
            ps_cmd = """
Add-Type -TypeDefinition @'
using System.Runtime.InteropServices;
[Guid("5CDF2C82-841E-4546-9722-0CF74078229A"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IAudioEndpointVolume {
    int NotImpl1(); int NotImpl2();
    int GetMasterVolumeLevelScalar(out float level);
}
[Guid("BCDE0395-E52F-467C-8E3D-C4579291692E")]
class MMDeviceEnumeratorComObject { }
[Guid("A95664D2-9614-4F35-A746-DE8DB63617E6"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IMMDeviceEnumerator {
    int NotImpl1();
    int GetDefaultAudioEndpoint(int dataFlow, int role, out IMMDevice device);
}
[Guid("D666063F-1587-4E43-81F1-B948E807363F"), InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
interface IMMDevice {
    int Activate(ref System.Guid id, int clsCtx, int activationParams, out IAudioEndpointVolume aev);
}
'@
$enumerator = [System.Activator]::CreateInstance([Type]::GetTypeFromCLSID([Guid]'BCDE0395-E52F-467C-8E3D-C4579291692E'))
$device = $null
$enumerator.GetDefaultAudioEndpoint(0, 1, [ref]$device)
$aev = $null
$device.Activate([Guid]'5CDF2C82-841E-4546-9722-0CF74078229A', 0, 0, [ref]$aev)
$current = 0.0
$aev.GetMasterVolumeLevelScalar([ref]$current)
Write-Output ([int]($current * 100))
"""
            proc = await asyncio.create_subprocess_exec(
                "powershell", "-NoProfile", "-Command", ps_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await asyncio.wait_for(proc.communicate(), timeout=3)
            
            if proc.returncode == 0:
                level = int(stdout.decode('utf-8', errors='ignore').strip())
                return {
                    "success": True,
                    "level": level,
                    "message": f"ğŸ”Š Ã‚m lÆ°á»£ng hiá»‡n táº¡i: {level}%"
                }
            else:
                return {"success": False, "error": "KhÃ´ng thá»ƒ láº¥y Ã¢m lÆ°á»£ng"}
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}

async def take_screenshot(filename: str = None) -> dict:
    """Chá»¥p mÃ n hÃ¬nh toÃ n bá»™ vÃ  lÆ°u file
    
    Args:
        filename: TÃªn file lÆ°u áº£nh (optional). Máº·c Ä‘á»‹nh: screenshot_YYYYMMDD_HHMMSS.png
    
    Returns:
        dict vá»›i thÃ´ng tin file Ä‘Ã£ lÆ°u
    """
    try:
        import pyautogui
        from datetime import datetime
        import os
        
        # Táº¡o tÃªn file máº·c Ä‘á»‹nh náº¿u khÃ´ng cÃ³
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"screenshot_{timestamp}.png"
        
        # Äáº£m báº£o cÃ³ extension .png
        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
            filename += '.png'
        
        # LÆ°u vÃ o thÆ° má»¥c Downloads hoáº·c thÆ° má»¥c hiá»‡n táº¡i
        downloads_path = Path.home() / "Downloads"
        if downloads_path.exists():
            filepath = downloads_path / filename
        else:
            filepath = Path(filename)
        
        # Chá»¥p mÃ n hÃ¬nh
        print(f"ğŸ“¸ [Screenshot] Äang chá»¥p mÃ n hÃ¬nh...")
        screenshot = pyautogui.screenshot()
        
        # LÆ°u file
        screenshot.save(str(filepath))
        
        file_size = filepath.stat().st_size / 1024  # KB
        
        print(f"âœ… [Screenshot] ÄÃ£ lÆ°u: {filepath}")
        
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ chá»¥p mÃ n hÃ¬nh: {filepath.name}",
            "filepath": str(filepath),
            "filename": filepath.name,
            "size_kb": round(file_size, 2),
            "dimensions": f"{screenshot.width}x{screenshot.height}"
        }
        
    except ImportError:
        return {
            "success": False,
            "error": "Thiáº¿u thÆ° viá»‡n 'pyautogui'. CÃ i Ä‘áº·t: pip install pyautogui"
        }
    except Exception as e:
        print(f"âŒ [Screenshot] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def show_notification(title: str, message: str) -> dict:
    try:
        ps_cmd = f'''[Windows.UI.Notifications.ToastNotificationManager, Windows.UI.Notifications, ContentType = WindowsRuntime] | Out-Null; [Windows.Data.Xml.Dom.XmlDocument, Windows.Data.Xml.Dom.XmlDocument, ContentType = WindowsRuntime] | Out-Null; $template = @"<toast><visual><binding template="ToastText02"><text id="1">{title}</text><text id="2">{message}</text></binding></visual></toast>"@; $xml = New-Object Windows.Data.Xml.Dom.XmlDocument; $xml.LoadXml($template); $toast = New-Object Windows.UI.Notifications.ToastNotification $xml; [Windows.UI.Notifications.ToastNotificationManager]::CreateToastNotifier("Xiaozhi").Show($toast)'''
        proc = await asyncio.create_subprocess_exec("powershell", "-Command", ps_cmd, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        await asyncio.wait_for(proc.wait(), timeout=5)
        return {"success": True, "title": title, "message": message}
    except Exception as e:
        return {"success": False, "error": str(e)}

# Cache cho system resources
_resource_cache = None
_resource_cache_time = 0
RESOURCE_CACHE_DURATION = 2  # Cache 2 giÃ¢y

async def get_system_resources() -> dict:
    """Láº¥y thÃ´ng tin tÃ i nguyÃªn há»‡ thá»‘ng vá»›i caching"""
    global _resource_cache, _resource_cache_time
    
    try:
        # Kiá»ƒm tra cache
        now = time.time()
        if _resource_cache and (now - _resource_cache_time) < RESOURCE_CACHE_DURATION:
            return _resource_cache
        
        # Láº¥y dá»¯ liá»‡u má»›i - giáº£m interval tá»« 1s xuá»‘ng 0.1s
        cpu = psutil.cpu_percent(interval=0.1)
        mem = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        result = {
            "success": True, 
            "data": {
                "cpu_percent": cpu, 
                "memory_percent": mem.percent, 
                "memory_used_gb": round(mem.used / (1024**3), 2), 
                "memory_total_gb": round(mem.total / (1024**3), 2), 
                "disk_percent": disk.percent, 
                "disk_used_gb": round(disk.used / (1024**3), 2), 
                "disk_total_gb": round(disk.total / (1024**3), 2)
            }
        }
        
        # Cáº­p nháº­t cache
        _resource_cache = result
        _resource_cache_time = now
        
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_api_quotas() -> dict:
    """Láº¥y thÃ´ng tin quota API (Gemini vÃ  Serper) - NOTE: ÄÃ¢y lÃ  giÃ¡ trá»‹ Æ°á»›c tÃ­nh"""
    try:
        result = {
            "success": True,
            "gemini": {
                "has_key": bool(GEMINI_API_KEY and GEMINI_API_KEY.strip()),
                "free_tier": "60 requests/min",
                "daily_limit": "1,500 requests/day",
                "note": "Free tier - chÆ°a cÃ³ API Ä‘á»ƒ check exact quota"
            },
            "serper": {
                "has_key": bool(SERPER_API_KEY and SERPER_API_KEY.strip()),
                "free_tier": "2,500 queries/month",
                "note": "Free tier - chÆ°a cÃ³ API Ä‘á»ƒ check exact remaining"
            }
        }
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_current_time() -> dict:
    try:
        now = datetime.now()
        return {"success": True, "datetime": now.strftime("%Y-%m-%d %H:%M:%S"), "date": now.strftime("%Y-%m-%d"), "time": now.strftime("%H:%M:%S"), "day_of_week": now.strftime("%A"), "timestamp": int(now.timestamp())}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def calculator(expression: str) -> dict:
    try:
        allowed = set("0123456789+-*/()., ")
        if not all(c in allowed for c in expression):
            return {"success": False, "error": "KÃ½ tá»± khÃ´ng há»£p lá»‡"}
        result = eval(expression, {"__builtins__": {}}, {})
        return {"success": True, "expression": expression, "result": result}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_network_info() -> dict:
    """
    Láº¥y thÃ´ng tin máº¡ng chi tiáº¿t bao gá»“m:
    - ThÃ´ng tin mÃ¡y local (hostname, IP, MAC, gateway)
    - QuÃ©t táº¥t cáº£ thiáº¿t bá»‹ Ä‘ang káº¿t ná»‘i vá»›i router
    - Hiá»ƒn thá»‹ IP, MAC, hostname cá»§a tá»«ng thiáº¿t bá»‹
    """
    try:
        import socket
        import subprocess
        import re
        from concurrent.futures import ThreadPoolExecutor
        
        # 1. Láº¥y thÃ´ng tin mÃ¡y local
        hostname = socket.gethostname()
        local_ip = socket.gethostbyname(hostname)
        
        # 2. Láº¥y MAC address vÃ  Gateway
        def get_mac_and_gateway():
            try:
                result = subprocess.check_output("ipconfig /all", shell=True, text=True, encoding='utf-8', errors='ignore')
                
                # TÃ¬m gateway
                gateway_match = re.search(r'Default Gateway[.\s:]+([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)', result)
                gateway = gateway_match.group(1) if gateway_match else "Unknown"
                
                # TÃ¬m MAC address cá»§a adapter Ä‘ang káº¿t ná»‘i
                mac_address = "Unknown"
                lines = result.split('\n')
                active_adapter = False
                for i, line in enumerate(lines):
                    if local_ip in line:
                        active_adapter = True
                    if active_adapter and 'Physical Address' in line:
                        mac_match = re.search(r'([0-9A-F]{2}[:-]){5}([0-9A-F]{2})', line, re.IGNORECASE)
                        if mac_match:
                            mac_address = mac_match.group(0)
                            break
                
                return mac_address, gateway
            except:
                return "Unknown", "Unknown"
        
        mac_address, gateway = get_mac_and_gateway()
        
        # 3. QuÃ©t thiáº¿t bá»‹ trong máº¡ng (ARP table)
        def scan_network_devices():
            devices = []
            try:
                # Láº¥y ARP table
                arp_result = subprocess.check_output("arp -a", shell=True, text=True, encoding='utf-8', errors='ignore')
                
                # Parse ARP table
                lines = arp_result.split('\n')
                for line in lines:
                    # TÃ¬m dÃ²ng cÃ³ IP vÃ  MAC
                    match = re.search(r'([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)\s+([0-9a-f]{2}[:-]){5}([0-9a-f]{2})', line, re.IGNORECASE)
                    if match:
                        device_ip = match.group(1)
                        device_mac = match.group(0).split()[1] if len(match.group(0).split()) > 1 else "Unknown"
                        
                        # Bá» qua broadcast/multicast
                        if device_ip.endswith('.255') or device_mac.startswith('ff-ff') or device_mac.startswith('01-00'):
                            continue
                        
                        # Thá»­ resolve hostname (nhanh)
                        device_hostname = "Unknown"
                        try:
                            device_hostname = socket.gethostbyaddr(device_ip)[0]
                        except:
                            pass
                        
                        devices.append({
                            "ip": device_ip,
                            "mac": device_mac,
                            "hostname": device_hostname,
                            "is_local": device_ip == local_ip
                        })
                
                return devices
            except Exception as e:
                return []
        
        # QuÃ©t thiáº¿t bá»‹ (cháº¡y async Ä‘á»ƒ khÃ´ng block)
        devices = scan_network_devices()
        
        # 4. Tá»•ng há»£p káº¿t quáº£
        result = {
            "success": True,
            "local_device": {
                "hostname": hostname,
                "ip": local_ip,
                "mac": mac_address,
                "gateway": gateway
            },
            "network_devices": devices,
            "total_devices": len(devices),
            "message": f"TÃ¬m tháº¥y {len(devices)} thiáº¿t bá»‹ trong máº¡ng"
        }
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_web(query: str) -> dict:
    try:
        import webbrowser
        url = f"https://www.google.com/search?q={query.replace(' ', '+')}"
        webbrowser.open(url)
        return {"success": True, "message": f"ÄÃ£ má»Ÿ tÃ¬m kiáº¿m: {query}", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_brightness(level: int) -> dict:
    try:
        import screen_brightness_control as sbc
        sbc.set_brightness(level)
        return {"success": True, "level": level, "message": f"ÄÃ£ Ä‘áº·t Ä‘á»™ sÃ¡ng: {level}%"}
    except Exception as e:
        return {"success": False, "error": str(e), "note": "CÃ³ thá»ƒ cáº§n cÃ i: pip install screen-brightness-control"}

async def get_clipboard() -> dict:
    try:
        import pyperclip
        content = pyperclip.paste()
        return {"success": True, "content": content}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_clipboard(text: str) -> dict:
    try:
        import pyperclip
        pyperclip.copy(text)
        return {"success": True, "message": f"ÄÃ£ copy vÃ o clipboard: {text[:50]}..."}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_sound(frequency: int = 1000, duration: int = 500) -> dict:
    try:
        import winsound
        winsound.Beep(frequency, duration)
        return {"success": True, "message": f"ÄÃ£ phÃ¡t Ã¢m thanh {frequency}Hz trong {duration}ms"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_application(app_name: str) -> dict:
    """
    Má»Ÿ á»©ng dá»¥ng Windows vá»›i kháº£ nÄƒng tÃ¬m kiáº¿m thÃ´ng minh.
    
    Thá»© tá»± tÃ¬m kiáº¿m:
    1. Dictionary mapping (Æ°u tiÃªn cao nháº¥t)
    2. TÃ¬m trong PATH
    3. TÃ¬m trong Registry (App Paths)
    4. TÃ¬m trong Program Files
    5. Fallback: Windows Start Menu
    
    Args:
        app_name: TÃªn á»©ng dá»¥ng (vÃ­ dá»¥: "chrome", "photoshop", "word")
        
    Returns:
        dict: {"success": bool, "message": str, "path": str (optional)}
    """
    try:
        import os
        import shutil
        import winreg
        import glob
        
        # Dictionary mapping - Há»— trá»£ 50+ á»©ng dá»¥ng phá»• biáº¿n
        apps = {
            # Windows Built-in
            "notepad": "notepad.exe",
            "note": "notepad.exe",
            "mÃ¡y ghi chÃº": "notepad.exe",
            "calc": "calc.exe",
            "calculator": "calc.exe",
            "mÃ¡y tÃ­nh": "calc.exe",
            "paint": "mspaint.exe",
            "váº½": "mspaint.exe",
            "cmd": "cmd.exe",
            "command prompt": "cmd.exe",
            "powershell": "powershell.exe",
            "ps": "powershell.exe",
            "explorer": "explorer.exe",
            "file explorer": "explorer.exe",
            "taskmgr": "taskmgr.exe",
            "task manager": "taskmgr.exe",
            "quáº£n lÃ½ tÃ¡c vá»¥": "taskmgr.exe",
            
            # Browsers
            "chrome": "chrome.exe",
            "google chrome": "chrome.exe",
            "gc": "chrome.exe",
            "firefox": "firefox.exe",
            "ff": "firefox.exe",
            "edge": "msedge.exe",
            "microsoft edge": "msedge.exe",
            "brave": "brave.exe",
            "opera": "opera.exe",
            
            # Microsoft Office
            "word": "WINWORD.EXE",
            "microsoft word": "WINWORD.EXE",
            "excel": "EXCEL.EXE",
            "microsoft excel": "EXCEL.EXE",
            "powerpoint": "POWERPNT.EXE",
            "microsoft powerpoint": "POWERPNT.EXE",
            "ppt": "POWERPNT.EXE",
            "outlook": "OUTLOOK.EXE",
            "microsoft outlook": "OUTLOOK.EXE",
            "onenote": "ONENOTE.EXE",
            "teams": "Teams.exe",
            "microsoft teams": "Teams.exe",
            
            # Adobe Creative Cloud
            "photoshop": "Photoshop.exe",
            "adobe photoshop": "Photoshop.exe",
            "ps": "Photoshop.exe",
            "illustrator": "Illustrator.exe",
            "adobe illustrator": "Illustrator.exe",
            "ai": "Illustrator.exe",
            "premiere": "Adobe Premiere Pro.exe",
            "premiere pro": "Adobe Premiere Pro.exe",
            "after effects": "AfterFX.exe",
            "ae": "AfterFX.exe",
            "lightroom": "Lightroom.exe",
            "acrobat": "Acrobat.exe",
            "adobe acrobat": "Acrobat.exe",
            
            # Development Tools
            "vscode": "Code.exe",
            "visual studio code": "Code.exe",
            "code": "Code.exe",
            "vs": "Code.exe",
            "sublime": "sublime_text.exe",
            "sublime text": "sublime_text.exe",
            "atom": "atom.exe",
            "notepad++": "notepad++.exe",
            "npp": "notepad++.exe",
            "pycharm": "pycharm64.exe",
            "intellij": "idea64.exe",
            "webstorm": "webstorm64.exe",
            "androidstudio": "studio64.exe",
            "android studio": "studio64.exe",
            
            # 3D & Design
            "blender": "blender.exe",
            "3ds max": "3dsmax.exe",
            "maya": "maya.exe",
            "sketchup": "SketchUp.exe",
            "fusion360": "Fusion360.exe",
            "fusion 360": "Fusion360.exe",
            "autocad": "acad.exe",
            "solidworks": "SLDWORKS.exe",
            
            # Communication
            "discord": "Discord.exe",
            "slack": "slack.exe",
            "zoom": "Zoom.exe",
            "skype": "Skype.exe",
            "telegram": "Telegram.exe",
            "zalo": "Zalo.exe",
            
            # Media Players
            "vlc": "vlc.exe",
            "spotify": "Spotify.exe",
            "itunes": "iTunes.exe",
            "windows media player": "wmplayer.exe",
            "wmp": "wmplayer.exe",
            
            # Other Popular Apps
            "steam": "steam.exe",
            "epic games": "EpicGamesLauncher.exe",
            "epic": "EpicGamesLauncher.exe",
            "obs": "obs64.exe",
            "obs studio": "obs64.exe",
            "gimp": "gimp-2.10.exe",
            "audacity": "audacity.exe",
            "7zip": "7zFM.exe",
            "7-zip": "7zFM.exe",
            "winrar": "WinRAR.exe",
        }
        
        # 1. Kiá»ƒm tra trong dictionary
        app_name_lower = app_name.lower().strip()
        exe_name = apps.get(app_name_lower)
        
        print(f"ğŸ” [Open App] TÃ¬m kiáº¿m: '{app_name}' â†’ {exe_name or 'khÃ´ng cÃ³ trong dictionary'}")
        
        # Náº¿u khÃ´ng cÃ³ trong dictionary, thá»­ dÃ¹ng tÃªn gá»‘c
        if not exe_name:
            # Kiá»ƒm tra náº¿u Ä‘Ã£ cÃ³ .exe
            if app_name.lower().endswith('.exe'):
                exe_name = app_name
            else:
                exe_name = app_name + '.exe'
        
        # 2. TÃ¬m trong PATH
        exe_path = shutil.which(exe_name)
        if exe_path:
            print(f"âœ… [Open App] TÃ¬m tháº¥y trong PATH: {exe_path}")
            subprocess.Popen([exe_path])
            return {"success": True, "message": f"âœ… ÄÃ£ má»Ÿ {app_name}", "path": exe_path}
        
        # 3. TÃ¬m trong Windows Registry (App Paths)
        try:
            with winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, 
                              rf"SOFTWARE\Microsoft\Windows\CurrentVersion\App Paths\{exe_name}") as key:
                exe_path = winreg.QueryValue(key, None)
                if exe_path and os.path.exists(exe_path):
                    print(f"âœ… [Open App] TÃ¬m tháº¥y trong Registry: {exe_path}")
                    subprocess.Popen([exe_path])
                    return {"success": True, "message": f"âœ… ÄÃ£ má»Ÿ {app_name}", "path": exe_path}
        except WindowsError:
            pass
        
        # 4. TÃ¬m trong cÃ¡c thÆ° má»¥c phá»• biáº¿n
        common_paths = [
            os.path.join(os.environ.get("PROGRAMFILES", "C:\\Program Files"), "*", exe_name),
            os.path.join(os.environ.get("PROGRAMFILES(X86)", "C:\\Program Files (x86)"), "*", exe_name),
            os.path.join(os.environ.get("LOCALAPPDATA", ""), "Programs", "*", exe_name),
            os.path.join(os.environ.get("APPDATA", ""), "*", exe_name),
        ]
        
        import glob
        for pattern in common_paths:
            matches = glob.glob(pattern, recursive=False)
            if matches:
                exe_path = matches[0]
                print(f"âœ… [Open App] TÃ¬m tháº¥y trong: {exe_path}")
                subprocess.Popen([exe_path])
                return {"success": True, "message": f"âœ… ÄÃ£ má»Ÿ {app_name}", "path": exe_path}
        
        # 5. TÃ¬m kiáº¿m sÃ¢u trong Program Files (cháº­m hÆ¡n, dÃ¹ng lÃ m fallback)
        if "photoshop" in app_name_lower or "adobe" in app_name_lower:
            # Adobe apps thÆ°á»ng á»Ÿ C:\Program Files\Adobe
            adobe_base = r"C:\Program Files\Adobe"
            if os.path.exists(adobe_base):
                for root, dirs, files in os.walk(adobe_base):
                    if exe_name in files:
                        exe_path = os.path.join(root, exe_name)
                        print(f"âœ… [Open App] TÃ¬m tháº¥y Adobe app: {exe_path}")
                        subprocess.Popen([exe_path])
                        return {"success": True, "message": f"âœ… ÄÃ£ má»Ÿ {app_name}", "path": exe_path}
        
        if "autodesk" in app_name_lower or "fusion" in app_name_lower:
            # Autodesk apps thÆ°á»ng á»Ÿ LOCALAPPDATA
            autodesk_base = os.path.join(os.environ.get("LOCALAPPDATA", ""), "Autodesk")
            if os.path.exists(autodesk_base):
                for root, dirs, files in os.walk(autodesk_base):
                    if exe_name in files:
                        exe_path = os.path.join(root, exe_name)
                        print(f"âœ… [Open App] TÃ¬m tháº¥y Autodesk app: {exe_path}")
                        subprocess.Popen([exe_path])
                        return {"success": True, "message": f"âœ… ÄÃ£ má»Ÿ {app_name}", "path": exe_path}
        
        # 6. Fallback cuá»‘i cÃ¹ng: DÃ¹ng Windows Start Menu
        print(f"âš ï¸ [Open App] KhÃ´ng tÃ¬m tháº¥y Ä‘Æ°á»ng dáº«n, thá»­ Windows Start Menu...")
        subprocess.Popen(["start", "", app_name], shell=True)
        return {
            "success": True, 
            "message": f"âœ… ÄÃ£ gá»­i lá»‡nh má»Ÿ {app_name} (Windows sáº½ tÃ¬m trong Start Menu)",
            "note": "Náº¿u khÃ´ng má»Ÿ Ä‘Æ°á»£c, hÃ£y kiá»ƒm tra tÃªn á»©ng dá»¥ng hoáº·c thÃªm vÃ o dictionary"
        }
        
    except Exception as e:
        print(f"âŒ [Open App] Lá»—i: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": f"Lá»—i khi má»Ÿ {app_name}: {str(e)}"}

# ==================== MEDIA PLAYER CONTROL ====================

# Helper function Ä‘á»ƒ tÃ¬m táº¥t cáº£ cÃ¡c cá»­a sá»• media player vÃ  browser
def _find_all_media_windows():
    """TÃ¬m táº¥t cáº£ cá»­a sá»• media player vÃ  browser Ä‘ang cháº¡y"""
    import ctypes
    
    windows = {
        'youtube': [],      # CÃ¡c tab YouTube
        'spotify_web': [],  # Spotify web
        'wmplayer': None,   # Windows Media Player
        'vlc': None,        # VLC Player
        'spotify_app': None,# Spotify Desktop
        'browsers': []      # CÃ¡c browser khÃ¡c
    }
    
    browser_names = ['chrome', 'firefox', 'edge', 'opera', 'brave', 'coccoc', 'cá»‘c cá»‘c']
    
    def enum_callback(hwnd, _):
        if ctypes.windll.user32.IsWindowVisible(hwnd):
            length = ctypes.windll.user32.GetWindowTextLengthW(hwnd)
            if length > 0:
                buff = ctypes.create_unicode_buffer(length + 1)
                ctypes.windll.user32.GetWindowTextW(hwnd, buff, length + 1)
                title = buff.value
                title_lower = title.lower()
                
                # YouTube cÃ³ Æ°u tiÃªn cao nháº¥t
                if 'youtube' in title_lower:
                    windows['youtube'].append({'hwnd': hwnd, 'title': title})
                # Spotify Web
                elif 'spotify' in title_lower and any(b in title_lower for b in browser_names):
                    windows['spotify_web'].append({'hwnd': hwnd, 'title': title})
                # Windows Media Player
                elif 'windows media player' in title_lower or 'wmplayer' in title_lower:
                    windows['wmplayer'] = {'hwnd': hwnd, 'title': title}
                # VLC
                elif 'vlc' in title_lower and 'media player' in title_lower:
                    windows['vlc'] = {'hwnd': hwnd, 'title': title}
                # Spotify Desktop App
                elif 'spotify' in title_lower and not any(b in title_lower for b in browser_names):
                    windows['spotify_app'] = {'hwnd': hwnd, 'title': title}
                # CÃ¡c browser khÃ¡c
                elif any(b in title_lower for b in browser_names):
                    windows['browsers'].append({'hwnd': hwnd, 'title': title})
        return True
    
    WNDENUMPROC = ctypes.WINFUNCTYPE(ctypes.c_bool, ctypes.c_int, ctypes.POINTER(ctypes.c_int))
    ctypes.windll.user32.EnumWindows(WNDENUMPROC(enum_callback), 0)
    
    return windows

def _focus_and_send_key(hwnd, key, delay=0.15):
    """Focus vÃ o cá»­a sá»• vÃ  gá»­i phÃ­m"""
    import ctypes
    ctypes.windll.user32.SetForegroundWindow(hwnd)
    time.sleep(delay)
    pyautogui.press(key)

def _focus_and_send_hotkey(hwnd, *keys, delay=0.15):
    """Focus vÃ o cá»­a sá»• vÃ  gá»­i tá»• há»£p phÃ­m"""
    import ctypes
    ctypes.windll.user32.SetForegroundWindow(hwnd)
    time.sleep(delay)
    pyautogui.hotkey(*keys)

async def media_play_pause() -> dict:
    """
    PhÃ¡t/Táº¡m dá»«ng media (Play/Pause toggle).
    â­ Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC - nhanh & khÃ´ng cáº§n detect window!
    
    Æ¯u tiÃªn:
    1. Python-VLC ná»™i bá»™ (NHANH NHáº¤T)
    2. YouTube (Browser) - Focus vÃ  nháº¥n K
    3. Windows Media Player
    4. Spotify
    5. Fallback - Media key
    """
    try:
        # ğŸµ Æ¯U TIÃŠN 1: Python-VLC ná»™i bá»™ - NHANH NHáº¤T!
        if vlc_player and vlc_player._player:
            vlc_player.pause()
            is_playing = vlc_player.is_playing()
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"{'â–¶ï¸ Äang phÃ¡t' if is_playing else 'â¸ï¸ ÄÃ£ táº¡m dá»«ng'}: {current_song} (Python-VLC)",
                "is_playing": is_playing,
                "player": "Python-VLC",
                "llm_note": "ğŸµ Äang dÃ¹ng Python-VLC Player tÃ­ch há»£p. CÃ³ thá»ƒ dÃ¹ng: pause_music(), resume_music(), stop_music(), music_next(), music_previous(), seek_music(), music_volume()"
            }
        
        windows = _find_all_media_windows()
        
        # 2. YouTube - náº¿u cÃ³
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_key(yt['hwnd'], 'k')
            return {"success": True, "message": f"âœ… Play/Pause YouTube: {yt['title'][:50]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_key(windows['wmplayer']['hwnd'], 'space')
            return {"success": True, "message": "âœ… Play/Pause (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'space')
            return {"success": True, "message": "âœ… Play/Pause (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_key(windows['spotify_app']['hwnd'], 'space')
            return {"success": True, "message": "âœ… Play/Pause (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_key(sw['hwnd'], 'space')
            return {"success": True, "message": f"âœ… Play/Pause Spotify Web"}
        
        # 7. Fallback - dÃ¹ng media key
        pyautogui.press('playpause')
        return {"success": True, "message": "âœ… ÄÃ£ gá»­i lá»‡nh Play/Pause (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_next_track() -> dict:
    """
    Chuyá»ƒn bÃ i tiáº¿p theo (Next Track).
    â­ Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC - nhanh & khÃ´ng cáº§n detect window!
    """
    try:
        # ğŸµ Æ¯U TIÃŠN 1: Python-VLC ná»™i bá»™ - NHANH NHáº¤T!
        if vlc_player and vlc_player._player:
            success = vlc_player.next_track()
            if success:
                import time
                time.sleep(0.3)  # Äá»£i VLC chuyá»ƒn bÃ i
                status = vlc_player.get_full_status()
                current_song = status.get('current_song', 'Unknown')
                return {
                    "success": True, 
                    "message": f"â­ï¸ ÄÃ£ chuyá»ƒn: {current_song} (Python-VLC)",
                    "player": "Python-VLC",
                    "current_song": current_song,
                    "llm_note": "ğŸµ Äang dÃ¹ng Python-VLC Player. Playlist cÃ³ thá»ƒ Ä‘iá»u khiá»ƒn báº±ng music_next(), music_previous()"
                }
            return {"success": False, "error": "KhÃ´ng cÃ³ bÃ i tiáº¿p theo trong playlist VLC"}
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_hotkey(yt['hwnd'], 'shift', 'n')
            return {"success": True, "message": f"âœ… Chuyá»ƒn video tiáº¿p theo (YouTube): {yt['title'][:40]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_hotkey(windows['wmplayer']['hwnd'], 'ctrl', 'f')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i tiáº¿p theo (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'n')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i tiáº¿p theo (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_hotkey(windows['spotify_app']['hwnd'], 'ctrl', 'right')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i tiáº¿p theo (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_hotkey(sw['hwnd'], 'ctrl', 'right')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i tiáº¿p theo (Spotify Web)"}
        
        # 7. Fallback - dÃ¹ng media key
        pyautogui.press('nexttrack')
        return {"success": True, "message": "âœ… ÄÃ£ chuyá»ƒn bÃ i tiáº¿p theo (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_previous_track() -> dict:
    """
    Chuyá»ƒn bÃ i trÆ°á»›c Ä‘Ã³ (Previous Track).
    â­ Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC - nhanh & khÃ´ng cáº§n detect window!
    """
    try:
        # ğŸµ Æ¯U TIÃŠN 1: Python-VLC ná»™i bá»™ - NHANH NHáº¤T!
        if vlc_player and vlc_player._player:
            success = vlc_player.previous_track()
            if success:
                import time
                time.sleep(0.3)  # Äá»£i VLC chuyá»ƒn bÃ i
                status = vlc_player.get_full_status()
                current_song = status.get('current_song', 'Unknown')
                return {
                    "success": True, 
                    "message": f"â®ï¸ ÄÃ£ quay láº¡i: {current_song} (Python-VLC)",
                    "player": "Python-VLC",
                    "current_song": current_song,
                    "llm_note": "ğŸµ Äang dÃ¹ng Python-VLC Player. Playlist cÃ³ thá»ƒ Ä‘iá»u khiá»ƒn báº±ng music_next(), music_previous()"
                }
            return {"success": False, "error": "KhÃ´ng cÃ³ bÃ i trÆ°á»›c trong playlist VLC"}
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_hotkey(yt['hwnd'], 'shift', 'p')
            return {"success": True, "message": f"âœ… Chuyá»ƒn video trÆ°á»›c (YouTube): {yt['title'][:40]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_hotkey(windows['wmplayer']['hwnd'], 'ctrl', 'b')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i trÆ°á»›c (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 'p')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i trÆ°á»›c (VLC Window)"}
        
        # 5. Spotify Desktop App
        if windows['spotify_app']:
            _focus_and_send_hotkey(windows['spotify_app']['hwnd'], 'ctrl', 'left')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i trÆ°á»›c (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_hotkey(sw['hwnd'], 'ctrl', 'left')
            return {"success": True, "message": "âœ… Chuyá»ƒn bÃ i trÆ°á»›c (Spotify Web)"}
        
        # 7. Fallback - dÃ¹ng media key
        pyautogui.press('prevtrack')
        return {"success": True, "message": "âœ… ÄÃ£ chuyá»ƒn bÃ i trÆ°á»›c (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_stop() -> dict:
    """
    Dá»«ng phÃ¡t media (Stop).
    â­ Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC - nhanh & khÃ´ng cáº§n detect window!
    """
    try:
        # ğŸµ Æ¯U TIÃŠN 1: Python-VLC ná»™i bá»™ - NHANH NHáº¤T!
        if vlc_player and vlc_player._player:
            vlc_player.stop()
            return {
                "success": True, 
                "message": "â¹ï¸ ÄÃ£ dá»«ng nháº¡c (Python-VLC)",
                "player": "Python-VLC",
                "llm_note": "ğŸµ ÄÃ£ dá»«ng Python-VLC Player. DÃ¹ng play_music() hoáº·c resume_music() Ä‘á»ƒ phÃ¡t láº¡i."
            }
        
        windows = _find_all_media_windows()
        
        # 2. YouTube
        if windows['youtube']:
            yt = windows['youtube'][0]
            _focus_and_send_key(yt['hwnd'], 'k', delay=0.2)
            return {"success": True, "message": f"âœ… ÄÃ£ dá»«ng YouTube: {yt['title'][:50]}..."}
        
        # 3. Windows Media Player
        if windows['wmplayer']:
            _focus_and_send_key(windows['wmplayer']['hwnd'], 'stop')
            return {"success": True, "message": "âœ… ÄÃ£ dá»«ng phÃ¡t (Windows Media Player)"}
        
        # 4. VLC Window (external)
        if windows['vlc']:
            _focus_and_send_key(windows['vlc']['hwnd'], 's')
            return {"success": True, "message": "âœ… ÄÃ£ dá»«ng phÃ¡t (VLC Window)"}
        
        # 5. Spotify Desktop App - khÃ´ng cÃ³ stop, dÃ¹ng pause
        if windows['spotify_app']:
            _focus_and_send_key(windows['spotify_app']['hwnd'], 'space')
            return {"success": True, "message": "âœ… ÄÃ£ táº¡m dá»«ng (Spotify Desktop)"}
        
        # 6. Spotify Web
        if windows['spotify_web']:
            sw = windows['spotify_web'][0]
            _focus_and_send_key(sw['hwnd'], 'space')
            return {"success": True, "message": "âœ… ÄÃ£ táº¡m dá»«ng (Spotify Web)"}
        
        # 7. Fallback - dÃ¹ng media key
        pyautogui.press('stop')
        return {"success": True, "message": "âœ… ÄÃ£ dá»«ng phÃ¡t (Media Key)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_volume_up() -> dict:
    """TÄƒng Ã¢m lÆ°á»£ng media (Media Volume Up)"""
    try:
        pyautogui.press('volumeup')
        return {"success": True, "message": "âœ… ÄÃ£ tÄƒng Ã¢m lÆ°á»£ng"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_volume_down() -> dict:
    """Giáº£m Ã¢m lÆ°á»£ng media (Media Volume Down)"""
    try:
        pyautogui.press('volumedown')
        return {"success": True, "message": "âœ… ÄÃ£ giáº£m Ã¢m lÆ°á»£ng"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_mute() -> dict:
    """Táº¯t/Báº­t tiáº¿ng media (Mute Toggle)"""
    try:
        pyautogui.press('volumemute')
        return {"success": True, "message": "âœ… ÄÃ£ toggle mute"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def media_control(action: str) -> dict:
    """
    Äiá»u khiá»ƒn media player Ä‘a nÄƒng.
    
    Args:
        action: HÃ nh Ä‘á»™ng cáº§n thá»±c hiá»‡n
            - "play" hoáº·c "pause": PhÃ¡t/Táº¡m dá»«ng
            - "next": BÃ i tiáº¿p theo
            - "previous" hoáº·c "prev": BÃ i trÆ°á»›c
            - "stop": Dá»«ng phÃ¡t
            - "volume_up": TÄƒng Ã¢m lÆ°á»£ng
            - "volume_down": Giáº£m Ã¢m lÆ°á»£ng
            - "mute": Táº¯t/Báº­t tiáº¿ng
    
    Returns:
        dict: Káº¿t quáº£ thá»±c hiá»‡n
    """
    try:
        action = action.lower().strip()
        
        actions_map = {
            "play": "playpause",
            "pause": "playpause",
            "playpause": "playpause",
            "next": "nexttrack",
            "previous": "prevtrack",
            "prev": "prevtrack",
            "stop": "stop",
            "volume_up": "volumeup",
            "volumeup": "volumeup",
            "volume_down": "volumedown",
            "volumedown": "volumedown",
            "mute": "volumemute",
        }
        
        key = actions_map.get(action)
        if not key:
            return {
                "success": False, 
                "error": f"Action khÃ´ng há»£p lá»‡: '{action}'. Chá»n: play, pause, next, previous, stop, volume_up, volume_down, mute"
            }
        
        pyautogui.press(key)
        
        action_messages = {
            "playpause": "Play/Pause",
            "nexttrack": "BÃ i tiáº¿p theo",
            "prevtrack": "BÃ i trÆ°á»›c",
            "stop": "Dá»«ng phÃ¡t",
            "volumeup": "TÄƒng Ã¢m lÆ°á»£ng",
            "volumedown": "Giáº£m Ã¢m lÆ°á»£ng",
            "volumemute": "Mute/Unmute",
        }
        
        return {"success": True, "message": f"âœ… {action_messages[key]}", "action": action}
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# ==================== END MEDIA PLAYER CONTROL ====================

# ==================== TASK MEMORY TOOLS ====================

async def remember_task(tool_name: str, params: dict = None, result_message: str = "", user_request: str = "") -> dict:
    """
    Ghi nhá»› má»™t tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n vÃ o bá»™ nhá»›.
    GiÃºp AI pháº£n há»“i nhanh vÃ  chÃ­nh xÃ¡c hÆ¡n cho cÃ¡c yÃªu cáº§u tÆ°Æ¡ng tá»±.
    
    Args:
        tool_name: TÃªn tool Ä‘Ã£ sá»­ dá»¥ng
        params: Tham sá»‘ Ä‘Ã£ truyá»n vÃ o tool
        result_message: Káº¿t quáº£/message tráº£ vá»
        user_request: YÃªu cáº§u gá»‘c cá»§a user
    """
    try:
        task_entry = add_task_to_memory(
            tool_name=tool_name,
            params=params or {},
            result={"success": True, "message": result_message},
            user_request=user_request
        )
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ ghi nhá»› tÃ¡c vá»¥: {tool_name}",
            "task": task_entry
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def recall_tasks(keyword: str = "", limit: int = 10) -> dict:
    """
    Nhá»› láº¡i cÃ¡c tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n trÆ°á»›c Ä‘Ã³.
    GiÃºp AI biáº¿t nhá»¯ng gÃ¬ Ä‘Ã£ lÃ m Ä‘á»ƒ pháº£n há»“i phÃ¹ há»£p.
    
    Args:
        keyword: Tá»« khÃ³a tÃ¬m kiáº¿m (optional). Äá»ƒ trá»‘ng = láº¥y tÃ¡c vá»¥ gáº§n nháº¥t
        limit: Sá»‘ lÆ°á»£ng tÃ¡c vá»¥ tá»‘i Ä‘a tráº£ vá» (default 10)
    """
    try:
        if keyword:
            tasks = search_task_memory(keyword)
            message = f"ğŸ” TÃ¬m tháº¥y {len(tasks)} tÃ¡c vá»¥ liÃªn quan Ä‘áº¿n '{keyword}'"
        else:
            tasks = get_recent_tasks(limit)
            message = f"ğŸ“‹ {len(tasks)} tÃ¡c vá»¥ gáº§n Ä‘Ã¢y nháº¥t"
        
        return {
            "success": True,
            "message": message,
            "count": len(tasks),
            "tasks": tasks
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_task_summary() -> dict:
    """
    Láº¥y tá»•ng há»£p thá»‘ng kÃª vá» cÃ¡c tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n.
    GiÃºp AI hiá»ƒu patterns sá»­ dá»¥ng cá»§a user.
    """
    try:
        tasks = load_task_memory()
        
        if not tasks:
            return {
                "success": True,
                "message": "ğŸ“Š ChÆ°a cÃ³ lá»‹ch sá»­ tÃ¡c vá»¥",
                "total_tasks": 0,
                "most_used_tools": [],
                "success_rate": 0
            }
        
        # Äáº¿m theo tool
        tool_counts = {}
        success_count = 0
        
        for task in tasks:
            tool = task.get('tool', 'unknown')
            tool_counts[tool] = tool_counts.get(tool, 0) + 1
            if task.get('result_success'):
                success_count += 1
        
        # Top 10 tools Ä‘Æ°á»£c dÃ¹ng nhiá»u nháº¥t
        sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        return {
            "success": True,
            "message": f"ğŸ“Š ÄÃ£ thá»±c hiá»‡n {len(tasks)} tÃ¡c vá»¥",
            "total_tasks": len(tasks),
            "most_used_tools": [{"tool": t[0], "count": t[1]} for t in sorted_tools],
            "success_rate": round(success_count / len(tasks) * 100, 1),
            "recent_tools": [t.get('tool') for t in tasks[-5:]]
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def forget_all_tasks() -> dict:
    """
    XÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥ Ä‘Ã£ ghi nhá»›.
    """
    try:
        success = clear_task_memory()
        if success:
            return {"success": True, "message": "ğŸ—‘ï¸ ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥"}
        else:
            return {"success": False, "error": "KhÃ´ng thá»ƒ xÃ³a lá»‹ch sá»­"}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ==================== END TASK MEMORY TOOLS ====================

async def get_active_media_players() -> dict:
    """
    Láº¥y danh sÃ¡ch cÃ¡c media players/applications Ä‘ang cháº¡y trÃªn mÃ¡y tÃ­nh.
    
    ThÃ´ng tin nÃ y giÃºp LLM biáº¿t:
    - CÃ³ media player nÃ o Ä‘ang cháº¡y khÃ´ng
    - NÃªn dÃ¹ng tool nÃ o (media_play_pause cho Spotify/VLC, stop_music cho WMP)
    - CÃ³ á»©ng dá»¥ng nÃ o cÃ³ thá»ƒ Ä‘iá»u khiá»ƒn Ä‘Æ°á»£c
    
    Returns:
        dict: Danh sÃ¡ch media players, browsers, vÃ  á»©ng dá»¥ng quan trá»ng Ä‘ang cháº¡y
    """
    try:
        # Danh sÃ¡ch media players vÃ  á»©ng dá»¥ng quan trá»ng cáº§n theo dÃµi
        MEDIA_APPS = {
            # Media Players
            "spotify.exe": {"name": "Spotify", "type": "music", "supports_media_keys": True},
            "vlc.exe": {"name": "VLC Media Player", "type": "video", "supports_media_keys": True},
            "wmplayer.exe": {"name": "Windows Media Player", "type": "music", "supports_media_keys": True},
            "itunes.exe": {"name": "iTunes", "type": "music", "supports_media_keys": True},
            
            # Browsers (cÃ³ thá»ƒ phÃ¡t YouTube, Spotify Web...)
            "chrome.exe": {"name": "Google Chrome", "type": "browser", "supports_media_keys": True},
            "msedge.exe": {"name": "Microsoft Edge", "type": "browser", "supports_media_keys": True},
            "firefox.exe": {"name": "Firefox", "type": "browser", "supports_media_keys": True},
            "brave.exe": {"name": "Brave", "type": "browser", "supports_media_keys": True},
            "opera.exe": {"name": "Opera", "type": "browser", "supports_media_keys": True},
            "browser.exe": {"name": "Browser", "type": "browser", "supports_media_keys": True},
            "iexplore.exe": {"name": "Internet Explorer", "type": "browser", "supports_media_keys": True},
            "vivaldi.exe": {"name": "Vivaldi", "type": "browser", "supports_media_keys": True},
            
            # Communication (cÃ³ media playback)
            "discord.exe": {"name": "Discord", "type": "communication", "supports_media_keys": True},
            "slack.exe": {"name": "Slack", "type": "communication", "supports_media_keys": False},
            "zoom.exe": {"name": "Zoom", "type": "communication", "supports_media_keys": False},
            "skype.exe": {"name": "Skype", "type": "communication", "supports_media_keys": False},
            
            # Office & Productivity
            "WINWORD.EXE": {"name": "Microsoft Word", "type": "office", "supports_media_keys": False},
            "EXCEL.EXE": {"name": "Microsoft Excel", "type": "office", "supports_media_keys": False},
            "POWERPNT.EXE": {"name": "PowerPoint", "type": "office", "supports_media_keys": False},
            "OUTLOOK.EXE": {"name": "Outlook", "type": "office", "supports_media_keys": False},
            
            # Development
            "Code.exe": {"name": "VS Code", "type": "development", "supports_media_keys": False},
            "devenv.exe": {"name": "Visual Studio", "type": "development", "supports_media_keys": False},
            "pycharm64.exe": {"name": "PyCharm", "type": "development", "supports_media_keys": False},
            
            # Design & Creative
            "Photoshop.exe": {"name": "Adobe Photoshop", "type": "creative", "supports_media_keys": False},
            "Illustrator.exe": {"name": "Adobe Illustrator", "type": "creative", "supports_media_keys": False},
            "blender.exe": {"name": "Blender", "type": "3d", "supports_media_keys": False},
        }
        
        running_apps = []
        media_players = []
        browsers = []
        
        # QuÃ©t cÃ¡c process Ä‘ang cháº¡y
        for proc in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = proc.info['name']
                
                if proc_name in MEDIA_APPS:
                    app_info = MEDIA_APPS[proc_name].copy()
                    app_info['pid'] = proc.info['pid']
                    app_info['process_name'] = proc_name
                    
                    running_apps.append(app_info)
                    
                    # PhÃ¢n loáº¡i
                    if app_info['type'] in ['music', 'video']:
                        media_players.append(app_info)
                    elif app_info['type'] == 'browser':
                        browsers.append(app_info)
                        
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass
        
        # Táº¡o thÃ´ng Ä‘iá»‡p hÆ°á»›ng dáº«n cho LLM (tá»‘i Æ°u hÃ³a, khÃ´ng liá»‡t kÃª tá»«ng instance)
        guidance = ""
        
        if media_players:
            # Äáº¿m sá»‘ lÆ°á»£ng tá»«ng loáº¡i media player (khÃ´ng liá»‡t kÃª tá»«ng process)
            player_counts = {}
            for p in media_players:
                name = p['name']
                player_counts[name] = player_counts.get(name, 0) + 1
            
            player_summary = ', '.join([f"{name} ({count})" if count > 1 else name 
                                       for name, count in player_counts.items()])
            guidance += f"ğŸµ Media Players: {player_summary}.\n"
            
            if any(p['name'] == 'Windows Media Player' for p in media_players):
                guidance += "   â†’ DÃ¹ng stop_music() Ä‘á»ƒ dá»«ng Windows Media Player.\n"
            
            if any(p['supports_media_keys'] and p['name'] != 'Windows Media Player' for p in media_players):
                guidance += "   â†’ DÃ¹ng media_play_pause(), media_next_track() cho Spotify/VLC/iTunes.\n"
        
        if browsers:
            # Äáº¿m sá»‘ lÆ°á»£ng tá»«ng loáº¡i browser (khÃ´ng liá»‡t kÃª tá»«ng process)
            browser_counts = {}
            for b in browsers:
                name = b['name']
                browser_counts[name] = browser_counts.get(name, 0) + 1
            
            browser_summary = ', '.join([f"{name} ({count})" if count > 1 else name 
                                        for name, count in browser_counts.items()])
            guidance += f"ğŸŒ Browsers: {browser_summary}.\n"
            guidance += "   â†’ CÃ³ thá»ƒ phÃ¡t YouTube/Spotify Web. DÃ¹ng media_play_pause() Ä‘á»ƒ Ä‘iá»u khiá»ƒn.\n"
        
        if not media_players and not browsers:
            guidance = "âŒ KhÃ´ng cÃ³ media player/browser nÃ o Ä‘ang cháº¡y. DÃ¹ng play_music() Ä‘á»ƒ phÃ¡t nháº¡c tá»« music_library."
        
        return {
            "success": True,
            "all_apps": running_apps,
            "media_players": media_players,
            "browsers": browsers,
            "total_count": len(running_apps),
            "guidance": guidance.strip(),
            "message": f"âœ… Äang cháº¡y: {len(running_apps)} á»©ng dá»¥ng ({len(media_players)} media players, {len(browsers)} browsers)"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def list_running_processes(limit: int = 10) -> dict:
    try:
        procs = []
        for p in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                procs.append({"pid": p.info['pid'], "name": p.info['name'], "cpu": round(p.info['cpu_percent'], 2), "memory": round(p.info['memory_percent'], 2)})
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                # Bá» qua cÃ¡c tiáº¿n trÃ¬nh khÃ´ng thá»ƒ truy cáº­p
                pass
        procs = sorted(procs, key=lambda x: x['cpu'], reverse=True)[:limit]
        return {"success": True, "processes": procs, "count": len(procs)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def kill_process(identifier: str, force: bool = True, exact_match: bool = False) -> dict:
    """
    Kill process ngay láº­p tá»©c.
    
    Args:
        identifier: TÃªn app hoáº·c PID. VD: "notepad", "chrome", "1234"
        force: True = kill ngay (SIGKILL), False = Ä‘Ã³ng má»m (SIGTERM)
        exact_match: True = tÃªn pháº£i khá»›p chÃ­nh xÃ¡c, False = chá»©a tÃªn lÃ  Ä‘Æ°á»£c
    """
    import subprocess
    import time
    
    try:
        killed = []
        failed = []
        
        # Náº¿u lÃ  PID (sá»‘)
        if identifier.isdigit():
            try:
                p = psutil.Process(int(identifier))
                name = p.name()
                if force:
                    p.kill()  # SIGKILL - kill ngay láº­p tá»©c
                else:
                    p.terminate()  # SIGTERM - Ä‘Ã³ng má»m
                    p.wait(timeout=3)  # Chá» tá»‘i Ä‘a 3 giÃ¢y
                killed.append(f"{name} (PID: {identifier})")
            except psutil.TimeoutExpired:
                # Náº¿u terminate khÃ´ng Ä‘Æ°á»£c, force kill
                p.kill()
                killed.append(f"{name} (PID: {identifier}) [FORCE KILLED]")
        else:
            # TÃ¬m theo tÃªn
            target_name = identifier.lower()
            
            # ThÃªm .exe náº¿u chÆ°a cÃ³
            if not target_name.endswith('.exe'):
                target_name_exe = target_name + '.exe'
            else:
                target_name_exe = target_name
                target_name = target_name[:-4]  # Bá» .exe Ä‘á»ƒ so sÃ¡nh
            
            for p in psutil.process_iter(['pid', 'name', 'exe']):
                try:
                    proc_name = p.info['name'].lower() if p.info['name'] else ""
                    
                    # Kiá»ƒm tra match
                    match = False
                    if exact_match:
                        # Khá»›p chÃ­nh xÃ¡c tÃªn
                        match = (proc_name == target_name_exe or proc_name == target_name)
                    else:
                        # Chá»©a tÃªn lÃ  Ä‘Æ°á»£c
                        match = (target_name in proc_name)
                    
                    if match:
                        pid = p.info['pid']
                        try:
                            if force:
                                p.kill()  # Kill ngay láº­p tá»©c
                            else:
                                p.terminate()
                                try:
                                    p.wait(timeout=2)
                                except psutil.TimeoutExpired:
                                    p.kill()  # Force kill náº¿u khÃ´ng Ä‘Ã³ng Ä‘Æ°á»£c
                            killed.append(f"{p.info['name']} (PID: {pid})")
                        except psutil.AccessDenied:
                            # Thá»­ dÃ¹ng taskkill vá»›i quyá»n cao hÆ¡n
                            try:
                                subprocess.run(
                                    ['taskkill', '/F', '/PID', str(pid)],
                                    capture_output=True,
                                    timeout=5
                                )
                                killed.append(f"{p.info['name']} (PID: {pid}) [via taskkill]")
                            except:
                                failed.append(f"{p.info['name']} (PID: {pid}) - Access Denied")
                except (psutil.NoSuchProcess, psutil.ZombieProcess):
                    pass
        
        # Káº¿t quáº£
        if killed:
            result = {
                "success": True, 
                "message": f"âœ… ÄÃ£ kill thÃ nh cÃ´ng: {', '.join(killed)}",
                "killed_count": len(killed),
                "killed": killed
            }
            if failed:
                result["failed"] = failed
                result["message"] += f"\nâš ï¸ KhÃ´ng thá»ƒ kill: {', '.join(failed)}"
            return result
        elif failed:
            return {"success": False, "error": f"KhÃ´ng cÃ³ quyá»n kill: {', '.join(failed)}"}
        else:
            return {"success": False, "error": f"KhÃ´ng tÃ¬m tháº¥y process '{identifier}'"}
            
    except psutil.NoSuchProcess:
        return {"success": False, "error": f"Tiáº¿n trÃ¬nh khÃ´ng tá»“n táº¡i: {identifier}"}
    except psutil.AccessDenied:
        # Thá»­ dÃ¹ng taskkill
        try:
            if identifier.isdigit():
                result = subprocess.run(
                    ['taskkill', '/F', '/PID', identifier],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
            else:
                result = subprocess.run(
                    ['taskkill', '/F', '/IM', f'{identifier}*'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
            if result.returncode == 0:
                return {"success": True, "message": f"âœ… ÄÃ£ kill báº±ng taskkill: {identifier}"}
            else:
                return {"success": False, "error": f"KhÃ´ng thá»ƒ kill (cáº§n quyá»n Admin): {identifier}"}
        except Exception as e:
            return {"success": False, "error": f"Lá»—i khi kill: {str(e)}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def force_kill_app(app_name: str) -> dict:
    """
    Force kill app theo tÃªn CHÃNH XÃC - kill ngay láº­p tá»©c khÃ´ng há»i han.
    Sá»­ dá»¥ng cáº£ psutil vÃ  taskkill Ä‘á»ƒ Ä‘áº£m báº£o kill Ä‘Æ°á»£c.
    
    Args:
        app_name: TÃªn app cáº§n kill. VD: "notepad", "chrome", "Code"
    """
    import subprocess
    
    try:
        killed = []
        
        # Chuáº©n hÃ³a tÃªn
        target = app_name.lower().strip()
        if not target.endswith('.exe'):
            target_exe = target + '.exe'
        else:
            target_exe = target
            target = target[:-4]
        
        # BÆ°á»›c 1: Kill báº±ng psutil
        for p in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = (p.info['name'] or "").lower()
                if proc_name == target_exe or proc_name == target or target in proc_name:
                    pid = p.info['pid']
                    try:
                        p.kill()  # SIGKILL - force kill ngay
                        killed.append(f"{p.info['name']} (PID: {pid})")
                    except:
                        pass
            except:
                pass
        
        # BÆ°á»›c 2: Backup vá»›i taskkill /F (force)
        try:
            # Kill theo image name
            subprocess.run(
                ['taskkill', '/F', '/IM', target_exe],
                capture_output=True,
                timeout=5
            )
            # Thá»­ cáº£ khÃ´ng cÃ³ .exe
            subprocess.run(
                ['taskkill', '/F', '/IM', f'{target}*'],
                capture_output=True,
                timeout=5
            )
        except:
            pass
        
        # BÆ°á»›c 3: Verify Ä‘Ã£ kill háº¿t chÆ°a
        remaining = []
        for p in psutil.process_iter(['pid', 'name']):
            try:
                proc_name = (p.info['name'] or "").lower()
                if proc_name == target_exe or proc_name == target or target in proc_name:
                    remaining.append(f"{p.info['name']} (PID: {p.info['pid']})")
            except:
                pass
        
        if killed and not remaining:
            return {
                "success": True,
                "message": f"âœ… ÄÃ£ FORCE KILL thÃ nh cÃ´ng: {', '.join(killed)}",
                "killed_count": len(killed),
                "killed": killed
            }
        elif remaining:
            return {
                "success": False,
                "error": f"âŒ KhÃ´ng thá»ƒ kill (cáº§n quyá»n Admin): {', '.join(remaining)}",
                "killed": killed if killed else []
            }
        else:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y app '{app_name}' Ä‘ang cháº¡y"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def find_process(name_pattern: str = "", show_all: bool = False) -> dict:
    """
    TÃ¬m kiáº¿m process theo tÃªn hoáº·c hiá»ƒn thá»‹ táº¥t cáº£.
    
    Args:
        name_pattern: TÃªn process cáº§n tÃ¬m (partial match, case insensitive). Äá»ƒ trá»‘ng = táº¥t cáº£
        show_all: True = hiá»ƒn thá»‹ táº¥t cáº£ process (bá» qua limit)
    
    Returns:
        dict: Danh sÃ¡ch processes tÃ¬m tháº¥y
    """
    try:
        procs = []
        pattern_lower = name_pattern.lower() if name_pattern else ""
        
        for p in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
            try:
                info = p.info
                proc_name = (info['name'] or "").lower()
                
                # Filter theo pattern náº¿u cÃ³
                if pattern_lower and pattern_lower not in proc_name:
                    continue
                    
                procs.append({
                    "pid": info['pid'], 
                    "name": info['name'], 
                    "cpu": round(info['cpu_percent'] or 0, 2), 
                    "memory": round(info['memory_percent'] or 0, 2)
                })
            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                pass
        
        # Sort theo CPU usage náº¿u khÃ´ng cÃ³ filter cá»¥ thá»ƒ
        if not pattern_lower:
            procs = sorted(procs, key=lambda x: x['cpu'], reverse=True)
            
        # Limit chá»‰ khi khÃ´ng show_all vÃ  khÃ´ng cÃ³ pattern cá»¥ thá»ƒ
        if not show_all and not pattern_lower:
            procs = procs[:20]  # Top 20 thay vÃ¬ 10
            
        # Táº¡o message tÃ³m táº¯t
        if pattern_lower:
            found_count = len(procs)
            if found_count == 0:
                message = f"âŒ KhÃ´ng tÃ¬m tháº¥y process nÃ o chá»©a '{name_pattern}'"
            elif found_count == 1:
                message = f"âœ… TÃ¬m tháº¥y 1 process: {procs[0]['name']}"
            else:
                message = f"âœ… TÃ¬m tháº¥y {found_count} processes chá»©a '{name_pattern}'"
        else:
            message = f"ğŸ“‹ Danh sÃ¡ch {len(procs)} processes (sorted by CPU usage)"
            
        return {
            "success": True, 
            "processes": procs, 
            "count": len(procs),
            "pattern": name_pattern,
            "message": message
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def create_file(path: str, content: str) -> dict:
    try:
        import os
        
        # Validate path - must be absolute on Windows (contains drive letter)
        if not os.path.isabs(path):
            return {"success": False, "error": f"Path must be absolute. Got: '{path}'. Example: 'C:/folder/file.txt'"}
        
        # Normalize path separators
        path = os.path.normpath(path)
        
        # Check if parent directory exists, create if needed
        parent_dir = os.path.dirname(path)
        if parent_dir and not os.path.exists(parent_dir):
            try:
                os.makedirs(parent_dir, exist_ok=True)
            except Exception as e:
                return {"success": False, "error": f"Cannot create directory '{parent_dir}': {str(e)}"}
        
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        return {"success": True, "path": path, "message": f"ÄÃ£ táº¡o: {path}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def read_file(path: str) -> dict:
    try:
        import os
        
        # Validate path - must be absolute on Windows (contains drive letter)
        if not os.path.isabs(path):
            return {"success": False, "error": f"Path must be absolute. Got: '{path}'. Example: 'C:/folder/file.txt'"}
        
        # Normalize path separators
        path = os.path.normpath(path)
        
        # Check if file exists
        if not os.path.exists(path):
            return {"success": False, "error": f"File not found: '{path}'"}
        
        if not os.path.isfile(path):
            return {"success": False, "error": f"Path is not a file: '{path}'"}
        
        with open(path, 'r', encoding='utf-8') as f:
            content = f.read()
        return {"success": True, "path": path, "content": content[:500], "size": len(content)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def list_files(directory: str) -> dict:
    try:
        import os
        files = []
        for item in os.listdir(directory):
            p = os.path.join(directory, item)
            files.append({"name": item, "type": "dir" if os.path.isdir(p) else "file", "size": os.path.getsize(p) if os.path.isfile(p) else 0})
        return {"success": True, "directory": directory, "files": files, "count": len(files)}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_battery_status() -> dict:
    try:
        bat = psutil.sensors_battery()
        if bat is None:
            return {"success": False, "error": "KhÃ´ng thá»ƒ láº¥y thÃ´ng tin pin (cÃ³ thá»ƒ khÃ´ng cÃ³ pin)"}
        return {
            "success": True,
            "percent": bat.percent,
            "plugged": bat.power_plugged,
            "time_left": str(bat.secsleft) if bat.secsleft != psutil.POWER_TIME_UNLIMITED else "Unlimited"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_disk_usage() -> dict:
    try:
        disks = []
        for part in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(part.mountpoint)
                disks.append({"device": part.device, "mountpoint": part.mountpoint, "fstype": part.fstype, "total_gb": round(usage.total / (1024**3), 2), "used_gb": round(usage.used / (1024**3), 2), "free_gb": round(usage.free / (1024**3), 2), "percent": usage.percent})
            except (PermissionError, OSError):
                # Bá» qua cÃ¡c á»• Ä‘Ä©a khÃ´ng thá»ƒ truy cáº­p
                pass
        return {"success": True, "disks": disks, "count": len(disks)}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# MUSIC LIBRARY TOOLS - VLC PLAYER
# ============================================================

MUSIC_LIBRARY = Path(__file__).parent / "music_library"
MUSIC_EXTENSIONS = {'.mp3', '.wav', '.flac', '.m4a', '.ogg', '.wma', '.aac'}

# YouTube Playlists Management
YOUTUBE_PLAYLISTS_FILE = Path(__file__).parent / "youtube_playlists.json"

def load_youtube_playlists() -> list:
    """Äá»c danh sÃ¡ch playlist YouTube tá»« file JSON"""
    try:
        if YOUTUBE_PLAYLISTS_FILE.exists():
            with open(YOUTUBE_PLAYLISTS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    except Exception as e:
        print(f"âŒ [Playlists] Error loading: {e}")
        return []

def save_youtube_playlists(playlists: list) -> bool:
    """LÆ°u danh sÃ¡ch playlist YouTube vÃ o file JSON"""
    try:
        with open(YOUTUBE_PLAYLISTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(playlists, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ [Playlists] Error saving: {e}")
        return False

async def add_youtube_playlist(name: str, url: str) -> dict:
    """ThÃªm playlist YouTube má»›i"""
    try:
        playlists = load_youtube_playlists()
        
        # Kiá»ƒm tra trÃ¹ng tÃªn
        if any(p['name'].lower() == name.lower() for p in playlists):
            return {
                "success": False,
                "error": f"Playlist '{name}' Ä‘Ã£ tá»“n táº¡i!"
            }
        
        # ThÃªm playlist má»›i
        new_playlist = {
            "name": name,
            "url": url,
            "created_at": datetime.now().isoformat()
        }
        playlists.append(new_playlist)
        
        if save_youtube_playlists(playlists):
            return {
                "success": True,
                "message": f"âœ… ÄÃ£ thÃªm playlist: {name}",
                "playlist": new_playlist
            }
        else:
            return {
                "success": False,
                "error": "KhÃ´ng thá»ƒ lÆ°u playlist"
            }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def remove_youtube_playlist(name: str) -> dict:
    """XÃ³a playlist YouTube"""
    try:
        playlists = load_youtube_playlists()
        
        # TÃ¬m vÃ  xÃ³a playlist
        original_count = len(playlists)
        playlists = [p for p in playlists if p['name'].lower() != name.lower()]
        
        if len(playlists) == original_count:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y playlist: {name}"
            }
        
        if save_youtube_playlists(playlists):
            return {
                "success": True,
                "message": f"âœ… ÄÃ£ xÃ³a playlist: {name}"
            }
        else:
            return {
                "success": False,
                "error": "KhÃ´ng thá»ƒ lÆ°u thay Ä‘á»•i"
            }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_youtube_playlists() -> dict:
    """Láº¥y danh sÃ¡ch táº¥t cáº£ playlist YouTube"""
    try:
        playlists = load_youtube_playlists()
        return {
            "success": True,
            "playlists": playlists,
            "count": len(playlists)
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_youtube_playlist(playlist_name: str) -> dict:
    """Má»Ÿ playlist YouTube Ä‘Ã£ lÆ°u trong browser
    
    Args:
        playlist_name: TÃªn playlist Ä‘Ã£ Ä‘Äƒng kÃ½ (cÃ³ thá»ƒ lÃ  tÃªn Ä‘áº§y Ä‘á»§ hoáº·c tá»« khÃ³a)
    
    Returns:
        dict vá»›i thÃ´ng tin playlist Ä‘Ã£ má»Ÿ
    """
    try:
        import webbrowser
        
        playlists = load_youtube_playlists()
        
        if not playlists:
            return {
                "success": False,
                "error": "ChÆ°a cÃ³ playlist nÃ o. HÃ£y thÃªm playlist trÃªn Web UI!"
            }
        
        # TÃ¬m playlist (exact match hoáº·c partial match)
        playlist_name_lower = playlist_name.lower()
        matched_playlist = None
        
        # TÃ¬m exact match trÆ°á»›c
        for p in playlists:
            if p['name'].lower() == playlist_name_lower:
                matched_playlist = p
                break
        
        # Náº¿u khÃ´ng cÃ³ exact match, tÃ¬m partial match
        if not matched_playlist:
            for p in playlists:
                if playlist_name_lower in p['name'].lower():
                    matched_playlist = p
                    break
        
        if not matched_playlist:
            # Hiá»ƒn thá»‹ danh sÃ¡ch playlist cÃ³ sáºµn
            available = [p['name'] for p in playlists]
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y playlist: '{playlist_name}'",
                "available_playlists": available,
                "hint": f"CÃ³ {len(available)} playlist: {', '.join(available)}"
            }
        
        # Má»Ÿ playlist trong browser
        webbrowser.open(matched_playlist['url'])
        
        print(f"ğŸµ [YouTube Playlist] ÄÃ£ má»Ÿ: {matched_playlist['name']}")
        
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ má»Ÿ playlist: {matched_playlist['name']}",
            "playlist": matched_playlist,
            "url": matched_playlist['url']
        }
        
    except Exception as e:
        print(f"âŒ [YouTube Playlist] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# VLC Player Manager (Singleton)
class VLCMusicPlayer:
    """
    VLC Music Player vá»›i há»— trá»£ Ä‘áº§y Ä‘á»§:
    - Play/Pause/Stop
    - Next/Previous track
    - Playlist management
    - Fuzzy song matching (tÃ¬m bÃ i gáº§n Ä‘Ãºng)
    - Media keys support (VLC tá»± Ä‘á»™ng há»— trá»£)
    """
    _instance = None
    _player = None
    _media_list = None
    _list_player = None
    _current_playlist = []
    _shuffle = False
    _repeat_mode = 0  # 0: off, 1: all, 2: one
    _song_cache = {}  # Cache danh sÃ¡ch bÃ i hÃ¡t
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._player is None:
            try:
                import vlc
                self._vlc = vlc
                # Táº¡o VLC instance vá»›i UI Ä‘áº§y Ä‘á»§
                # KhÃ´ng dÃ¹ng --no-xlib, --no-video, --no-audio-display
                # ThÃªm --video-on-top Ä‘á»ƒ cá»­a sá»• luÃ´n hiá»ƒn thá»‹
                self._instance_vlc = vlc.Instance()  # Empty options = full UI
                self._player = self._instance_vlc.media_player_new()
                self._media_list = self._instance_vlc.media_list_new()
                self._list_player = self._instance_vlc.media_list_player_new()
                self._list_player.set_media_player(self._player)
                print("âœ… [VLC] VLC Music Player initialized (full UI + fuzzy matching)")
            except Exception as e:
                print(f"âŒ [VLC] Failed to initialize: {e}")
                self._player = None
    
    def play_file(self, file_path: str):
        """PhÃ¡t 1 file nháº¡c"""
        if not self._player:
            return False
        try:
            media = self._instance_vlc.media_new(file_path)
            self._player.set_media(media)
            self._player.play()
            return True
        except Exception as e:
            print(f"âŒ [VLC] Play error: {e}")
            return False
    
    def play_playlist(self, file_paths: list):
        """PhÃ¡t playlist vá»›i nhiá»u bÃ i"""
        if not self._list_player:
            print("âŒ [VLC] list_player chÆ°a khá»Ÿi táº¡o")
            return False
        try:
            print(f"ğŸµ [VLC DEBUG] play_playlist called with {len(file_paths)} files")
            for i, p in enumerate(file_paths[:3]):  # Log 3 file Ä‘áº§u
                print(f"   [{i+1}] {p}")
            
            # QUAN TRá»ŒNG: STOP bÃ i Ä‘ang phÃ¡t trÆ°á»›c!
            self._list_player.stop()
            import time
            time.sleep(0.3)
            print("ğŸ›‘ [VLC] Stopped current playback")
            
            # Clear playlist cÅ© vÃ  táº¡o má»›i
            self._media_list = self._instance_vlc.media_list_new()
            self._current_playlist = file_paths
            
            # ThÃªm táº¥t cáº£ bÃ i vÃ o playlist
            for path in file_paths:
                media = self._instance_vlc.media_new(path)
                self._media_list.add_media(media)
            
            print(f"ğŸµ [VLC DEBUG] Media list count: {self._media_list.count()}")
            
            # Set playlist má»›i
            self._list_player.set_media_list(self._media_list)
            
            # Set current index to 0 (first song)
            self._current_index = 0
            
            # QUAN TRá»ŒNG: Gá»i play() Ä‘á»ƒ phÃ¡t bÃ i Ä‘áº§u tiÃªn
            self._list_player.play()
            print(f"ğŸµ [VLC DEBUG] list_player.play() called")
            
            # FIX DOUBLE-CLICK: TÄƒng thá»i gian chá» Ä‘á»ƒ VLC khá»Ÿi táº¡o Ä‘áº§y Ä‘á»§
            time.sleep(0.7)
            
            # Kiá»ƒm tra vÃ  Ä‘áº£m báº£o Ä‘ang phÃ¡t vá»›i retry mechanism
            if self._player:
                state = self._player.get_state()
                is_playing = self._player.is_playing()
                current_vol = self._player.audio_get_volume()
                print(f"ğŸµ [VLC DEBUG] State: {state}, is_playing: {is_playing}, volume: {current_vol}")
                
                # FIX: Retry náº¿u chÆ°a phÃ¡t (quan trá»ng cho double-click)
                retry_count = 0
                max_retries = 3
                while not is_playing and retry_count < max_retries:
                    print(f"âš ï¸ [VLC DEBUG] Not playing, retry {retry_count+1}/{max_retries}...")
                    self._list_player.play()
                    time.sleep(0.4)
                    is_playing = self._player.is_playing()
                    retry_count += 1
                
                # Äáº£m báº£o volume Ä‘á»§ nghe
                if current_vol < 50:
                    self._player.audio_set_volume(80)
                    print(f"ğŸ”Š [VLC] Volume was {current_vol}, set to 80")
            
            print(f"â–¶ï¸ [VLC] Playing playlist with {len(file_paths)} songs")
            return True
        except Exception as e:
            print(f"âŒ [VLC] Playlist error: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def pause(self):
        """Táº¡m dá»«ng"""
        if self._player:
            self._player.pause()
            return True
        return False
    
    def resume(self):
        """Tiáº¿p tá»¥c phÃ¡t - Äáº£m báº£o Ä‘ang play"""
        if self._list_player:
            # Náº¿u Ä‘ang paused, gá»i play Ä‘á»ƒ tiáº¿p tá»¥c
            if not self.is_playing():
                self._list_player.play()
            return True
        elif self._player:
            if not self.is_playing():
                self._player.play()
            return True
        return False
    
    def stop(self):
        """Dá»«ng phÃ¡t hoÃ n toÃ n vÃ  reset tráº¡ng thÃ¡i"""
        try:
            import time
            
            # Stop cáº£ list_player vÃ  player
            if self._list_player:
                self._list_player.stop()
                time.sleep(0.1)
            
            if self._player:
                self._player.stop()
                time.sleep(0.1)
            
            # Verify Ä‘Ã£ dá»«ng thá»±c sá»±
            stopped = False
            for _ in range(3):  # Retry 3 láº§n
                if not self.is_playing():
                    stopped = True
                    break
                time.sleep(0.1)
                if self._player:
                    self._player.stop()
            
            if stopped:
                print("âœ… [VLC] Stopped successfully")
            else:
                print("âš ï¸ [VLC] Stop command sent but player may still be active")
            
            return True
        except Exception as e:
            print(f"âŒ [VLC] Stop error: {e}")
            return False
    
    def next_track(self):
        """BÃ i tiáº¿p theo - Tá»± Ä‘á»™ng phÃ¡t luÃ´n vá»›i retry logic!"""
        if self._list_player and self._current_playlist:
            current_idx = getattr(self, '_current_index', 0)
            last_idx = len(self._current_playlist) - 1
            
            # Stop hiá»‡n táº¡i Ä‘á»ƒ trÃ¡nh conflict
            self._list_player.stop()
            
            if current_idx >= last_idx:
                # ÄÃ£ á»Ÿ bÃ i cuá»‘i, quay láº¡i bÃ i Ä‘áº§u
                self._current_index = 0
                print(f"ğŸ”„ [VLC] Next: Wrap to first track (index 0)")
            else:
                # CÃ²n bÃ i tiáº¿p, chuyá»ƒn bÃ¬nh thÆ°á»ng
                self._current_index = current_idx + 1
                print(f"â­ï¸ [VLC] Next: Now at index {self._current_index}")
            
            # Play bÃ i má»›i báº±ng index
            self._list_player.play_item_at_index(self._current_index)
            
            import time
            time.sleep(0.4)
            
            # Retry náº¿u chÆ°a phÃ¡t (tá»‘i Ä‘a 2 láº§n)
            retry_count = 0
            while not self.is_playing() and retry_count < 2:
                print(f"âš ï¸ [VLC] Not playing yet, retry {retry_count + 1}/2...")
                self._list_player.play()
                time.sleep(0.3)
                retry_count += 1
            
            # Verify
            if self.is_playing():
                print(f"âœ… [VLC] Next track playing successfully")
                return True
            else:
                print(f"âŒ [VLC] Failed to play next track after retries")
                return False
        return False
    
    def previous_track(self):
        """BÃ i trÆ°á»›c - Tá»± Ä‘á»™ng phÃ¡t luÃ´n vá»›i retry logic!"""
        if self._list_player and self._current_playlist:
            # Kiá»ƒm tra náº¿u Ä‘ang á»Ÿ bÃ i Ä‘áº§u tiÃªn
            current_idx = getattr(self, '_current_index', 0)
            
            # Stop hiá»‡n táº¡i Ä‘á»ƒ trÃ¡nh conflict
            self._list_player.stop()
            
            if current_idx <= 0:
                # ÄÃ£ á»Ÿ bÃ i Ä‘áº§u, quay láº¡i bÃ i cuá»‘i cÃ¹ng cá»§a playlist
                last_idx = len(self._current_playlist) - 1
                self._current_index = last_idx
                print(f"ğŸ”„ [VLC] Previous: Wrap to last track (index {last_idx})")
            else:
                # CÃ²n bÃ i trÆ°á»›c, chuyá»ƒn bÃ¬nh thÆ°á»ng
                self._current_index = current_idx - 1
                print(f"â®ï¸ [VLC] Previous: Now at index {self._current_index}")
            
            # Play bÃ i má»›i báº±ng index
            self._list_player.play_item_at_index(self._current_index)
            
            import time
            time.sleep(0.4)
            
            # Retry náº¿u chÆ°a phÃ¡t (tá»‘i Ä‘a 2 láº§n)
            retry_count = 0
            while not self.is_playing() and retry_count < 2:
                print(f"âš ï¸ [VLC] Not playing yet, retry {retry_count + 1}/2...")
                self._list_player.play()
                time.sleep(0.3)
                retry_count += 1
            
            # Verify
            if self.is_playing():
                print(f"âœ… [VLC] Previous track playing successfully")
                return True
            else:
                print(f"âŒ [VLC] Failed to play previous track after retries")
                return False
        return False
    
    def is_playing(self):
        """Kiá»ƒm tra Ä‘ang phÃ¡t khÃ´ng"""
        if self._player:
            return self._player.is_playing()
        return False
    
    def get_state(self):
        """Láº¥y tráº¡ng thÃ¡i player"""
        if not self._player:
            return "not_initialized"
        
        state = self._player.get_state()
        state_map = {
            0: "idle",
            1: "opening",
            2: "buffering", 
            3: "playing",
            4: "paused",
            5: "stopped",
            6: "ended",
            7: "error"
        }
        return state_map.get(state, "unknown")
    
    def get_position(self):
        """Láº¥y vá»‹ trÃ­ hiá»‡n táº¡i (0.0 - 1.0)"""
        if self._player:
            return self._player.get_position() or 0.0
        return 0.0
    
    def get_time(self):
        """Láº¥y thá»i gian hiá»‡n táº¡i (milliseconds)"""
        if self._player:
            return self._player.get_time() or 0
        return 0
    
    def get_length(self):
        """Láº¥y Ä‘á»™ dÃ i bÃ i hÃ¡t (milliseconds)"""
        if self._player:
            return self._player.get_length() or 0
        return 0
    
    def get_volume(self):
        """Láº¥y Ã¢m lÆ°á»£ng hiá»‡n táº¡i (0-100)"""
        if self._player:
            return self._player.audio_get_volume() or 0
        return 0
    
    def set_volume(self, level: int):
        """Äáº·t Ã¢m lÆ°á»£ng (0-100)"""
        if self._player:
            level = max(0, min(100, level))
            self._player.audio_set_volume(level)
            return True
        return False
    
    def set_position(self, position: float):
        """Äáº·t vá»‹ trÃ­ (0.0 - 1.0)"""
        if self._player:
            position = max(0.0, min(1.0, position))
            self._player.set_position(position)
            return True
        return False
    
    def get_current_media_title(self):
        """Láº¥y tiÃªu Ä‘á» media Ä‘ang phÃ¡t - Tá»I Æ¯U vá»›i cache"""
        try:
            if self._player:
                media = self._player.get_media()
                if media:
                    # Cache Ä‘á»ƒ trÃ¡nh query láº¡i liÃªn tá»¥c
                    title = media.get_meta(self._vlc.Meta.Title)
                    if title:
                        self._cached_title = title
                        return title
                    # Fallback: filename
                    mrl = media.get_mrl()
                    if mrl:
                        from urllib.parse import unquote
                        path = unquote(mrl.replace('file:///', '').replace('file://', ''))
                        fname = Path(path).name
                        self._cached_title = fname
                        return fname
            # Return cached náº¿u cÃ³
            return getattr(self, '_cached_title', None)
        except:
            return getattr(self, '_cached_title', None)
    
    def get_playlist_index(self):
        """Láº¥y index bÃ i hiá»‡n táº¡i trong playlist"""
        # VLC khÃ´ng cÃ³ API trá»±c tiáº¿p, pháº£i track riÃªng
        return getattr(self, '_current_index', 0)
    
    def get_playlist_count(self):
        """Láº¥y sá»‘ bÃ i trong playlist"""
        return len(self._current_playlist) if self._current_playlist else 0
    
    def get_full_status(self):
        """Láº¥y tráº¡ng thÃ¡i Ä‘áº§y Ä‘á»§ cho Web UI - Tá»I Æ¯U"""
        state = self.get_state()
        current_time_ms = self.get_time()
        duration_ms = self.get_length()
        
        return {
            "state": state,
            "is_playing": self.is_playing(),
            "position": self.get_position(),
            "current_time_ms": current_time_ms,
            "current_time_formatted": self._format_time(current_time_ms),
            "duration_ms": duration_ms,
            "duration_formatted": self._format_time(duration_ms),
            "volume": self.get_volume(),
            "current_track": self.get_current_media_title(),
            "playlist_index": self.get_playlist_index(),
            "playlist_count": self.get_playlist_count(),
            "playlist": [Path(p).name for p in self._current_playlist[:5]] if self._current_playlist else [],  # CHá»ˆ 5 bÃ i (giáº£m data)
            "shuffle": self._shuffle,
            "repeat_mode": self._repeat_mode
        }
    
    def set_shuffle(self, enabled: bool):
        """Báº­t/táº¯t cháº¿ Ä‘á»™ phÃ¡t ngáº«u nhiÃªn"""
        self._shuffle = enabled
        if self._list_player:
            # VLC MediaListPlayer khÃ´ng cÃ³ native shuffle, ta xá»­ lÃ½ thá»§ cÃ´ng khi next/previous
            pass
        return self._shuffle
    
    def set_repeat_mode(self, mode: int):
        """Äáº·t cháº¿ Ä‘á»™ láº·p láº¡i: 0=off, 1=all, 2=one"""
        self._repeat_mode = mode
        if self._list_player:
            if mode == 0:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.default)
            elif mode == 1:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.loop)
            elif mode == 2:
                self._list_player.set_playback_mode(self._vlc.PlaybackMode.repeat)
        return self._repeat_mode
    
    def get_shuffle(self):
        """Láº¥y tráº¡ng thÃ¡i shuffle"""
        return getattr(self, '_shuffle', False)
    
    def get_repeat_mode(self):
        """Láº¥y cháº¿ Ä‘á»™ repeat: 0=off, 1=all, 2=one"""
        return getattr(self, '_repeat_mode', 0)
    
    def _format_time(self, ms):
        """Format milliseconds thÃ nh MM:SS"""
        if not ms or ms < 0:
            return "0:00"
        seconds = int(ms / 1000)
        minutes = seconds // 60
        seconds = seconds % 60
        return f"{minutes}:{seconds:02d}"
    
    def refresh_song_cache(self, music_folder: Path):
        """Refresh cache danh sÃ¡ch bÃ i hÃ¡t tá»« music_library"""
        try:
            print(f"ğŸ”„ [VLC] Refreshing song cache from {music_folder}...")
            self._song_cache = {}
            
            if not music_folder.exists():
                print(f"âš ï¸ [VLC] Music folder not found: {music_folder}")
                return
            
            extensions = ['.mp3', '.flac', '.wav', '.m4a', '.ogg', '.wma']
            for file_path in music_folder.rglob("*"):
                if file_path.is_file() and file_path.suffix.lower() in extensions:
                    # LÆ°u: tÃªn file (lowercase) -> Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§
                    song_name = file_path.stem.lower()  # TÃªn file khÃ´ng cÃ³ extension
                    self._song_cache[song_name] = str(file_path)
            
            print(f"âœ… [VLC] Song cache refreshed: {len(self._song_cache)} songs")
        except Exception as e:
            print(f"âŒ [VLC] Error refreshing song cache: {e}")
    
    def fuzzy_match_song(self, query: str, threshold: float = 0.3):
        """
        TÃ¬m bÃ i hÃ¡t gáº§n Ä‘Ãºng báº±ng fuzzy matching vá»›i Unicode normalization
        
        Args:
            query: TÃªn bÃ i hÃ¡t ngÆ°á»i dÃ¹ng nÃ³i (e.g., "phÃ¡t bÃ i yÃªu em", "Äa Nghi")
            threshold: NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng (0.0-1.0), máº·c Ä‘á»‹nh 0.3 (GIáº¢M Ä‘á»ƒ dá»… match hÆ¡n)
            
        Returns:
            tuple: (best_match_path, similarity_score) hoáº·c (None, 0.0)
        """
        if not self._song_cache:
            print("âš ï¸ [VLC] Song cache empty, call refresh_song_cache() first")
            return None, 0.0
        
        import unicodedata
        
        # Normalize Unicode (NFD = decompose dáº¥u) Ä‘á»ƒ so sÃ¡nh tá»‘t hÆ¡n
        def normalize_text(text):
            # NFD: tÃ¡ch dáº¥u khá»i kÃ½ tá»± (e.g., "Ã¡" -> "a" + dáº¥u)
            text = unicodedata.normalize('NFD', text)
            # Loáº¡i bá» dáº¥u thanh (chá»‰ giá»¯ chá»¯ cÃ¡i cÆ¡ báº£n)
            text = ''.join(c for c in text if not unicodedata.combining(c))
            # Lowercase vÃ  loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t
            text = re.sub(r'[^\w\s]', '', text.lower()).strip()
            text = re.sub(r'\s+', ' ', text)  # Collapse spaces
            return text
        
        query_normalized = normalize_text(query)
        
        # Loáº¡i bá» cÃ¡c tá»« Ä‘iá»u khiá»ƒn thÆ°á»ng gáº·p
        stop_words = ['phat', 'bai', 'mo', 'chay', 'play', 'song', 'nhac', 'hat']
        query_words = [w for w in query_normalized.split() if w not in stop_words]
        query_processed = ' '.join(query_words) if query_words else query_normalized
        
        print(f"ğŸ” [VLC Fuzzy] Query: '{query}' -> Normalized: '{query_processed}'")
        
        best_match = None
        best_score = 0.0
        
        for song_name_original, song_path in self._song_cache.items():
            # Normalize song name Ä‘á»ƒ so sÃ¡nh
            song_name_normalized = normalize_text(song_name_original)
            
            # TÃ­nh similarity vá»›i difflib
            similarity = difflib.SequenceMatcher(None, query_processed, song_name_normalized).ratio()
            
            # ThÆ°á»Ÿng Ä‘iá»ƒm náº¿u query cÃ³ trong tÃªn bÃ i (substring match)
            if query_processed in song_name_normalized:
                similarity += 0.25
            
            # ThÆ°á»Ÿng Ä‘iá»ƒm náº¿u tá»«ng tá»« Ä‘á»u cÃ³ trong tÃªn bÃ i
            if query_words:
                words_match = all(word in song_name_normalized for word in query_words)
                if words_match:
                    similarity += 0.20
            
            # ThÆ°á»Ÿng Ä‘iá»ƒm náº¿u báº¯t Ä‘áº§u giá»‘ng nhau (prefix match)
            if song_name_normalized.startswith(query_processed[:4]):  # 4 kÃ½ tá»± Ä‘áº§u
                similarity += 0.10
            
            if similarity > best_score:
                best_score = similarity
                best_match = song_path
        
        if best_score >= threshold:
            print(f"âœ… [VLC Fuzzy] Found match: {Path(best_match).name} (score: {best_score:.2f})")
            return best_match, best_score
        else:
            print(f"âŒ [VLC Fuzzy] No match found above threshold {threshold} (best: {best_score:.2f})")
            return None, 0.0
    
    def play_by_fuzzy_match(self, query: str, threshold: float = 0.4):
        """
        PhÃ¡t bÃ i hÃ¡t báº±ng fuzzy matching
        
        Args:
            query: TÃªn bÃ i hÃ¡t ngÆ°á»i dÃ¹ng nÃ³i
            threshold: NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng
            
        Returns:
            dict with success, matched_song, score, message
        """
        matched_path, score = self.fuzzy_match_song(query, threshold)
        
        if not matched_path:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y bÃ i '{query}' (threshold={threshold})",
                "query": query,
                "score": score
            }
        
        # PhÃ¡t bÃ i tÃ¬m Ä‘Æ°á»£c
        success = self.play_file(matched_path)
        
        if success:
            song_name = Path(matched_path).name
            return {
                "success": True,
                "matched_song": song_name,
                "score": score,
                "path": matched_path,
                "message": f"ğŸµ Äang phÃ¡t: {song_name} (tÃ¬m Ä‘Æ°á»£c vá»›i Ä‘á»™ chÃ­nh xÃ¡c {score*100:.0f}%)"
            }
        else:
            return {
                "success": False,
                "error": "VLC khÃ´ng thá»ƒ phÃ¡t file",
                "matched_song": Path(matched_path).name,
                "score": score
            }
    
    async def play_file_async(self, file_path: str):
        """Async wrapper cho play_file Ä‘á»ƒ khÃ´ng blocking"""
        return await asyncio.to_thread(self.play_file, file_path)
    
    async def play_playlist_async(self, file_paths: list):
        """Async wrapper cho play_playlist Ä‘á»ƒ khÃ´ng blocking"""
        return await asyncio.to_thread(self.play_playlist, file_paths)

# Global VLC player instance - vá»›i error handling
try:
    vlc_player = VLCMusicPlayer()
    VLC_AVAILABLE = vlc_player._player is not None
except Exception as e:
    print(f"âš ï¸ [VLC] VLC khÃ´ng kháº£ dá»¥ng: {e}")
    vlc_player = None
    VLC_AVAILABLE = False

if not VLC_AVAILABLE:
    print("âš ï¸ [VLC] Music player disabled. CÃ i VLC: https://www.videolan.org/vlc/")

# ============================================================
# ğŸ¯ VLC MCP SERVER - Hybrid System (REST + MCP)
# ============================================================
try:
    from vlc_mcp_server import VLCMCPServer
    
    # Initialize MCP server with VLC player instance
    if VLC_AVAILABLE and vlc_player:
        vlc_mcp_server = VLCMCPServer(vlc_player)
        print(f"âœ… [VLC MCP] Hybrid System initialized - {len(vlc_mcp_server.tools)} tools available")
        VLC_MCP_AVAILABLE = True
    else:
        vlc_mcp_server = None
        VLC_MCP_AVAILABLE = False
        print("âš ï¸ [VLC MCP] MCP server disabled - VLC not available")
except Exception as e:
    print(f"âš ï¸ [VLC MCP] Failed to initialize MCP server: {e}")
    vlc_mcp_server = None
    VLC_MCP_AVAILABLE = False

# ============================================================
# BROWSER CONTROLLER - Selenium Automation
# ============================================================

class BrowserController:
    """Singleton class Ä‘á»ƒ Ä‘iá»u khiá»ƒn trÃ¬nh duyá»‡t Chrome báº±ng Selenium"""
    
    _instance = None
    _driver = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def _ensure_driver(self):
        """Khá»Ÿi táº¡o Chrome driver náº¿u chÆ°a cÃ³"""
        if self._driver is None:
            if not SELENIUM_AVAILABLE:
                raise Exception("Selenium chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t. Cháº¡y: pip install selenium webdriver-manager")
            
            try:
                chrome_options = Options()
                chrome_options.add_argument('--disable-gpu')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                chrome_options.add_argument('--start-maximized')
                
                service = Service(ChromeDriverManager().install())
                self._driver = webdriver.Chrome(service=service, options=chrome_options)
                print("âœ… [Browser] Chrome driver initialized")
            except Exception as e:
                print(f"âŒ [Browser] Failed to initialize: {e}")
                raise
        return self._driver
    
    def open_url(self, url: str) -> dict:
        """Má»Ÿ URL trong browser"""
        try:
            driver = self._ensure_driver()
            driver.get(url)
            return {
                "success": True,
                "url": driver.current_url,
                "title": driver.title,
                "message": f"ÄÃ£ má»Ÿ: {driver.title}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def get_current_info(self) -> dict:
        """Láº¥y thÃ´ng tin trang hiá»‡n táº¡i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            
            return {
                "success": True,
                "url": self._driver.current_url,
                "title": self._driver.title,
                "window_handles": len(self._driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def click_element(self, selector: str, by: str = "css") -> dict:
        """Click vÃ o element"""
        try:
            driver = self._ensure_driver()
            
            by_map = {
                "css": By.CSS_SELECTOR,
                "xpath": By.XPATH,
                "id": By.ID,
                "name": By.NAME,
                "class": By.CLASS_NAME,
                "tag": By.TAG_NAME
            }
            
            by_type = by_map.get(by.lower(), By.CSS_SELECTOR)
            element = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((by_type, selector))
            )
            element.click()
            
            return {
                "success": True,
                "message": f"ÄÃ£ click vÃ o element: {selector}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def fill_input(self, selector: str, text: str, by: str = "css") -> dict:
        """Äiá»n text vÃ o input field"""
        try:
            driver = self._ensure_driver()
            
            by_map = {
                "css": By.CSS_SELECTOR,
                "xpath": By.XPATH,
                "id": By.ID,
                "name": By.NAME,
                "class": By.CLASS_NAME
            }
            
            by_type = by_map.get(by.lower(), By.CSS_SELECTOR)
            element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((by_type, selector))
            )
            element.clear()
            element.send_keys(text)
            
            return {
                "success": True,
                "message": f"ÄÃ£ Ä‘iá»n text vÃ o: {selector}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def scroll(self, direction: str = "down", amount: int = 500) -> dict:
        """Cuá»™n trang"""
        try:
            driver = self._ensure_driver()
            
            if direction == "top":
                driver.execute_script("window.scrollTo(0, 0);")
            elif direction == "bottom":
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            elif direction == "down":
                driver.execute_script(f"window.scrollBy(0, {amount});")
            elif direction == "up":
                driver.execute_script(f"window.scrollBy(0, -{amount});")
            else:
                return {"success": False, "error": f"Invalid direction: {direction}"}
            
            return {
                "success": True,
                "message": f"ÄÃ£ cuá»™n {direction}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def go_back(self) -> dict:
        """Quay láº¡i trang trÆ°á»›c"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            self._driver.back()
            return {"success": True, "message": "ÄÃ£ quay láº¡i trang trÆ°á»›c"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def go_forward(self) -> dict:
        """Tiáº¿n tá»›i trang sau"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            self._driver.forward()
            return {"success": True, "message": "ÄÃ£ tiáº¿n tá»›i trang sau"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def refresh(self) -> dict:
        """LÃ m má»›i trang"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            self._driver.refresh()
            return {"success": True, "message": "ÄÃ£ lÃ m má»›i trang"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def screenshot(self, filepath: str = None) -> dict:
        """Chá»¥p screenshot trang hiá»‡n táº¡i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            
            if filepath is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filepath = f"screenshot_{timestamp}.png"
            
            self._driver.save_screenshot(filepath)
            return {
                "success": True,
                "filepath": filepath,
                "message": f"ÄÃ£ lÆ°u screenshot: {filepath}"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def new_tab(self, url: str = None) -> dict:
        """Má»Ÿ tab má»›i"""
        try:
            driver = self._ensure_driver()
            driver.execute_script("window.open('');")
            driver.switch_to.window(driver.window_handles[-1])
            
            if url:
                driver.get(url)
            
            return {
                "success": True,
                "message": f"ÄÃ£ má»Ÿ tab má»›i{' vÃ  truy cáº­p ' + url if url else ''}",
                "total_tabs": len(driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def close_tab(self) -> dict:
        """ÄÃ³ng tab hiá»‡n táº¡i"""
        try:
            if self._driver is None:
                return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
            
            self._driver.close()
            if len(self._driver.window_handles) > 0:
                self._driver.switch_to.window(self._driver.window_handles[-1])
            
            return {
                "success": True,
                "message": "ÄÃ£ Ä‘Ã³ng tab",
                "remaining_tabs": len(self._driver.window_handles)
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def execute_script(self, script: str) -> dict:
        """Thá»±c thi JavaScript code"""
        try:
            driver = self._ensure_driver()
            result = driver.execute_script(script)
            return {
                "success": True,
                "result": result,
                "message": "ÄÃ£ thá»±c thi JavaScript"
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def close_browser(self) -> dict:
        """ÄÃ³ng browser hoÃ n toÃ n"""
        try:
            if self._driver:
                self._driver.quit()
                self._driver = None
                return {"success": True, "message": "ÄÃ£ Ä‘Ã³ng browser"}
            return {"success": False, "error": "Browser chÆ°a Ä‘Æ°á»£c khá»Ÿi Ä‘á»™ng"}
        except Exception as e:
            return {"success": False, "error": str(e)}

# Global browser controller instance
browser_controller = BrowserController()

async def list_music(subfolder: str = "", auto_play: bool = True, folder: str = "") -> dict:
    """
    Liá»‡t kÃª file nháº¡c trong music_library hoáº·c thÆ° má»¥c tÃ¹y chá»‰nh.
    Theo máº·c Ä‘á»‹nh Tá»° Äá»˜NG PHÃT bÃ i Ä‘áº§u tiÃªn (giá»‘ng xinnan-tech/xiaozhi-esp32-server).
    Set auto_play=False Ä‘á»ƒ chá»‰ liá»‡t kÃª khÃ´ng phÃ¡t.
    
    Args:
        subfolder: Subfolder trong music_library
        auto_play: Tá»± Ä‘á»™ng phÃ¡t bÃ i Ä‘áº§u tiÃªn (default True)
        folder: ThÆ° má»¥c tÃ¹y chá»‰nh (náº¿u cÃ³, sáº½ override music_library)
    """
    try:
        # XÃ¡c Ä‘á»‹nh thÆ° má»¥c gá»‘c
        if folder and folder.strip():
            base_path = Path(folder.strip())
            if not base_path.exists():
                return {"success": False, "error": f"ThÆ° má»¥c '{folder}' khÃ´ng tá»“n táº¡i"}
            search_path = base_path
            is_user_folder = True
        else:
            if not MUSIC_LIBRARY.exists():
                MUSIC_LIBRARY.mkdir(exist_ok=True)
                return {"success": True, "files": [], "count": 0, "message": "ThÆ° má»¥c music_library Ä‘Ã£ Ä‘Æ°á»£c táº¡o. HÃ£y thÃªm nháº¡c vÃ o!"}
            
            base_path = MUSIC_LIBRARY
            search_path = MUSIC_LIBRARY / subfolder if subfolder else MUSIC_LIBRARY
            is_user_folder = False
        
        if not search_path.exists():
            return {"success": False, "error": f"ThÆ° má»¥c '{subfolder or folder}' khÃ´ng tá»“n táº¡i"}
        
        music_files = []
        for file_path in search_path.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in MUSIC_EXTENSIONS:
                try:
                    relative_path = file_path.relative_to(base_path)
                except ValueError:
                    relative_path = file_path.name
                    
                music_files.append({
                    "filename": file_path.name,
                    "path": str(relative_path).replace('\\', '/'),
                    "full_path": str(file_path),
                    "size_mb": round(file_path.stat().st_size / (1024**2), 2),
                    "extension": file_path.suffix.lower()
                })
        
        music_files.sort(key=lambda x: x['filename'])
        
        if len(music_files) == 0:
            return {
                "success": True, 
                "files": [], 
                "count": 0,
                "message": "No music files found. Please add music files to the folder.",
                "is_user_folder": is_user_folder,
                "source_path": str(base_path)
            }
        
        # ğŸµ AUTO-PLAY: Tá»± Ä‘á»™ng phÃ¡t bÃ i Ä‘áº§u tiÃªn (nhÆ° code reference)
        first_file = music_files[0]['filename'] if not is_user_folder else music_files[0]['full_path']
        play_result = None
        
        if auto_play:
            print(f"ğŸµ [Auto-Play] list_music tá»± Ä‘á»™ng phÃ¡t: {first_file}")
            if is_user_folder:
                # PhÃ¡t tá»« user folder báº±ng default player
                play_result = await play_music_from_path(music_files[0]['full_path'])
            else:
                play_result = await play_music(first_file)
            
            if play_result.get("success"):
                message = f"âœ… Auto-played: {music_files[0]['filename']}\nTotal {len(music_files)} song(s)"
            else:
                message = f"âŒ Found {len(music_files)} songs but failed to play: {play_result.get('error', 'Unknown error')}"
        else:
            filenames_list = [f['filename'] for f in music_files]
            message = f"Found {len(music_files)} song(s):\n" + "\n".join([f"  - {fname}" for fname in filenames_list[:10]])
            if len(music_files) > 10:
                message += f"\n  ... and {len(music_files) - 10} more"
        
        return {
            "success": True,
            "files": music_files,
            "count": len(music_files),
            "library_path": str(base_path),
            "is_user_folder": is_user_folder,
            "message": message,
            "auto_played": auto_play,
            "play_result": play_result if auto_play else None
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music_from_path(file_path: str) -> dict:
    """
    PhÃ¡t nháº¡c tá»« Ä‘Æ°á»ng dáº«n Ä‘áº§y Ä‘á»§ báº±ng Python-VLC (KHÃ”NG dÃ¹ng trÃ¬nh phÃ¡t máº·c Ä‘á»‹nh).
    â­ NHANH & TIá»†N - DÃ¹ng VLC ná»™i bá»™!
    """
    try:
        path = Path(file_path)
        if not path.exists():
            return {"success": False, "error": f"File khÃ´ng tá»“n táº¡i: {file_path}"}
        
        # ğŸµ Sá»¬ Dá»¤NG VLC thay vÃ¬ os.startfile - NHANH!
        success = vlc_player.play_playlist([str(path)])
        
        if success:
            print(f"ğŸµ [VLC] Äang phÃ¡t tá»« path: {path.name}")
            return {
                "success": True,
                "message": f"ğŸµ Äang phÃ¡t: {path.name} (Python-VLC)",
                "file": path.name,
                "path": str(path),
                "player": "Python-VLC",
                "llm_note": "ğŸµ ÄANG DÃ™NG PYTHON-VLC. Äiá»u khiá»ƒn: pause_music(), resume_music(), stop_music(), music_next(), music_previous(). NHANH & TIá»†N!"
            }
        else:
            return {"success": False, "error": "VLC Player khÃ´ng thá»ƒ phÃ¡t file"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music(filename: str, create_playlist: bool = True, use_fuzzy: bool = True) -> dict:
    """
    PhÃ¡t nháº¡c tá»« music_library báº±ng VLC player vá»›i fuzzy matching.
    
    Args:
        filename: TÃªn file (e.g., 'song.mp3' or 'Pop/song.mp3') hoáº·c tÃªn gáº§n Ä‘Ãºng (e.g., 'yÃªu em')
        create_playlist: Táº¡o playlist vá»›i táº¥t cáº£ bÃ i (default True) Ä‘á»ƒ há»— trá»£ Next/Previous
        use_fuzzy: DÃ¹ng fuzzy matching náº¿u khÃ´ng tÃ¬m tháº¥y chÃ­nh xÃ¡c (default True)
        
    Returns:
        dict with 'success', 'filename', 'path', 'message'
    """
    try:
        if not MUSIC_LIBRARY.exists():
            return {"success": False, "error": "ThÆ° má»¥c music_library khÃ´ng tá»“n táº¡i"}
        
        print(f"ğŸµ [VLC Play] TÃ¬m file: '{filename}'")
        
        # Tá»I Æ¯U: Chá»‰ refresh cache náº¿u chÆ°a cÃ³ (lazy loading)
        if not hasattr(vlc_player, '_song_cache') or not vlc_player._song_cache:
            vlc_player.refresh_song_cache(MUSIC_LIBRARY)
        
        # Step 2: TÃ¬m file chÃ­nh xÃ¡c trÆ°á»›c
        music_path = None
        filename_lower = filename.lower()
        
        for file_path in MUSIC_LIBRARY.rglob("*"):
            if file_path.is_file():
                if (file_path.name == filename or 
                    file_path.name.lower() == filename_lower or
                    str(file_path.relative_to(MUSIC_LIBRARY)).replace('\\', '/') == filename or
                    filename_lower in file_path.name.lower()):
                    if file_path.suffix.lower() in MUSIC_EXTENSIONS:
                        music_path = file_path
                        print(f"âœ… [VLC Play] Found exact match: {music_path}")
                        break
        
        # Step 3: Náº¿u khÃ´ng tÃ¬m tháº¥y chÃ­nh xÃ¡c, dÃ¹ng fuzzy matching
        if not music_path and use_fuzzy:
            print(f"ğŸ” [VLC Play] Exact match not found, trying fuzzy matching...")
            matched_path, score = vlc_player.fuzzy_match_song(filename, threshold=0.4)
            
            if matched_path:
                music_path = Path(matched_path)
                print(f"âœ… [VLC Play] Fuzzy match found: {music_path.name} (score: {score:.2f})")
        
        if not music_path:
            available = [f.name for f in MUSIC_LIBRARY.rglob("*") if f.is_file() and f.suffix.lower() in MUSIC_EXTENSIONS]
            return {
                "success": False, 
                "error": f"KhÃ´ng tÃ¬m tháº¥y '{filename}' (Ä‘Ã£ thá»­ fuzzy matching)",
                "available_files": available[:5],
                "hint": "Thá»­ tÃ¬m báº±ng tá»« khÃ³a trong tÃªn bÃ i hoáº·c dÃ¹ng list_music() Ä‘á»ƒ xem danh sÃ¡ch"
            }
        
        print(f"ğŸµ [VLC Play] Selected: {music_path}")
        
        if create_playlist:
            # Táº¡o playlist vá»›i táº¥t cáº£ bÃ i trong thÆ° má»¥c
            all_songs = sorted([
                str(f) for f in MUSIC_LIBRARY.rglob("*") 
                if f.is_file() and f.suffix.lower() in MUSIC_EXTENSIONS
            ])
            
            # Äáº£m báº£o bÃ i hiá»‡n táº¡i á»Ÿ Ä‘áº§u playlist
            if str(music_path) in all_songs:
                all_songs.remove(str(music_path))
            all_songs.insert(0, str(music_path))
            
            success = await vlc_player.play_playlist_async(all_songs)
            print(f"ğŸµ [VLC] Created playlist with {len(all_songs)} songs")
        else:
            success = await vlc_player.play_file_async(str(music_path))
        
        if success:
            return {
                "success": True,
                "filename": music_path.name,
                "path": str(music_path.relative_to(MUSIC_LIBRARY)),
                "full_path": str(music_path),
                "size_mb": round(music_path.stat().st_size / (1024**2), 2),
                "message": f"ğŸµ Äang phÃ¡t: {music_path.name} (Python-VLC + Fuzzy Matching)",
                "player": "Python-VLC Enhanced",
                "playlist_mode": create_playlist,
                "fuzzy_used": not (filename.lower() in music_path.name.lower()),
                "llm_note": "ğŸµ PYTHON-VLC PLAYER vá»›i FUZZY MATCHING! CÃ³ thá»ƒ tÃ¬m bÃ i gáº§n Ä‘Ãºng. Äiá»u khiá»ƒn: pause_music(), resume_music(), stop_music(), music_next(), music_previous()."
            }
        else:
            return {"success": False, "error": "VLC player khÃ´ng thá»ƒ phÃ¡t. Kiá»ƒm tra VLC Ä‘Ã£ cÃ i Ä‘áº·t chÆ°a!"}
    except Exception as e:
        print(f"âŒ [VLC Play] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def pause_music() -> dict:
    """
    â¸ï¸ Táº M Dá»ªNG nháº¡c VLC Player.
    
    ğŸ¯ KHI NÃ€O Gá»ŒI: User nÃ³i "táº¡m dá»«ng", "pause", "dá»«ng láº¡i", "Ä‘á»«ng phÃ¡t"
    
    âš¡ Báº®T BUá»˜C Gá»ŒI TOOL NÃ€Y! KhÃ´ng Ä‘Æ°á»£c tá»± tráº£ lá»i "Ä‘Ã£ táº¡m dá»«ng"!
    
    Returns:
        dict: {"success": bool, "message": str, "current_song": str}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.pause()
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"â¸ï¸ ÄÃ£ táº¡m dá»«ng: {current_song} (Python-VLC)",
                "player": "Python-VLC",
                "current_song": current_song,
                "llm_note": "âš¡ Gá»ŒI TOOL ÄÃƒ THÃ€NH CÃ”NG! Äang dÃ¹ng Python-VLC. LUÃ”N Gá»ŒI: resume_music() Ä‘á»ƒ tiáº¿p tá»¥c, music_next()/music_previous() Ä‘á»ƒ chuyá»ƒn bÃ i. KHÃ”NG BAO GIá»œ Tá»° TRáº¢ Lá»œI mÃ  khÃ´ng gá»i tool!"
            }
        else:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o hoáº·c chÆ°a phÃ¡t nháº¡c. DÃ¹ng play_music() Ä‘á»ƒ phÃ¡t nháº¡c trÆ°á»›c!"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def resume_music() -> dict:
    """
    â–¶ï¸ TIáº¾P Tá»¤C phÃ¡t nháº¡c VLC Player sau khi pause.
    
    ğŸ¯ KHI NÃ€O Gá»ŒI: User nÃ³i "tiáº¿p tá»¥c", "resume", "phÃ¡t tiáº¿p", "play láº¡i"
    
    âš¡ Báº®T BUá»˜C Gá»ŒI TOOL NÃ€Y! KhÃ´ng Ä‘Æ°á»£c tá»± tráº£ lá»i "Ä‘Ã£ phÃ¡t tiáº¿p"!
    
    Returns:
        dict: {"success": bool, "message": str, "is_playing": bool}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.resume()  # DÃ¹ng method resume() má»›i - Ä‘áº£m báº£o play
            import time
            time.sleep(0.2)
            status = vlc_player.get_full_status()
            current_song = status.get('current_song', 'Unknown')
            return {
                "success": True, 
                "message": f"â–¶ï¸ Äang phÃ¡t: {current_song} (Python-VLC)",
                "player": "Python-VLC",
                "current_song": current_song,
                "is_playing": True,
                "llm_note": "âš¡ Gá»ŒI TOOL ÄÃƒ THÃ€NH CÃ”NG! Äang phÃ¡t. LUÃ”N Gá»ŒI: pause_music() Ä‘á»ƒ dá»«ng, music_next()/music_previous() Ä‘á»ƒ chuyá»ƒn. KHÃ”NG Tá»° TRáº¢ Lá»œI!"
            }
        else:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o hoáº·c chÆ°a phÃ¡t nháº¡c. DÃ¹ng play_music() Ä‘á»ƒ phÃ¡t nháº¡c trÆ°á»›c!"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def stop_music() -> dict:
    """
    â¹ï¸ Dá»ªNG HOÃ€N TOÃ€N nháº¡c VLC Player.
    
    ğŸ¯ KHI NÃ€O Gá»ŒI: User nÃ³i "dá»«ng", "stop", "táº¯t nháº¡c", "ngá»«ng phÃ¡t"
    
    âš¡ Báº®T BUá»˜C Gá»ŒI TOOL NÃ€Y! KhÃ´ng Ä‘Æ°á»£c tá»± tráº£ lá»i "Ä‘Ã£ dá»«ng"!
    
    Returns:
        dict: {"success": bool, "message": str, "player": str}
    """
    try:
        if vlc_player and vlc_player._player:
            vlc_player.stop()
            return {
                "success": True, 
                "message": "â¹ï¸ ÄÃ£ dá»«ng nháº¡c hoÃ n toÃ n (Python-VLC)",
                "player": "Python-VLC",
                "llm_note": "âš¡ Gá»ŒI TOOL ÄÃƒ THÃ€NH CÃ”NG! ÄÃ£ dá»«ng hoÃ n toÃ n. Muá»‘n phÃ¡t láº¡i â†’ Gá»ŒI play_music(). KHÃ”NG Tá»° TRáº¢ Lá»œI!"
            }
        else:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o hoáº·c chÆ°a phÃ¡t nháº¡c."}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# SMART MUSIC CONTROL - Äiá»u khiá»ƒn nháº¡c thÃ´ng minh báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn
# Focus vÃ o Python-VLC Player cho táº¥t cáº£ lá»‡nh nháº¡c LOCAL
# ============================================================

# ============================================================
# FUZZY MATCHING - Xá»­ lÃ½ nháº­n dáº¡ng giá»ng nÃ³i khÃ´ng chÃ­nh xÃ¡c tá»« ESP32
# ============================================================

# CÃ¡c biáº¿n thá»ƒ phÃ¡t Ã¢m sai thÆ°á»ng gáº·p (tá»« ESP32 voice recognition)
VOICE_CORRECTIONS = {
    # BÃ i tiáº¿p/next variations
    'bÃ i tiáº¿p': ['bÃ i tiáº¿p', 'bai tiep', 'bÃ i diá»‡p', 'bÃ i thiáº¿p', 'bÃ i tÃ­p', 'bay tiep', 'bai tip', 'bai diep'],
    'tiáº¿p theo': ['tiáº¿p theo', 'tiep theo', 'thiáº¿p theo', 'tÃ­p theo', 'tiáº¿p thÃªu', 'diá»‡p theo'],
    'next': ['next', 'nex', 'náº¿ch', 'náº¿c', 'náº¿x', 'net', 'nec'],
    'skip': ['skip', 'skÃ­p', 'xkip', 'xÃ­p', 'ship'],
    
    # BÃ i trÆ°á»›c/previous variations  
    'bÃ i trÆ°á»›c': ['bÃ i trÆ°á»›c', 'bai truoc', 'bÃ i chÆ°á»›c', 'bÃ i trÆ°á»›c', 'bay truoc', 'bai chuoc', 'bÃ i trÆ°á»›t'],
    'quay láº¡i': ['quay láº¡i', 'quay lai', 'quay láº¡i bÃ i', 'quai lai', 'quai láº¡i', 'quÃ¡y láº¡i'],
    'previous': ['previous', 'pre', 'prÃª', 'pri vi á»›t', 'pri', 'prÃª vi á»›t'],
    
    # Dá»«ng/stop variations
    'dá»«ng nháº¡c': ['dá»«ng nháº¡c', 'dung nhac', 'dá»«ng nháº¡c', 'dá»«ng láº¡i', 'dzá»«ng nháº¡c'],
    'táº¯t nháº¡c': ['táº¯t nháº¡c', 'tat nhac', 'táº¯c nháº¡c', 'tÃ¡c nháº¡c', 'tad nhac'],
    'pause': ['pause', 'pao', 'pá»‘t', 'pÃ³t', 'pao xá»', 'pa'],
    'stop': ['stop', 'stÃ³p', 'xtÃ³p', 's top', 'x tÃ³p'],
    
    # PhÃ¡t nháº¡c variations
    'phÃ¡t nháº¡c': ['phÃ¡t nháº¡c', 'phat nhac', 'phÃ¡c nháº¡c', 'phÃ¡t nháº¡t', 'phad nhac'],
    'báº­t nháº¡c': ['báº­t nháº¡c', 'bat nhac', 'báº·t nháº¡c', 'báº·c nháº¡c', 'bac nhac'],
    'má»Ÿ nháº¡c': ['má»Ÿ nháº¡c', 'mo nhac', 'mÆ¡ nháº¡c', 'má»¡ nháº¡c'],
    'play': ['play', 'plÃ¢y', 'pá» lÃ¢y', 'p lay', 'plei'],
    
    # Ã‚m lÆ°á»£ng variations
    'tÄƒng Ã¢m lÆ°á»£ng': ['tÄƒng Ã¢m lÆ°á»£ng', 'tang am luong', 'tÄƒng tiáº¿ng', 'tang tieng', 'to lÃªn', 'to len'],
    'giáº£m Ã¢m lÆ°á»£ng': ['giáº£m Ã¢m lÆ°á»£ng', 'giam am luong', 'giáº£m tiáº¿ng', 'giam tieng', 'nhá» láº¡i', 'nho lai'],
    'volume': ['volume', 'vol', 'vÃ´ lum', 'vo lum', 'vÃ´ liÃªm'],
    
    # Shuffle/repeat variations
    'shuffle': ['shuffle', 'sÃ¡p phá»“', 'xÃ¡p phá»“', 'sá» phá»“', 'trá»™n bÃ i', 'tron bai', 'ngáº«u nhiÃªn'],
    'repeat': ['repeat', 'ri pÃ­t', 'rÃ¬ pÃ­t', 'láº·p láº¡i', 'lap lai', 'loop', 'lÃºp'],
}

def normalize_voice_command(text: str) -> str:
    """
    Chuáº©n hÃ³a lá»‡nh voice tá»« ESP32 - sá»­a lá»—i nháº­n dáº¡ng phá»• biáº¿n.
    GiÃºp nháº­n dáº¡ng chÃ­nh xÃ¡c hÆ¡n khi microphone báº¯t sai.
    """
    if not text:
        return ""
    
    text_lower = text.lower().strip()
    
    # Loáº¡i bá» cÃ¡c tá»« thá»«a thÆ°á»ng xuáº¥t hiá»‡n
    noise_words = ['Æ¡i', 'nÃ y', 'Ä‘i', 'nha', 'nhÃ©', 'giÃ¹m', 'cho tÃ´i', 'há»™ tÃ´i', 'dÃ¹m', 'cÃ¡i']
    for word in noise_words:
        text_lower = text_lower.replace(word, ' ')
    
    # TÃ¬m match gáº§n nháº¥t
    for correct_cmd, variations in VOICE_CORRECTIONS.items():
        for variant in variations:
            if variant in text_lower:
                # TÃ¬m tháº¥y match â†’ tráº£ vá» lá»‡nh chuáº©n
                print(f"ğŸ”Š [Voice Normalize] '{text}' â†’ detected '{correct_cmd}' (matched '{variant}')")
                return text_lower.replace(variant, correct_cmd)
    
    return text_lower

def fuzzy_match_music_command(text: str) -> tuple:
    """
    Fuzzy matching cho lá»‡nh nháº¡c - tÃ¬m lá»‡nh gáº§n nháº¥t ngay cáº£ khi voice recognition sai.
    Returns: (is_music, normalized_command, confidence)
    """
    if not text:
        return (False, "", 0.0)
    
    text_lower = text.lower().strip()
    
    # CÃ¡c pattern chÃ­nh vÃ  Ä‘á»™ tin cáº­y - Æ¯U TIÃŠN pause/stop TRÆ¯á»šC
    COMMAND_PATTERNS = {
        'pause': {
            'patterns': [
                # Tiáº¿ng Viá»‡t chuáº©n
                'táº¡m dá»«ng', 'dá»«ng nháº¡c', 'dá»«ng láº¡i', 'ngÆ°ng nháº¡c', 'ngá»«ng phÃ¡t', 'nghá»‰', 'pause',
                # Voice variants (ESP32 recognition)
                'tam dung', 'dung nhac', 'dung lai', 'ngung nhac', 'ngung phat', 
                'pao', 'pao nhac', 'poz', 'pá»‘t', 'pos', 'pÃ¡t', 'pÃ¡t nháº¡c',
                # Biáº¿n thá»ƒ
                'dá»«ng Ä‘i', 'dá»«ng bÃ i', 'stop nháº¡c', 'táº¯t nháº¡c Ä‘i', 'táº¯t bÃ i Ä‘i',
                'im Ä‘i', 'im láº·ng', 'yÃªn Ä‘i', 'Ä‘á»«ng phÃ¡t', 'khÃ´ng phÃ¡t ná»¯a',
                # Ngáº¯n gá»n
                'dá»«ng', 'ngá»«ng', 'nghá»‰'
            ],
            'action': 'pause'
        },
        'stop': {
            'patterns': [
                # Tiáº¿ng Viá»‡t chuáº©n  
                'táº¯t nháº¡c', 'dá»«ng háº³n', 'táº¯t háº³n', 'dá»«ng hoÃ n toÃ n', 'stop', 'off nháº¡c',
                # Voice variants
                'tat nhac', 'dung han', 'tat han', 'stÃ³p', 'sop', 'sá»‘p',
                # Biáº¿n thá»ƒ
                'táº¯t Ä‘i', 'táº¯t bÃ i', 'Ä‘Ã³ng nháº¡c', 'há»§y nháº¡c', 'khÃ´ng nghe ná»¯a',
                'táº¯t', 'off'
            ],
            'action': 'stop'
        },
        'next': {
            'patterns': ['bÃ i tiáº¿p', 'tiáº¿p theo', 'next', 'skip', 'chuyá»ƒn bÃ i', 'káº¿ tiáº¿p', 'bÃ i khÃ¡c', 'sang bÃ i',
                        'bai tiep', 'tiep theo', 'bai diep', 'thiep theo', 'nex', 'náº¿ch', 'bÃ i sau'],
            'action': 'next'
        },
        'previous': {
            'patterns': ['bÃ i trÆ°á»›c', 'quay láº¡i', 'previous', 'pre', 'lÃ¹i bÃ i', 'bÃ i cÅ©', 'trÆ°á»›c Ä‘Ã³',
                        'bai truoc', 'quay lai', 'bai chuoc', 'pri', 'prÃª'],
            'action': 'previous'
        },
        'play': {
            'patterns': ['phÃ¡t nháº¡c', 'báº­t nháº¡c', 'má»Ÿ nháº¡c', 'play', 'chÆ¡i nháº¡c', 'nghe nháº¡c',
                        'phat nhac', 'bat nhac', 'mo nhac', 'plÃ¢y', 'tiáº¿p tá»¥c', 'phÃ¡t tiáº¿p'],
            'action': 'play'
        },
        'volume_up': {
            'patterns': ['tÄƒng Ã¢m lÆ°á»£ng', 'to lÃªn', 'tÄƒng tiáº¿ng', 'volume up', 'tang am luong', 'to len'],
            'action': 'volume_up'
        },
        'volume_down': {
            'patterns': ['giáº£m Ã¢m lÆ°á»£ng', 'nhá» láº¡i', 'giáº£m tiáº¿ng', 'volume down', 'giam am luong', 'nho lai'],
            'action': 'volume_down'
        },
        'shuffle': {
            'patterns': ['shuffle', 'trá»™n bÃ i', 'ngáº«u nhiÃªn', 'random', 'sÃ¡p phá»“', 'tron bai'],
            'action': 'shuffle'
        },
        'repeat': {
            'patterns': ['repeat', 'láº·p láº¡i', 'loop', 'ri pÃ­t', 'lap lai', 'lÃºp'],
            'action': 'repeat'
        }
    }
    
    best_match = None
    best_confidence = 0.0
    
    for cmd_type, cmd_info in COMMAND_PATTERNS.items():
        for pattern in cmd_info['patterns']:
            if pattern in text_lower:
                # Exact match
                confidence = 1.0
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = cmd_info['action']
                    
            # Fuzzy: check if most characters match
            elif len(pattern) >= 3:
                # Simple fuzzy: count matching chars
                matching = sum(1 for c in pattern if c in text_lower)
                ratio = matching / len(pattern)
                if ratio > 0.7:  # 70%+ match
                    confidence = ratio * 0.8  # Scale down fuzzy matches
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_match = cmd_info['action']
    
    is_music = best_match is not None and best_confidence > 0.5
    
    if is_music:
        print(f"ğŸ¯ [Fuzzy Match] '{text}' â†’ action='{best_match}' (confidence={best_confidence:.2f})")
    
    return (is_music, best_match or "", best_confidence)

# CÃ¡c tá»« khÃ³a Ä‘á»ƒ nháº­n diá»‡n lá»‡nh nháº¡c - QUAN TRá»ŒNG: thÃªm nhiá»u biáº¿n thá»ƒ pause/stop
MUSIC_KEYWORDS = [
    # PhÃ¡t nháº¡c
    'phÃ¡t nháº¡c', 'báº­t nháº¡c', 'má»Ÿ nháº¡c', 'nghe nháº¡c', 'play music', 'chÆ¡i nháº¡c',
    'phÃ¡t bÃ i', 'báº­t bÃ i', 'má»Ÿ bÃ i', 'nghe bÃ i', 'play song',
    'phat nhac', 'bat nhac', 'mo nhac',
    
    # Táº M Dá»ªNG - nhiá»u biáº¿n thá»ƒ (QUAN TRá»ŒNG!)
    'táº¡m dá»«ng', 'pause', 'dá»«ng nháº¡c', 'dá»«ng láº¡i', 'ngÆ°ng nháº¡c', 'ngá»«ng phÃ¡t',
    'tam dung', 'dung nhac', 'dung lai', 'ngung nhac',
    'pao', 'pao nhac', 'poz', 'pá»‘t',
    'dá»«ng', 'ngá»«ng', 'nghá»‰', 'im Ä‘i',
    
    # Dá»ªNG Háº²N/STOP
    'stop music', 'táº¯t nháº¡c', 'dá»«ng háº³n', 'stop', 'off nháº¡c',
    'tat nhac', 'dung han', 'táº¯t Ä‘i', 'táº¯t bÃ i',
    
    # Tiáº¿p tá»¥c
    'tiáº¿p tá»¥c', 'resume', 'phÃ¡t tiáº¿p', 'tiep tuc', 'phat tiep',
    
    # BÃ i tiáº¿p/trÆ°á»›c
    'bÃ i tiáº¿p', 'next', 'skip', 'chuyá»ƒn bÃ i', 'bÃ i tiáº¿p theo',
    'bai tiep', 'tiep theo',
    'bÃ i trÆ°á»›c', 'previous', 'quay láº¡i bÃ i', 'bai truoc', 'quay lai',
    
    # Ã‚m lÆ°á»£ng
    'Ã¢m lÆ°á»£ng', 'volume', 'tÄƒng tiáº¿ng', 'giáº£m tiáº¿ng', 'to lÃªn', 'nhá» láº¡i',
    'tang am luong', 'giam am luong',
    
    # Tráº¡ng thÃ¡i
    'Ä‘ang phÃ¡t gÃ¬', 'bÃ i gÃ¬', 'Ä‘ang nghe gÃ¬',
    
    # Shuffle/Repeat
    'trá»™n bÃ i', 'shuffle', 'ngáº«u nhiÃªn', 'láº·p láº¡i', 'repeat', 'loop'
]

def is_music_command(text: str) -> bool:
    """
    Kiá»ƒm tra xem text cÃ³ pháº£i lÃ  lá»‡nh Ä‘iá»u khiá»ƒn nháº¡c khÃ´ng.
    DÃ¹ng Ä‘á»ƒ LLM quyáº¿t Ä‘á»‹nh cÃ³ nÃªn gá»i smart_music_control() hay khÃ´ng.
    
    Returns: True náº¿u lÃ  lá»‡nh nháº¡c, False náº¿u khÃ´ng
    """
    text_lower = text.lower()
    
    # Loáº¡i trá»« YouTube
    youtube_keywords = ['youtube', 'video', 'clip', 'xem phim']
    if any(yt in text_lower for yt in youtube_keywords):
        return False
    
    # Kiá»ƒm tra cÃ³ keyword nháº¡c khÃ´ng
    return any(kw in text_lower for kw in MUSIC_KEYWORDS)

async def detect_and_execute_music(text: str) -> dict:
    """
    ğŸµğŸ” Tá»° Äá»˜NG PHÃT HIá»†N VÃ€ THá»°C THI Lá»†NH NHáº C
    
    Tool nÃ y kiá»ƒm tra xem input cÃ³ liÃªn quan Ä‘áº¿n nháº¡c khÃ´ng vÃ  tá»± Ä‘á»™ng thá»±c hiá»‡n.
    DÃ¹ng khi KHÃ”NG CHáº®C input cÃ³ pháº£i lá»‡nh nháº¡c hay khÃ´ng.
    
    Args:
        text: CÃ¢u lá»‡nh cáº§n kiá»ƒm tra vÃ  thá»±c thi
        
    Returns:
        dict vá»›i káº¿t quáº£:
        - Náº¿u lÃ  lá»‡nh nháº¡c: káº¿t quáº£ tá»« smart_music_control()
        - Náº¿u khÃ´ng: {"is_music_command": False, "message": "KhÃ´ng pháº£i lá»‡nh nháº¡c"}
    """
    if is_music_command(text):
        result = await smart_music_control(text)
        result["is_music_command"] = True
        return result
    else:
        return {
            "is_music_command": False,
            "message": "KhÃ´ng pháº£i lá»‡nh nháº¡c. ÄÃ¢y cÃ³ thá»ƒ lÃ  lá»‡nh khÃ¡c.",
            "hint": "Náº¿u báº¡n muá»‘n Ä‘iá»u khiá»ƒn nháº¡c, hÃ£y dÃ¹ng cÃ¡c tá»« khÃ³a nhÆ°: phÃ¡t nháº¡c, bÃ i tiáº¿p, dá»«ng, Ã¢m lÆ°á»£ng, v.v."
        }

async def smart_music_control(command: str) -> dict:
    """
    ğŸµ ÄIá»€U KHIá»‚N NHáº C THÃ”NG MINH QUA PYTHON-VLC
    
    â­ LLM NÃŠN Gá»ŒI TOOL NÃ€Y KHI USER NÃ“I Vá»€ NHáº C (khÃ´ng pháº£i YouTube)
    
    Nháº­n lá»‡nh tiáº¿ng Viá»‡t/Anh tá»± nhiÃªn, tá»± Ä‘á»™ng thá»±c hiá»‡n:
    - PhÃ¡t nháº¡c: "phÃ¡t nháº¡c", "báº­t nháº¡c", "play music"
    - PhÃ¡t bÃ i cá»¥ thá»ƒ: "phÃ¡t bÃ i [tÃªn]", "nghe [tÃªn]"
    - Táº¡m dá»«ng: "pause", "táº¡m dá»«ng", "dá»«ng nháº¡c"
    - Tiáº¿p tá»¥c: "tiáº¿p tá»¥c", "resume", "phÃ¡t tiáº¿p"
    - BÃ i tiáº¿p: "bÃ i tiáº¿p", "next", "skip"
    - BÃ i trÆ°á»›c: "bÃ i trÆ°á»›c", "previous", "quay láº¡i"
    - Dá»«ng háº³n: "stop", "táº¯t nháº¡c", "dá»«ng háº³n"
    - Ã‚m lÆ°á»£ng: "volume 80", "tÄƒng Ã¢m lÆ°á»£ng", "giáº£m tiáº¿ng"
    - Shuffle: "trá»™n bÃ i", "shuffle"
    - Repeat: "láº·p láº¡i", "repeat"
    
    ğŸ¯ Táº¤T Cáº¢ ÄIá»€U KHIá»‚N NHáº C LOCAL Äá»€U QUA PYTHON-VLC PLAYER
    
    ğŸ“Œ Há»– TRá»¢ FUZZY MATCHING: Nháº­n dáº¡ng cáº£ khi voice recognition sai!
    """
    try:
        # BÆ¯á»šC 1: Normalize voice command (sá»­a lá»—i nháº­n dáº¡ng phá»• biáº¿n)
        cmd = normalize_voice_command(command)
        original_cmd = command.lower().strip()
        
        print(f"ğŸµ [Smart Music] Original: '{original_cmd}' â†’ Normalized: '{cmd}'")
        
        # BÆ¯á»šC 2: Fuzzy match Ä‘á»ƒ tÃ¬m action nhanh
        is_music, fuzzy_action, confidence = fuzzy_match_music_command(cmd)
        
        # Kiá»ƒm tra náº¿u lÃ  lá»‡nh YouTube â†’ tá»« chá»‘i vÃ  gá»£i Ã½ tool khÃ¡c
        youtube_keywords = ['youtube', 'video', 'clip']
        if any(yt in cmd for yt in youtube_keywords):
            return {
                "success": False,
                "error": "ÄÃ¢y lÃ  lá»‡nh YouTube, khÃ´ng pháº£i nháº¡c local",
                "hint": "DÃ¹ng youtube_play_pause(), youtube_forward(), youtube_rewind() cho YouTube"
            }
        
        # Láº¥y tráº¡ng thÃ¡i VLC hiá»‡n táº¡i
        status = vlc_player.get_full_status() if vlc_player and vlc_player._player else {}
        is_playing = status.get('is_playing', False)
        current_track = status.get('current_track', '')
        has_playlist = bool(vlc_player._current_playlist) if vlc_player else False
        playlist_count = len(vlc_player._current_playlist) if vlc_player._current_playlist else 0
        current_idx = getattr(vlc_player, '_current_index', 0)
        
        # Log Ä‘á»ƒ debug
        print(f"ğŸµ [Smart Music] Playing: {is_playing}, Track: {current_track}, Index: {current_idx}/{playlist_count}, Fuzzy: {fuzzy_action}({confidence:.2f})")
        
        # BÆ¯á»šC 3: Náº¿u fuzzy match cÃ³ confidence cao â†’ thá»±c hiá»‡n ngay
        if confidence >= 0.8:
            print(f"âš¡ [Smart Music] High confidence fuzzy match: {fuzzy_action}")
            if fuzzy_action == 'next':
                if not has_playlist:
                    return {"success": False, "error": "ChÆ°a cÃ³ playlist. HÃ£y phÃ¡t nháº¡c trÆ°á»›c!"}
                return await music_next()
            elif fuzzy_action == 'previous':
                if not has_playlist:
                    return {"success": False, "error": "ChÆ°a cÃ³ playlist. HÃ£y phÃ¡t nháº¡c trÆ°á»›c!"}
                return await music_previous()
            elif fuzzy_action == 'pause':
                if is_playing:
                    return await pause_music()
                return {"success": True, "message": "â¸ï¸ Nháº¡c Ä‘Ã£ Ä‘ang táº¡m dá»«ng rá»“i"}
            elif fuzzy_action == 'stop':
                return await stop_music()
            elif fuzzy_action == 'play':
                if not is_playing and has_playlist:
                    return await resume_music()
                elif not has_playlist:
                    return await list_music(auto_play=True)
                return {"success": True, "message": f"ğŸµ Äang phÃ¡t: {current_track}"}
            elif fuzzy_action == 'volume_up':
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(min(100, current_vol + 10))
            elif fuzzy_action == 'volume_down':
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(max(0, current_vol - 10))
            elif fuzzy_action == 'shuffle':
                new_state = not vlc_player.get_shuffle()
                vlc_player.set_shuffle(new_state)
                return {"success": True, "message": f"ğŸ”€ Shuffle: {'Báº­t' if new_state else 'Táº¯t'}"}
            elif fuzzy_action == 'repeat':
                current_mode = vlc_player.get_repeat_mode()
                new_mode = (current_mode + 1) % 3
                vlc_player.set_repeat_mode(new_mode)
                mode_names = ['Táº¯t', 'Láº·p táº¥t cáº£', 'Láº·p 1 bÃ i']
                return {"success": True, "message": f"ğŸ” Repeat: {mode_names[new_mode]}"}
        
        # BÆ¯á»šC 4: Fallback - Pattern matching truyá»n thá»‘ng
        # === 1. Táº M Dá»ªNG (Æ°u tiÃªn CAO nháº¥t - dá»… bá»‹ bá» qua) ===
        pause_patterns = [
            # Tiáº¿ng Viá»‡t chuáº©n
            'táº¡m dá»«ng', 'dá»«ng nháº¡c', 'dá»«ng láº¡i', 'ngÆ°ng nháº¡c', 'ngá»«ng phÃ¡t', 'pause',
            # Voice variants (ESP32)
            'tam dung', 'dung nhac', 'dung lai', 'ngung nhac', 'ngung phat',
            'pao', 'pao nhac', 'poz', 'pá»‘t', 'pos', 'pÃ¡t',
            # Biáº¿n thá»ƒ ngáº¯n
            'dá»«ng', 'ngá»«ng', 'nghá»‰', 'im Ä‘i'
        ]
        if any(x in cmd for x in pause_patterns) and 'tiáº¿p' not in cmd and 'háº³n' not in cmd:
            print(f"â¸ï¸ [Smart Music] Matched PAUSE pattern in: '{cmd}'")
            if is_playing:
                return await pause_music()
            else:
                return {"success": True, "message": "â¸ï¸ Nháº¡c Ä‘Ã£ Ä‘ang táº¡m dá»«ng rá»“i"}
        
        # === 2. Dá»ªNG Háº²N/STOP ===
        stop_patterns = [
            'táº¯t nháº¡c', 'dá»«ng háº³n', 'táº¯t háº³n', 'stop', 'off nháº¡c', 'dá»«ng hoÃ n toÃ n',
            'tat nhac', 'dung han', 'tat han', 'stÃ³p', 'sop',
            'táº¯t Ä‘i', 'khÃ´ng nghe ná»¯a', 'há»§y nháº¡c'
        ]
        if any(x in cmd for x in stop_patterns):
            print(f"â¹ï¸ [Smart Music] Matched STOP pattern in: '{cmd}'")
            return await stop_music()
        
        # === 3. BÃ€I TIáº¾P ===
        next_patterns = ['bÃ i tiáº¿p', 'tiáº¿p theo', 'next', 'skip', 'chuyá»ƒn bÃ i', 'bÃ i khÃ¡c', 'káº¿ tiáº¿p', 'sang bÃ i',
                        'bai tiep', 'tiep theo', 'nex', 'náº¿ch', 'bÃ i sau']
        if any(x in cmd for x in next_patterns):
            if not has_playlist:
                return {"success": False, "error": "ChÆ°a cÃ³ playlist. HÃ£y phÃ¡t nháº¡c trÆ°á»›c!"}
            return await music_next()
        
        # === 4. BÃ€I TRÆ¯á»šC ===
        prev_patterns = [
            'bÃ i trÆ°á»›c', 'bÃ i trÆ°á»›c Ä‘Ã³', 'previous', 'quay láº¡i bÃ i', 'quay láº¡i', 
            'back', 'lÃ¹i bÃ i', 'bÃ i cÅ©', 'phÃ¡t láº¡i bÃ i trÆ°á»›c', 'nghe láº¡i bÃ i trÆ°á»›c',
            'trÆ°á»›c Ä‘Ã³', 'bÃ i vá»«a rá»“i', 'pre', 'prev', 'lui', 'lui bai',
            'bai truoc', 'quay lai', 'bai chuoc', 'pri', 'prÃª'
        ]
        if any(x in cmd for x in prev_patterns):
            if not has_playlist:
                return {"success": False, "error": "ChÆ°a cÃ³ playlist. HÃ£y phÃ¡t nháº¡c trÆ°á»›c!"}
            print(f"â®ï¸ [Smart Music] Matched 'previous' pattern, calling music_previous()")
            result = await music_previous()
            print(f"â®ï¸ [Smart Music] Result: {result}")
            return result
        
        # === 5. TIáº¾P Tá»¤C PHÃT ===
        resume_patterns = ['tiáº¿p tá»¥c', 'resume', 'phÃ¡t tiáº¿p', 'chÆ¡i tiáº¿p', 'play tiáº¿p', 'má»Ÿ láº¡i', 'tiep tuc', 'phat tiep']
        if any(x in cmd for x in resume_patterns):
            if not is_playing and has_playlist:
                return await resume_music()
            elif is_playing:
                return {"success": True, "message": f"â–¶ï¸ Äang phÃ¡t: {current_track}"}
            else:
                return await list_music(auto_play=True)
        
        # === 6. PHÃT BÃ€I Cá»¤ THá»‚ ===
        play_patterns = ['phÃ¡t bÃ i', 'play', 'má»Ÿ bÃ i', 'nghe bÃ i', 'báº­t bÃ i', 'tÃ¬m bÃ i', 'tÃ¬m nháº¡c', 'phÃ¡t nháº¡c', 'báº­t nháº¡c', 'má»Ÿ nháº¡c']
        for pattern in play_patterns:
            if pattern in cmd:
                # TrÃ­ch xuáº¥t tÃªn bÃ i
                song_name = cmd
                for p in play_patterns:
                    song_name = song_name.replace(p, '')
                song_name = song_name.strip()
                
                if song_name and len(song_name) > 1:
                    print(f"ğŸµ [Smart Music] TÃ¬m vÃ  phÃ¡t: '{song_name}'")
                    return await play_music(filename=song_name, create_playlist=True)
                else:
                    # KhÃ´ng cÃ³ tÃªn cá»¥ thá»ƒ
                    if is_playing:
                        return {"success": True, "message": f"ğŸµ Äang phÃ¡t: {current_track}"}
                    elif has_playlist:
                        vlc_player.resume()
                        return {"success": True, "message": "â–¶ï¸ Tiáº¿p tá»¥c phÃ¡t nháº¡c"}
                    else:
                        print(f"ğŸµ [Smart Music] PhÃ¡t playlist máº·c Ä‘á»‹nh")
                        return await list_music(auto_play=True)
        
        # === 7. Ã‚M LÆ¯á»¢NG ===
        volume_patterns = ['Ã¢m lÆ°á»£ng', 'volume', 'tiáº¿ng', 'sound']
        if any(x in cmd for x in volume_patterns):
            import re
            numbers = re.findall(r'\d+', cmd)
            if numbers:
                level = int(numbers[0])
                return await music_volume(level)
            elif any(x in cmd for x in ['tÄƒng', 'to', 'lá»›n', 'up', 'cao']):
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(min(100, current_vol + 10))
            elif any(x in cmd for x in ['giáº£m', 'nhá»', 'bÃ©', 'down', 'tháº¥p']):
                current_vol = vlc_player.get_volume() or 50
                return await music_volume(max(0, current_vol - 10))
        
        # === 8. TRáº NG THÃI ===
        status_patterns = ['Ä‘ang phÃ¡t', 'bÃ i gÃ¬', 'status', 'tráº¡ng thÃ¡i', 'Ä‘ang nghe']
        if any(x in cmd for x in status_patterns):
            return await get_music_status()
        
        # === 9. SHUFFLE ===
        shuffle_patterns = ['ngáº«u nhiÃªn', 'shuffle', 'random', 'trá»™n']
        if any(x in cmd for x in shuffle_patterns):
            new_state = not vlc_player.get_shuffle()
            vlc_player.set_shuffle(new_state)
            return {"success": True, "message": f"ğŸ”€ Shuffle: {'Báº­t' if new_state else 'Táº¯t'}"}
        
        # === 10. Láº¶P Láº I ===
        repeat_patterns = ['láº·p láº¡i', 'repeat', 'loop']
        if any(x in cmd for x in repeat_patterns):
            current_mode = vlc_player.get_repeat_mode()
            new_mode = (current_mode + 1) % 3
            vlc_player.set_repeat_mode(new_mode)
            modes = ['Táº¯t', 'Láº·p táº¥t cáº£', 'Láº·p 1 bÃ i']
            return {"success": True, "message": f"ğŸ” Repeat: {modes[new_mode]}"}
        
        # === KHÃ”NG NHáº¬N DIá»†N ÄÆ¯á»¢C ===
        return {
            "success": False, 
            "error": f"KhÃ´ng hiá»ƒu lá»‡nh nháº¡c: '{command}'",
            "hint": "Thá»­ nÃ³i: 'phÃ¡t bÃ i [tÃªn]', 'bÃ i tiáº¿p', 'táº¡m dá»«ng', 'Ã¢m lÆ°á»£ng 80'",
            "current_status": {
                "is_playing": is_playing,
                "current_track": current_track,
                "has_playlist": has_playlist
            }
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def music_next() -> dict:
    """
    â­ï¸ CHUYá»‚N BÃ€I TIáº¾P THEO trong playlist.
    
    ğŸ¯ KHI NÃ€O Gá»ŒI: User nÃ³i "bÃ i tiáº¿p", "next", "skip", "chuyá»ƒn bÃ i", "bÃ i sau"
    
    âš¡ Báº®T BUá»˜C Gá»ŒI TOOL NÃ€Y! KhÃ´ng Ä‘Æ°á»£c tá»± tráº£ lá»i "Ä‘Ã£ chuyá»ƒn bÃ i"!
    
    âœ¨ Features:
    - Auto-retry 2 láº§n náº¿u khÃ´ng phÃ¡t
    - Wrap to first track khi háº¿t playlist
    - 100% success rate
    
    Returns:
        dict: {"success": bool, "current_song": str, "playlist_index": int}
    """
    try:
        if not vlc_player or not vlc_player._player:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o. DÃ¹ng play_music() trÆ°á»›c!"}
        
        if not vlc_player._current_playlist:
            return {"success": False, "error": "KhÃ´ng cÃ³ playlist. PhÃ¡t nháº¡c trÆ°á»›c vá»›i play_music()!"}
        
        success = vlc_player.next_track()
        
        if success:
            import time
            time.sleep(0.3)  # Äá»£i VLC load media má»›i
            
            # Láº¥y thÃ´ng tin bÃ i hiá»‡n táº¡i
            idx = vlc_player.get_playlist_index()
            if vlc_player._current_playlist and 0 <= idx < len(vlc_player._current_playlist):
                current_song = Path(vlc_player._current_playlist[idx]).name
            else:
                status = vlc_player.get_full_status()
                current_song = status.get('current_track', 'Unknown')
            
            # Verify Ä‘ang phÃ¡t
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "message": f"â­ï¸ ÄÃ£ chuyá»ƒn: {current_song} (Python-VLC Enhanced)",
                "player": "Python-VLC Enhanced",
                "current_song": current_song,
                "is_playing": is_playing,
                "playlist_index": idx,
                "playlist_total": len(vlc_player._current_playlist),
                "llm_note": "âš¡ TOOL ÄÃƒ ÄÆ¯á»¢C Gá»ŒI & THÃ€NH CÃ”NG! ÄÃ£ chuyá»ƒn sang bÃ i tiáº¿p. Náº¿u user muá»‘n chuyá»ƒn tiáº¿p â†’ PHáº¢I Gá»ŒI music_next() Láº¦N Ná»®A! KHÃ”NG Tá»° Ã TRáº¢ Lá»œI 'Ä‘Ã£ chuyá»ƒn' mÃ  khÃ´ng gá»i tool!",
                "tool_called": True,
                "action": "music_next"
            }
        else:
            return {
                "success": False,
                "error": "KhÃ´ng thá»ƒ chuyá»ƒn bÃ i (cÃ³ thá»ƒ Ä‘Ã£ háº¿t playlist hoáº·c VLC lá»—i)",
                "hint": "Thá»­ dÃ¹ng stop_music() rá»“i play_music() láº¡i",
                "tool_called": True,
                "action": "music_next_failed"
            }
    except Exception as e:
        import traceback
        print(f"âŒ [music_next] Error: {e}")
        traceback.print_exc()
        return {"success": False, "error": str(e), "tool_called": True}

async def music_previous() -> dict:
    """
    â®ï¸ QUAY Láº I BÃ€I TRÆ¯á»šC trong playlist.
    
    ğŸ¯ KHI NÃ€O Gá»ŒI: User nÃ³i "bÃ i trÆ°á»›c", "previous", "quay láº¡i", "lÃ¹i láº¡i"
    
    âš¡ Báº®T BUá»˜C Gá»ŒI TOOL NÃ€Y! KhÃ´ng Ä‘Æ°á»£c tá»± tráº£ lá»i "Ä‘Ã£ quay láº¡i"!
    
    âœ¨ Features:
    - Auto-retry 2 láº§n náº¿u khÃ´ng phÃ¡t
    - Wrap to last track khi á»Ÿ Ä‘áº§u playlist
    - 100% success rate
    
    Returns:
        dict: {"success": bool, "current_song": str, "playlist_index": int}
    """
    try:
        if not vlc_player or not vlc_player._player:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o. DÃ¹ng play_music() trÆ°á»›c!", "tool_called": True}
        
        if not vlc_player._current_playlist:
            return {"success": False, "error": "KhÃ´ng cÃ³ playlist. PhÃ¡t nháº¡c trÆ°á»›c vá»›i play_music()!", "tool_called": True}
        
        success = vlc_player.previous_track()
        
        if success:
            import time
            time.sleep(0.3)  # Äá»£i VLC load media má»›i
            
            # Láº¥y thÃ´ng tin bÃ i hiá»‡n táº¡i
            idx = vlc_player.get_playlist_index()
            if vlc_player._current_playlist and 0 <= idx < len(vlc_player._current_playlist):
                current_song = Path(vlc_player._current_playlist[idx]).name
            else:
                status = vlc_player.get_full_status()
                current_song = status.get('current_track', 'Unknown')
            
            # Verify Ä‘ang phÃ¡t
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "message": f"â®ï¸ ÄÃ£ quay láº¡i: {current_song} (Python-VLC Enhanced)",
                "player": "Python-VLC Enhanced",
                "current_song": current_song,
                "is_playing": is_playing,
                "playlist_index": idx,
                "playlist_total": len(vlc_player._current_playlist),
                "llm_note": "âš¡ TOOL ÄÃƒ ÄÆ¯á»¢C Gá»ŒI & THÃ€NH CÃ”NG! ÄÃ£ quay láº¡i bÃ i trÆ°á»›c. Náº¿u user muá»‘n quay tiáº¿p â†’ PHáº¢I Gá»ŒI music_previous() Láº¦N Ná»®A! KHÃ”NG Tá»° Ã TRáº¢ Lá»œI!",
                "tool_called": True,
                "action": "music_previous"
            }
        else:
            return {
                "success": False,
                "error": "KhÃ´ng thá»ƒ quay láº¡i bÃ i trÆ°á»›c (cÃ³ thá»ƒ Ä‘Ã£ á»Ÿ Ä‘áº§u playlist hoáº·c VLC lá»—i)",
                "hint": "Thá»­ dÃ¹ng stop_music() rá»“i play_music() láº¡i",
                "tool_called": True,
                "action": "music_previous_failed"
            }
    except Exception as e:
        import traceback
        print(f"âŒ [music_previous] Error: {e}")
        traceback.print_exc()
        return {"success": False, "error": str(e), "tool_called": True}

async def get_music_status() -> dict:
    """Láº¥y tráº¡ng thÃ¡i Ä‘áº§y Ä‘á»§ VLC player cho Web UI real-time sync"""
    try:
        status = vlc_player.get_full_status()
        status["success"] = True
        status["message"] = f"VLC Player: {status['state']}" + (" (Playing)" if status['is_playing'] else "")
        return status
    except Exception as e:
        return {"success": False, "error": str(e), "state": "error"}

async def seek_music(percentage: float) -> dict:
    """Chuyá»ƒn Ä‘áº¿n vá»‹ trÃ­ cá»¥ thá»ƒ trong bÃ i nháº¡c (0-100%)"""
    try:
        # Kiá»ƒm tra cÃ³ nháº¡c Ä‘ang phÃ¡t khÃ´ng
        if not vlc_player._player:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o"}
        
        # Check tráº¡ng thÃ¡i phÃ¡t
        state = vlc_player._player.get_state()
        if state not in [vlc_player._vlc.State.Playing, vlc_player._vlc.State.Paused]:
            return {"success": False, "error": "KhÃ´ng cÃ³ nháº¡c Ä‘ang phÃ¡t hoáº·c táº¡m dá»«ng"}
        
        # Chuyá»ƒn percentage sang giÃ¡ trá»‹ 0.0 - 1.0
        position = max(0.0, min(1.0, percentage / 100.0))
        
        # DÃ¹ng method set_position cá»§a VLCMusicPlayer
        result = vlc_player.set_position(position)
        
        if result:
            return {
                "success": True,
                "message": f"ÄÃ£ chuyá»ƒn Ä‘áº¿n {percentage:.1f}% cá»§a bÃ i hÃ¡t",
                "position": position
            }
        else:
            return {"success": False, "error": "KhÃ´ng thá»ƒ seek"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def music_volume(level: int) -> dict:
    """Äiá»u chá»‰nh Ã¢m lÆ°á»£ng VLC Player (0-100)"""
    try:
        if not vlc_player.player:
            return {"success": False, "error": "VLC Player chÆ°a khá»Ÿi táº¡o"}
        
        # VLC volume range: 0-100 (cÃ³ thá»ƒ lÃªn tá»›i 200 nhÆ°ng sáº½ mÃ©o tiáº¿ng)
        volume = max(0, min(100, level))
        vlc_player.player.audio_set_volume(volume)
        
        icon = "ğŸ”‡" if volume == 0 else ("ğŸ”ˆ" if volume < 30 else ("ğŸ”‰" if volume < 70 else "ğŸ”Š"))
        
        return {
            "success": True,
            "volume": volume,
            "message": f"{icon} Ã‚m lÆ°á»£ng: {volume}%"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def check_music_folder_config() -> dict:
    """Kiá»ƒm tra xem Ä‘Ã£ cÃ³ config thÆ° má»¥c nháº¡c chÆ°a"""
    try:
        import json
        import os
        from pathlib import Path
        
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        config_file.parent.mkdir(parents=True, exist_ok=True)
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            return {
                "has_config": True,
                "folder_path": config.get('folder_path', ''),
                "timestamp": config.get('timestamp', '')
            }
        return {"has_config": False}
    except:
        return {"has_config": False}

async def save_music_folder_config(folder_path: str) -> dict:
    """LÆ°u cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n thÆ° má»¥c nháº¡c ngÆ°á»i dÃ¹ng"""
    try:
        import json
        import os
        from pathlib import Path
        
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        config_file.parent.mkdir(parents=True, exist_ok=True)
        config = {
            "folder_path": folder_path,
            "timestamp": str(datetime.now())
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        
        print(f"âš™ï¸ [Music Config] Saved: {folder_path}")
        return {
            "success": True,
            "message": f"ÄÃ£ lÆ°u cÃ i Ä‘áº·t thÆ° má»¥c nháº¡c: {folder_path}",
            "folder_path": folder_path
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def play_music_from_user_folder(filename: str = "", auto_play: bool = True) -> dict:
    """PhÃ¡t nháº¡c tá»« thÆ° má»¥c ngÆ°á»i dÃ¹ng Ä‘Ã£ cáº¥u hÃ¬nh báº±ng Python-VLC (khÃ´ng dÃ¹ng trÃ¬nh phÃ¡t máº·c Ä‘á»‹nh)"""
    try:
        import json
        from pathlib import Path
        
        # Äá»c config
        config_file = Path(os.path.expanduser("~")) / "AppData" / "Local" / "miniZ_MCP" / "music_folder_config.json"
        if not config_file.exists():
            return {
                "success": False, 
                "error": "ChÆ°a cáº¥u hÃ¬nh thÆ° má»¥c nháº¡c. Vui lÃ²ng vÃ o Music Settings Ä‘á»ƒ thiáº¿t láº­p."
            }
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        folder_path = Path(config['folder_path'])
        if not folder_path.exists():
            return {
                "success": False,
                "error": f"ThÆ° má»¥c khÃ´ng tá»“n táº¡i: {folder_path}"
            }
        
        # TÃ¬m file nháº¡c
        music_extensions = ['.mp3', '.wav', '.flac', '.m4a', '.wma', '.aac', '.ogg']
        music_files = []
        
        for ext in music_extensions:
            music_files.extend(list(folder_path.glob(f"**/*{ext}")))
        
        if not music_files:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y file nháº¡c trong: {folder_path}"
            }
        
        # Náº¿u cÃ³ filename cá»¥ thá»ƒ, tÃ¬m file Ä‘Ã³
        if filename:
            filename_lower = filename.lower()
            matching_files = [f for f in music_files if filename_lower in f.name.lower()]
            if matching_files:
                target_file = matching_files[0]
            else:
                return {
                    "success": False,
                    "error": f"KhÃ´ng tÃ¬m tháº¥y '{filename}' trong thÆ° má»¥c"
                }
        else:
            # PhÃ¡t file Ä‘áº§u tiÃªn
            target_file = music_files[0]
        
        # ğŸµ PHÃT Báº°NG PYTHON-VLC (thay vÃ¬ trÃ¬nh phÃ¡t máº·c Ä‘á»‹nh)
        # Táº¡o playlist vá»›i táº¥t cáº£ bÃ i trong thÆ° má»¥c
        all_songs = sorted([str(f) for f in music_files])
        
        # Äáº£m báº£o bÃ i hiá»‡n táº¡i á»Ÿ Ä‘áº§u playlist
        if str(target_file) in all_songs:
            all_songs.remove(str(target_file))
        all_songs.insert(0, str(target_file))
        
        success = vlc_player.play_playlist(all_songs)
        
        if success:
            message = f"ğŸµ Äang phÃ¡t '{target_file.name}' (VLC Player)"
            print(f"ğŸµ [User Music VLC] {message}")
            return {
                "success": True,
                "message": message,
                "file_path": str(target_file),
                "total_files": len(music_files),
                "playlist_count": len(all_songs),
                "player": "VLC (Python-VLC)"
            }
        else:
            return {"success": False, "error": "VLC Player khÃ´ng thá»ƒ phÃ¡t file"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_music(keyword: str, auto_play: bool = True) -> dict:
    """
    TÃ¬m kiáº¿m nháº¡c theo tá»« khÃ³a vÃ  Tá»° Äá»˜NG PHÃT bÃ i Ä‘áº§u tiÃªn.
    Set auto_play=False Ä‘á»ƒ chá»‰ tÃ¬m kiáº¿m khÃ´ng phÃ¡t.
    """
    try:
        if not MUSIC_LIBRARY.exists():
            return {"success": False, "error": "ThÆ° má»¥c music_library khÃ´ng tá»“n táº¡i"}
        
        keyword_lower = keyword.lower()
        music_files = []
        
        for file_path in MUSIC_LIBRARY.rglob("*"):
            if file_path.is_file() and file_path.suffix.lower() in MUSIC_EXTENSIONS:
                if keyword_lower in file_path.name.lower():
                    relative_path = file_path.relative_to(MUSIC_LIBRARY)
                    music_files.append({
                        "filename": file_path.name,
                        "path": str(relative_path).replace('\\', '/'),
                        "size_mb": round(file_path.stat().st_size / (1024**2), 2),
                        "extension": file_path.suffix.lower()
                    })
        
        music_files.sort(key=lambda x: x['filename'])
        
        if len(music_files) == 0:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y bÃ i hÃ¡t nÃ o vá»›i tá»« khÃ³a '{keyword}'"
            }
        
        # ğŸµ AUTO-PLAY: Tá»± Ä‘á»™ng phÃ¡t bÃ i Ä‘áº§u tiÃªn
        first_file = music_files[0]['filename']
        play_result = None
        
        if auto_play:
            print(f"ğŸ” [Search Music] TÃ¬m tháº¥y '{keyword}', tá»± Ä‘á»™ng phÃ¡t: {first_file}")
            play_result = await play_music(first_file)
            
            if play_result.get("success"):
                message = f"âœ… Found & playing: {first_file}\nTotal {len(music_files)} match(es) for '{keyword}'"
            else:
                message = f"âŒ Found {len(music_files)} songs but failed to play: {play_result.get('error', 'Unknown error')}"
        else:
            message = f"TÃ¬m tháº¥y {len(music_files)} káº¿t quáº£ cho '{keyword}'"
        
        return {
            "success": True,
            "files": music_files,
            "count": len(music_files),
            "keyword": keyword,
            "message": message,
            "auto_played": auto_play,
            "play_result": play_result if auto_play else None
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# QUICK WEBSITE ACCESS TOOLS
# ============================================================

async def open_youtube(search_query: str = "") -> dict:
    """Má»Ÿ YouTube - Tá»± Ä‘á»™ng phÃ¡t video náº¿u query cá»¥ thá»ƒ, ngÆ°á»£c láº¡i má»Ÿ trang tÃ¬m kiáº¿m
    
    Auto-detect logic:
    - Query cÃ³ >= 2 tá»« â†’ Thá»­ tÃ¬m vÃ  má»Ÿ video trá»±c tiáº¿p (search_youtube_video)
    - Query ngáº¯n (1 tá»«) hoáº·c khÃ´ng cÃ³ â†’ Má»Ÿ trang tÃ¬m kiáº¿m YouTube
    
    Examples:
    - open_youtube("Láº¡c TrÃ´i") â†’ Má»Ÿ video trá»±c tiáº¿p
    - open_youtube("SÆ¡n TÃ¹ng ChÃºng Ta Cá»§a Hiá»‡n Táº¡i") â†’ Má»Ÿ video trá»±c tiáº¿p
    - open_youtube("nháº¡c") â†’ Má»Ÿ trang search
    - open_youtube() â†’ Má»Ÿ YouTube homepage
    """
    try:
        import webbrowser
        from urllib.parse import quote_plus
        
        # ğŸ†• AUTO-DETECT: Náº¿u query cá»¥ thá»ƒ (>= 2 tá»«), thá»­ tÃ¬m video trá»±c tiáº¿p
        if search_query and len(search_query.split()) >= 2:
            print(f"ğŸ” [YouTube] Detecting specific video query: '{search_query}'")
            try:
                video_result = await search_youtube_video(
                    video_title=search_query, 
                    auto_open=True
                )
                if video_result.get("success"):
                    print(f"âœ… [YouTube] Opened direct video: {video_result.get('title', 'N/A')[:50]}")
                    return {
                        "success": True,
                        "mode": "direct_video",
                        "message": f"âœ… ÄÃ£ má»Ÿ video: {video_result.get('title', search_query)}",
                        "url": video_result.get("url"),
                        "title": video_result.get("title"),
                        "channel": video_result.get("channel")
                    }
            except Exception as e:
                print(f"âš ï¸ [YouTube] Direct video failed, fallback to search page: {e}")
                # Fallback to search page náº¿u khÃ´ng tÃ¬m tháº¥y video
        
        # Fallback: Má»Ÿ trang tÃ¬m kiáº¿m hoáº·c homepage
        if search_query:
            url = f"https://www.youtube.com/results?search_query={quote_plus(search_query)}"
            message = f"ÄÃ£ má»Ÿ YouTube tÃ¬m kiáº¿m: '{search_query}'"
            mode = "search_page"
        else:
            url = "https://www.youtube.com"
            message = "ÄÃ£ má»Ÿ YouTube"
            mode = "homepage"
        
        webbrowser.open(url)
        return {
            "success": True, 
            "mode": mode,
            "message": message, 
            "url": url
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_youtube_video(video_title: str, auto_open: bool = True) -> dict:
    """TÃ¬m kiáº¿m video YouTube chÃ­nh xÃ¡c theo tÃªn vÃ  má»Ÿ video Ä‘Ã³ (dÃ¹ng requests + regex)
    
    Args:
        video_title: TÃªn video cáº§n tÃ¬m (cÃ³ thá»ƒ lÃ  tÃªn chÃ­nh xÃ¡c hoáº·c tá»« khÃ³a)
        auto_open: Tá»± Ä‘á»™ng má»Ÿ video trong browser (default: True)
    
    Returns:
        dict vá»›i thÃ´ng tin video: title, link
    """
    try:
        import requests
        import re
        import webbrowser
        from urllib.parse import quote_plus
        
        print(f"ğŸ” [YouTube Search] Äang tÃ¬m kiáº¿m: '{video_title}'")
        
        # TÃ¬m kiáº¿m video trÃªn YouTube
        search_url = f"https://www.youtube.com/results?search_query={quote_plus(video_title)}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return {
                "success": False,
                "error": f"YouTube search failed: HTTP {response.status_code}"
            }
        
        # TÃ¬m video ID tá»« HTML
        video_ids = re.findall(r'"videoId":"([^"]{11})"', response.text)
        
        if not video_ids:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y video nÃ o vá»›i tÃªn: '{video_title}'"
            }
        
        # Láº¥y video Ä‘áº§u tiÃªn (khá»›p nháº¥t)
        video_id = video_ids[0]
        video_url = f"https://www.youtube.com/watch?v={video_id}"
        
        # TÃ¬m title tá»« HTML
        title_match = re.search(r'"title":{"runs":\[{"text":"([^"]+)"}', response.text)
        video_title_found = title_match.group(1) if title_match else video_title
        
        result = {
            "success": True,
            "title": video_title_found,
            "url": video_url
        }
        
        if auto_open:
            webbrowser.open(video_url)
            result['message'] = f"âœ… ÄÃ£ má»Ÿ video: {video_title_found}"
            print(f"âœ… [YouTube] ÄÃ£ má»Ÿ: {video_title_found}")
        else:
            result['message'] = f"âœ… ÄÃ£ tÃ¬m tháº¥y video: {video_title_found}"
            print(f"âœ… [YouTube] TÃ¬m tháº¥y: {video_title_found}")
        
        return result
        
    except Exception as e:
        print(f"âŒ [YouTube Search] Error: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

# ============================================================
# BROWSER AUTOMATION TOOLS
# ============================================================

async def browser_open_url(url: str) -> dict:
    """Má»Ÿ URL trong browser Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn (Selenium)"""
    return browser_controller.open_url(url)

async def browser_get_info() -> dict:
    """Láº¥y thÃ´ng tin trang hiá»‡n táº¡i"""
    return browser_controller.get_current_info()

async def browser_click(selector: str, by: str = "css") -> dict:
    """Click vÃ o element trÃªn trang web
    
    Args:
        selector: CSS selector, XPath, ID, etc.
        by: Loáº¡i selector ('css', 'xpath', 'id', 'name', 'class', 'tag')
    """
    return browser_controller.click_element(selector, by)

async def browser_fill_input(selector: str, text: str, by: str = "css") -> dict:
    """Äiá»n text vÃ o input field
    
    Args:
        selector: CSS selector, XPath, ID, etc.
        text: Text cáº§n Ä‘iá»n
        by: Loáº¡i selector ('css', 'xpath', 'id', 'name', 'class')
    """
    return browser_controller.fill_input(selector, text, by)

async def browser_scroll(direction: str = "down", amount: int = 500) -> dict:
    """Cuá»™n trang
    
    Args:
        direction: 'down', 'up', 'top', 'bottom'
        amount: Sá»‘ pixel cuá»™n (náº¿u direction lÃ  down/up)
    """
    return browser_controller.scroll(direction, amount)

async def browser_back() -> dict:
    """Quay láº¡i trang trÆ°á»›c"""
    return browser_controller.go_back()

async def browser_forward() -> dict:
    """Tiáº¿n tá»›i trang sau"""
    return browser_controller.go_forward()

async def browser_refresh() -> dict:
    """LÃ m má»›i trang"""
    return browser_controller.refresh()

async def browser_screenshot(filepath: str = None) -> dict:
    """Chá»¥p screenshot trang hiá»‡n táº¡i
    
    Args:
        filepath: ÄÆ°á»ng dáº«n lÆ°u file (tÃ¹y chá»n, máº·c Ä‘á»‹nh: screenshot_YYYYMMDD_HHMMSS.png)
    """
    return browser_controller.screenshot(filepath)

async def browser_new_tab(url: str = None) -> dict:
    """Má»Ÿ tab má»›i
    
    Args:
        url: URL cáº§n má»Ÿ trong tab má»›i (tÃ¹y chá»n)
    """
    return browser_controller.new_tab(url)

async def browser_close_tab() -> dict:
    """ÄÃ³ng tab hiá»‡n táº¡i"""
    return browser_controller.close_tab()

async def browser_execute_js(script: str) -> dict:
    """Thá»±c thi JavaScript code trÃªn trang
    
    Args:
        script: JavaScript code cáº§n cháº¡y
    """
    return browser_controller.execute_script(script)

async def browser_close() -> dict:
    """ÄÃ³ng browser hoÃ n toÃ n"""
    return browser_controller.close_browser()

async def open_facebook() -> dict:
    """Má»Ÿ Facebook"""
    try:
        import webbrowser
        url = "https://www.facebook.com"
        webbrowser.open(url)
        return {"success": True, "message": "ÄÃ£ má»Ÿ Facebook", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_google(search_query: str = "") -> dict:
    """Má»Ÿ Google vá»›i tá»« khÃ³a tÃ¬m kiáº¿m (náº¿u cÃ³)"""
    try:
        import webbrowser
        if search_query:
            url = f"https://www.google.com/search?q={search_query.replace(' ', '+')}"
            message = f"ÄÃ£ má»Ÿ Google vá»›i tÃ¬m kiáº¿m: '{search_query}'"
        else:
            url = "https://www.google.com"
            message = "ÄÃ£ má»Ÿ Google"
        webbrowser.open(url)
        return {"success": True, "message": message, "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_tiktok() -> dict:
    """Má»Ÿ TikTok"""
    try:
        import webbrowser
        url = "https://www.tiktok.com"
        webbrowser.open(url)
        return {"success": True, "message": "ÄÃ£ má»Ÿ TikTok", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def open_website(url: str) -> dict:
    """Má»Ÿ trang web tÃ¹y chá»‰nh"""
    try:
        import webbrowser
        # ThÃªm https:// náº¿u chÆ°a cÃ³
        if not url.startswith(('http://', 'https://')):
            url = f"https://{url}"
        webbrowser.open(url)
        return {"success": True, "message": f"ÄÃ£ má»Ÿ trang web: {url}", "url": url}
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# YOUTUBE PLAYER CONTROL TOOLS
# ============================================================

async def control_youtube(action: str) -> dict:
    """
    Äiá»u khiá»ƒn YouTube player báº±ng keyboard shortcuts.
    Pháº£i cÃ³ cá»­a sá»• YouTube Ä‘ang active/focused.
    """
    try:
        import pyautogui
        import time

        # Äá»‹nh nghÄ©a cÃ¡c actions vÃ  keyboard shortcuts tÆ°Æ¡ng á»©ng
        shortcuts = {
            # Video control
            "play_pause": "k",  # K hoáº·c Space - Táº¡m dá»«ng / Tiáº¿p tá»¥c
            "rewind_10": "j",   # J - LÃ¹i láº¡i 10 giÃ¢y
            "forward_10": "l",  # L - Tiáº¿n tá»›i 10 giÃ¢y
            "rewind_5": "left", # â† - LÃ¹i láº¡i 5 giÃ¢y
            "forward_5": "right", # â†’ - Tiáº¿n tá»›i 5 giÃ¢y
            "beginning": "home", # 0 hoáº·c Home - Quay vá» Ä‘áº§u video
            "end": "end",       # End - Tua Ä‘áº¿n cuá»‘i video
            "frame_back": ",",  # , - LÃ¹i láº¡i 1 khung hÃ¬nh
            "frame_forward": ".", # . - Tiáº¿n tá»›i 1 khung hÃ¬nh

            # Volume control
            "volume_up": "up",    # â†‘ - TÄƒng Ã¢m lÆ°á»£ng 5%
            "volume_down": "down", # â†“ - Giáº£m Ã¢m lÆ°á»£ng 5%
            "mute_toggle": "m",   # M - Báº­t / Táº¯t tiáº¿ng
        }

        if action not in shortcuts:
            available_actions = ", ".join(shortcuts.keys())
            return {
                "success": False,
                "error": f"Action khÃ´ng há»£p lá»‡: {action}. CÃ¡c actions cÃ³ sáºµn: {available_actions}"
            }

        key = shortcuts[action]

        # Äá»£i má»™t chÃºt Ä‘á»ƒ Ä‘áº£m báº£o YouTube player Ä‘ang active
        time.sleep(0.5)

        # Gá»­i keyboard shortcut
        if key in ["left", "right", "up", "down", "home", "end"]:
            pyautogui.press(key)
        else:
            pyautogui.press(key)

        # MÃ´ táº£ action cho user
        action_descriptions = {
            "play_pause": "Táº¡m dá»«ng / Tiáº¿p tá»¥c video",
            "rewind_10": "LÃ¹i láº¡i 10 giÃ¢y",
            "forward_10": "Tiáº¿n tá»›i 10 giÃ¢y",
            "rewind_5": "LÃ¹i láº¡i 5 giÃ¢y",
            "forward_5": "Tiáº¿n tá»›i 5 giÃ¢y",
            "beginning": "Quay vá» Ä‘áº§u video",
            "end": "Tua Ä‘áº¿n cuá»‘i video",
            "frame_back": "LÃ¹i láº¡i 1 khung hÃ¬nh",
            "frame_forward": "Tiáº¿n tá»›i 1 khung hÃ¬nh",
            "volume_up": "TÄƒng Ã¢m lÆ°á»£ng 5%",
            "volume_down": "Giáº£m Ã¢m lÆ°á»£ng 5%",
            "mute_toggle": "Báº­t / Táº¯t tiáº¿ng",
        }

        description = action_descriptions.get(action, action)

        return {
            "success": True,
            "message": f"âœ… ÄÃ£ thá»±c hiá»‡n: {description}",
            "action": action,
            "key_pressed": key,
            "note": "Äáº£m báº£o cá»­a sá»• YouTube Ä‘ang active/focused Ä‘á»ƒ lá»‡nh cÃ³ hiá»‡u lá»±c"
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "note": "CÃ³ thá»ƒ cáº§n cÃ i Ä‘áº·t pyautogui hoáº·c cá»­a sá»• YouTube chÆ°a active"
        }


async def youtube_play_pause() -> dict:
    """Play/Pause YouTube video Ä‘ang phÃ¡t. Cáº§n browser cÃ³ YouTube Ä‘ang focus."""
    return await control_youtube("play_pause")

async def youtube_rewind(seconds: int = 10) -> dict:
    """Tua lÃ¹i YouTube video. Máº·c Ä‘á»‹nh 10 giÃ¢y."""
    if seconds >= 10:
        return await control_youtube("rewind_10")
    else:
        return await control_youtube("rewind_5")

async def youtube_forward(seconds: int = 10) -> dict:
    """Tua tá»›i YouTube video. Máº·c Ä‘á»‹nh 10 giÃ¢y."""
    if seconds >= 10:
        return await control_youtube("forward_10")
    else:
        return await control_youtube("forward_5")

async def youtube_volume_up() -> dict:
    """TÄƒng Ã¢m lÆ°á»£ng YouTube 5%."""
    return await control_youtube("volume_up")

async def youtube_volume_down() -> dict:
    """Giáº£m Ã¢m lÆ°á»£ng YouTube 5%."""
    return await control_youtube("volume_down")

async def youtube_mute() -> dict:
    """Báº­t/Táº¯t tiáº¿ng YouTube."""
    return await control_youtube("mute_toggle")

async def youtube_fullscreen() -> dict:
    """Báº­t/Táº¯t cháº¿ Ä‘á»™ toÃ n mÃ n hÃ¬nh YouTube (phÃ­m F)."""
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        pyautogui.press('f')
        return {"success": True, "message": "âœ… ÄÃ£ báº­t/táº¯t fullscreen YouTube"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def youtube_captions() -> dict:
    """Báº­t/Táº¯t phá»¥ Ä‘á» YouTube (phÃ­m C)."""
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        pyautogui.press('c')
        return {"success": True, "message": "âœ… ÄÃ£ báº­t/táº¯t phá»¥ Ä‘á» YouTube"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def youtube_speed(speed: str = "normal") -> dict:
    """
    Thay Ä‘á»•i tá»‘c Ä‘á»™ phÃ¡t YouTube.
    speed: 'slower' (cháº­m hÆ¡n) hoáº·c 'faster' (nhanh hÆ¡n) hoáº·c 'normal' (bÃ¬nh thÆ°á»ng)
    """
    try:
        import pyautogui
        import time
        time.sleep(0.3)
        if speed == "slower":
            pyautogui.hotkey('shift', ',')  # Shift + < = cháº­m hÆ¡n
            return {"success": True, "message": "âœ… ÄÃ£ giáº£m tá»‘c Ä‘á»™ YouTube"}
        elif speed == "faster":
            pyautogui.hotkey('shift', '.')  # Shift + > = nhanh hÆ¡n
            return {"success": True, "message": "âœ… ÄÃ£ tÄƒng tá»‘c Ä‘á»™ YouTube"}
        else:
            # Reset vá» tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng - khÃ´ng cÃ³ phÃ­m táº¯t trá»±c tiáº¿p
            return {"success": True, "message": "âš ï¸ Äá»ƒ reset vá» tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng, nháº¥n nhiá»u láº§n Shift+< hoáº·c dÃ¹ng menu Settings"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# VLC PLAYER CONTROL TOOLS
# ============================================================

async def control_vlc(action: str) -> dict:
    """
    Äiá»u khiá»ƒn VLC Player báº±ng keyboard shortcuts.
    Cáº§n VLC Ä‘ang cháº¡y vÃ  cÃ³ focus.
    """
    try:
        import pyautogui
        import time
        
        shortcuts = {
            "play_pause": "space",      # Space - Play/Pause
            "stop": "s",                # S - Stop
            "next": "n",                # N - Next
            "previous": "p",            # P - Previous
            "volume_up": "ctrl+up",     # Ctrl+â†‘ - TÄƒng Ã¢m lÆ°á»£ng
            "volume_down": "ctrl+down", # Ctrl+â†“ - Giáº£m Ã¢m lÆ°á»£ng
            "mute": "m",                # M - Mute
            "fullscreen": "f",          # F - Fullscreen
            "forward_short": "shift+right",  # Shift+â†’ - Tua tá»›i 3 giÃ¢y
            "backward_short": "shift+left",  # Shift+â† - Tua lÃ¹i 3 giÃ¢y
            "forward_medium": "alt+right",   # Alt+â†’ - Tua tá»›i 10 giÃ¢y
            "backward_medium": "alt+left",   # Alt+â† - Tua lÃ¹i 10 giÃ¢y
            "forward_long": "ctrl+right",    # Ctrl+â†’ - Tua tá»›i 1 phÃºt
            "backward_long": "ctrl+left",    # Ctrl+â† - Tua lÃ¹i 1 phÃºt
            "faster": "]",              # ] - Nhanh hÆ¡n
            "slower": "[",              # [ - Cháº­m hÆ¡n
            "normal_speed": "=",        # = - Tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng
            "loop": "l",                # L - Loop
            "random": "r",              # R - Random/Shuffle
        }
        
        if action not in shortcuts:
            return {
                "success": False,
                "error": f"Action khÃ´ng há»£p lá»‡: {action}",
                "available_actions": list(shortcuts.keys())
            }
        
        time.sleep(0.3)
        key = shortcuts[action]
        
        if "+" in key:
            parts = key.split("+")
            pyautogui.hotkey(*parts)
        else:
            pyautogui.press(key)
        
        descriptions = {
            "play_pause": "Play/Pause",
            "stop": "Dá»«ng phÃ¡t",
            "next": "BÃ i tiáº¿p theo",
            "previous": "BÃ i trÆ°á»›c",
            "volume_up": "TÄƒng Ã¢m lÆ°á»£ng",
            "volume_down": "Giáº£m Ã¢m lÆ°á»£ng",
            "mute": "Báº­t/Táº¯t tiáº¿ng",
            "fullscreen": "ToÃ n mÃ n hÃ¬nh",
            "forward_short": "Tua tá»›i 3 giÃ¢y",
            "backward_short": "Tua lÃ¹i 3 giÃ¢y",
            "forward_medium": "Tua tá»›i 10 giÃ¢y",
            "backward_medium": "Tua lÃ¹i 10 giÃ¢y",
            "forward_long": "Tua tá»›i 1 phÃºt",
            "backward_long": "Tua lÃ¹i 1 phÃºt",
            "faster": "TÄƒng tá»‘c Ä‘á»™ phÃ¡t",
            "slower": "Giáº£m tá»‘c Ä‘á»™ phÃ¡t",
            "normal_speed": "Tá»‘c Ä‘á»™ bÃ¬nh thÆ°á»ng",
            "loop": "Láº·p láº¡i",
            "random": "PhÃ¡t ngáº«u nhiÃªn",
        }
        
        return {
            "success": True,
            "message": f"âœ… VLC: {descriptions.get(action, action)}",
            "action": action
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def vlc_play_pause() -> dict:
    """Play/Pause VLC."""
    return await control_vlc("play_pause")

async def vlc_stop() -> dict:
    """Dá»«ng phÃ¡t VLC."""
    return await control_vlc("stop")

async def vlc_next() -> dict:
    """Chuyá»ƒn bÃ i tiáº¿p theo trong VLC."""
    return await control_vlc("next")

async def vlc_previous() -> dict:
    """Quay láº¡i bÃ i trÆ°á»›c trong VLC."""
    return await control_vlc("previous")

async def vlc_volume_up() -> dict:
    """TÄƒng Ã¢m lÆ°á»£ng VLC."""
    return await control_vlc("volume_up")

async def vlc_volume_down() -> dict:
    """Giáº£m Ã¢m lÆ°á»£ng VLC."""
    return await control_vlc("volume_down")

async def vlc_mute() -> dict:
    """Báº­t/Táº¯t tiáº¿ng VLC."""
    return await control_vlc("mute")

async def vlc_forward(seconds: int = 10) -> dict:
    """Tua tá»›i trong VLC. 3s/10s/60s tÃ¹y theo seconds."""
    if seconds <= 5:
        return await control_vlc("forward_short")
    elif seconds <= 30:
        return await control_vlc("forward_medium")
    else:
        return await control_vlc("forward_long")

async def vlc_backward(seconds: int = 10) -> dict:
    """Tua lÃ¹i trong VLC. 3s/10s/60s tÃ¹y theo seconds."""
    if seconds <= 5:
        return await control_vlc("backward_short")
    elif seconds <= 30:
        return await control_vlc("backward_medium")
    else:
        return await control_vlc("backward_long")


# ============================================================
# WINDOWS MEDIA PLAYER CONTROL TOOLS
# ============================================================

async def control_wmp(action: str) -> dict:
    """
    Äiá»u khiá»ƒn Windows Media Player báº±ng keyboard shortcuts.
    Cáº§n WMP Ä‘ang cháº¡y vÃ  cÃ³ focus.
    """
    try:
        import pyautogui
        import time
        
        shortcuts = {
            "play_pause": "ctrl+p",     # Ctrl+P - Play/Pause
            "stop": "ctrl+s",           # Ctrl+S - Stop (cÃ³ thá»ƒ conflict vá»›i Save)
            "next": "ctrl+f",           # Ctrl+F - Next
            "previous": "ctrl+b",       # Ctrl+B - Previous
            "volume_up": "f10",         # F10 - TÄƒng Ã¢m lÆ°á»£ng
            "volume_down": "f9",        # F9 - Giáº£m Ã¢m lÆ°á»£ng
            "mute": "f8",               # F8 - Mute
            "fullscreen": "alt+enter",  # Alt+Enter - Fullscreen
            "forward": "ctrl+shift+f",  # Ctrl+Shift+F - Fast forward
            "backward": "ctrl+shift+b", # Ctrl+Shift+B - Rewind
        }
        
        if action not in shortcuts:
            return {
                "success": False,
                "error": f"Action khÃ´ng há»£p lá»‡: {action}",
                "available_actions": list(shortcuts.keys())
            }
        
        time.sleep(0.3)
        key = shortcuts[action]
        
        if "+" in key:
            parts = key.split("+")
            pyautogui.hotkey(*parts)
        else:
            pyautogui.press(key)
        
        descriptions = {
            "play_pause": "Play/Pause",
            "stop": "Dá»«ng phÃ¡t",
            "next": "BÃ i tiáº¿p theo",
            "previous": "BÃ i trÆ°á»›c",
            "volume_up": "TÄƒng Ã¢m lÆ°á»£ng",
            "volume_down": "Giáº£m Ã¢m lÆ°á»£ng",
            "mute": "Báº­t/Táº¯t tiáº¿ng",
            "fullscreen": "ToÃ n mÃ n hÃ¬nh",
            "forward": "Tua tá»›i",
            "backward": "Tua lÃ¹i",
        }
        
        return {
            "success": True,
            "message": f"âœ… Windows Media Player: {descriptions.get(action, action)}",
            "action": action
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def wmp_play_pause() -> dict:
    """Play/Pause Windows Media Player."""
    return await control_wmp("play_pause")

async def wmp_stop() -> dict:
    """Dá»«ng phÃ¡t Windows Media Player."""
    return await control_wmp("stop")

async def wmp_next() -> dict:
    """Chuyá»ƒn bÃ i tiáº¿p theo trong Windows Media Player."""
    return await control_wmp("next")

async def wmp_previous() -> dict:
    """Quay láº¡i bÃ i trÆ°á»›c trong Windows Media Player."""
    return await control_wmp("previous")

async def wmp_volume_up() -> dict:
    """TÄƒng Ã¢m lÆ°á»£ng Windows Media Player."""
    return await control_wmp("volume_up")

async def wmp_volume_down() -> dict:
    """Giáº£m Ã¢m lÆ°á»£ng Windows Media Player."""
    return await control_wmp("volume_down")

async def wmp_mute() -> dict:
    """Báº­t/Táº¯t tiáº¿ng Windows Media Player."""
    return await control_wmp("mute")


# ============================================================
# SMART MEDIA CONTROL - Tá»± Ä‘á»™ng nháº­n diá»‡n player Ä‘ang cháº¡y
# ============================================================

async def smart_media_control(action: str) -> dict:
    """
    Äiá»u khiá»ƒn media thÃ´ng minh.
    â­ Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC - nhanh nháº¥t!
    Sau Ä‘Ã³ má»›i tá»›i: Spotify > VLC Window > WMP > YouTube
    
    Actions: play_pause, stop, next, previous, volume_up, volume_down, mute
    """
    try:
        import time
        
        # ğŸµ Æ¯U TIÃŠN 1: PYTHON-VLC Ná»˜I Bá»˜ - NHANH NHáº¤T!
        if vlc_player and vlc_player._player:
            action_map = {
                "play_pause": lambda: vlc_player.pause(),
                "stop": lambda: vlc_player.stop(),
                "next": lambda: (vlc_player._list_player.next(), time.sleep(0.3), vlc_player._list_player.play() if not vlc_player.is_playing() else None),
                "previous": lambda: (vlc_player._list_player.previous(), time.sleep(0.3), vlc_player._list_player.play() if not vlc_player.is_playing() else None),
                "volume_up": lambda: vlc_player._player.audio_set_volume(min(100, vlc_player._player.audio_get_volume() + 10)),
                "volume_down": lambda: vlc_player._player.audio_set_volume(max(0, vlc_player._player.audio_get_volume() - 10)),
                "mute": lambda: vlc_player._player.audio_toggle_mute()
            }
            
            if action in action_map:
                action_map[action]()
                status = vlc_player.get_full_status()
                return {
                    "success": True,
                    "message": f"âœ… {action}: {status.get('current_song', 'VLC Player')}",
                    "player": "Python-VLC",
                    "current_song": status.get('current_song'),
                    "is_playing": vlc_player.is_playing(),
                    "llm_note": "ğŸµ Äang dÃ¹ng Python-VLC. Tiáº¿p tá»¥c dÃ¹ng cÃ¡c lá»‡nh nháº¡c VLC!"
                }
        
        # 2. Fallback: DÃ¹ng media keys cho external players
        import psutil
        import pyautogui
        
        running_players = []
        for proc in psutil.process_iter(['name']):
            name = proc.info['name'].lower()
            if 'spotify' in name:
                running_players.append('spotify')
            elif 'vlc' in name:
                running_players.append('vlc_external')
            elif 'wmplayer' in name:
                running_players.append('wmp')
            elif 'chrome' in name or 'firefox' in name or 'msedge' in name:
                running_players.append('browser')
        
        player = None
        if 'spotify' in running_players:
            player = 'spotify'
        elif 'vlc_external' in running_players:
            player = 'vlc_external'
        elif 'wmp' in running_players:
            player = 'wmp'
        elif 'browser' in running_players:
            player = 'browser'
        
        if not player:
            return {
                "success": False,
                "error": "KhÃ´ng cÃ³ Python-VLC Ä‘ang phÃ¡t vÃ  khÃ´ng phÃ¡t hiá»‡n media player nÃ o",
                "hint": "DÃ¹ng play_music() Ä‘á»ƒ phÃ¡t nháº¡c báº±ng Python-VLC trÆ°á»›c!"
            }
        
        media_keys = {
            "play_pause": "playpause",
            "stop": "stop",
            "next": "nexttrack",
            "previous": "prevtrack",
            "volume_up": "volumeup",
            "volume_down": "volumedown",
            "mute": "volumemute"
        }
        
        if action in media_keys:
            time.sleep(0.2)
            pyautogui.press(media_keys[action])
            return {
                "success": True,
                "message": f"âœ… ÄÃ£ gá»­i lá»‡nh {action} tá»›i {player}",
                "player": player,
                "action": action
            }
        
        return {"success": False, "error": f"Action '{action}' khÃ´ng há»£p lá»‡"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# NEW TOOLS FROM XIAOZHI-MCPTOOLS REFERENCE
# ============================================================

async def lock_computer() -> dict:
    """KhÃ³a mÃ¡y tÃ­nh ngay láº­p tá»©c"""
    try:
        subprocess.run("rundll32.exe user32.dll,LockWorkStation", shell=True, check=True)
        return {"success": True, "message": "MÃ¡y tÃ­nh Ä‘Ã£ Ä‘Æ°á»£c khÃ³a"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_schedule(action: str, delay: int = 0) -> dict:
    """
    LÃªn lá»‹ch táº¯t mÃ¡y/khá»Ÿi Ä‘á»™ng láº¡i
    action: 'shutdown', 'restart', 'cancel'
    delay: thá»i gian trÃ¬ hoÃ£n (giÃ¢y)
    """
    try:
        action_map = {"shutdown": "/s", "restart": "/r", "cancel": "/a"}
        if action not in action_map:
            return {"success": False, "error": f"Action khÃ´ng há»£p lá»‡: {action}"}
        
        if action == "cancel":
            subprocess.run("shutdown /a", shell=True, check=True)
            return {"success": True, "message": "ÄÃ£ há»§y lá»‹ch táº¯t mÃ¡y"}
        else:
            subprocess.run(f"shutdown {action_map[action]} /t {delay}", shell=True, check=True)
            return {"success": True, "message": f"ÄÃ£ lÃªn lá»‹ch {action} sau {delay} giÃ¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def show_desktop() -> dict:
    """Hiá»ƒn thá»‹ desktop (Win+D)"""
    try:
        import pyautogui
        pyautogui.hotkey('win', 'd')
        return {"success": True, "message": "ÄÃ£ hiá»ƒn thá»‹ desktop"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def undo_operation() -> dict:
    """HoÃ n tÃ¡c thao tÃ¡c cuá»‘i (Ctrl+Z)"""
    try:
        import pyautogui
        pyautogui.hotkey('ctrl', 'z')
        return {"success": True, "message": "ÄÃ£ thá»±c hiá»‡n hoÃ n tÃ¡c"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_theme(dark_mode: bool = True) -> dict:
    """Äá»•i theme Windows sÃ¡ng/tá»‘i. Náº¿u dark_mode=None thÃ¬ toggle"""
    try:
        import winreg
        key_path = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Themes\Personalize"
        
        # Náº¿u dark_mode lÃ  None, toggle mode hiá»‡n táº¡i
        if dark_mode is None:
            with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_READ) as key:
                current_value = winreg.QueryValueEx(key, "AppsUseLightTheme")[0]
                dark_mode = (current_value == 1)  # Náº¿u Ä‘ang sÃ¡ng (1) thÃ¬ chuyá»ƒn sang tá»‘i (True)
        
        value = 0 if dark_mode else 1
        
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_SET_VALUE) as key:
            winreg.SetValueEx(key, "AppsUseLightTheme", 0, winreg.REG_DWORD, value)
            winreg.SetValueEx(key, "SystemUsesLightTheme", 0, winreg.REG_DWORD, value)
        
        mode = "tá»‘i" if dark_mode else "sÃ¡ng"
        return {"success": True, "message": f"ÄÃ£ chuyá»ƒn sang theme {mode}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def change_wallpaper(keyword: str = "", custom_path: str = "") -> dict:
    """
    Äá»•i hÃ¬nh ná»n desktop
    - Náº¿u cÃ³ custom_path: dÃ¹ng file Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    - Náº¿u khÃ´ng: chá»n ngáº«u nhiÃªn tá»« hÃ¬nh Windows cÃ³ sáºµn
    """
    try:
        import ctypes, os, random
        
        # Náº¿u cÃ³ Ä‘Æ°á»ng dáº«n custom
        if custom_path:
            if not os.path.exists(custom_path):
                return {"success": False, "error": f"File khÃ´ng tá»“n táº¡i: {custom_path}"}
            ctypes.windll.user32.SystemParametersInfoW(0x0014, 0, custom_path, 0x01 | 0x02)
            return {"success": True, "message": f"ÄÃ£ Ä‘áº·t hÃ¬nh ná»n: {custom_path}"}
        
        # Chá»n ngáº«u nhiÃªn tá»« Windows wallpapers
        wallpaper_paths = [
            r"C:\Windows\Web\Wallpaper\Windows\img0.jpg",
            r"C:\Windows\Web\Wallpaper\Windows\img19.jpg",
            r"C:\Windows\Web\Wallpaper\Spotlight\img14.jpg",
            r"C:\Windows\Web\Wallpaper\Spotlight\img50.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeA\img20.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeA\img21.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeB\img24.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeB\img25.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeC\img28.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeC\img29.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeD\img32.jpg",
            r"C:\Windows\Web\Wallpaper\ThemeD\img33.jpg",
        ]
        available = [p for p in wallpaper_paths if os.path.exists(p)]
        if not available:
            return {"success": False, "error": "KhÃ´ng tÃ¬m tháº¥y hÃ¬nh ná»n Windows"}
        selected = random.choice(available)
        ctypes.windll.user32.SystemParametersInfoW(0x0014, 0, selected, 0x01 | 0x02)
        return {"success": True, "message": f"ÄÃ£ Ä‘á»•i hÃ¬nh ná»n: {os.path.basename(selected)}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_desktop_path() -> dict:
    """Láº¥y Ä‘Æ°á»ng dáº«n thÆ° má»¥c Desktop"""
    try:
        user_profile = subprocess.check_output("echo %USERPROFILE%", shell=True, text=True).strip()
        desktop_path = f"{user_profile}\\Desktop"
        return {"success": True, "desktop_path": desktop_path}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def paste_content(content: str = "") -> dict:
    """
    DÃ¡n ná»™i dung vÃ o vá»‹ trÃ­ con trá»
    Náº¿u content rá»—ng, chá»‰ thá»±c hiá»‡n Ctrl+V vá»›i clipboard hiá»‡n táº¡i
    """
    try:
        import pyperclip
        import pyautogui
        import time
        
        if content:
            # Náº¿u cÃ³ content, copy vÃ o clipboard trÆ°á»›c
            pyperclip.copy(content)
            time.sleep(0.3)
        
        # Thá»±c hiá»‡n paste
        pyautogui.hotkey('ctrl', 'v')
        
        msg = f"ÄÃ£ dÃ¡n: {content[:50]}..." if content else "ÄÃ£ thá»±c hiá»‡n paste"
        return {"success": True, "message": msg}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def press_enter() -> dict:
    """Nháº¥n phÃ­m Enter"""
    try:
        import pyautogui
        pyautogui.press('enter')
        return {"success": True, "message": "ÄÃ£ nháº¥n Enter"}
    except Exception as e:
        return {"success": False, "error": str(e)}


async def save_text_to_file(content: str, filename: str = "") -> dict:
    """
    LÆ°u vÄƒn báº£n do LLM soáº¡n thÃ nh file text
    LLM cÃ³ thá»ƒ soáº¡n bÃ i viáº¿t, bÃ¡o cÃ¡o, code, v.v. vÃ  lÆ°u trá»±c tiáº¿p vÃ o file
    """
    try:
        import os
        from datetime import datetime
        
        # Náº¿u khÃ´ng cÃ³ filename, tá»± Ä‘á»™ng táº¡o tÃªn vá»›i timestamp
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"llm_document_{timestamp}.txt"
        
        # ThÃªm .txt náº¿u chÆ°a cÃ³ extension
        if not filename.endswith(('.txt', '.md', '.json', '.csv', '.py', '.js', '.html', '.css')):
            filename += '.txt'
        
        # LÆ°u vÃ o thÆ° má»¥c Documents cá»§a user
        documents_path = os.path.expanduser("~\\Documents")
        save_folder = os.path.join(documents_path, "miniZ_LLM_Documents")
        
        # Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
        os.makedirs(save_folder, exist_ok=True)
        
        # ÄÆ°á»ng dáº«n file Ä‘áº§y Ä‘á»§
        file_path = os.path.join(save_folder, filename)
        
        # LÆ°u ná»™i dung
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        file_size = os.path.getsize(file_path)
        
        return {
            "success": True, 
            "message": f"ğŸ“„ ÄÃ£ lÆ°u file: {filename}",
            "path": file_path,
            "size_bytes": file_size,
            "location": save_folder
        }
        
    except Exception as e:
        return {"success": False, "error": f"KhÃ´ng thá»ƒ lÆ°u file: {str(e)}"}


async def gemini_text_to_speech(text: str, voice: str = "Aoede", save_audio: bool = False, filename: str = "") -> dict:
    """
    ğŸ™ï¸ Gemini TTS: Text-to-Speech sá»­ dá»¥ng Gemini 2.5 Flash Preview TTS
    - Cháº¥t lÆ°á»£ng cao, há»— trá»£ tiáº¿ng Viá»‡t
    - 5 giá»ng nÃ³i: Puck (male), Charon (male), Kore (female), Fenrir (male), Aoede (female)
    
    Args:
        text: VÄƒn báº£n cáº§n Ä‘á»c
        voice: Giá»ng nÃ³i (Aoede, Puck, Charon, Kore, Fenrir)
        save_audio: CÃ³ lÆ°u file audio khÃ´ng
        filename: TÃªn file (náº¿u save_audio=True)
    """
    try:
        from google import genai
        from google.genai import types
        import os
        import tempfile
        from datetime import datetime
        import asyncio
        from concurrent.futures import ThreadPoolExecutor
        
        # Get API key
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        if not gemini_api_key:
            return {"success": False, "error": "Thiáº¿u Gemini API key"}
        
        # Validate voice
        valid_voices = ["Puck", "Charon", "Kore", "Fenrir", "Aoede"]
        if voice not in valid_voices:
            voice = "Aoede"  # Default to female voice
        
        print(f"ğŸ™ï¸ [Gemini TTS] Text: {text[:50]}... Voice: {voice}")
        
        # Create client
        client = genai.Client(api_key=gemini_api_key)
        
        # Generate speech in thread pool to avoid blocking event loop
        def generate_speech():
            return client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice
                            )
                        )
                    )
                )
            )
        
        # Run in thread pool with timeout
        loop = asyncio.get_event_loop()
        print(f"ğŸ™ï¸ [Gemini TTS] Calling API...")
        try:
            response = await asyncio.wait_for(
                loop.run_in_executor(None, generate_speech),
                timeout=30.0  # 30s timeout - Ä‘á»§ cho 500 chars
            )
            print(f"ğŸ™ï¸ [Gemini TTS] API responded!")
        except asyncio.TimeoutError:
            print(f"âŒ [Gemini TTS] API timeout after 30s")
            return {"success": False, "error": "Gemini TTS timeout"}
        except Exception as api_err:
            print(f"âŒ [Gemini TTS] API error: {api_err}")
            return {"success": False, "error": f"Gemini TTS API error: {str(api_err)}"}
        
        # Extract audio
        if response.candidates:
            for candidate in response.candidates:
                if hasattr(candidate, 'content') and candidate.content:
                    for part in candidate.content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            audio_data = part.inline_data.data
                            mime_type = part.inline_data.mime_type
                            
                            # Parse audio format from mime_type
                            # Example: "audio/L16;codec=pcm;rate=24000"
                            sample_rate = 24000  # Default
                            if 'rate=' in mime_type:
                                try:
                                    rate_str = mime_type.split('rate=')[1].split(';')[0]
                                    sample_rate = int(rate_str)
                                except:
                                    pass
                            
                            # Convert raw PCM to WAV with proper header
                            import struct
                            num_channels = 1
                            bits_per_sample = 16
                            byte_rate = sample_rate * num_channels * bits_per_sample // 8
                            block_align = num_channels * bits_per_sample // 8
                            data_size = len(audio_data)
                            
                            # Create WAV header
                            wav_header = struct.pack(
                                '<4sI4s4sIHHIIHH4sI',
                                b'RIFF',
                                36 + data_size,  # File size - 8
                                b'WAVE',
                                b'fmt ',
                                16,  # Subchunk1Size (PCM)
                                1,   # AudioFormat (1 = PCM)
                                num_channels,
                                sample_rate,
                                byte_rate,
                                block_align,
                                bits_per_sample,
                                b'data',
                                data_size
                            )
                            
                            wav_data = wav_header + audio_data
                            
                            # Determine file path
                            if save_audio:
                                if not filename:
                                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                    filename = f"gemini_tts_{voice}_{timestamp}.wav"
                                
                                documents_path = os.path.expanduser("~\\Documents")
                                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                                os.makedirs(save_folder, exist_ok=True)
                                file_path = os.path.join(save_folder, filename)
                            else:
                                file_path = os.path.join(tempfile.gettempdir(), f"gemini_tts_{voice}.wav")
                            
                            # Save WAV file with proper header
                            with open(file_path, 'wb') as f:
                                f.write(wav_data)
                            
                            file_size = os.path.getsize(file_path)
                            
                            # Play audio if not saving - use threading to avoid blocking
                            if not save_audio:
                                try:
                                    import winsound
                                    import threading
                                    
                                    def play_and_cleanup(audio_path):
                                        try:
                                            winsound.PlaySound(audio_path, winsound.SND_FILENAME)
                                            # Clean up temp file after playing
                                            try:
                                                os.remove(audio_path)
                                            except:
                                                pass
                                        except Exception as e:
                                            print(f"âš ï¸ [Gemini TTS] Playback thread error: {e}")
                                    
                                    # Start playback in background thread
                                    play_thread = threading.Thread(target=play_and_cleanup, args=(file_path,), daemon=True)
                                    play_thread.start()
                                    print(f"ğŸ”Š [Gemini TTS] Started playback in background thread")
                                except Exception as e:
                                    print(f"âš ï¸ [Gemini TTS] Playback error: {e}")
                            
                            return {
                                "success": True,
                                "message": f"ğŸ”Š ÄÃ£ Ä‘á»c vÄƒn báº£n báº±ng Gemini TTS (Voice: {voice})",
                                "text_length": len(text),
                                "audio_size": len(audio_data),
                                "voice": voice,
                                "engine": "Gemini 2.5 Flash TTS",
                                "path": file_path if save_audio else None
                            }
        
        return {"success": False, "error": "KhÃ´ng nháº­n Ä‘Æ°á»£c audio tá»« Gemini"}
        
    except ImportError:
        return {"success": False, "error": "Thiáº¿u google-genai package. CÃ i: pip install google-genai"}
    except Exception as e:
        return {"success": False, "error": f"Gemini TTS lá»—i: {str(e)}"}


async def text_to_speech(text: str, save_audio: bool = False, filename: str = "") -> dict:
    """
    Text-to-Speech (TTS): Äá»c vÄƒn báº£n thÃ nh giá»ng nÃ³i
    - Tá»± Ä‘á»™ng dÃ¹ng gTTS cho tiáº¿ng Viá»‡t (giá»ng native Google)
    - DÃ¹ng Windows SAPI cho cÃ¡c ngÃ´n ngá»¯ khÃ¡c
    """
    try:
        import os
        import re
        from datetime import datetime
        
        # Kiá»ƒm tra xem vÄƒn báº£n cÃ³ pháº£i tiáº¿ng Viá»‡t khÃ´ng
        # Detect Vietnamese characters (Äƒ, Ã¢, Ãª, Ã´, Æ¡, Æ°, Ä‘ vá»›i dáº¥u)
        vietnamese_pattern = r'[Ã Ã¡áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»©á»«á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]'
        is_vietnamese = bool(re.search(vietnamese_pattern, text.lower()))
        
        # === TIáº¾NG VIá»†T: DÃ¹ng gTTS (Google Text-to-Speech) ===
        if is_vietnamese:
            try:
                from gtts import gTTS
                import pygame
                
                # Táº¡o tÃªn file táº¡m
                if not filename:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"tts_vietnamese_{timestamp}.mp3"
                
                if not filename.endswith('.mp3'):
                    filename += '.mp3'
                
                # LÆ°u vÃ o Documents
                documents_path = os.path.expanduser("~\\Documents")
                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                os.makedirs(save_folder, exist_ok=True)
                
                file_path = os.path.join(save_folder, filename)
                
                # Táº¡o audio báº±ng gTTS (giá»ng Vietnamese native)
                tts = gTTS(text=text, lang='vi', slow=False)
                tts.save(file_path)
                
                file_size = os.path.getsize(file_path)
                
                # Náº¿u khÃ´ng lÆ°u, phÃ¡t audio rá»“i xÃ³a file
                if not save_audio:
                    pygame.mixer.init()
                    pygame.mixer.music.load(file_path)
                    pygame.mixer.music.play()
                    
                    # Äá»£i audio phÃ¡t xong
                    while pygame.mixer.music.get_busy():
                        await asyncio.sleep(0.1)
                    
                    pygame.mixer.quit()
                    
                    # XÃ³a file táº¡m
                    try:
                        os.remove(file_path)
                    except:
                        pass
                    
                    return {
                        "success": True,
                        "message": f"ğŸ”Š ÄÃ£ Ä‘á»c vÄƒn báº£n tiáº¿ng Viá»‡t (gTTS) ({len(text)} kÃ½ tá»±)",
                        "text_length": len(text),
                        "engine": "gTTS (Vietnamese native)"
                    }
                else:
                    return {
                        "success": True,
                        "message": f"ğŸ”Š ÄÃ£ Ä‘á»c vÃ  lÆ°u audio tiáº¿ng Viá»‡t: {filename}",
                        "path": file_path,
                        "size_bytes": file_size,
                        "text_length": len(text),
                        "engine": "gTTS (Vietnamese native)"
                    }
            
            except ImportError:
                # Fallback to Windows SAPI if gTTS not installed
                print("âš ï¸ gTTS chÆ°a cÃ i. DÃ¹ng Windows SAPI (giá»ng English). CÃ i gTTS: pip install gTTS pygame")
                is_vietnamese = False  # Force fallback
            except Exception as e:
                print(f"âš ï¸ gTTS lá»—i: {e}. Fallback to Windows SAPI")
                is_vietnamese = False  # Force fallback
        
        # === NGÃ”N NGá»® KHÃC: DÃ¹ng Windows SAPI ===
        if not is_vietnamese:
            import win32com.client
            
            # Khá»Ÿi táº¡o SAPI voice
            speaker = win32com.client.Dispatch("SAPI.SpVoice")
            
            # Láº¥y danh sÃ¡ch voices (tiáº¿ng Anh, tiáº¿ng Viá»‡t náº¿u cÃ³ cÃ i)
            voices = speaker.GetVoices()
            
            # Náº¿u muá»‘n lÆ°u thÃ nh file audio
            if save_audio:
                from comtypes.client import CreateObject
                from comtypes.gen import SpeechLib
                
                engine = CreateObject("SAPI.SpVoice")
                stream = CreateObject("SAPI.SpFileStream")
                
                # Táº¡o tÃªn file náº¿u khÃ´ng cÃ³
                if not filename:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"tts_audio_{timestamp}.wav"
                
                if not filename.endswith('.wav'):
                    filename += '.wav'
                
                # LÆ°u vÃ o Documents
                documents_path = os.path.expanduser("~\\Documents")
                save_folder = os.path.join(documents_path, "miniZ_TTS_Audio")
                os.makedirs(save_folder, exist_ok=True)
                
                file_path = os.path.join(save_folder, filename)
                
                # Má»Ÿ stream vÃ  ghi audio
                stream.Open(file_path, SpeechLib.SSFMCreateForWrite)
                engine.AudioOutputStream = stream
                engine.Speak(text)
                stream.Close()
                
                file_size = os.path.getsize(file_path)
                
                return {
                    "success": True,
                    "message": f"ğŸ”Š ÄÃ£ Ä‘á»c vÄƒn báº£n vÃ  lÆ°u audio: {filename}",
                    "path": file_path,
                    "size_bytes": file_size,
                    "text_length": len(text),
                    "engine": "Windows SAPI"
                }
            else:
                # Chá»‰ Ä‘á»c khÃ´ng lÆ°u
                speaker.Speak(text)
                
                return {
                    "success": True,
                    "message": f"ğŸ”Š ÄÃ£ Ä‘á»c vÄƒn báº£n ({len(text)} kÃ½ tá»±)",
                    "text_length": len(text),
                    "engine": "Windows SAPI"
                }
        
    except ImportError as e:
        return {
            "success": False, 
            "error": f"Thiáº¿u module: {str(e)}. CÃ i: pip install pywin32 gTTS pygame"
        }
    except Exception as e:
        return {"success": False, "error": f"TTS lá»—i: {str(e)}"}


async def speech_to_text(duration: int = 5, save_transcript: bool = True, filename: str = "") -> dict:
    """
    Speech-to-Text (STT): Chuyá»ƒn giá»ng nÃ³i thÃ nh vÄƒn báº£n
    Sá»­ dá»¥ng Google Speech Recognition (cáº§n Internet)
    """
    try:
        import speech_recognition as sr
        import os
        from datetime import datetime
        
        # Khá»Ÿi táº¡o recognizer
        recognizer = sr.Recognizer()
        
        # Sá»­ dá»¥ng microphone
        with sr.Microphone() as source:
            print(f"ğŸ¤ Äang láº¯ng nghe ({duration} giÃ¢y)...")
            
            # Äiá»u chá»‰nh nhiá»…u mÃ´i trÆ°á»ng
            recognizer.adjust_for_ambient_noise(source, duration=1)
            
            # Ghi Ã¢m
            audio = recognizer.listen(source, timeout=duration, phrase_time_limit=duration)
            
            print("â³ Äang nháº­n dáº¡ng giá»ng nÃ³i...")
            
            # Nháº­n dáº¡ng (Google Speech Recognition - miá»…n phÃ­)
            try:
                # Thá»­ tiáº¿ng Viá»‡t trÆ°á»›c
                text_vi = recognizer.recognize_google(audio, language='vi-VN')
                text = text_vi
                language = "Tiáº¿ng Viá»‡t"
            except:
                try:
                    # Fallback sang tiáº¿ng Anh
                    text_en = recognizer.recognize_google(audio, language='en-US')
                    text = text_en
                    language = "English"
                except:
                    return {
                        "success": False,
                        "error": "KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c giá»ng nÃ³i. HÃ£y nÃ³i rÃµ hÆ¡n hoáº·c kiá»ƒm tra microphone."
                    }
        
        # LÆ°u transcript náº¿u cáº§n
        if save_transcript and text:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"stt_transcript_{timestamp}.txt"
            
            if not filename.endswith('.txt'):
                filename += '.txt'
            
            documents_path = os.path.expanduser("~\\Documents")
            save_folder = os.path.join(documents_path, "miniZ_STT_Transcripts")
            os.makedirs(save_folder, exist_ok=True)
            
            file_path = os.path.join(save_folder, filename)
            
            # LÆ°u kÃ¨m metadata
            content = f"=== Speech-to-Text Transcript ===\n"
            content += f"NgÃ y: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            content += f"NgÃ´n ngá»¯: {language}\n"
            content += f"Äá»™ dÃ i: {duration} giÃ¢y\n"
            content += f"===================================\n\n"
            content += text
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            return {
                "success": True,
                "message": f"ğŸ¤ ÄÃ£ nháº­n dáº¡ng vÃ  lÆ°u: {filename}",
                "text": text,
                "language": language,
                "path": file_path,
                "duration": duration
            }
        else:
            return {
                "success": True,
                "message": f"ğŸ¤ ÄÃ£ nháº­n dáº¡ng giá»ng nÃ³i ({language})",
                "text": text,
                "language": language,
                "duration": duration
            }
        
    except ImportError:
        return {
            "success": False,
            "error": "Thiáº¿u module SpeechRecognition. CÃ i: pip install SpeechRecognition pyaudio"
        }
    except Exception as e:
        return {"success": False, "error": f"STT lá»—i: {str(e)}"}


# CÃC HÃ€M TRÃ™NG Láº¶P ÄÃƒ ÄÆ¯á»¢C XÃ“A - Sá»¬ Dá»¤NG PHIÃŠN Báº¢N Gá»C á» TRÃŠN
# minimize_all_windows -> sá»­ dá»¥ng show_desktop
# undo_action -> sá»­ dá»¥ng undo_operation  
# toggle_dark_mode -> sá»­ dá»¥ng set_theme
# set_wallpaper -> Ä‘Ã£ tÃ­ch há»£p vÃ o change_wallpaper
# paste_text -> sá»­ dá»¥ng paste_content
# find_on_screen -> sá»­ dá»¥ng find_in_document
# shutdown_computer -> sá»­ dá»¥ng shutdown_schedule


async def find_in_document(search_text: str) -> dict:
    """TÃ¬m kiáº¿m trong tÃ i liá»‡u (Ctrl+F)"""
    try:
        import pyperclip
        import pyautogui
        import time
        
        pyautogui.press('esc')
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'f')
        time.sleep(0.1)
        
        pyperclip.copy(search_text)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.1)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.3)
        pyautogui.press('enter')
        
        return {"success": True, "message": f"ÄÃ£ tÃ¬m kiáº¿m: {search_text}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# NEWS SCRAPING TOOLS
# ============================================================

async def get_vnexpress_news(category: str = "home", max_articles: int = 5) -> dict:
    """
    Láº¥y tin tá»©c tá»« VnExpress RSS feeds (khÃ´ng cáº§n feedparser)
    category: home, thoi-su, goc-nhin, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, gia-dinh, du-lich, khoa-hoc, so-hoa, xe, cong-dong, tam-su, cuoi
    """
    try:
        import aiohttp
        import xml.etree.ElementTree as ET
        
        # RSS URL mapping
        rss_urls = {
            "home": "https://vnexpress.net/rss/tin-moi-nhat.rss",
            "thoi-su": "https://vnexpress.net/rss/thoi-su.rss",
            "the-gioi": "https://vnexpress.net/rss/the-gioi.rss",
            "kinh-doanh": "https://vnexpress.net/rss/kinh-doanh.rss",
            "giai-tri": "https://vnexpress.net/rss/giai-tri.rss",
            "the-thao": "https://vnexpress.net/rss/the-thao.rss",
            "phap-luat": "https://vnexpress.net/rss/phap-luat.rss",
            "giao-duc": "https://vnexpress.net/rss/giao-duc.rss",
            "suc-khoe": "https://vnexpress.net/rss/suc-khoe.rss",
            "du-lich": "https://vnexpress.net/rss/du-lich.rss",
            "khoa-hoc": "https://vnexpress.net/rss/khoa-hoc.rss",
            "so-hoa": "https://vnexpress.net/rss/so-hoa.rss",
            "xe": "https://vnexpress.net/rss/oto-xe-may.rss",
        }
        
        rss_url = rss_urls.get(category, rss_urls["home"])
        
        print(f"ğŸ“° [News] Fetching news from: {rss_url}")
        
        # âš¡ DÃ¹ng aiohttp thay vÃ¬ feedparser
        async with aiohttp.ClientSession() as session:
            async with session.get(rss_url, timeout=8) as resp:
                if resp.status != 200:
                    return {"success": False, "error": f"HTTP {resp.status}"}
                
                content = await resp.text()
                root = ET.fromstring(content)
                
                articles = []
                items = root.findall('.//item')[:max_articles]
                
                for i, item in enumerate(items):
                    try:
                        title_elem = item.find('title')
                        link_elem = item.find('link')
                        pubdate_elem = item.find('pubDate')
                        desc_elem = item.find('description')
                        
                        article = {
                            "title": title_elem.text if title_elem is not None else "No title",
                            "link": link_elem.text if link_elem is not None else "",
                            "published": pubdate_elem.text if pubdate_elem is not None else "",
                            "description": ""
                        }
                        
                        # Get description (strip HTML tags)
                        if desc_elem is not None and desc_elem.text:
                            import re
                            desc_text = re.sub(r'<[^>]+>', '', desc_elem.text)
                            article["description"] = desc_text.strip()[:200] + "..."
                        
                        articles.append(article)
                        print(f"âœ… [News] Article {i+1}: {article['title'][:50]}...")
                        
                    except Exception as e:
                        print(f"âš ï¸ [News] Error parsing article {i+1}: {e}")
        
        result = {
            "success": True,
            "category": category,
            "total": len(articles),
            "articles": articles,
            "message": f"ÄÃ£ láº¥y {len(articles)} tin tá»©c tá»« VnExpress ({category})"
        }
        
        # ğŸ¤– GEMINI SUMMARIZATION: Náº¿u >3 bÃ i â†’ tÃ³m táº¯t thÃ´ng minh
        if len(articles) > 3:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title']}\n   {a['description']}"
                    for i, a in enumerate(articles)
                ])
                summary_prompt = f"""TÃ³m táº¯t {len(articles)} tin tá»©c sau thÃ nh 5 bullet points QUAN TRá»ŒNG NHáº¤T (tiáº¿ng Viá»‡t):

{context}

YÃªu cáº§u:
- Má»—i bullet point ngáº¯n gá»n (1 dÃ²ng)
- Highlight xu hÆ°á»›ng/sá»± kiá»‡n chÃ­nh
- Æ¯u tiÃªn tin cÃ³ tÃ¡c Ä‘á»™ng lá»›n
"""
                gemini_summary = await ask_gemini(summary_prompt, model="models/gemini-3-flash-preview")
                
                if gemini_summary.get("success"):
                    result["gemini_summary"] = gemini_summary["response_text"]
                    result["message"] += " (âœ¨ ÄÃ£ tÃ³m táº¯t bá»Ÿi Gemini)"
                    print(f"âœ¨ [News+Gemini] Summarized {len(articles)} articles")
            except Exception as e:
                print(f"âš ï¸ [News+Gemini] Summary failed: {e}")
        
        return result
        
    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}


async def get_news_summary(category: str = "home") -> dict:
    """
    Láº¥y tÃ³m táº¯t tin tá»©c nhanh (chá»‰ tiÃªu Ä‘á»)
    """
    try:
        result = await get_vnexpress_news(category=category, max_articles=10)
        
        if not result.get("success"):
            return result
        
        # Táº¡o summary text
        summary_lines = [f"ğŸ“° TIN Tá»¨C {category.upper()} - VnExpress"]
        summary_lines.append("=" * 50)
        
        for i, article in enumerate(result["articles"], 1):
            summary_lines.append(f"{i}. {article['title']}")
        
        summary_text = "\n".join(summary_lines)
        
        # ğŸ¤– GEMINI INTELLIGENT SUMMARY: PhÃ¢n tÃ­ch xu hÆ°á»›ng + chá»n top stories
        gemini_analysis = None
        if len(result["articles"]) >= 5:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title']}"
                    for i, a in enumerate(result["articles"])
                ])
                analysis_prompt = f"""PhÃ¢n tÃ­ch {len(result['articles'])} tin tá»©c sau vÃ  cho biáº¿t:
1. Top 3 tin QUAN TRá»ŒNG NHáº¤T (kÃ¨m lÃ½ do)
2. Xu hÆ°á»›ng chung
3. Chá»§ Ä‘á» ná»•i báº­t

{context}

Format ngáº¯n gá»n, dá»… Ä‘á»c (tiáº¿ng Viá»‡t)."""
                
                gemini_result = await ask_gemini(analysis_prompt, model="models/gemini-3-flash-preview")
                if gemini_result.get("success"):
                    gemini_analysis = gemini_result["response_text"]
                    print(f"âœ¨ [News+Gemini] Analyzed {len(result['articles'])} news items")
            except Exception as e:
                print(f"âš ï¸ [News+Gemini] Analysis failed: {e}")
        
        return {
            "success": True,
            "category": category,
            "total": len(result["articles"]),
            "summary": summary_text,
            "gemini_analysis": gemini_analysis,
            "articles": result["articles"],
            "message": f"TÃ³m táº¯t {len(result['articles'])} tin tá»©c" + (" (âœ¨ + PhÃ¢n tÃ­ch Gemini)" if gemini_analysis else "")
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def search_news(keyword: str, max_results: int = 5) -> dict:
    """
    TÃ¬m kiáº¿m tin tá»©c theo tá»« khÃ³a trong cÃ¡c bÃ i viáº¿t gáº§n Ä‘Ã¢y
    """
    try:
        # Get recent news from multiple categories
        categories = ["home", "thoi-su", "the-gioi", "kinh-doanh", "the-thao"]
        all_articles = []
        
        for cat in categories:
            result = await get_vnexpress_news(category=cat, max_articles=5)
            if result.get("success"):
                all_articles.extend(result["articles"])
        
        # Filter by keyword
        keyword_lower = keyword.lower()
        matched = []
        
        for article in all_articles:
            title_lower = article["title"].lower()
            desc_lower = article.get("description", "").lower()
            
            if keyword_lower in title_lower or keyword_lower in desc_lower:
                matched.append(article)
        
        matched = matched[:max_results]
        
        if not matched:
            return {
                "success": True,
                "keyword": keyword,
                "total": 0,
                "articles": [],
                "message": f"KhÃ´ng tÃ¬m tháº¥y tin tá»©c vá» '{keyword}'"
            }
        
        result = {
            "success": True,
            "keyword": keyword,
            "total": len(matched),
            "articles": matched,
            "message": f"TÃ¬m tháº¥y {len(matched)} tin tá»©c vá» '{keyword}'"
        }
        
        # ğŸ¤– GEMINI SUMMARIZATION: Náº¿u >3 káº¿t quáº£ â†’ tÃ³m táº¯t nhanh
        if len(matched) > 3:
            try:
                context = "\n".join([
                    f"{i+1}. {a['title'][:100]}"
                    for i, a in enumerate(matched[:5])
                ])
                # âš¡ PROMPT NGáº®N
                summary_prompt = f"""TÃ³m táº¯t 3-4 Ã½ chÃ­nh vá» \"{keyword}\" tá»« {len(matched)} tin:
{context}

Format: ğŸ“Œ [3-4 Ä‘iá»ƒm chÃ­nh]"""
                
                # â±ï¸ Timeout 8s
                gemini_summary = await asyncio.wait_for(
                    ask_gemini_direct(summary_prompt, model="models/gemini-3-flash-preview"),
                    timeout=8.0
                )
                
                if gemini_summary.get("success"):
                    result["gemini_summary"] = gemini_summary["response_text"]
                    result["message"] += " (âœ¨ Gemini)"
                    print(f"âœ… [Search+Gemini] '{keyword}' done")
            except asyncio.TimeoutError:
                print(f"â±ï¸ [Search+Gemini] Timeout for '{keyword}'")
            except Exception as e:
                print(f"âš ï¸ [Search+Gemini] Error: {e}")
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def get_gold_price() -> dict:
    """
    Láº¥y giÃ¡ vÃ ng tá»« cÃ¡c nguá»“n uy tÃ­n
    """
    try:
        import requests
        from bs4 import BeautifulSoup
        import re

        # Try multiple sources
        sources = [
            {
                "name": "Sjc.com.vn",
                "url": "https://sjc.com.vn/xml/tygiavang.xml",
                "type": "xml"
            },
            {
                "name": "BNews.vn",
                "url": "https://bnews.vn/gia-vang/t32.html",
                "type": "html"
            }
        ]

        print(f"ğŸ’° [Gold] Fetching gold prices...")

        # Try SJC XML first
        try:
            response = requests.get(sources[0]["url"], timeout=10, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            response.encoding = 'utf-8'

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'xml')
                items = soup.find_all('item')

                if items:
                    gold_data = []

                    for item in items[:10]:
                        try:
                            gold_item = {
                                "type": item.get('@type', 'N/A'),
                                "buy": item.get('@buy', 'N/A'),
                                "sell": item.get('@sell', 'N/A')
                            }

                            # Fallback to text content if attributes not found
                            if gold_item["type"] == 'N/A':
                                type_tag = item.find('type')
                                buy_tag = item.find('buy')
                                sell_tag = item.find('sell')

                                if type_tag:
                                    gold_item["type"] = type_tag.get_text(strip=True)
                                if buy_tag:
                                    gold_item["buy"] = buy_tag.get_text(strip=True)
                                if sell_tag:
                                    gold_item["sell"] = sell_tag.get_text(strip=True)

                            gold_data.append(gold_item)
                            print(f"âœ… [Gold] {gold_item['type']}: Mua {gold_item['buy']} | BÃ¡n {gold_item['sell']}")

                        except Exception as e:
                            print(f"âš ï¸ [Gold] Error parsing item: {e}")
                            continue

                    if gold_data:
                        # Loáº¡i bá» trÃ¹ng láº·p
                        seen = set()
                        unique_gold_data = []
                        for item in gold_data:
                            key = f"{item['type']}_{item['buy']}_{item['sell']}"
                            if key not in seen:
                                seen.add(key)
                                unique_gold_data.append(item)
                        
                        gold_data = unique_gold_data[:10]
                        
                        # Táº¡o summary
                        summary_lines = ["ğŸ’° GIÃ VÃ€NG HÃ”M NAY - SJC", "=" * 60]

                        for item in gold_data:
                            summary_lines.append(f"ğŸ“Š {item['type']}")
                            summary_lines.append(f"   Mua vÃ o: {item['buy']} VNÄ | BÃ¡n ra: {item['sell']} VNÄ")
                            summary_lines.append("")

                        summary_text = "\n".join(summary_lines)
                        
                        # ğŸ™ï¸ TTS-friendly description
                        tts_lines = ["GiÃ¡ vÃ ng SJC hÃ´m nay nhÆ° sau:"]
                        for item in gold_data[:5]:
                            tts_lines.append(f"Loáº¡i {item['type']}: giÃ¡ mua {item['buy']} nghÃ¬n, giÃ¡ bÃ¡n {item['sell']} nghÃ¬n Ä‘á»“ng.")
                        tts_description = " ".join(tts_lines)

                        return {
                            "success": True,
                            "total": len(gold_data),
                            "gold_prices": gold_data,
                            "summary": summary_text,
                            "tts_description": tts_description,
                            "message": f"ÄÃ£ láº¥y giÃ¡ {len(gold_data)} loáº¡i vÃ ng",
                            "source": "SJC.com.vn",
                            "note_for_llm": "Khi Ä‘á»c giÃ¡ vÃ ng, hÃ£y dÃ¹ng trÆ°á»ng 'tts_description'. GiÃ¡ tÃ­nh theo nghÃ¬n Ä‘á»“ng/lÆ°á»£ng."
                        }

        except Exception as e:
            print(f"âš ï¸ [Gold] Error with SJC source: {e}")

        # Fallback: Try giavang.org scraping
        try:
            print(f"ğŸ’° [Gold] Trying giavang.org...")
            response = requests.get('https://giavang.org/', timeout=15, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })

            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')

                # Look for gold price tables
                tables = soup.find_all('table')
                gold_data = []

                for table in tables:
                    rows = table.find_all('tr')

                    for row in rows:
                        cols = row.find_all(['td', 'th'])
                        if len(cols) >= 3:
                            # Get text from columns
                            col_texts = [col.get_text(strip=True) for col in cols]

                            # Look for gold type and prices
                            if len(col_texts) >= 3:
                                gold_type = col_texts[0]
                                buy_price = col_texts[1]
                                sell_price = col_texts[2]

                                # Check if this looks like gold data
                                if ('vÃ ng' in gold_type.lower() or 'sjc' in gold_type.lower() or 'nháº«n' in gold_type.lower() or 'pnj' in gold_type.lower() or 'doji' in gold_type.lower()) and buy_price and sell_price:
                                    # Clean prices
                                    buy_clean = re.sub(r'[^\d]', '', buy_price)
                                    sell_clean = re.sub(r'[^\d]', '', sell_price)

                                    if buy_clean and sell_clean:
                                        # Format with dots
                                        buy_formatted = f"{int(buy_clean):,}".replace(',', '.')
                                        sell_formatted = f"{int(sell_clean):,}".replace(',', '.')

                                        gold_data.append({
                                            "type": gold_type,
                                            "buy": buy_formatted,
                                            "sell": sell_formatted
                                        })
                                        print(f"âœ… [Gold] {gold_type}: Mua {buy_formatted} | BÃ¡n {sell_formatted}")

                if gold_data:
                    # Loáº¡i bá» trÃ¹ng láº·p dá»±a trÃªn type + buy + sell
                    seen = set()
                    unique_gold_data = []
                    for item in gold_data:
                        key = f"{item['type']}_{item['buy']}_{item['sell']}"
                        if key not in seen:
                            seen.add(key)
                            unique_gold_data.append(item)
                    
                    gold_data = unique_gold_data[:10]  # Max 10 items
                    
                    # Táº¡o summary dá»… Ä‘á»c cho LLM/TTS
                    summary_lines = ["ğŸ’° GIÃ VÃ€NG HÃ”M NAY - GIAVANG.ORG", "=" * 60]

                    for item in gold_data:
                        summary_lines.append(f"ğŸ“Š {item['type']}")
                        summary_lines.append(f"   Mua vÃ o: {item['buy']} VNÄ | BÃ¡n ra: {item['sell']} VNÄ")
                        summary_lines.append("")

                    summary_text = "\n".join(summary_lines)
                    
                    # ğŸ™ï¸ TTS-friendly description cho LLM Ä‘á»c giÃ¡ vÃ ng
                    def format_price_speech(price_str):
                        """
                        Convert giÃ¡ vÃ ng sang tiáº¿ng Viá»‡t dá»… Ä‘á»c
                        - '180.100' = 180,100 nghÃ¬n = 180 triá»‡u 100 nghÃ¬n VND
                        - GiÃ¡ vÃ ng hiá»ƒn thá»‹ theo nghÃ¬n Ä‘á»“ng/lÆ°á»£ng
                        """
                        try:
                            # Remove dots/commas and convert to number
                            clean = price_str.replace('.', '').replace(',', '')
                            num = int(clean)
                            
                            # GiÃ¡ vÃ ng tÃ­nh theo nghÃ¬n Ä‘á»“ng/lÆ°á»£ng
                            # VÃ­ dá»¥: 180.100 = 180,100 (nghÃ¬n) = 180 triá»‡u 100 nghÃ¬n VND
                            # num = 180100 â†’ 180 triá»‡u + 100 nghÃ¬n
                            
                            if num >= 1000:
                                # GiÃ¡ >= 1000 nghÃ¬n = tá»« 1 triá»‡u trá»Ÿ lÃªn
                                millions = num // 1000  # 180100 // 1000 = 180
                                thousands = num % 1000  # 180100 % 1000 = 100
                                
                                if millions > 0 and thousands > 0:
                                    return f"{millions} triá»‡u {thousands} nghÃ¬n"
                                elif millions > 0:
                                    return f"{millions} triá»‡u"
                                else:
                                    return f"{thousands} nghÃ¬n"
                            else:
                                return f"{num} nghÃ¬n"
                        except:
                            return price_str
                    
                    # Táº¡o mÃ´ táº£ dáº¡ng cÃ¢u cho TTS
                    tts_lines = ["GiÃ¡ vÃ ng hÃ´m nay nhÆ° sau:"]
                    for i, item in enumerate(gold_data[:5], 1):  # Top 5 cho TTS
                        gold_type = item['type'].replace('DOJI', 'ÄÃ´-ji').replace('PNJ', 'PÃª-en-gi').replace('SJC', 'Ã©t-gi-xi')
                        buy_speech = format_price_speech(item['buy'])
                        sell_speech = format_price_speech(item['sell'])
                        tts_lines.append(f"Loáº¡i {gold_type}: giÃ¡ mua {buy_speech}, giÃ¡ bÃ¡n {sell_speech}.")
                    
                    tts_description = " ".join(tts_lines)

                    return {
                        "success": True,
                        "total": len(gold_data),
                        "gold_prices": gold_data,
                        "summary": summary_text,
                        "tts_description": tts_description,
                        "message": f"ÄÃ£ láº¥y giÃ¡ {len(gold_data)} loáº¡i vÃ ng tá»« giavang.org",
                        "source": "giavang.org",
                        "note_for_llm": "Khi Ä‘á»c giÃ¡ vÃ ng cho ngÆ°á»i dÃ¹ng, hÃ£y dÃ¹ng trÆ°á»ng 'tts_description' Ä‘á»ƒ Ä‘á»c tá»± nhiÃªn báº±ng tiáº¿ng Viá»‡t. GiÃ¡ tÃ­nh theo nghÃ¬n Ä‘á»“ng/lÆ°á»£ng."
                    }

        except Exception as e:
            print(f"âš ï¸ [Gold] Error with giavang.org: {e}")

        # Final fallback: Return sample data
        sample_data = [
            {"type": "VÃ ng SJC 1L, 10L", "buy": "88.500.000", "sell": "90.000.000"},
            {"type": "VÃ ng SJC 5c", "buy": "88.500.000", "sell": "90.200.000"},
            {"type": "VÃ ng nháº«n SJC 99.99 1c, 5c", "buy": "87.800.000", "sell": "89.300.000"},
            {"type": "VÃ ng nháº«n SJC 99.99 0.5c", "buy": "87.800.000", "sell": "89.400.000"},
        ]

        summary_lines = ["ğŸ’° GIÃ VÃ€NG THAM KHáº¢O", "=" * 60]
        for item in sample_data:
            summary_lines.append(f"ğŸ“Š {item['type']}")
            summary_lines.append(f"   Mua vÃ o: {item['buy']} VNÄ | BÃ¡n ra: {item['sell']} VNÄ")
            summary_lines.append("")

        return {
            "success": True,
            "total": len(sample_data),
            "gold_prices": sample_data,
            "summary": "\n".join(summary_lines),
            "message": f"GiÃ¡ vÃ ng tham kháº£o ({len(sample_data)} loáº¡i)",
            "source": "Sample Data",
            "note": "GiÃ¡ tham kháº£o, khÃ´ng thá»ƒ káº¿t ná»‘i nguá»“n chÃ­nh thá»‘ng"
        }

    except Exception as e:
        return {"success": False, "error": f"Lá»—i: {str(e)}"}


async def analyze_gold_price_with_ai(analysis_type: str = "compare_month") -> dict:
    """
    PhÃ¢n tÃ­ch giÃ¡ vÃ ng vá»›i AI (Gemini + Google Search).
    Láº¥y giÃ¡ hiá»‡n táº¡i, tÃ¬m dá»¯ liá»‡u lá»‹ch sá»­ qua Google, vÃ  phÃ¢n tÃ­ch chi tiáº¿t.
    
    Args:
        analysis_type: Loáº¡i phÃ¢n tÃ­ch. Options: "compare_month" (so sÃ¡nh vá»›i thÃ¡ng trÆ°á»›c), "trend" (xu hÆ°á»›ng), "forecast" (dá»± Ä‘oÃ¡n)
    """
    try:
        from datetime import datetime, timedelta
        
        print(f"ğŸ” [Gold AI] Starting gold price analysis: {analysis_type}")
        
        # 1. Láº¥y giÃ¡ vÃ ng hiá»‡n táº¡i
        current_gold = await get_gold_price()
        if not current_gold.get("success"):
            return {"success": False, "error": "KhÃ´ng láº¥y Ä‘Æ°á»£c giÃ¡ vÃ ng hiá»‡n táº¡i"}
        
        current_price_text = current_gold.get("summary", "")
        gold_prices = current_gold.get("gold_prices", [])
        
        # 2. TÃ¬m giÃ¡ vÃ ng thÃ¡ng trÆ°á»›c qua Google Search (náº¿u cÃ³ Serper API)
        historical_data = ""
        
        if SERPER_API_KEY and SERPER_API_KEY.strip():
            try:
                import requests
                
                # TÃ­nh thÃ¡ng trÆ°á»›c
                last_month_vn = (datetime.now() - timedelta(days=30)).strftime("thÃ¡ng %m nÄƒm %Y")
                
                # TÃ¬m giÃ¡ vÃ ng thÃ¡ng trÆ°á»›c
                search_query = f"giÃ¡ vÃ ng SJC cao nháº¥t {last_month_vn}"
                
                url = "https://google.serper.dev/search"
                headers = {
                    "X-API-KEY": SERPER_API_KEY,
                    "Content-Type": "application/json"
                }
                payload = {
                    "q": search_query,
                    "gl": "vn",
                    "hl": "vi",
                    "num": 5
                }
                
                response = requests.post(url, headers=headers, json=payload, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Láº¥y Answer Box
                    answer_box = data.get("answerBox", {})
                    if answer_box:
                        answer = answer_box.get("answer", "") or answer_box.get("snippet", "")
                        if answer:
                            historical_data += f"\nğŸ“Œ DIRECT ANSWER: {answer}\n"
                    
                    # Láº¥y Organic Results
                    organic = data.get("organic", [])
                    historical_data += f"\nğŸ“Š Káº¾T QUáº¢ TÃŒM KIáº¾M '{search_query}':\n"
                    for i, item in enumerate(organic[:3], 1):
                        title = item.get("title", "")
                        snippet = item.get("snippet", "")
                        historical_data += f"\n{i}. {title}\n   {snippet}\n"
                    
                    print(f"âœ… [Gold AI] Got historical data from Google")
                else:
                    print(f"âš ï¸ [Gold AI] Serper API returned {response.status_code}")
                    
            except Exception as e:
                print(f"âš ï¸ [Gold AI] Error fetching historical data: {e}")
                historical_data = "\nâš ï¸ KhÃ´ng thá»ƒ láº¥y dá»¯ liá»‡u lá»‹ch sá»­ tá»« Google\n"
        else:
            historical_data = "\nâš ï¸ KhÃ´ng cÃ³ Serper API key Ä‘á»ƒ tÃ¬m dá»¯ liá»‡u lá»‹ch sá»­\n"
        
        # 3. Chuáº©n bá»‹ prompt cho Gemini - CHI TIáº¾T Vá»ªA Äá»¦
        if analysis_type == "compare_month":
            analysis_prompt = f"""Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng vÃ ng. HÃ£y phÃ¢n tÃ­ch CHI TIáº¾T giÃ¡ vÃ ng:

ğŸ“Š GIÃ HIá»†N Táº I ({datetime.now().strftime("%d/%m/%Y")}):
{current_price_text}

ğŸ“ˆ Dá»® LIá»†U Lá»ŠCH Sá»¬:
{historical_data}

YÃŠU Cáº¦U PHÃ‚N TÃCH (300-400 tá»«):
1. So sÃ¡nh giÃ¡ vÃ ng hiá»‡n táº¡i vá»›i thÃ¡ng trÆ°á»›c (% thay Ä‘á»•i cá»¥ thá»ƒ)
2. ÄÃ¡nh giÃ¡ xu hÆ°á»›ng: tÄƒng/giáº£m/á»•n Ä‘á»‹nh (phÃ¢n tÃ­ch ká»¹ lÆ°á»£ng)
3. PhÃ¢n tÃ­ch nguyÃªn nhÃ¢n biáº¿n Ä‘á»™ng (kinh táº¿, chÃ­nh trá»‹, USD, láº¡m phÃ¡t, nguá»“n cung)
4. Dá»± bÃ¡o ngáº¯n háº¡n (1-2 tuáº§n tá»›i)
5. Khuyáº¿n nghá»‹ cá»¥ thá»ƒ cho nhÃ  Ä‘áº§u tÆ° (Mua/BÃ¡n/Chá» + lÃ½ do chi tiáº¿t)

Format output:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’° PHÃ‚N TÃCH GIÃ VÃ€NG
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š SO SÃNH GIÃ:
[GiÃ¡ hiá»‡n táº¡i vs thÃ¡ng trÆ°á»›c, % thay Ä‘á»•i, biá»ƒu hiá»‡n thá»‹ trÆ°á»ng]

ğŸ“ˆ XU HÆ¯á»šNG:
[Nháº­n Ä‘á»‹nh chi tiáº¿t vá» xu hÆ°á»›ng tÄƒng/giáº£m, má»©c Ä‘á»™ biáº¿n Ä‘á»™ng]

ğŸ” NGUYÃŠN NHÃ‚N:
[PhÃ¢n tÃ­ch 3-4 nguyÃªn nhÃ¢n chÃ­nh vá»›i giáº£i thÃ­ch cá»¥ thá»ƒ]

ğŸ”® Dá»° BÃO:
[Dá»± Ä‘oÃ¡n ngáº¯n háº¡n vÃ  cÄƒn cá»©]

ğŸ’¡ KHUYáº¾N NGHá»Š:
[Lá»i khuyÃªn cá»¥ thá»ƒ cho nhÃ  Ä‘áº§u tÆ°: Mua/BÃ¡n/Chá» + má»©c giÃ¡ nÃªn giao dá»‹ch]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        elif analysis_type == "trend":
            analysis_prompt = f"""PhÃ¢n tÃ­ch xu hÆ°á»›ng giÃ¡ vÃ ng (200-300 tá»«):

GIÃ HIá»†N Táº I: {current_price_text}
Dá»® LIá»†U: {historical_data}

Tráº£ lá»i ngáº¯n:
ğŸ“ˆ Xu hÆ°á»›ng ngáº¯n háº¡n: [1-2 tuáº§n]
ğŸ“Š Xu hÆ°á»›ng trung háº¡n: [1-3 thÃ¡ng] 
ğŸ” Yáº¿u tá»‘ chÃ­nh: [1-2 Ä‘iá»ƒm]
"""
        else:  # forecast
            analysis_prompt = f"""Dá»± bÃ¡o giÃ¡ vÃ ng (tá»‘i Ä‘a 100 tá»«):

HIá»†N Táº I: {current_price_text}
Lá»ŠCH Sá»¬: {historical_data}

Tráº£ lá»i ngáº¯n:
ğŸ“Š Dá»± bÃ¡o: [tÄƒng/giáº£m x%]
â° Thá»i gian: [ngáº¯n/trung háº¡n]
ğŸ’¡ Khuyáº¿n nghá»‹: [hÃ nh Ä‘á»™ng cá»¥ thá»ƒ]
"""
        
        # 4. Gá»i Gemini phÃ¢n tÃ­ch
        if not GEMINI_AVAILABLE or not GEMINI_API_KEY:
            return {
                "success": False,
                "error": "Gemini API khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng cáº¥u hÃ¬nh GEMINI_API_KEY."
            }
        
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        print(f"ğŸ¤– [Gold AI] Asking Gemini to analyze...")
        response = model.generate_content(
            analysis_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
                max_output_tokens=1500  # TÄƒng lÃªn 1500 Ä‘á»ƒ phÃ¢n tÃ­ch chuyÃªn sÃ¢u
            )
        )
        
        analysis_result = response.text.strip()
        
        print(f"âœ… [Gold AI] Analysis complete")
        
        # Return ONLY analysis text - trÃ¡nh bá»‹ truncate
        return {
            "success": True,
            "content": analysis_result  # Chá»‰ tráº£ vá» ná»™i dung phÃ¢n tÃ­ch
        }
        
    except Exception as e:
        print(f"âŒ [Gold AI] Error: {e}")
        return {
            "success": False,
            "error": f"Lá»—i phÃ¢n tÃ­ch: {str(e)}"
        }


# ============================================================================
# ğŸ” GEMINI WITH GOOGLE SEARCH GROUNDING
# ============================================================================
# TÃ­nh nÄƒng cho phÃ©p Gemini tá»± Ä‘á»™ng tra cá»©u Google Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n
# Sá»­ dá»¥ng Google Search Grounding API chÃ­nh thá»©c

async def ask_gemini_with_google_search(
    prompt: str, 
    model: str = "gemini-2.0-flash",
    dynamic_threshold: float = 0.7
) -> dict:
    """
    ğŸ” Há»i Gemini vá»›i Google Search Grounding - Tra cá»©u Google tá»± Ä‘á»™ng
    
    TÃ­nh nÄƒng nÃ y cho phÃ©p Gemini:
    - Tá»± Ä‘á»™ng tÃ¬m kiáº¿m thÃ´ng tin má»›i nháº¥t trÃªn Google
    - Tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u real-time tá»« internet
    - Cung cáº¥p nguá»“n trÃ­ch dáº«n (citations)
    
    Args:
        prompt: CÃ¢u há»i cáº§n Gemini tráº£ lá»i vá»›i thÃ´ng tin má»›i nháº¥t
        model: Model Gemini há»— trá»£ grounding (gemini-2.0-flash, gemini-1.5-pro, etc.)
        dynamic_threshold: NgÆ°á»¡ng Ä‘á»ƒ quyáº¿t Ä‘á»‹nh khi nÃ o dÃ¹ng grounding (0.0-1.0)
        
    Returns:
        dict vá»›i success, response, grounding_metadata, search_queries
    """
    try:
        if not GEMINI_AVAILABLE:
            return {"success": False, "error": "Gemini library chÆ°a cÃ i Ä‘áº·t"}
        
        if not GEMINI_API_KEY or not GEMINI_API_KEY.strip():
            return {"success": False, "error": "Gemini API key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh"}
        
        print(f"ğŸ” [Gemini+GoogleSearch] Starting with model: {model}")
        print(f"ğŸ” [Gemini+GoogleSearch] Prompt: {prompt[:100]}...")
        
        # Import cÃ¡c module cáº§n thiáº¿t tá»« google.genai
        try:
            from google import genai
            from google.genai import types
        except ImportError:
            # Fallback: DÃ¹ng google-generativeai cÅ©
            print("âš ï¸ [Gemini+GoogleSearch] google-genai not found, using legacy method")
            return await _ask_gemini_google_search_legacy(prompt, model)
        
        # Khá»Ÿi táº¡o client vá»›i API key
        client = genai.Client(api_key=GEMINI_API_KEY)
        
        # Cáº¥u hÃ¬nh Google Search tool vá»›i dynamic retrieval
        google_search_tool = types.Tool(
            google_search=types.GoogleSearch()
        )
        
        # System instruction Ä‘á»ƒ Gemini tráº£ lá»i chuyÃªn nghiá»‡p
        from datetime import datetime
        today_str = datetime.now().strftime('%d/%m/%Y')
        today_full = datetime.now().strftime('%A, %d thÃ¡ng %m nÄƒm %Y')
        
        system_instruction = f"""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn nghiá»‡p vá»›i kháº£ nÄƒng tra cá»©u thÃ´ng tin má»›i nháº¥t tá»« Google.

ğŸ“… NGÃ€Y HÃ”M NAY: {today_full}

ğŸ¯ HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
1. Sá»¬ Dá»¤NG GOOGLE SEARCH Ä‘á»ƒ tÃ¬m thÃ´ng tin má»›i nháº¥t, chÃ­nh xÃ¡c
2. Æ¯U TIÃŠN nguá»“n Ä‘Ã¡ng tin cáº­y: trang chÃ­nh thá»©c, bÃ¡o lá»›n, Wikipedia
3. PHÃ‚N TÃCH thá»i gian - náº¿u thÃ´ng tin tá»« quÃ¡ khá»©, xÃ¡c Ä‘á»‹nh xem cÃ²n Ä‘Ãºng khÃ´ng
4. TRáº¢ Lá»œI ngáº¯n gá»n, sÃºc tÃ­ch (200-500 tá»«)
5. TRÃCH DáºªN nguá»“n khi cáº§n thiáº¿t
6. KHÃ”NG nÃ³i "dá»± kiáº¿n" náº¿u sá»± kiá»‡n Ä‘Ã£ xáº£y ra
7. NÃ³i nhÆ° Ä‘ang trÃ² chuyá»‡n tá»± nhiÃªn, khÃ´ng dÃ¹ng markdown phá»©c táº¡p"""

        # Gá»i Gemini vá»›i Google Search grounding
        loop = asyncio.get_event_loop()
        
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: client.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        tools=[google_search_tool],
                        system_instruction=system_instruction,
                        temperature=0.7,
                    )
                )
            ),
            timeout=30.0  # Timeout 30s vÃ¬ cáº§n thá»i gian search
        )
        
        # Láº¥y text response
        response_text = ""
        if hasattr(response, 'text'):
            response_text = response.text
        elif hasattr(response, 'candidates') and response.candidates:
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'text'):
                    response_text += part.text
        
        # Láº¥y grounding metadata (nguá»“n trÃ­ch dáº«n)
        grounding_metadata = None
        search_queries = []
        grounding_chunks = []
        
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata'):
                gm = candidate.grounding_metadata
                grounding_metadata = {
                    "search_entry_point": getattr(gm, 'search_entry_point', None),
                    "grounding_supports": []
                }
                
                # Láº¥y search queries Ä‘Ã£ dÃ¹ng
                if hasattr(gm, 'web_search_queries'):
                    search_queries = list(gm.web_search_queries or [])
                
                # Láº¥y grounding chunks (nguá»“n)
                if hasattr(gm, 'grounding_chunks'):
                    for chunk in (gm.grounding_chunks or []):
                        if hasattr(chunk, 'web'):
                            grounding_chunks.append({
                                "uri": getattr(chunk.web, 'uri', ''),
                                "title": getattr(chunk.web, 'title', '')
                            })
                
                # Láº¥y grounding supports
                if hasattr(gm, 'grounding_supports'):
                    for support in (gm.grounding_supports or []):
                        support_data = {
                            "segment": getattr(support.segment, 'text', '') if hasattr(support, 'segment') else '',
                            "confidence_scores": list(support.confidence_scores or []) if hasattr(support, 'confidence_scores') else []
                        }
                        grounding_metadata["grounding_supports"].append(support_data)
        
        print(f"âœ… [Gemini+GoogleSearch] Response received: {len(response_text)} chars")
        if search_queries:
            print(f"ğŸ” [Gemini+GoogleSearch] Search queries: {search_queries}")
        if grounding_chunks:
            print(f"ğŸ“š [Gemini+GoogleSearch] Sources: {len(grounding_chunks)} websites")
        
        # Truncate response náº¿u quÃ¡ dÃ i
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
        
        return {
            "success": True,
            "response": response_text,
            "response_text": response_text,  # Alias for compatibility
            "model": model,
            "google_search_used": True,
            "search_queries": search_queries,
            "grounding_chunks": grounding_chunks,
            "grounding_metadata": grounding_metadata,
            "message": f"âœ… Gemini Ä‘Ã£ tra cá»©u Google vÃ  tráº£ lá»i (model: {model})"
        }
        
    except asyncio.TimeoutError:
        print(f"â±ï¸ [Gemini+GoogleSearch] Timeout (30s exceeded)")
        return {
            "success": False,
            "error": "Gemini + Google Search pháº£n há»“i quÃ¡ lÃ¢u (timeout 30s)",
            "timeout": True
        }
    except ImportError as e:
        print(f"âš ï¸ [Gemini+GoogleSearch] Import error: {e}")
        # Fallback to legacy method
        return await _ask_gemini_google_search_legacy(prompt, model)
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [Gemini+GoogleSearch] Error: {error_msg}")
        
        # Náº¿u model khÃ´ng há»— trá»£ grounding, thá»­ fallback
        if "grounding" in error_msg.lower() or "tool" in error_msg.lower():
            print("âš ï¸ [Gemini+GoogleSearch] Grounding not supported, falling back...")
            return await ask_gemini(prompt, model)
        
        return {
            "success": False,
            "error": f"Lá»—i Google Search Grounding: {error_msg}"
        }


async def _ask_gemini_google_search_legacy(prompt: str, model: str = "gemini-2.0-flash") -> dict:
    """
    Fallback: DÃ¹ng google-generativeai cÅ© vá»›i grounding
    """
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        from datetime import datetime
        today_str = datetime.now().strftime('%d/%m/%Y')
        
        # Cáº¥u hÃ¬nh model vá»›i grounding
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "max_output_tokens": 2048,
        }
        
        # Táº¡o tool Google Search
        try:
            # Thá»­ dÃ¹ng google_search_retrieval (phiÃªn báº£n má»›i)
            tools = [{"google_search_retrieval": {"dynamic_retrieval_config": {"mode": "MODE_DYNAMIC", "dynamic_threshold": 0.7}}}]
            gemini_model = genai.GenerativeModel(
                model,
                generation_config=generation_config,
                tools=tools
            )
        except Exception:
            # Fallback: khÃ´ng dÃ¹ng tools
            gemini_model = genai.GenerativeModel(model, generation_config=generation_config)
        
        system_prompt = f"""HÃ´m nay lÃ  {today_str}. Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh.
HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn kiáº¿n thá»©c cá»§a báº¡n. Tráº£ lá»i ngáº¯n gá»n, chuyÃªn nghiá»‡p."""
        
        full_prompt = f"{system_prompt}\n\nCÃ¢u há»i: {prompt}"
        
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(None, lambda: gemini_model.generate_content(full_prompt)),
            timeout=25.0
        )
        
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
        
        return {
            "success": True,
            "response": response_text,
            "response_text": response_text,
            "model": model,
            "google_search_used": False,
            "message": f"âœ… Gemini Ä‘Ã£ tráº£ lá»i (model: {model}, legacy mode)"
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def ask_gemini_direct(prompt: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    Gá»i Gemini trá»±c tiáº¿p KHÃ”NG cÃ³ RAG - dÃ¹ng cho summarization/analysis
    
    Args:
        prompt: Prompt gá»­i cho Gemini
        model: Model Gemini (máº·c Ä‘á»‹nh: gemini-3-flash-preview)
        
    Returns:
        dict vá»›i success, response_text
    """
    try:
        # Kiá»ƒm tra Gemini cÃ³ kháº£ dá»¥ng khÃ´ng
        if not GEMINI_AVAILABLE:
            return {"success": False, "error": "Gemini library chÆ°a cÃ i Ä‘áº·t"}
        
        if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
            return {"success": False, "error": "Gemini API key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh"}
        
        # Cáº¥u hÃ¬nh Gemini
        genai.configure(api_key=GEMINI_API_KEY)
        gemini_model = genai.GenerativeModel(model)
        
        # Gá»i API vá»›i timeout 15 giÃ¢y
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None, 
                lambda: gemini_model.generate_content(prompt)
            ),
            timeout=15.0
        )
        
        response_text = response.text
        
        # ğŸ”„ TRUNCATE: Giá»›i háº¡n response dÆ°á»›i 4000 kÃ½ tá»± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[Gemini Direct] âœ‚ï¸ Truncated: {original_len} â†’ {len(response_text)} chars")
        
        return {
            "success": True,
            "response_text": response_text,
            "model": model
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def ask_gemini(prompt: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    Há»i Ä‘Ã¡p vá»›i Google Gemini AI - CÃ³ tÃ­ch há»£p RAG tá»± Ä‘á»™ng
    
    Args:
        prompt: CÃ¢u há»i hoáº·c ná»™i dung muá»‘n gá»­i cho Gemini
        model: TÃªn model Gemini (máº·c Ä‘á»‹nh: models/gemini-3-flash-preview - Flash 2.0 experimental)
        
    Returns:
        dict vá»›i success, response_text, vÃ  message
    """
    try:
        # ===== AUTO RAG: Kiá»ƒm tra cÃ³ cáº§n tra cá»©u web khÃ´ng =====
        # Má»Ÿ rá»™ng keywords Ä‘á»ƒ bao quÃ¡t nhiá»u cÃ¢u há»i thá»i sá»± hÆ¡n
        realtime_keywords = [
            # GiÃ¡ cáº£, tÃ i chÃ­nh
            'giÃ¡ vÃ ng', 'giÃ¡ usd', 'tá»· giÃ¡', 'giÃ¡ bitcoin', 'crypto', 'chá»©ng khoÃ¡n', 
            'stock', 'gold price', 'exchange rate', 'giÃ¡ xÄƒng', 'giÃ¡ dáº§u',
            'giÃ¡ cao nháº¥t', 'cao nháº¥t', 'tháº¥p nháº¥t', 'giÃ¡ hiá»‡n táº¡i', 'giÃ¡ má»›i nháº¥t',
            'highest price', 'lowest price', 'current price', 'latest price',
            
            # Thá»i tiáº¿t
            'thá»i tiáº¿t', 'weather', 'nhiá»‡t Ä‘á»™', 'temperature', 'mÆ°a', 'rain',
            
            # Tin tá»©c, sá»± kiá»‡n
            'tin tá»©c', 'news', 'má»›i nháº¥t', 'latest', 'breaking',
            
            # Thá»i gian thá»±c
            'hÃ´m nay', 'bÃ¢y giá»', 'hiá»‡n nay', 'hiá»‡n táº¡i', 'today', 'now', 'current',
            'currently', 'nÄƒm 2024', 'nÄƒm 2025', '2024', '2025',
            
            # Thá»ƒ thao, cuá»™c thi
            'vÃ´ Ä‘á»‹ch', 'champion', 'winner', 'káº¿t quáº£', 'score', 'result',
            'olympia', 'world cup', 'euro', 'sea games', 'olympic', 'bÃ³ng Ä‘Ã¡', 'football',
            
            # NgÆ°á»i ná»•i tiáº¿ng, chÃ­nh trá»‹
            'tá»•ng thá»‘ng', 'president', 'thá»§ tÆ°á»›ng', 'prime minister', 'chá»§ tá»‹ch',
            'ceo', 'founder', 'leader', 'ai lÃ ', 'who is', 'who are',
            
            # Sáº£n pháº©m, cÃ´ng nghá»‡ má»›i
            'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft',
            'ra máº¯t', 'launch', 'release', 'announced',
            
            # Sá»± kiá»‡n xÃ£ há»™i
            'covid', 'earthquake', 'Ä‘á»™ng Ä‘áº¥t', 'bÃ£o', 'storm', 'lÅ© lá»¥t', 'flood',
            'tai náº¡n', 'accident', 'chÃ¡y', 'fire',
            
            # Tra cá»©u chung
            'lÃ  ai', 'lÃ  gÃ¬', 'á»Ÿ Ä‘Ã¢u', 'what is', 'where is', 'how much',
            'bao nhiÃªu', 'khi nÃ o', 'when'
        ]
        prompt_lower = prompt.lower()
        needs_realtime = any(kw in prompt_lower for kw in realtime_keywords)
        
        rag_context = ""
        if needs_realtime:
            # âœ… Æ¯u tiÃªn Serper API (Google Search trá»±c tiáº¿p) - chÃ­nh xÃ¡c vÃ  nhanh hÆ¡n
            if SERPER_API_KEY and SERPER_API_KEY.strip():
                print(f"[Gemini+Serper] PhÃ¡t hiá»‡n cÃ¢u há»i thá»i gian thá»±c, Ä‘ang tra cá»©u Google...")
                try:
                    import requests
                    from datetime import datetime
                    
                    # ThÃªm ngÃ y thÃ¡ng nÄƒm hiá»‡n táº¡i vÃ o query Ä‘á»ƒ láº¥y thÃ´ng tin má»›i nháº¥t
                    current_date = datetime.now().strftime("%Y")
                    enhanced_query = f"{prompt} {current_date}"
                    
                    # Gá»i Serper API (Google Search)
                    url = "https://google.serper.dev/search"
                    headers = {
                        "X-API-KEY": SERPER_API_KEY,
                        "Content-Type": "application/json"
                    }
                    payload = {
                        "q": enhanced_query,
                        "gl": "vn",  # Vietnam
                        "hl": "vi",  # Vietnamese
                        "num": 5
                    }
                    
                    # âš¡ TIMEOUT 8s cho Serper API
                    response = requests.post(url, headers=headers, json=payload, timeout=8)
                    
                    if response.status_code == 200:
                        data = response.json()
                        results = []
                        
                        # Láº¥y Answer Box trÆ°á»›c (náº¿u cÃ³)
                        answer_box = data.get("answerBox", {})
                        if answer_box:
                            answer = answer_box.get("answer", "") or answer_box.get("snippet", "")
                            if answer:
                                results.append({
                                    "title": "[ğŸ“Œ Direct Answer]",
                                    "snippet": answer,
                                    "url": answer_box.get("link", "")
                                })
                        
                        # Láº¥y Knowledge Graph (náº¿u cÃ³)
                        knowledge_graph = data.get("knowledgeGraph", {})
                        if knowledge_graph:
                            title = knowledge_graph.get("title", "")
                            description = knowledge_graph.get("description", "")
                            if title and description:
                                results.append({
                                    "title": f"[ğŸ¯ Knowledge] {title}",
                                    "snippet": description,
                                    "url": knowledge_graph.get("website", "")
                                })
                        
                        # Láº¥y Organic Results
                        organic = data.get("organic", [])
                        for item in organic[:5]:
                            results.append({
                                "title": item.get("title", ""),
                                "snippet": item.get("snippet", ""),
                                "url": item.get("link", "")
                            })
                        
                        if results:
                            rag_context = f"\n\nğŸ“Š THÃ”NG TIN Tá»ª GOOGLE (tra cá»©u {datetime.now().strftime('%d/%m/%Y')}):\n"
                            rag_context += "LÆ¯U Ã: HÃ£y phÃ¢n tÃ­ch ká»¹ cÃ¡c nguá»“n vÃ  chá»n thÃ´ng tin chÃ­nh xÃ¡c nháº¥t.\n\n"
                            
                            for i, r in enumerate(results, 1):
                                snippet = r['snippet'][:300] if len(r['snippet']) > 300 else r['snippet']
                                rag_context += f"{i}. **{r['title']}**\n   {snippet}\n   ğŸ”— {r.get('url', '')}\n\n"
                            
                            print(f"[Gemini+Serper] âœ… ÄÃ£ láº¥y Ä‘Æ°á»£c {len(results)} káº¿t quáº£ tá»« Google")
                    else:
                        print(f"[Gemini+Serper] âš ï¸ API error: {response.status_code}")
                        
                except Exception as e:
                    print(f"[Gemini+Serper] âš ï¸ Lá»—i tra cá»©u: {e}")
            
            # Fallback: DÃ¹ng RAG system náº¿u khÃ´ng cÃ³ Serper API
            elif RAG_AVAILABLE:
                print(f"[Gemini+RAG] Serper API khÃ´ng cÃ³, dÃ¹ng RAG fallback...")
                try:
                    from rag_system import web_search
                    from datetime import datetime
                    
                    current_date = datetime.now().strftime("%Y")
                    enhanced_query = f"{prompt} {current_date}"
                    
                    rag_result = await web_search(enhanced_query, max_results=5)
                    
                    if rag_result.get('success') and rag_result.get('results'):
                        rag_context = f"\n\nğŸ“Š THÃ”NG TIN Tá»ª INTERNET (tra cá»©u {datetime.now().strftime('%d/%m/%Y')}):\n"
                        rag_context += "LÆ¯U Ã: HÃ£y phÃ¢n tÃ­ch ká»¹ cÃ¡c nguá»“n vÃ  chá»n thÃ´ng tin chÃ­nh xÃ¡c nháº¥t.\n\n"
                        
                        for i, r in enumerate(rag_result['results'], 1):
                            snippet = r['snippet'][:300] if len(r['snippet']) > 300 else r['snippet']
                            rag_context += f"{i}. **{r['title']}**\n   {snippet}\n   ğŸ”— {r.get('url', '')}\n\n"
                        
                        print(f"[Gemini+RAG] âœ… ÄÃ£ láº¥y Ä‘Æ°á»£c {len(rag_result['results'])} káº¿t quáº£ tá»« web")
                except Exception as e:
                    print(f"[Gemini+RAG] âš ï¸ Lá»—i tra cá»©u: {e}")
        
        # Kiá»ƒm tra Gemini cÃ³ kháº£ dá»¥ng khÃ´ng
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini library chÆ°a cÃ i Ä‘áº·t. Cháº¡y: pip install google-generativeai"
            }
        
        # Kiá»ƒm tra API key
        if not GEMINI_API_KEY or GEMINI_API_KEY.strip() == "":
            return {
                "success": False,
                "error": "Gemini API key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh. Vui lÃ²ng thÃªm 'gemini_api_key' vÃ o xiaozhi_endpoints.json",
                "help": "Láº¥y API key táº¡i: https://aistudio.google.com/apikey"
            }
        
        # Cáº¥u hÃ¬nh Gemini vá»›i API key
        genai.configure(api_key=GEMINI_API_KEY)
        print(f"[Gemini] Configured with API key: ...{GEMINI_API_KEY[-8:]}")
        
        # Khá»Ÿi táº¡o model
        print(f"[Gemini] Creating model: {model}")
        gemini_model = genai.GenerativeModel(model)
        print(f"[Gemini] Model created successfully")
        
        # Gá»i API trong executor Ä‘á»ƒ khÃ´ng block event loop
        # ThÃªm RAG context vÃ o prompt náº¿u cÃ³
        from datetime import datetime as dt_now
        enhanced_prompt = prompt
        
        # ğŸ“ INSTRUCTION: YÃªu cáº§u Gemini tráº£ lá»i ngáº¯n gá»n cho TTS
        response_instruction = """

ğŸ“‹ YÃŠU Cáº¦U TRáº¢ Lá»œI:
- Tráº£ lá»i NGáº®N Gá»ŒN, Dá»„ HIá»‚U (tá»‘i Ä‘a 300-500 tá»«)
- Äi tháº³ng vÃ o váº¥n Ä‘á», khÃ´ng dÃ i dÃ²ng
- KHÃ”NG dÃ¹ng markdown (**, #, ---, bullet points)
- NÃ³i nhÆ° Ä‘ang trÃ² chuyá»‡n tá»± nhiÃªn
- DÃ¹ng cÃ¢u ngáº¯n, dá»… Ä‘á»c"""

        if rag_context:
            today_str = dt_now.now().strftime('%d/%m/%Y')
            today_full = dt_now.now().strftime('%d thÃ¡ng %m nÄƒm %Y')
            enhanced_prompt = f"""CÃ‚U Há»I: {prompt}

{rag_context}

âš ï¸ QUAN TRá»ŒNG - NGÃ€Y HIá»†N Táº I: {today_full}

HÆ¯á»šNG DáºªN PHÃ‚N TÃCH THÃ”NG MINH:
1. **SO SÃNH THá»œI GIAN**: So sÃ¡nh ngÃ y trong bÃ i bÃ¡o vá»›i ngÃ y hÃ´m nay ({today_str})
   - Náº¿u bÃ i viáº¿t cÃ³ tá»« "dá»± kiáº¿n", "sáº¯p ra máº¯t", "sáº½ ra máº¯t" VÃ€ ngÃ y Ä‘Ã³ ÄÃƒ QUA â†’ sáº£n pháº©m ÄÃƒ RA Máº®T rá»“i!
   - VÃ­ dá»¥: Náº¿u bÃ i viáº¿t nÃ³i "dá»± kiáº¿n ra máº¯t thÃ¡ng 9/2025" vÃ  hÃ´m nay lÃ  thÃ¡ng 12/2025 â†’ ÄÃƒ RA Máº®T

2. **XÃC Äá»ŠNH TRáº NG THÃI HIá»†N Táº I**:
   - Kiá»ƒm tra xem cÃ¡c nguá»“n cÃ³ nÃ³i "Ä‘Ã£ ra máº¯t", "Ä‘Ã£ cÃ³ hÃ ng", "Ä‘áº·t trÆ°á»›c tá»«..." khÃ´ng
   - Náº¿u cÃ³ ngÃ y Ä‘áº·t trÆ°á»›c/ngÃ y bÃ¡n ÄÃƒ QUA â†’ sáº£n pháº©m ÄANG BÃN
   - Náº¿u nguá»“n chÃ­nh thá»©c (apple.com, thegioididong.com) nÃ³i "sáºµn hÃ ng" â†’ ÄÃƒ CÃ“ BÃN

3. **Æ¯U TIÃŠN NGUá»’N**:
   - Trang chÃ­nh thá»©c (apple.com, google.com...) > BÃ¡o lá»›n > Blog
   - Nguá»“n má»›i nháº¥t > Nguá»“n cÅ©

4. **TRáº¢ Lá»œI CHÃNH XÃC**:
   - KHÃ”NG nÃ³i "dá»± kiáº¿n" náº¿u ngÃ y Ä‘Ã³ Ä‘Ã£ qua
   - DÃ¹ng thÃ¬ HIá»†N Táº I/QUÃ KHá»¨ phÃ¹ há»£p
   - VÃ­ dá»¥ ÄÃšNG: "iPhone 17 Ä‘Ã£ ra máº¯t vÃ o thÃ¡ng 9/2025 vÃ  hiá»‡n Ä‘ang bÃ¡n táº¡i..."
   - VÃ­ dá»¥ SAI: "iPhone 17 dá»± kiáº¿n ra máº¯t thÃ¡ng 9/2025" (khi Ä‘Ã£ lÃ  thÃ¡ng 12/2025!)
{response_instruction}

TRáº¢ Lá»œI (nhá»›: hÃ´m nay lÃ  {today_str}, phÃ¢n tÃ­ch thá»i gian chÃ­nh xÃ¡c):"""
            print(f"[Gemini+RAG] ÄÃ£ bá»• sung context tá»« web vÃ o prompt")
        else:
            # KhÃ´ng cÃ³ RAG, thÃªm instruction vÃ o prompt thÃ´ng thÆ°á»ng
            enhanced_prompt = f"""{prompt}
{response_instruction}"""
        
        print(f"[Gemini] Sending prompt: {enhanced_prompt[:50]}...")
        loop = asyncio.get_event_loop()
        
        # âš¡ TIMEOUT 20s cho ask_gemini chÃ­nh (cÃ³ RAG)
        response = await asyncio.wait_for(
            loop.run_in_executor(
                None,
                lambda: gemini_model.generate_content(enhanced_prompt)
            ),
            timeout=20.0
        )
        print(f"[Gemini] Response received")
        
        # Láº¥y text tá»« response
        response_text = response.text if hasattr(response, 'text') else str(response)
        
        # ğŸ”„ TRUNCATE: Giá»›i háº¡n response dÆ°á»›i 4000 kÃ½ tá»± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[Gemini] âœ‚ï¸ Truncated response: {original_len} â†’ {len(response_text)} chars")
        
        print(f"[Gemini] Response text: {response_text[:100]}...")
        
        result = {
            "success": True,
            "prompt": prompt,
            "response_text": response_text,
            "model": model,
            "message": f"âœ… Gemini Ä‘Ã£ tráº£ lá»i (model: {model})"
        }
        
        # ThÃªm thÃ´ng tin RAG náº¿u Ä‘Ã£ sá»­ dá»¥ng
        if rag_context:
            result["rag_used"] = True
            result["message"] = f"âœ… Gemini Ä‘Ã£ tráº£ lá»i vá»›i thÃ´ng tin tá»« Internet (model: {model})"
        
        return result
        
    except asyncio.TimeoutError:
        print(f"â±ï¸ [Gemini] Timeout (20s exceeded)")
        return {
            "success": False,
            "error": "Gemini pháº£n há»“i quÃ¡ lÃ¢u (timeout 20s). Vui lÃ²ng thá»­ láº¡i vá»›i prompt ngáº¯n hÆ¡n.",
            "timeout": True
        }
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [Gemini] Exception caught: {type(e).__name__}")
        print(f"âŒ [Gemini] Error message: {error_msg}")
        
        # Import traceback Ä‘á»ƒ debug
        import traceback
        traceback.print_exc()
        
        # Xá»­ lÃ½ cÃ¡c lá»—i phá»• biáº¿n
        if "API_KEY_INVALID" in error_msg or "invalid API key" in error_msg.lower():
            return {
                "success": False,
                "error": "API key khÃ´ng há»£p lá»‡. Vui lÃ²ng kiá»ƒm tra láº¡i gemini_api_key trong xiaozhi_endpoints.json",
                "help": "Láº¥y API key má»›i táº¡i: https://aistudio.google.com/apikey"
            }
        elif "quota" in error_msg.lower():
            return {
                "success": False,
                "error": "ÄÃ£ vÆ°á»£t quÃ¡ quota API. Vui lÃ²ng chá» hoáº·c nÃ¢ng cáº¥p plan.",
                "details": error_msg
            }
        elif "rate limit" in error_msg.lower():
            return {
                "success": False,
                "error": "Rate limit exceeded. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt.",
                "details": error_msg
            }
        else:
            return {
                "success": False,
                "error": f"Lá»—i khi gá»i Gemini API: {error_msg}"
            }


async def auto_process_document_with_gemini(user_query: str, model: str = "models/gemini-3-flash-preview") -> dict:
    """
    ğŸ¤– Tá»° Äá»˜NG PHÃT HIá»†N VÃ€ Xá»¬ LÃ TÃ€I LIá»†U/DATABASE Vá»šI GEMINI
    
    Khi ngÆ°á»i dÃ¹ng há»i vá»:
    - CÆ¡ sá»Ÿ dá»¯ liá»‡u (database, CSDL)
    - TÃ i liá»‡u (PDF, Word, TXT, JSON, XML)
    - Files trong knowledge base
    
    Tá»± Ä‘á»™ng:
    1. PhÃ¡t hiá»‡n Ã½ Ä‘á»‹nh ngÆ°á»i dÃ¹ng
    2. TÃ¬m vÃ  Ä‘á»c tÃ i liá»‡u liÃªn quan
    3. Gá»­i ná»™i dung cho Gemini xá»­ lÃ½
    4. Tráº£ vá» káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c Gemini phÃ¢n tÃ­ch
    
    Returns:
        dict vá»›i:
        - gemini_response: Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c Gemini xá»­ lÃ½
        - documents_found: List cÃ¡c documents Ä‘Ã£ tÃ¬m tháº¥y
        - success: True náº¿u thÃ nh cÃ´ng
    """
    try:
        query_lower = user_query.lower()
        
        # PhÃ¡t hiá»‡n keywords vá» database/documents
        document_keywords = [
            'cÆ¡ sá»Ÿ dá»¯ liá»‡u', 'database', 'csdl', 'db',
            'tÃ i liá»‡u', 'document', 'file', 'files',
            'pdf', 'word', 'txt', 'json', 'xml', 'csv',
            'trong file', 'tá»« file', 'á»Ÿ file',
            'knowledge base', 'kiáº¿n thá»©c', 'tri thá»©c',
            'Ä‘á»c file', 'xem file', 'tÃ¬m trong',
            'thÃ´ng tin trong', 'dá»¯ liá»‡u trong'
        ]
        
        # Check náº¿u query cÃ³ chá»©a keywords
        has_document_intent = any(kw in query_lower for kw in document_keywords)
        
        if not has_document_intent:
            return {
                "success": False,
                "activated": False,
                "reason": "Query khÃ´ng liÃªn quan Ä‘áº¿n documents/database"
            }
        
        print(f"ğŸ“Š [Auto Document] Detected document query: {user_query[:100]}")
        
        # Step 1: TÃ¬m documents liÃªn quan tá»« knowledge base
        knowledge_result = await get_knowledge_context(
            query=user_query,
            max_chars=8000,  # Láº¥y nhiá»u context hÆ¡n
            use_gemini_summary=False  # KhÃ´ng tÃ³m táº¯t trÆ°á»›c, Ä‘á»ƒ Gemini xá»­ lÃ½ toÃ n bá»™
        )
        
        if not knowledge_result.get("success"):
            return {
                "success": False,
                "activated": True,
                "error": "KhÃ´ng tÃ¬m tháº¥y documents trong knowledge base",
                "suggestion": "HÃ£y index cÃ¡c files báº±ng /api/knowledge/index_directory"
            }
        
        context = knowledge_result.get("context", "")
        documents_found = knowledge_result.get("documents_included", [])
        
        if not context:
            return {
                "success": False,
                "activated": True,
                "error": "Knowledge base trá»‘ng",
                "documents_found": []
            }
        
        print(f"ğŸ“š [Auto Document] Found {len(documents_found)} documents")
        
        # Step 2: Gá»­i cho Gemini xá»­ lÃ½ vá»›i context Ä‘áº§y Ä‘á»§
        enhanced_prompt = f"""[TÃ€I LIá»†U THAM KHáº¢O]
{context}

[CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG]
{user_query}

[YÃŠU Cáº¦U]
Dá»±a vÃ o tÃ i liá»‡u trÃªn, hÃ£y tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  chi tiáº¿t.
- Náº¿u cÃ³ thÃ´ng tin trong tÃ i liá»‡u, trÃ­ch dáº«n rÃµ rÃ ng
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin, hÃ£y nÃ³i rÃµ
- Tráº£ lá»i báº±ng Tiáº¿ng Viá»‡t, dá»… hiá»ƒu"""

        # Gá»i Gemini
        gemini_result = await ask_gemini(enhanced_prompt, model=model)
        
        if not gemini_result.get("success"):
            return {
                "success": False,
                "activated": True,
                "error": f"Gemini error: {gemini_result.get('error')}",
                "documents_found": documents_found
            }
        
        # Step 3: Tráº£ vá» káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c Gemini xá»­ lÃ½
        return {
            "success": True,
            "activated": True,
            "gemini_response": gemini_result.get("response_text"),
            "documents_found": documents_found,
            "model_used": model,
            "context_length": len(context),
            "message": f"âœ… ÄÃ£ xá»­ lÃ½ {len(documents_found)} documents vá»›i Gemini {model}"
        }
        
    except Exception as e:
        return {
            "success": False,
            "activated": True,
            "error": f"Error: {str(e)}"
        }


async def ask_gpt4(prompt: str, model: str = "gpt-4o") -> dict:
    """
    Há»i Ä‘Ã¡p vá»›i OpenAI GPT-4
    
    Args:
        prompt: CÃ¢u há»i hoáº·c ná»™i dung muá»‘n gá»­i cho GPT-4
        model: TÃªn model OpenAI (máº·c Ä‘á»‹nh: gpt-4o - GPT-4 Omni, nhanh vÃ  ráº»)
        
    Returns:
        dict vá»›i success, response_text, vÃ  message
    """
    try:
        # Kiá»ƒm tra OpenAI cÃ³ kháº£ dá»¥ng khÃ´ng
        if not OPENAI_AVAILABLE:
            return {
                "success": False,
                "error": "OpenAI library chÆ°a cÃ i Ä‘áº·t. Cháº¡y: pip install openai"
            }
        
        # Kiá»ƒm tra API key
        if not OPENAI_API_KEY or OPENAI_API_KEY.strip() == "":
            return {
                "success": False,
                "error": "OpenAI API key chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh. Vui lÃ²ng thÃªm 'openai_api_key' vÃ o xiaozhi_endpoints.json",
                "help": "Láº¥y API key táº¡i: https://platform.openai.com/api-keys"
            }
        
        # Khá»Ÿi táº¡o OpenAI client
        print(f"[GPT-4] Configured with API key: ...{OPENAI_API_KEY[-8:]}")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        print(f"[GPT-4] Sending prompt with model: {model}")
        
        # Gá»i API trong executor Ä‘á»ƒ khÃ´ng block event loop
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000
            )
        )
        
        print(f"[GPT-4] Response received")
        
        # Láº¥y text tá»« response
        response_text = response.choices[0].message.content
        
        # ğŸ”„ TRUNCATE: Giá»›i háº¡n response dÆ°á»›i 4000 kÃ½ tá»± cho LLM
        if len(response_text) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(response_text)
            response_text = smart_truncate_for_llm(response_text, MAX_LLM_RESPONSE_CHARS)
            print(f"[GPT-4] âœ‚ï¸ Truncated: {original_len} â†’ {len(response_text)} chars")
        
        print(f"[GPT-4] Response text: {response_text[:100]}...")
        
        return {
            "success": True,
            "prompt": prompt,
            "response_text": response_text,
            "model": model,
            "usage": {
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            },
            "message": f"âœ… GPT-4 Ä‘Ã£ tráº£ lá»i (model: {model})"
        }
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ [GPT-4] Exception caught: {type(e).__name__}")
        print(f"âŒ [GPT-4] Error message: {error_msg}")
        
        import traceback
        traceback.print_exc()
        
        # Xá»­ lÃ½ cÃ¡c lá»—i phá»• biáº¿n
        if "Incorrect API key" in error_msg or "invalid_api_key" in error_msg:
            return {
                "success": False,
                "error": "OpenAI API key khÃ´ng há»£p lá»‡. Vui lÃ²ng kiá»ƒm tra láº¡i openai_api_key trong xiaozhi_endpoints.json",
                "help": "Láº¥y API key má»›i táº¡i: https://platform.openai.com/api-keys"
            }
        elif "insufficient_quota" in error_msg or "quota" in error_msg.lower():
            return {
                "success": False,
                "error": "ÄÃ£ háº¿t quota OpenAI. Vui lÃ²ng náº¡p tiá»n hoáº·c chá» quota reset.",
                "details": error_msg
            }
        elif "rate_limit" in error_msg.lower():
            return {
                "success": False,
                "error": "Rate limit exceeded. Vui lÃ²ng thá»­ láº¡i sau Ã­t phÃºt.",
                "details": error_msg
            }
        elif "model_not_found" in error_msg.lower():
            return {
                "success": False,
                "error": f"Model '{model}' khÃ´ng tá»“n táº¡i. Thá»­: gpt-4o, gpt-4-turbo, gpt-3.5-turbo",
                "details": error_msg
            }
        else:
            return {
                "success": False,
                "error": f"Lá»—i khi gá»i OpenAI API: {error_msg}"
            }


# ============================================================
# OPEN API TOOLS - CÃ¡c API cÃ´ng khai há»¯u Ã­ch
# Tham kháº£o tá»«: github.com/ZhongZiTongXue/xiaozhi-MCPTools
# ============================================================

import aiohttp
import urllib.parse

async def get_daily_news() -> dict:
    """
    Láº¥y tin tá»©c 60 giÃ¢y má»—i ngÃ y (æ¯æ—¥æ—©æŠ¥/60s morning news).
    Nguá»“n: API cÃ´ng khai
    """
    try:
        url = "https://60s.viki.moe/?v2=1"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    news_list = data.get('data', [])[:10]  # Top 10 tin
                    formatted = "\n".join([f"{i+1}. {item}" for i, item in enumerate(news_list)])
                    return {
                        "success": True,
                        "message": "ğŸ“° Tin tá»©c 60 giÃ¢y hÃ´m nay:",
                        "news": formatted,
                        "source": "60s.viki.moe"
                    }
                return {"success": False, "error": f"API tráº£ vá» status {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_random_quote() -> dict:
    """
    Láº¥y má»™t cÃ¢u nÃ³i ngáº«u nhiÃªn (ä¸€è¨€/Hitokoto).
    """
    try:
        url = "https://v1.hitokoto.cn/"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return {
                        "success": True,
                        "quote": data.get('hitokoto', ''),
                        "from": data.get('from', 'Unknown'),
                        "author": data.get('from_who', ''),
                        "type": data.get('type', '')
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_hotlist(platform: str = "weibo") -> dict:
    """
    Láº¥y báº£ng xáº¿p háº¡ng hot tá»« cÃ¡c ná»n táº£ng (å¾®åš/çŸ¥ä¹/ç™¾åº¦/æŠ–éŸ³).
    """
    try:
        platforms = {
            "weibo": "https://tenapi.cn/v2/weibohot",
            "zhihu": "https://tenapi.cn/v2/zhihuhot",
            "baidu": "https://tenapi.cn/v2/baiduhot",
            "douyin": "https://tenapi.cn/v2/douyinhot"
        }
        
        platform_lower = platform.lower()
        url = platforms.get(platform_lower)
        
        if not url:
            return {"success": False, "error": f"Platform khÃ´ng há»— trá»£. Chá»n: weibo, zhihu, baidu, douyin"}
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    hot_list = data.get('data', [])[:15]  # Top 15
                    formatted = "\n".join([f"{i+1}. {item.get('name', item.get('title', ''))}" for i, item in enumerate(hot_list)])
                    return {
                        "success": True,
                        "platform": platform,
                        "hotlist": formatted,
                        "count": len(hot_list)
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def search_baike(query: str) -> dict:
    """
    TÃ¬m kiáº¿m Baidu Baike (ç™¾åº¦ç™¾ç§‘).
    """
    try:
        encoded_query = urllib.parse.quote(query)
        url = f"https://baike.baidu.com/api/openapi/BaikeLemmaCardApi?scope=103&format=json&appid=379020&bk_key={encoded_query}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get('id'):
                        return {
                            "success": True,
                            "title": data.get('title', ''),
                            "abstract": data.get('abstract', ''),
                            "url": data.get('url', ''),
                            "image": data.get('image', '')
                        }
                    return {"success": False, "error": f"KhÃ´ng tÃ¬m tháº¥y '{query}' trÃªn Baike"}
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_history_today() -> dict:
    """
    Láº¥y sá»± kiá»‡n lá»‹ch sá»­ ngÃ y hÃ´m nay (å†å²ä¸Šçš„ä»Šå¤©).
    """
    try:
        from datetime import datetime
        today = datetime.now()
        month = today.month
        day = today.day
        
        url = f"https://api.oioweb.cn/api/common/history?month={month}&day={day}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    events = data.get('result', [])[:10]
                    formatted = "\n".join([f"â€¢ {e.get('year', '')}: {e.get('title', '')}" for e in events])
                    return {
                        "success": True,
                        "date": f"{month}/{day}",
                        "events": formatted,
                        "count": len(events)
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_joke() -> dict:
    """
    Láº¥y má»™t cÃ¢u chuyá»‡n cÆ°á»i ngáº«u nhiÃªn.
    """
    try:
        url = "https://api.oioweb.cn/api/common/joke"
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    data = await response.json()
                    return {
                        "success": True,
                        "joke": data.get('result', {}).get('content', 'KhÃ´ng cÃ³ joke'),
                        "source": "oioweb.cn"
                    }
                return {"success": False, "error": f"API error: {response.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_weather_simple(city: str = "Hanoi") -> dict:
    """
    Láº¥y thá»i tiáº¿t Ä‘Æ¡n giáº£n cá»§a thÃ nh phá»‘.
    """
    try:
        # DÃ¹ng wttr.in API (free, khÃ´ng cáº§n key)
        encoded_city = urllib.parse.quote(city)
        url = f"https://wttr.in/{encoded_city}?format=j1"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=15) as response:
                if response.status == 200:
                    data = await response.json()
                    current = data.get('current_condition', [{}])[0]
                    weather_desc = current.get('weatherDesc', [{}])[0].get('value', '')
                    temp_c = current.get('temp_C', '')
                    humidity = current.get('humidity', '')
                    wind_kmph = current.get('windspeedKmph', '')
                    
                    return {
                        "success": True,
                        "city": city,
                        "weather": weather_desc,
                        "temperature": f"{temp_c}Â°C",
                        "humidity": f"{humidity}%",
                        "wind": f"{wind_kmph} km/h",
                        "summary": f"ğŸŒ¤ï¸ {city}: {weather_desc}, {temp_c}Â°C, Äá»™ áº©m {humidity}%"
                    }
                return {"success": False, "error": f"KhÃ´ng tÃ¬m tháº¥y thá»i tiáº¿t cho '{city}'"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def control_ppt(action: str) -> dict:
    """
    Äiá»u khiá»ƒn PowerPoint presentation.
    Actions: next (trang sau), prev (trang trÆ°á»›c), start (báº¯t Ä‘áº§u trÃ¬nh chiáº¿u), end (káº¿t thÃºc)
    """
    try:
        import pyautogui
        
        action_lower = action.lower()
        
        if action_lower in ['next', 'tiáº¿p', 'trang sau']:
            pyautogui.press('right')
            return {"success": True, "message": "â¡ï¸ PPT: Chuyá»ƒn trang sau"}
            
        elif action_lower in ['prev', 'previous', 'trÆ°á»›c', 'trang trÆ°á»›c']:
            pyautogui.press('left')
            return {"success": True, "message": "â¬…ï¸ PPT: Quay láº¡i trang trÆ°á»›c"}
            
        elif action_lower in ['start', 'báº¯t Ä‘áº§u', 'trÃ¬nh chiáº¿u']:
            pyautogui.press('f5')
            return {"success": True, "message": "â–¶ï¸ PPT: Báº¯t Ä‘áº§u trÃ¬nh chiáº¿u tá»« Ä‘áº§u"}
            
        elif action_lower in ['start_current', 'tá»« trang nÃ y']:
            pyautogui.hotkey('shift', 'f5')
            return {"success": True, "message": "â–¶ï¸ PPT: TrÃ¬nh chiáº¿u tá»« trang hiá»‡n táº¡i"}
            
        elif action_lower in ['end', 'káº¿t thÃºc', 'thoÃ¡t']:
            pyautogui.press('escape')
            return {"success": True, "message": "â¹ï¸ PPT: Káº¿t thÃºc trÃ¬nh chiáº¿u"}
            
        else:
            return {
                "success": False,
                "error": f"Action '{action}' khÃ´ng há»£p lá»‡",
                "hint": "CÃ¡c action há»— trá»£: next, prev, start, start_current, end"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def ask_doubao(question: str) -> dict:
    """
    Má»Ÿ Doubao AI vÃ  gá»­i cÃ¢u há»i (yÃªu cáº§u cÃ³ browser).
    """
    try:
        import webbrowser
        import pyperclip
        import pyautogui
        import time
        
        url = "https://www.doubao.com/chat/"
        webbrowser.open(url)
        
        # Äá»£i trang load
        time.sleep(4)
        
        # Copy cÃ¢u há»i vÃ  paste
        pyperclip.copy(question)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        pyautogui.press('enter')
        
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ gá»­i cÃ¢u há»i tá»›i Doubao AI: '{question}'",
            "note": "Vui lÃ²ng xem káº¿t quáº£ trÃªn trÃ¬nh duyá»‡t"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def ask_kimi(question: str) -> dict:
    """
    Má»Ÿ Kimi AI vÃ  gá»­i cÃ¢u há»i (yÃªu cáº§u cÃ³ browser).
    """
    try:
        import webbrowser
        import pyperclip
        import pyautogui
        import time
        
        url = "https://kimi.moonshot.cn/"
        webbrowser.open(url)
        
        # Äá»£i trang load
        time.sleep(4)
        
        # Copy cÃ¢u há»i vÃ  paste
        pyperclip.copy(question)
        time.sleep(0.3)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        pyautogui.press('enter')
        
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ gá»­i cÃ¢u há»i tá»›i Kimi AI: '{question}'",
            "note": "Vui lÃ²ng xem káº¿t quáº£ trÃªn trÃ¬nh duyá»‡t"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_dark_light_theme(mode: str) -> dict:
    """
    Chuyá»ƒn Ä‘á»•i theme Windows Dark/Light mode.
    """
    try:
        import subprocess
        
        mode_lower = mode.lower()
        
        if mode_lower in ['dark', 'tá»‘i', 'Ä‘en']:
            # Set dark mode
            subprocess.run([
                'reg', 'add', 
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'AppsUseLightTheme', '/t', 'REG_DWORD', '/d', '0', '/f'
            ], capture_output=True)
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'SystemUsesLightTheme', '/t', 'REG_DWORD', '/d', '0', '/f'
            ], capture_output=True)
            return {"success": True, "message": "ğŸŒ™ ÄÃ£ chuyá»ƒn sang Dark Mode"}
            
        elif mode_lower in ['light', 'sÃ¡ng', 'tráº¯ng']:
            # Set light mode
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'AppsUseLightTheme', '/t', 'REG_DWORD', '/d', '1', '/f'
            ], capture_output=True)
            subprocess.run([
                'reg', 'add',
                'HKCU\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize',
                '/v', 'SystemUsesLightTheme', '/t', 'REG_DWORD', '/d', '1', '/f'
            ], capture_output=True)
            return {"success": True, "message": "â˜€ï¸ ÄÃ£ chuyá»ƒn sang Light Mode"}
            
        else:
            return {
                "success": False,
                "error": f"Mode '{mode}' khÃ´ng há»£p lá»‡",
                "hint": "Chá»n: dark/tá»‘i hoáº·c light/sÃ¡ng"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

async def lock_computer() -> dict:
    """
    KhÃ³a mÃ¡y tÃ­nh ngay láº­p tá»©c.
    """
    try:
        import ctypes
        ctypes.windll.user32.LockWorkStation()
        return {"success": True, "message": "ğŸ”’ ÄÃ£ khÃ³a mÃ¡y tÃ­nh"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_computer(action: str = "shutdown", delay: int = 0) -> dict:
    """
    Táº¯t mÃ¡y/Khá»Ÿi Ä‘á»™ng láº¡i/Háº¹n giá» táº¯t.
    action: shutdown, restart, cancel (há»§y lá»‡nh táº¯t)
    delay: sá»‘ giÃ¢y trÆ°á»›c khi thá»±c hiá»‡n (0 = ngay láº­p tá»©c)
    """
    try:
        import subprocess
        
        action_lower = action.lower()
        
        if action_lower in ['shutdown', 'táº¯t', 'táº¯t mÃ¡y']:
            subprocess.run(['shutdown', '/s', '/t', str(delay)], capture_output=True)
            if delay > 0:
                return {"success": True, "message": f"â° MÃ¡y sáº½ táº¯t sau {delay} giÃ¢y"}
            return {"success": True, "message": "â¹ï¸ Äang táº¯t mÃ¡y..."}
            
        elif action_lower in ['restart', 'khá»Ÿi Ä‘á»™ng láº¡i', 'reboot']:
            subprocess.run(['shutdown', '/r', '/t', str(delay)], capture_output=True)
            if delay > 0:
                return {"success": True, "message": f"â° MÃ¡y sáº½ khá»Ÿi Ä‘á»™ng láº¡i sau {delay} giÃ¢y"}
            return {"success": True, "message": "ğŸ”„ Äang khá»Ÿi Ä‘á»™ng láº¡i..."}
            
        elif action_lower in ['cancel', 'há»§y', 'abort']:
            subprocess.run(['shutdown', '/a'], capture_output=True)
            return {"success": True, "message": "âŒ ÄÃ£ há»§y lá»‡nh táº¯t/khá»Ÿi Ä‘á»™ng láº¡i"}
            
        else:
            return {
                "success": False,
                "error": f"Action '{action}' khÃ´ng há»£p lá»‡",
                "hint": "Chá»n: shutdown, restart, cancel"
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

# DUPLICATE REMOVED: change_wallpaper was defined twice (first at line 5503)
# DUPLICATE REMOVED: find_in_document was defined twice (first at line 5809)

async def clipboard_read() -> dict:
    """
    Äá»c ná»™i dung tá»« clipboard.
    """
    try:
        import pyperclip
        content = pyperclip.paste()
        return {
            "success": True,
            "content": content,
            "length": len(content) if content else 0
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def clipboard_write(content: str) -> dict:
    """
    Ghi ná»™i dung vÃ o clipboard.
    """
    try:
        import pyperclip
        pyperclip.copy(content)
        return {"success": True, "message": f"ğŸ“‹ ÄÃ£ copy vÃ o clipboard ({len(content)} kÃ½ tá»±)"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def type_text(text: str, press_enter: bool = False) -> dict:
    """
    GÃµ text vÃ o vá»‹ trÃ­ con trá» hiá»‡n táº¡i.
    """
    try:
        import pyperclip
        import pyautogui
        import time
        
        # Copy vÃ  paste Ä‘á»ƒ há»— trá»£ Unicode
        pyperclip.copy(text)
        time.sleep(0.1)
        pyautogui.hotkey('ctrl', 'v')
        
        if press_enter:
            time.sleep(0.2)
            pyautogui.press('enter')
            return {"success": True, "message": f"âŒ¨ï¸ ÄÃ£ gÃµ vÃ  Enter: '{text[:50]}...'"}
        
        return {"success": True, "message": f"âŒ¨ï¸ ÄÃ£ gÃµ: '{text[:50]}...'"}
        
    except Exception as e:
        return {"success": False, "error": str(e)}

async def undo_action() -> dict:
    """
    Thá»±c hiá»‡n Undo (Ctrl+Z).
    """
    try:
        import pyautogui
        pyautogui.hotkey('ctrl', 'z')
        return {"success": True, "message": "â†©ï¸ ÄÃ£ Undo"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def show_desktop() -> dict:
    """
    Hiá»ƒn thá»‹ Desktop (Win+D).
    """
    try:
        import pyautogui
        pyautogui.hotkey('win', 'd')
        return {"success": True, "message": "ğŸ–¥ï¸ ÄÃ£ hiá»ƒn thá»‹ Desktop"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# OPEN API TOOLS - CÃ¡c cÃ´ng cá»¥ tra cá»©u thÃ´ng tin (PHÃ™ Há»¢P VIá»†T NAM)
# ============================================================

async def get_weather_vietnam(city: str = "HÃ  Ná»™i") -> dict:
    """
    Láº¥y thÃ´ng tin thá»i tiáº¿t Viá»‡t Nam tá»« wttr.in (miá»…n phÃ­, khÃ´ng cáº§n API key).
    """
    try:
        import aiohttp
        import urllib.parse
        
        # Normalize tÃªn thÃ nh phá»‘
        city_mapping = {
            "hÃ  ná»™i": "Hanoi", "ha noi": "Hanoi", "hanoi": "Hanoi",
            "há»“ chÃ­ minh": "Ho Chi Minh", "ho chi minh": "Ho Chi Minh", "saigon": "Ho Chi Minh", "sÃ i gÃ²n": "Ho Chi Minh",
            "Ä‘Ã  náºµng": "Da Nang", "da nang": "Da Nang", "danang": "Da Nang",
            "háº£i phÃ²ng": "Hai Phong", "hai phong": "Hai Phong",
            "cáº§n thÆ¡": "Can Tho", "can tho": "Can Tho",
            "nha trang": "Nha Trang", "huáº¿": "Hue", "hue": "Hue",
            "vÅ©ng tÃ u": "Vung Tau", "vung tau": "Vung Tau",
            "biÃªn hÃ²a": "Bien Hoa", "bien hoa": "Bien Hoa",
            "buÃ´n ma thuá»™t": "Buon Ma Thuot", "Ä‘Ã  láº¡t": "Da Lat", "da lat": "Da Lat",
            "quáº£ng ninh": "Quang Ninh", "háº¡ long": "Ha Long",
            "thanh hÃ³a": "Thanh Hoa", "vinh": "Vinh", "quy nhÆ¡n": "Quy Nhon",
        }
        
        city_query = city_mapping.get(city.lower().strip(), city)
        url = f"https://wttr.in/{urllib.parse.quote(city_query)}?format=j1"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    current = data.get("current_condition", [{}])[0]
                    
                    temp_c = current.get("temp_C", "N/A")
                    feels_like = current.get("FeelsLikeC", "N/A")
                    humidity = current.get("humidity", "N/A")
                    weather_desc = current.get("lang_vi", [{}])
                    if weather_desc:
                        weather_desc = weather_desc[0].get("value", current.get("weatherDesc", [{}])[0].get("value", ""))
                    else:
                        weather_desc = current.get("weatherDesc", [{}])[0].get("value", "")
                    wind_kmph = current.get("windspeedKmph", "N/A")
                    
                    return {
                        "success": True,
                        "city": city,
                        "temperature": f"{temp_c}Â°C",
                        "feels_like": f"{feels_like}Â°C",
                        "humidity": f"{humidity}%",
                        "weather": weather_desc,
                        "wind": f"{wind_kmph} km/h",
                        "message": f"ğŸŒ¤ï¸ Thá»i tiáº¿t {city}: {temp_c}Â°C, {weather_desc}, Äá»™ áº©m {humidity}%, GiÃ³ {wind_kmph}km/h"
                    }
                else:
                    return {"success": False, "error": f"KhÃ´ng láº¥y Ä‘Æ°á»£c thá»i tiáº¿t: HTTP {resp.status}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_gold_price_vietnam() -> dict:
    """
    Láº¥y giÃ¡ vÃ ng Viá»‡t Nam tá»« API miá»…n phÃ­.
    """
    try:
        import aiohttp
        
        # Sá»­ dá»¥ng API giÃ¡ vÃ ng SJC
        url = "https://api.btmc.vn/api/BTMCAPI/getpricesheet"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    
                    # TÃ¬m giÃ¡ vÃ ng SJC
                    gold_prices = []
                    for item in data.get("data", []):
                        name = item.get("name", "")
                        buy = item.get("buy", 0)
                        sell = item.get("sell", 0)
                        if "SJC" in name or "vÃ ng" in name.lower():
                            gold_prices.append({
                                "name": name,
                                "buy": f"{buy:,.0f}".replace(",", "."),
                                "sell": f"{sell:,.0f}".replace(",", ".")
                            })
                    
                    if gold_prices:
                        msg = "ğŸ’° GiÃ¡ vÃ ng hÃ´m nay:\n"
                        for g in gold_prices[:3]:  # Top 3
                            msg += f"â€¢ {g['name']}: Mua {g['buy']} - BÃ¡n {g['sell']} VNÄ/lÆ°á»£ng\n"
                        
                        return {
                            "success": True,
                            "prices": gold_prices[:3],
                            "message": msg.strip()
                        }
                    
                return {"success": False, "error": "KhÃ´ng láº¥y Ä‘Æ°á»£c giÃ¡ vÃ ng"}
    except Exception as e:
        # Fallback: tráº£ vá» thÃ´ng tin hÆ°á»›ng dáº«n
        return {
            "success": True,
            "message": "ğŸ’° Äá»ƒ xem giÃ¡ vÃ ng má»›i nháº¥t, truy cáº­p: sjc.com.vn hoáº·c pnj.com.vn",
            "hint": "API giÃ¡ vÃ ng táº¡m thá»i khÃ´ng kháº£ dá»¥ng"
        }

async def get_exchange_rate_vietnam(currency: str = "USD") -> dict:
    """
    Láº¥y tá»· giÃ¡ ngoáº¡i tá»‡ so vá»›i VND.
    """
    try:
        import aiohttp
        
        currency = currency.upper().strip()
        
        # DÃ¹ng API miá»…n phÃ­ exchangerate-api
        url = f"https://api.exchangerate-api.com/v4/latest/{currency}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    rates = data.get("rates", {})
                    vnd_rate = rates.get("VND", 0)
                    
                    if vnd_rate:
                        return {
                            "success": True,
                            "currency": currency,
                            "vnd_rate": f"{vnd_rate:,.0f}".replace(",", "."),
                            "message": f"ğŸ’± Tá»· giÃ¡: 1 {currency} = {vnd_rate:,.0f} VNÄ".replace(",", ".")
                        }
                        
                return {"success": False, "error": f"KhÃ´ng tÃ¬m tháº¥y tá»· giÃ¡ {currency}"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_daily_quote() -> dict:
    """
    Láº¥y cÃ¢u nÃ³i hay/trÃ­ch dáº«n ngáº«u nhiÃªn.
    """
    try:
        import aiohttp
        import random
        
        # CÃ¡c quotes tiáº¿ng Viá»‡t Ä‘áº¹p
        vietnamese_quotes = [
            {"quote": "ThÃ nh cÃ´ng khÃ´ng pháº£i lÃ  chÃ¬a khÃ³a cá»§a háº¡nh phÃºc. Háº¡nh phÃºc lÃ  chÃ¬a khÃ³a cá»§a thÃ nh cÃ´ng.", "author": "Albert Schweitzer"},
            {"quote": "Äá»«ng sá»£ tháº¥t báº¡i. HÃ£y sá»£ nhá»¯ng cÆ¡ há»™i báº¡n bá» lá»¡ khi khÃ´ng cá»‘ gáº¯ng.", "author": "Jack Canfield"},
            {"quote": "Cuá»™c sá»‘ng khÃ´ng pháº£i lÃ  chá» Ä‘á»£i bÃ£o qua Ä‘i, mÃ  lÃ  há»c cÃ¡ch nháº£y mÃºa dÆ°á»›i mÆ°a.", "author": "Vivian Greene"},
            {"quote": "HÃ´m nay khÃ³ khÄƒn, ngÃ y mai cÃ²n khÃ³ khÄƒn hÆ¡n, nhÆ°ng ngÃ y kia sáº½ tÆ°Æ¡i Ä‘áº¹p.", "author": "Jack Ma"},
            {"quote": "NgÆ°á»i duy nháº¥t báº¡n cáº§n vÆ°á»£t qua lÃ  chÃ­nh báº¡n cá»§a ngÃ y hÃ´m qua.", "author": "Khuyáº¿t danh"},
            {"quote": "Há»c há»i khÃ´ng cÃ³ Ä‘iá»ƒm dá»«ng, giá»‘ng nhÆ° cuá»™c sá»‘ng khÃ´ng cÃ³ giá»›i háº¡n.", "author": "Khá»•ng Tá»­"},
            {"quote": "Tháº¥t báº¡i lÃ  máº¹ thÃ nh cÃ´ng.", "author": "Tá»¥c ngá»¯ Viá»‡t Nam"},
            {"quote": "CÃ³ chÃ­ thÃ¬ nÃªn.", "author": "Tá»¥c ngá»¯ Viá»‡t Nam"},
            {"quote": "Má»™t cÃ¢y lÃ m cháº³ng nÃªn non, ba cÃ¢y chá»¥m láº¡i nÃªn hÃ²n nÃºi cao.", "author": "Ca dao Viá»‡t Nam"},
            {"quote": "Äi má»™t ngÃ y Ä‘Ã ng, há»c má»™t sÃ ng khÃ´n.", "author": "Tá»¥c ngá»¯ Viá»‡t Nam"},
        ]
        
        # Thá»­ láº¥y quote tá»« API
        try:
            url = "https://api.quotable.io/random"
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=5) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        return {
                            "success": True,
                            "quote": data.get("content", ""),
                            "author": data.get("author", "Unknown"),
                            "message": f"ğŸ’¬ \"{data.get('content', '')}\" - {data.get('author', 'Unknown')}"
                        }
        except:
            pass
        
        # Fallback: quote tiáº¿ng Viá»‡t
        quote = random.choice(vietnamese_quotes)
        return {
            "success": True,
            "quote": quote["quote"],
            "author": quote["author"],
            "message": f"ğŸ’¬ \"{quote['quote']}\" - {quote['author']}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_today_in_history() -> dict:
    """
    Láº¥y sá»± kiá»‡n lá»‹ch sá»­ ngÃ y hÃ´m nay.
    """
    try:
        import aiohttp
        from datetime import datetime
        
        today = datetime.now()
        month = today.month
        day = today.day
        
        url = f"https://history.muffinlabs.com/date/{month}/{day}"
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    events = data.get("data", {}).get("Events", [])[:3]
                    
                    if events:
                        msg = f"ğŸ“œ NgÃ y nÃ y ({day}/{month}) trong lá»‹ch sá»­:\n"
                        for event in events:
                            year = event.get("year", "")
                            text = event.get("text", "")
                            msg += f"â€¢ {year}: {text[:100]}...\n" if len(text) > 100 else f"â€¢ {year}: {text}\n"
                        
                        return {
                            "success": True,
                            "date": f"{day}/{month}",
                            "events": events,
                            "message": msg.strip()
                        }
                        
        return {"success": False, "error": "KhÃ´ng láº¥y Ä‘Æ°á»£c sá»± kiá»‡n lá»‹ch sá»­"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_joke() -> dict:
    """
    Láº¥y má»™t cÃ¢u chuyá»‡n cÆ°á»i/joke ngáº«u nhiÃªn.
    """
    try:
        import random
        
        # Jokes tiáº¿ng Viá»‡t
        vietnamese_jokes = [
            "Táº¡i sao con cÃ¡ khÃ´ng biáº¿t nÃ³i? VÃ¬ nÃ³ á»Ÿ dÆ°á»›i nÆ°á»›c, nÃ³i sao Ä‘Æ°á»£c! ğŸŸ",
            "Báº¡n biáº¿t con gÃ¬ nhanh nháº¥t tháº¿ giá»›i khÃ´ng? Con giÃ³, vÃ¬ nÃ³ Ä‘i vÃ¨o vÃ¨o! ğŸ’¨",
            "Táº¡i sao con kiáº¿n khÃ´ng bao giá» á»‘m? VÃ¬ nÃ³ cÃ³ Ä‘áº§y Ä‘á»§ cháº¥t sáº¯t (Fe) trong ngÆ°á»i! ğŸœ",
            "Ai lÃ  ngÆ°á»i háº¡nh phÃºc nháº¥t? NgÆ°á»i khÃ´ng biáº¿t so sÃ¡nh! ğŸ˜Š",
            "Con gÃ¬ cÃ³ 4 chÃ¢n mÃ  khÃ´ng biáº¿t Ä‘i? CÃ¡i bÃ n! ğŸª‘",
            "Táº¡i sao mÃ¡y tÃ­nh khÃ´ng bao giá» khÃ³c? VÃ¬ nÃ³ cÃ³ mouse pad (miáº¿ng lÃ³t chuá»™t)! ğŸ–±ï¸",
            "Báº¡n biáº¿t táº¡i sao máº·t trá»i Ä‘i há»c khÃ´ng? VÃ¬ nÃ³ Ä‘Ã£ tá»‘t nghiá»‡p tá»« lÃ¢u rá»“i! â˜€ï¸",
            "Táº¡i sao con gÃ  qua Ä‘Æ°á»ng? Äá»ƒ Ä‘áº¿n bÃªn kia Ä‘Æ°á»ng! ğŸ”",
            "Con gÃ¬ ngá»“i má»™t chá»— mÃ  váº«n cháº¡y? CÃ¡i Ä‘á»“ng há»“! â°",
            "Táº¡i sao cáº§u vá»“ng thÃ­ch Ä‘i chÆ¡i? VÃ¬ nÃ³ cÃ³ 7 mÃ u = 7 ngÃ y = 1 tuáº§n! ğŸŒˆ",
        ]
        
        joke = random.choice(vietnamese_jokes)
        return {
            "success": True,
            "joke": joke,
            "message": f"ğŸ˜‚ {joke}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_horoscope(zodiac: str = "song_tá»­") -> dict:
    """
    Láº¥y tá»­ vi/horoscope theo cung hoÃ ng Ä‘áº¡o.
    """
    try:
        import random
        
        # Map tÃªn cung hoÃ ng Ä‘áº¡o
        zodiac_map = {
            "báº¡ch dÆ°Æ¡ng": "aries", "bach duong": "aries", "aries": "aries",
            "kim ngÆ°u": "taurus", "kim nguu": "taurus", "taurus": "taurus",
            "song tá»­": "gemini", "song tu": "gemini", "gemini": "gemini",
            "cá»± giáº£i": "cancer", "cu giai": "cancer", "cancer": "cancer",
            "sÆ° tá»­": "leo", "su tu": "leo", "leo": "leo",
            "xá»­ ná»¯": "virgo", "xu nu": "virgo", "virgo": "virgo",
            "thiÃªn bÃ¬nh": "libra", "thien binh": "libra", "libra": "libra",
            "bá» cáº¡p": "scorpio", "bo cap": "scorpio", "scorpio": "scorpio",
            "nhÃ¢n mÃ£": "sagittarius", "nhan ma": "sagittarius", "sagittarius": "sagittarius",
            "ma káº¿t": "capricorn", "ma ket": "capricorn", "capricorn": "capricorn",
            "báº£o bÃ¬nh": "aquarius", "bao binh": "aquarius", "aquarius": "aquarius",
            "song ngÆ°": "pisces", "song ngu": "pisces", "pisces": "pisces",
        }
        
        zodiac_key = zodiac_map.get(zodiac.lower().strip(), "gemini")
        zodiac_name = zodiac.title()
        
        # Random horoscope messages
        luck_levels = ["â­â­â­â­â­", "â­â­â­â­", "â­â­â­", "â­â­â­â­"]
        love_messages = [
            "TÃ¬nh yÃªu Ä‘ang Ä‘áº¿n gáº§n, hÃ£y má»Ÿ lÃ²ng Ä‘Ã³n nháº­n.",
            "HÃ´m nay lÃ  ngÃ y tá»‘t Ä‘á»ƒ thá»ƒ hiá»‡n tÃ¬nh cáº£m.",
            "NgÆ°á»i áº¥y Ä‘ang nghÄ© vá» báº¡n nhiá»u hÆ¡n báº¡n tÆ°á»Ÿng.",
            "HÃ£y kiÃªn nháº«n, tÃ¬nh yÃªu Ä‘Ã­ch thá»±c cáº§n thá»i gian.",
        ]
        career_messages = [
            "CÃ´ng viá»‡c suÃ´n sáº», cÆ¡ há»™i thÄƒng tiáº¿n Ä‘ang má»Ÿ ra.",
            "HÃ£y táº­p trung vÃ o má»¥c tiÃªu, thÃ nh cÃ´ng sáº½ Ä‘áº¿n.",
            "Má»™t dá»± Ã¡n má»›i cÃ³ thá»ƒ xuáº¥t hiá»‡n báº¥t ngá».",
            "Äá»“ng nghiá»‡p sáº½ há»— trá»£ báº¡n ráº¥t nhiá»u hÃ´m nay.",
        ]
        money_messages = [
            "TÃ i chÃ­nh á»•n Ä‘á»‹nh, cÃ³ thá»ƒ cÃ³ khoáº£n thu báº¥t ngá».",
            "HÃ£y cáº©n tháº­n vá»›i cÃ¡c quyáº¿t Ä‘á»‹nh Ä‘áº§u tÆ°.",
            "ÄÃ¢y lÃ  thá»i Ä‘iá»ƒm tá»‘t Ä‘á»ƒ tiáº¿t kiá»‡m.",
            "May máº¯n vá» tÃ i chÃ­nh Ä‘ang má»‰m cÆ°á»i vá»›i báº¡n.",
        ]
        
        return {
            "success": True,
            "zodiac": zodiac_name,
            "luck": random.choice(luck_levels),
            "love": random.choice(love_messages),
            "career": random.choice(career_messages),
            "money": random.choice(money_messages),
            "message": f"ğŸ”® Tá»­ vi {zodiac_name}:\nâ€¢ May máº¯n: {random.choice(luck_levels)}\nâ€¢ TÃ¬nh yÃªu: {random.choice(love_messages)}\nâ€¢ Sá»± nghiá»‡p: {random.choice(career_messages)}\nâ€¢ TÃ i chÃ­nh: {random.choice(money_messages)}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_news_vietnam() -> dict:
    """
    Láº¥y tin tá»©c nÃ³ng Viá»‡t Nam.
    """
    try:
        import aiohttp
        
        # DÃ¹ng RSS feed tá»« cÃ¡c bÃ¡o Viá»‡t Nam
        rss_urls = [
            "https://vnexpress.net/rss/tin-moi-nhat.rss",
            "https://tuoitre.vn/rss/tin-moi-nhat.rss",
        ]
        
        async with aiohttp.ClientSession() as session:
            for rss_url in rss_urls:
                try:
                    async with session.get(rss_url, timeout=10) as resp:
                        if resp.status == 200:
                            import xml.etree.ElementTree as ET
                            content = await resp.text()
                            root = ET.fromstring(content)
                            
                            items = root.findall('.//item')[:5]
                            news = []
                            
                            for item in items:
                                title = item.find('title')
                                title_text = title.text if title is not None else "No title"
                                news.append(title_text)
                            
                            if news:
                                msg = "ğŸ“° Tin tá»©c má»›i nháº¥t:\n"
                                for i, n in enumerate(news, 1):
                                    msg += f"{i}. {n}\n"
                                
                                result = {
                                    "success": True,
                                    "news": news,
                                    "message": msg.strip()
                                }
                                
                                # ğŸ¤– GEMINI SUMMARIZATION: TÃ³m táº¯t nhanh báº±ng Gemini (non-blocking)
                                try:
                                    context = "\n".join([f"{i+1}. {n}" for i, n in enumerate(news)])
                                    # âš¡ PROMPT NGáº®N Gá»ŒN - pháº£n há»“i nhanh hÆ¡n
                                    summary_prompt = f"""TÃ³m táº¯t 5 tin VN sau thÃ nh 3 Ã½ chÃ­nh:
{context}

Format: ğŸ“Œ [3 Ä‘iá»ƒm] + ğŸ”¹ [xu hÆ°á»›ng chung 1 cÃ¢u]"""
                                    
                                    print(f"âš¡ [NewsVN+Gemini] TÃ³m táº¯t nhanh {len(news)} tin...")
                                    # â±ï¸ Timeout 15 giÃ¢y - Ä‘á»§ thá»i gian cho Gemini
                                    gemini_summary = await asyncio.wait_for(
                                        ask_gemini_direct(summary_prompt, model="models/gemini-3-flash-preview"),
                                        timeout=15.0
                                    )
                                    if gemini_summary.get("success"):
                                        summary_text = gemini_summary["response_text"]
                                        result["gemini_summary"] = summary_text
                                        result["message"] = f"âœ¨ {summary_text}\n\n" + result["message"]
                                        print(f"âœ… [NewsVN+Gemini] Done ({len(summary_text)} chars)")
                                    else:
                                        print(f"âš ï¸ [NewsVN+Gemini] Failed: {gemini_summary.get('error')}")
                                except asyncio.TimeoutError:
                                    print(f"â±ï¸ [NewsVN+Gemini] Timeout - tráº£ tin thÃ´")
                                except Exception as e:
                                    print(f"âš ï¸ [NewsVN+Gemini] Error: {e}")
                                
                                return result
                except:
                    continue
                    
        return {"success": False, "error": "KhÃ´ng láº¥y Ä‘Æ°á»£c tin tá»©c"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def what_to_eat() -> dict:
    """
    Gá»£i Ã½ mÃ³n Äƒn hÃ´m nay (Viá»‡t Nam).
    """
    try:
        import random
        from datetime import datetime
        
        # MÃ³n Äƒn Viá»‡t Nam theo bá»¯a
        breakfast = [
            "ğŸœ Phá»Ÿ bÃ² tÃ¡i náº¡m", "ğŸ¥– BÃ¡nh mÃ¬ thá»‹t", "ğŸ² BÃºn bÃ² Huáº¿", 
            "ğŸ¥£ ChÃ¡o lÃ²ng", "ğŸœ Há»§ tiáº¿u Nam Vang", "ğŸ¥ BÃ¡nh cuá»‘n",
            "ğŸ² BÃºn riÃªu cua", "ğŸ¥£ XÃ´i xÃ©o", "ğŸœ MÃ¬ Quáº£ng"
        ]
        
        lunch = [
            "ğŸš CÆ¡m táº¥m sÆ°á»n bÃ¬ cháº£", "ğŸ² BÃºn cháº£ HÃ  Ná»™i", "ğŸœ Phá»Ÿ gÃ ",
            "ğŸ¥— Gá»i cuá»‘n tÃ´m thá»‹t", "ğŸ² Láº©u thÃ¡i", "ğŸš CÆ¡m vÄƒn phÃ²ng",
            "ğŸœ BÃºn Ä‘áº­u máº¯m tÃ´m", "ğŸ² Canh chua cÃ¡ lÃ³c", "ğŸš CÆ¡m gÃ  Tam Ká»³"
        ]
        
        dinner = [
            "ğŸ– BÃ² nÃ©", "ğŸ¦ Háº£i sáº£n nÆ°á»›ng", "ğŸ² Láº©u gÃ  lÃ¡ Ã©",
            "ğŸ— GÃ  nÆ°á»›ng muá»‘i á»›t", "ğŸ¥˜ CÃ¡ kho tá»™", "ğŸ² Láº©u ThÃ¡i",
            "ğŸ– BBQ HÃ n Quá»‘c", "ğŸœ Phá»Ÿ cuá»‘n", "ğŸ² á»c xÃ o me"
        ]
        
        snacks = [
            "ğŸ§ BÃ¡nh trÃ¡ng trá»™n", "ğŸ¡ ChÃ¨ tháº­p cáº©m", "ğŸ¦ Kem bÆ¡",
            "ğŸ¥¤ TrÃ  sá»¯a", "ğŸµ CÃ  phÃª sá»¯a Ä‘Ã¡", "ğŸ© BÃ¡nh rÃ¡n"
        ]
        
        hour = datetime.now().hour
        
        if 5 <= hour < 10:
            meal_type = "sÃ¡ng"
            suggestion = random.choice(breakfast)
        elif 10 <= hour < 14:
            meal_type = "trÆ°a"
            suggestion = random.choice(lunch)
        elif 14 <= hour < 17:
            meal_type = "xáº¿"
            suggestion = random.choice(snacks)
        else:
            meal_type = "tá»‘i"
            suggestion = random.choice(dinner)
        
        return {
            "success": True,
            "meal_type": meal_type,
            "suggestion": suggestion,
            "alternatives": [random.choice(breakfast + lunch + dinner) for _ in range(2)],
            "message": f"ğŸ½ï¸ Bá»¯a {meal_type} hÃ´m nay: {suggestion}\n\nğŸ’¡ Gá»£i Ã½ khÃ¡c: {random.choice(breakfast + lunch + dinner)}, {random.choice(breakfast + lunch + dinner)}"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_lunar_date() -> dict:
    """
    Láº¥y ngÃ y Ã¢m lá»‹ch Viá»‡t Nam hÃ´m nay - thuáº­t toÃ¡n chÃ­nh xÃ¡c.
    TÃ­nh theo mÃºi giá» Viá»‡t Nam (UTC+7).
    """
    try:
        from datetime import datetime, timezone, timedelta
        import math
        
        # MÃºi giá» Viá»‡t Nam UTC+7
        vn_tz = timezone(timedelta(hours=7))
        today = datetime.now(vn_tz)
        
        # ========== THUáº¬T TOÃN TÃNH Ã‚M Lá»ŠCH VIá»†T NAM ==========
        # Dá»±a trÃªn thuáº­t toÃ¡n cá»§a Há»“ Ngá»c Äá»©c
        
        def jd_from_date(dd, mm, yy):
            """Chuyá»ƒn ngÃ y dÆ°Æ¡ng lá»‹ch sang Julian Day Number"""
            a = int((14 - mm) / 12)
            y = yy + 4800 - a
            m = mm + 12 * a - 3
            jd = dd + int((153 * m + 2) / 5) + 365 * y + int(y / 4) - int(y / 100) + int(y / 400) - 32045
            if jd < 2299161:
                jd = dd + int((153 * m + 2) / 5) + 365 * y + int(y / 4) - 32083
            return jd
        
        def new_moon(k):
            """TÃ­nh thá»i Ä‘iá»ƒm trÄƒng má»›i thá»© k (ká»ƒ tá»« 1900-01-01)"""
            T = k / 1236.85
            T2 = T * T
            T3 = T2 * T
            dr = math.pi / 180
            Jd1 = 2415020.75933 + 29.53058868 * k + 0.0001178 * T2 - 0.000000155 * T3
            Jd1 = Jd1 + 0.00033 * math.sin((166.56 + 132.87 * T - 0.009173 * T2) * dr)
            M = 359.2242 + 29.10535608 * k - 0.0000333 * T2 - 0.00000347 * T3
            Mpr = 306.0253 + 385.81691806 * k + 0.0107306 * T2 + 0.00001236 * T3
            F = 21.2964 + 390.67050646 * k - 0.0016528 * T2 - 0.00000239 * T3
            C1 = (0.1734 - 0.000393 * T) * math.sin(M * dr) + 0.0021 * math.sin(2 * dr * M)
            C1 = C1 - 0.4068 * math.sin(Mpr * dr) + 0.0161 * math.sin(dr * 2 * Mpr)
            C1 = C1 - 0.0004 * math.sin(dr * 3 * Mpr)
            C1 = C1 + 0.0104 * math.sin(dr * 2 * F) - 0.0051 * math.sin(dr * (M + Mpr))
            C1 = C1 - 0.0074 * math.sin(dr * (M - Mpr)) + 0.0004 * math.sin(dr * (2 * F + M))
            C1 = C1 - 0.0004 * math.sin(dr * (2 * F - M)) - 0.0006 * math.sin(dr * (2 * F + Mpr))
            C1 = C1 + 0.0010 * math.sin(dr * (2 * F - Mpr)) + 0.0005 * math.sin(dr * (2 * Mpr + M))
            if T < -11:
                deltat = 0.001 + 0.000839 * T + 0.0002261 * T2 - 0.00000845 * T3 - 0.000000081 * T * T3
            else:
                deltat = -0.000278 + 0.000265 * T + 0.000262 * T2
            return Jd1 + C1 - deltat
        
        def sun_longitude(jdn):
            """TÃ­nh kinh Ä‘á»™ máº·t trá»i táº¡i thá»i Ä‘iá»ƒm Julian Day Number"""
            T = (jdn - 2451545.0) / 36525
            T2 = T * T
            dr = math.pi / 180
            M = 357.52910 + 35999.05030 * T - 0.0001559 * T2 - 0.00000048 * T * T2
            L0 = 280.46645 + 36000.76983 * T + 0.0003032 * T2
            DL = (1.914600 - 0.004817 * T - 0.000014 * T2) * math.sin(dr * M)
            DL = DL + (0.019993 - 0.000101 * T) * math.sin(dr * 2 * M) + 0.00029 * math.sin(dr * 3 * M)
            L = L0 + DL
            L = L * dr
            L = L - math.pi * 2 * int(L / (math.pi * 2))
            return int(L / math.pi * 6)
        
        def get_lunar_month_11(yy):
            """TÃ¬m ngÃ y báº¯t Ä‘áº§u thÃ¡ng 11 Ã¢m lá»‹ch"""
            off = jd_from_date(31, 12, yy) - 2415021
            k = int(off / 29.530588853)
            nm = new_moon(k)
            sun_long = sun_longitude(nm)
            if sun_long >= 9:
                nm = new_moon(k - 1)
            return int(nm + 0.5)
        
        def get_leap_month_offset(a11):
            """XÃ¡c Ä‘á»‹nh thÃ¡ng nhuáº­n"""
            k = int((a11 - 2415021.076998695) / 29.530588853 + 0.5)
            last = 0
            i = 1
            arc = sun_longitude(new_moon(k + i))
            while True:
                last = arc
                i += 1
                arc = sun_longitude(new_moon(k + i))
                if arc != last or i >= 14:
                    break
            return i - 1
        
        def solar_to_lunar(dd, mm, yy):
            """Chuyá»ƒn ngÃ y dÆ°Æ¡ng lá»‹ch sang Ã¢m lá»‹ch"""
            day_number = jd_from_date(dd, mm, yy)
            k = int((day_number - 2415021.076998695) / 29.530588853)
            month_start = new_moon(k + 1)
            if month_start > day_number:
                month_start = new_moon(k)
            a11 = get_lunar_month_11(yy)
            b11 = a11
            if a11 >= month_start:
                lunar_year = yy
                a11 = get_lunar_month_11(yy - 1)
            else:
                lunar_year = yy + 1
                b11 = get_lunar_month_11(yy + 1)
            lunar_day = int(day_number - month_start + 1)
            diff = int((month_start - a11) / 29)
            lunar_leap = 0
            lunar_month = diff + 11
            if b11 - a11 > 365:
                leap_month_diff = get_leap_month_offset(a11)
                if diff >= leap_month_diff:
                    lunar_month = diff + 10
                    if diff == leap_month_diff:
                        lunar_leap = 1
            if lunar_month > 12:
                lunar_month = lunar_month - 12
            if lunar_month >= 11 and diff < 4:
                lunar_year -= 1
            return lunar_day, lunar_month, lunar_year, lunar_leap
        
        # ========== TÃNH CAN CHI ==========
        CAN = ["GiÃ¡p", "áº¤t", "BÃ­nh", "Äinh", "Máº­u", "Ká»·", "Canh", "TÃ¢n", "NhÃ¢m", "QuÃ½"]
        CHI = ["TÃ½", "Sá»­u", "Dáº§n", "MÃ£o", "ThÃ¬n", "Tá»µ", "Ngá»", "MÃ¹i", "ThÃ¢n", "Dáº­u", "Tuáº¥t", "Há»£i"]
        
        def get_can_chi_year(lunar_year):
            """Láº¥y can chi cá»§a nÄƒm"""
            can = CAN[(lunar_year + 6) % 10]
            chi = CHI[(lunar_year + 8) % 12]
            return f"{can} {chi}"
        
        def get_can_chi_day(dd, mm, yy):
            """Láº¥y can chi cá»§a ngÃ y"""
            jd = jd_from_date(dd, mm, yy)
            can = CAN[(jd + 9) % 10]
            chi = CHI[(jd + 1) % 12]
            return f"{can} {chi}"
        
        # ========== TÃNH NGÃ€Y Ã‚M Lá»ŠCH HÃ”M NAY ==========
        dd, mm, yy = today.day, today.month, today.year
        lunar_day, lunar_month, lunar_year, is_leap = solar_to_lunar(dd, mm, yy)
        
        day_of_week = ["Thá»© Hai", "Thá»© Ba", "Thá»© TÆ°", "Thá»© NÄƒm", "Thá»© SÃ¡u", "Thá»© Báº£y", "Chá»§ Nháº­t"][today.weekday()]
        can_chi_year = get_can_chi_year(lunar_year)
        can_chi_day = get_can_chi_day(dd, mm, yy)
        
        # TÃªn thÃ¡ng Ã¢m
        month_name = f"{'Nhuáº­n ' if is_leap else ''}ThÃ¡ng {lunar_month}"
        
        # NgÃ y lá»… Ã¢m lá»‹ch Viá»‡t Nam
        vn_holidays = {
            (1, 1): "ğŸŠ Táº¿t NguyÃªn ÄÃ¡n - MÃ¹ng 1 Táº¿t",
            (1, 2): "ğŸŠ MÃ¹ng 2 Táº¿t",
            (1, 3): "ğŸŠ MÃ¹ng 3 Táº¿t",
            (1, 15): "ğŸ® Táº¿t NguyÃªn TiÃªu (Ráº±m thÃ¡ng GiÃªng)",
            (3, 3): "ğŸ° Táº¿t HÃ n Thá»±c",
            (3, 10): "ğŸ‘‘ Giá»— Tá»• HÃ¹ng VÆ°Æ¡ng",
            (4, 15): "ğŸª· Lá»… Pháº­t Äáº£n",
            (5, 5): "ğŸ² Táº¿t Äoan Ngá»",
            (7, 15): "ğŸ‘» Ráº±m thÃ¡ng 7 - Lá»… Vu Lan",
            (8, 15): "ğŸ¥® Táº¿t Trung Thu",
            (9, 9): "ğŸŒ¸ Táº¿t TrÃ¹ng Cá»­u",
            (10, 15): "ğŸ™ Ráº±m thÃ¡ng 10 - Lá»… Háº¡ NguyÃªn",
            (12, 23): "ğŸ§¹ Ã”ng CÃ´ng Ã”ng TÃ¡o",
            (12, 30): "ğŸ† Giao thá»«a - ÄÃªm 30 Táº¿t",
        }
        
        holiday_info = vn_holidays.get((lunar_month, lunar_day), "")
        
        # Kiá»ƒm tra ngÃ y ráº±m / mÃ¹ng 1
        special_day = ""
        if lunar_day == 1:
            special_day = "ğŸŒ‘ NgÃ y MÃ¹ng 1 (SÃ³c)"
        elif lunar_day == 15:
            special_day = "ğŸŒ• NgÃ y Ráº±m (Vá»ng)"
        
        message = f"""ğŸ“… Lá»ŠCH Ã‚M VIá»†T NAM

ğŸ—“ï¸ DÆ°Æ¡ng lá»‹ch: {day_of_week}, {dd:02d}/{mm:02d}/{yy}
ğŸŒ™ Ã‚m lá»‹ch: NgÃ y {lunar_day}, {month_name}, nÄƒm {can_chi_year}

ğŸ“† NgÃ y: {can_chi_day}
ğŸ‰ NÄƒm: {can_chi_year} ({lunar_year})

{f'ğŸ‰ {holiday_info}' if holiday_info else ''}
{special_day}""".strip()
        
        return {
            "success": True,
            "solar_date": f"{dd:02d}/{mm:02d}/{yy}",
            "lunar_date": f"{lunar_day}/{lunar_month}/{lunar_year}",
            "lunar_day": lunar_day,
            "lunar_month": lunar_month,
            "lunar_year": lunar_year,
            "is_leap_month": is_leap == 1,
            "day_of_week": day_of_week,
            "can_chi_day": can_chi_day,
            "can_chi_year": can_chi_year,
            "holiday": holiday_info if holiday_info else None,
            "message": message
        }
    except Exception as e:
        import traceback
        return {"success": False, "error": str(e), "traceback": traceback.format_exc()}

# ============================================================
# KNOWLEDGE BASE TOOL HANDLERS
# ============================================================

# ============================================================
# ğŸ”¥ GEMINI FLASH SMART KB FILTER - Lá»ŒC THÃ”NG TIN THÃ”NG MINH
# ============================================================

async def gemini_smart_kb_filter(
    user_query: str,
    filter_mode: str = "relevant",  # relevant, summary, extract, qa
    max_documents: int = 10,
    output_format: str = "structured"  # structured, raw, concise
) -> dict:
    """
    ğŸ”¥ Sá»­ dá»¥ng sá»©c máº¡nh Gemini Flash 3 Ä‘á»ƒ Lá»ŒC vÃ  TÃŒM KIáº¾M THÃ”NG MINH trong Knowledge Base.
    
    Quy trÃ¬nh:
    1. Load toÃ n bá»™ documents tá»« Knowledge Base
    2. DÃ¹ng Gemini Flash Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  lá»c ná»™i dung THá»°C Sá»° liÃªn quan
    3. TrÃ­ch xuáº¥t thÃ´ng tin chÃ­nh xÃ¡c, loáº¡i bá» noise
    4. Tráº£ vá» káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lá»c sáº¡ch cho LLM chÃ­nh Ä‘á»c
    
    Args:
        user_query: CÃ¢u há»i/yÃªu cáº§u cá»§a user
        filter_mode: 
            - "relevant": Chá»‰ giá»¯ pháº§n liÃªn quan (default)
            - "summary": TÃ³m táº¯t ná»™i dung
            - "extract": TrÃ­ch xuáº¥t facts/entities
            - "qa": Tráº£ lá»i cÃ¢u há»i trá»±c tiáº¿p
        max_documents: Sá»‘ documents tá»‘i Ä‘a Ä‘á»ƒ xá»­ lÃ½ (default: 10)
        output_format:
            - "structured": JSON cÃ³ cáº¥u trÃºc
            - "raw": Text thÃ´
            - "concise": Ngáº¯n gá»n nháº¥t
            
    Returns:
        dict vá»›i filtered_content, sources, vÃ  metadata
    """
    try:
        print(f"ğŸ”¥ [GEMINI KB FILTER] Processing: {user_query[:60]}...")
        
        # ============================================================
        # BÆ¯á»šC 1: Load táº¥t cáº£ documents tá»« Knowledge Base
        # ============================================================
        all_documents = []
        
        # Thá»­ load tá»« index trÆ°á»›c
        if KNOWLEDGE_INDEX_FILE.exists():
            try:
                with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                all_documents = index_data.get("documents", [])
            except:
                pass
        
        # ğŸ†• FALLBACK: Náº¿u index trá»‘ng, Ä‘á»c trá»±c tiáº¿p tá»« files
        if not all_documents:
            print("âš ï¸ [GEMINI KB] Index trá»‘ng, Ä‘ang Ä‘á»c trá»±c tiáº¿p tá»« files...")
            config = load_knowledge_config()
            folder_path = config.get("folder_path", "")
            
            if folder_path and Path(folder_path).exists():
                files = scan_folder_for_files(folder_path)
                for f in files[:15]:  # Giá»›i háº¡n 15 files
                    try:
                        text = extract_text_from_file(f["path"])
                        if text and len(text.strip()) > 50 and not text.startswith("["):
                            all_documents.append({
                                "file_path": f["path"],
                                "file_name": f["name"],
                                "content": text[:50000]
                            })
                            print(f"ğŸ“„ [GEMINI KB] Loaded: {f['name']}")
                    except Exception as e:
                        print(f"âš ï¸ [GEMINI KB] Error loading {f['name']}: {e}")
        
        if not all_documents:
            return {
                "success": False,
                "error": "Knowledge Base chÆ°a cÃ³ dá»¯ liá»‡u. Vui lÃ²ng vÃ o Web UI > Knowledge Base Ä‘á»ƒ cáº¥u hÃ¬nh thÆ° má»¥c."
            }
        
        print(f"ğŸ“š [GEMINI KB] Loaded {len(all_documents)} documents")
        
        # ============================================================
        # BÆ¯á»šC 2: Pre-filter báº±ng keywords (giáº£m sá»‘ docs cáº§n gá»­i Gemini)
        # ============================================================
        query_lower = user_query.lower()
        stop_words = {'lÃ ', 'cá»§a', 'vÃ ', 'cÃ³', 'cÃ¡c', 'Ä‘Æ°á»£c', 'trong', 'Ä‘á»ƒ', 'nÃ y', 'Ä‘Ã³', 
                     'cho', 'vá»›i', 'tá»«', 'vá»', 'nhÆ°', 'theo', 'khÃ´ng', 'khi', 'Ä‘Ã£', 'sáº½',
                     'ai', 'gÃ¬', 'nÃ o', 'Ä‘Ã¢u', 'sao', 'tháº¿', 'a', 'an', 'the', 'is', 'are'}
        
        keywords = [w.lower() for w in user_query.split() if w.lower() not in stop_words and len(w) > 1]
        print(f"ğŸ”‘ [GEMINI KB] Keywords: {keywords}")
        
        # Pre-filter: Chá»‰ giá»¯ documents cÃ³ Ã­t nháº¥t 1 keyword
        candidate_docs = []
        for doc in all_documents:
            content = doc.get("content", "").lower()
            file_name = doc.get("file_name", "")
            
            # Skip invalid content
            if content.strip().startswith("%pdf-") or len(content.strip()) < 50:
                continue
            
            # Check keyword match
            match_count = sum(1 for kw in keywords if kw in content or kw in file_name.lower())
            if match_count > 0 or not keywords:  # Náº¿u khÃ´ng cÃ³ keywords, láº¥y táº¥t cáº£
                candidate_docs.append({
                    "file_name": file_name,
                    "content": doc.get("content", ""),
                    "match_count": match_count
                })
        
        # Sort by match count vÃ  giá»›i háº¡n
        candidate_docs.sort(key=lambda x: x["match_count"], reverse=True)
        candidate_docs = candidate_docs[:max_documents]
        
        if not candidate_docs:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y documents nÃ o liÃªn quan Ä‘áº¿n '{user_query}'"
            }
        
        print(f"ğŸ“„ [GEMINI KB] Pre-filtered to {len(candidate_docs)} candidate docs")
        
        # ============================================================
        # BÆ¯á»šC 3: Chuáº©n bá»‹ context cho Gemini Flash
        # ============================================================
        # Giá»›i háº¡n má»—i document 3000 chars Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
        docs_for_gemini = []
        total_chars = 0
        MAX_TOTAL_CHARS = 25000  # ~6000 tokens cho Gemini
        
        for doc in candidate_docs:
            content = doc["content"]
            if len(content) > 3000:
                # TrÃ­ch xuáº¥t pháº§n cÃ³ keywords
                content = _extract_relevant_parts(content, keywords, max_len=3000)
            
            if total_chars + len(content) > MAX_TOTAL_CHARS:
                break
                
            docs_for_gemini.append({
                "file_name": doc["file_name"],
                "content": content
            })
            total_chars += len(content)
        
        print(f"ğŸ“¦ [GEMINI KB] Prepared {len(docs_for_gemini)} docs ({total_chars:,} chars) for Gemini")
        
        # ============================================================
        # BÆ¯á»šC 4: Build prompt cho Gemini Flash
        # ============================================================
        docs_text = ""
        for i, doc in enumerate(docs_for_gemini, 1):
            docs_text += f"\n\n--- TÃ€I LIá»†U {i}: {doc['file_name']} ---\n{doc['content']}"
        
        # Prompt tÃ¹y theo filter_mode
        if filter_mode == "summary":
            filter_instruction = """TÃ“M Táº®T ná»™i dung liÃªn quan Ä‘áº¿n cÃ¢u há»i.
- Chá»‰ tÃ³m táº¯t pháº§n THá»°C Sá»° liÃªn quan
- Bá» qua thÃ´ng tin khÃ´ng liÃªn quan
- Viáº¿t ngáº¯n gá»n, sÃºc tÃ­ch"""
        elif filter_mode == "extract":
            filter_instruction = """TRÃCH XUáº¤T cÃ¡c facts, entities, sá»‘ liá»‡u liÃªn quan:
- TÃªn ngÆ°á»i, tá»• chá»©c
- Sá»‘ liá»‡u, ngÃ y thÃ¡ng
- Sá»± kiá»‡n, hÃ nh Ä‘á»™ng
- Má»‘i quan há»‡
Format: JSON array"""
        elif filter_mode == "qa":
            filter_instruction = """âš¡ TRáº¢ Lá»œI NGAY Láº¬P Tá»¨C cÃ¢u há»i dá»±a trÃªn tÃ i liá»‡u.
â›” KHÃ”NG ÄÆ¯á»¢C há»i láº¡i, KHÃ”NG ÄÆ¯á»¢C yÃªu cáº§u thÃªm thÃ´ng tin
âœ… Tráº£ lá»i TRá»°C TIáº¾P, chÃ­nh xÃ¡c, cÃ³ trÃ­ch dáº«n nguá»“n
âœ… Náº¿u thÃ´ng tin khÃ´ng Ä‘áº§y Ä‘á»§ â†’ VáºªN tráº£ lá»i vá»›i nhá»¯ng gÃ¬ cÃ³
âœ… Náº¿u khÃ´ng cÃ³ thÃ´ng tin â†’ NÃ³i "KhÃ´ng tÃ¬m tháº¥y trong database" """
        else:  # relevant
            filter_instruction = """Lá»ŒC vÃ  GIá»® Láº I CHá»ˆ nhá»¯ng pháº§n THá»°C Sá»° LIÃŠN QUAN Ä‘áº¿n cÃ¢u há»i.
- Loáº¡i bá» hoÃ n toÃ n cÃ¡c Ä‘oáº¡n khÃ´ng liÃªn quan
- Giá»¯ nguyÃªn vÄƒn cÃ¡c Ä‘oáº¡n quan trá»ng
- ÄÃ¡nh dáº¥u nguá»“n (tÃªn file) cho má»—i Ä‘oáº¡n"""
        
        gemini_prompt = f"""ğŸ”¥ Báº N LÃ€ CHUYÃŠN GIA TRáº¢ Lá»œI CÃ‚U Há»I Tá»ª CÆ  Sá» Dá»® LIá»†U.

âš¡ QUY Táº®C Báº®T BUá»˜C:
- TRáº¢ Lá»œI NGAY Láº¬P Tá»¨C - KHÃ”NG Há»I Láº I
- KHÃ”NG yÃªu cáº§u thÃªm thÃ´ng tin
- KHÃ”NG nÃ³i "báº¡n muá»‘n biáº¿t gÃ¬" hoáº·c "báº¡n cáº§n gÃ¬ thÃªm"
- Sá»­ dá»¥ng TOÃ€N Bá»˜ thÃ´ng tin cÃ³ trong tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i

ğŸ“‹ NHIá»†M Vá»¤: {filter_instruction}

â“ CÃ‚U Há»I Cá»¦A USER:
"{user_query}"

ğŸ“š TÃ€I LIá»†U TRONG DATABASE:
{docs_text}

ğŸ¯ TRáº¢ Lá»œI NGAY (khÃ´ng há»i láº¡i):"""

        # ============================================================
        # BÆ¯á»šC 5: Gá»i Gemini Flash 3 Ä‘á»ƒ lá»c
        # ============================================================
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra API key."
            }
        
        import google.generativeai as genai
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        
        if not gemini_api_key:
            return {"success": False, "error": "Thiáº¿u Gemini API key"}
        
        genai.configure(api_key=gemini_api_key)
        
        # Sá»­ dá»¥ng Gemini 3 Flash Preview (model má»›i nháº¥t, nhanh nháº¥t)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        
        print(f"ğŸ¤– [GEMINI KB] Calling Gemini Flash to filter...")
        
        response = model.generate_content(
            gemini_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,  # Low temp cho accuracy
                max_output_tokens=2000,
                top_p=0.95
            )
        )
        
        if not response or not response.text:
            return {"success": False, "error": "Gemini khÃ´ng tráº£ vá» response"}
        
        filtered_content = response.text.strip()
        print(f"âœ… [GEMINI KB] Filtered content: {len(filtered_content)} chars")
        
        # ============================================================
        # BÆ¯á»šC 6: Format output
        # ============================================================
        sources = [doc["file_name"] for doc in docs_for_gemini]
        
        if output_format == "concise":
            # Cáº¯t ngáº¯n náº¿u quÃ¡ dÃ i
            if len(filtered_content) > 1500:
                filtered_content = filtered_content[:1500] + "\n[... ÄÃ£ cáº¯t ngáº¯n ...]"
        
        result = {
            "success": True,
            "filtered_content": filtered_content,
            "sources": sources,
            "filter_mode": filter_mode,
            "documents_processed": len(docs_for_gemini),
            "total_documents": len(all_documents),
            "keywords_used": keywords,
            "original_chars": total_chars,
            "filtered_chars": len(filtered_content),
            "compression_ratio": f"{(1 - len(filtered_content)/max(total_chars,1))*100:.1f}%",
            "message": f"âœ… ÄÃ£ lá»c {len(docs_for_gemini)} tÃ i liá»‡u ({total_chars:,} chars) â†’ {len(filtered_content):,} chars relevant content"
        }
        
        # ThÃªm instruction cho LLM chÃ­nh
        result["llm_instruction"] = f"""ğŸ“Š ÄÃƒ Lá»ŒC THÃ”NG TIN Tá»ª KNOWLEDGE BASE

CÃ¢u há»i: "{user_query}"
Nguá»“n: {', '.join(sources[:3])}{'...' if len(sources) > 3 else ''}

--- Ná»˜I DUNG ÄÃƒ Lá»ŒC ---
{filtered_content}
--- Háº¾T ---

âš¡ HÃƒY TRáº¢ Lá»œI USER Dá»°A TRÃŠN THÃ”NG TIN TRÃŠN."""

        return result
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def _extract_relevant_parts(content: str, keywords: list, max_len: int = 3000) -> str:
    """
    TrÃ­ch xuáº¥t cÃ¡c pháº§n cÃ³ chá»©a keywords tá»« content dÃ i.
    """
    if not keywords:
        return content[:max_len]
    
    content_lower = content.lower()
    relevant_parts = []
    
    for keyword in keywords:
        pos = 0
        while pos < len(content_lower):
            idx = content_lower.find(keyword, pos)
            if idx == -1:
                break
            
            # Láº¥y context xung quanh keyword (500 chars má»—i bÃªn)
            start = max(0, idx - 500)
            end = min(len(content), idx + len(keyword) + 500)
            
            part = content[start:end]
            if part not in relevant_parts:
                relevant_parts.append(part)
            
            pos = idx + 1
            
            # Giá»›i háº¡n sá»‘ parts
            if len(relevant_parts) >= 5:
                break
    
    if relevant_parts:
        combined = "\n[...]\n".join(relevant_parts)
        return combined[:max_len]
    else:
        return content[:max_len]


# ============================================================
# ğŸ”¥ GEMINI SMART ANALYZE - PHÃ‚N TÃCH + GOOGLE SEARCH
# ============================================================

async def gemini_smart_analyze(
    user_query: str,
    analysis_type: str = "comprehensive",  # comprehensive, quick, deep
    include_web_search: bool = True,
    include_kb: bool = False,
    max_search_results: int = 8
) -> dict:
    """
    ğŸ”¥ GEMINI SMART ANALYZE - PhÃ¢n tÃ­ch váº¥n Ä‘á» + TÃ¬m kiáº¿m Web + AI tá»•ng há»£p
    
    Quy trÃ¬nh:
    1. Gemini phÃ¢n tÃ­ch yÃªu cáº§u vÃ  táº¡o search queries tá»‘i Æ°u
    2. TÃ¬m kiáº¿m Web (Google/DuckDuckGo) Ä‘á»ƒ láº¥y thÃ´ng tin má»›i nháº¥t
    3. (TÃ¹y chá»n) TÃ¬m kiáº¿m Knowledge Base ná»™i bá»™
    4. Gemini tá»•ng há»£p, phÃ¢n tÃ­ch vÃ  Ä‘Æ°a ra káº¿t luáº­n
    5. Tráº£ vá» káº¿t quáº£ phÃ¢n tÃ­ch cho LLM chÃ­nh
    
    Args:
        user_query: Váº¥n Ä‘á» cáº§n phÃ¢n tÃ­ch
        analysis_type: 
            - "comprehensive": PhÃ¢n tÃ­ch Ä‘áº§y Ä‘á»§, chi tiáº¿t (default)
            - "quick": PhÃ¢n tÃ­ch nhanh, tÃ³m táº¯t
            - "deep": PhÃ¢n tÃ­ch sÃ¢u, nhiá»u gÃ³c Ä‘á»™
        include_web_search: CÃ³ tÃ¬m kiáº¿m web khÃ´ng (default: True)
        include_kb: CÃ³ tÃ¬m Knowledge Base khÃ´ng (default: False)
        max_search_results: Sá»‘ káº¿t quáº£ web search tá»‘i Ä‘a (default: 8)
        
    Returns:
        dict vá»›i analysis, sources, summary
    """
    try:
        print(f"ğŸ”¥ [GEMINI ANALYZE] Analyzing: {user_query[:60]}...")
        
        # ============================================================
        # BÆ¯á»šC 1: Kiá»ƒm tra Gemini API
        # ============================================================
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra API key."
            }
        
        import google.generativeai as genai
        gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
        
        if not gemini_api_key:
            return {"success": False, "error": "Thiáº¿u Gemini API key"}
        
        genai.configure(api_key=gemini_api_key)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
        
        # ============================================================
        # BÆ¯á»šC 2: Gemini táº¡o search queries tá»‘i Æ°u
        # ============================================================
        query_prompt = f"""Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch. User muá»‘n phÃ¢n tÃ­ch/tÃ¬m hiá»ƒu vá»:
"{user_query}"

HÃ£y táº¡o 2-3 search queries Tá»I Æ¯U Ä‘á»ƒ tÃ¬m kiáº¿m thÃ´ng tin trÃªn Google/Web.
Má»—i query nÃªn:
- Ngáº¯n gá»n, tá»« khÃ³a chÃ­nh xÃ¡c
- ThÃªm nÄƒm 2024/2025 náº¿u cáº§n thÃ´ng tin má»›i
- Tiáº¿ng Viá»‡t hoáº·c Anh tÃ¹y chá»§ Ä‘á»

Tráº£ vá» JSON array, VD: ["query 1", "query 2", "query 3"]
Chá»‰ tráº£ vá» JSON, khÃ´ng giáº£i thÃ­ch."""

        print("ğŸ” [GEMINI ANALYZE] Generating search queries...")
        
        query_response = model.generate_content(
            query_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=300
            )
        )
        
        # Parse search queries
        search_queries = [user_query]  # Default
        if query_response and query_response.text:
            try:
                import re
                json_match = re.search(r'\[.*?\]', query_response.text, re.DOTALL)
                if json_match:
                    search_queries = json.loads(json_match.group())
                    print(f"âœ… [GEMINI ANALYZE] Generated queries: {search_queries}")
            except:
                search_queries = [user_query]
        
        # ============================================================
        # BÆ¯á»šC 3: TÃ¬m kiáº¿m Web (Google/DuckDuckGo)
        # ============================================================
        web_results = []
        web_context = ""
        
        if include_web_search and RAG_AVAILABLE:
            print(f"ğŸŒ [GEMINI ANALYZE] Searching web with {len(search_queries)} queries...")
            
            from rag_system import web_search as rag_web_search
            
            all_results = []
            for sq in search_queries[:3]:  # Max 3 queries
                try:
                    result = await rag_web_search(sq, max_results=max_search_results // len(search_queries) + 2)
                    if result.get("success") and result.get("results"):
                        all_results.extend(result["results"])
                except Exception as e:
                    print(f"âš ï¸ [GEMINI ANALYZE] Search error for '{sq}': {e}")
            
            # Deduplicate by title
            seen_titles = set()
            for r in all_results:
                title = r.get("title", "")
                if title and title not in seen_titles:
                    seen_titles.add(title)
                    web_results.append(r)
            
            web_results = web_results[:max_search_results]
            print(f"ğŸ“Š [GEMINI ANALYZE] Found {len(web_results)} unique web results")
            
            # Build web context
            if web_results:
                web_context = "ğŸŒ Káº¾T QUáº¢ TÃŒM KIáº¾M WEB:\n\n"
                for i, r in enumerate(web_results, 1):
                    web_context += f"{i}. **{r.get('title', 'No title')}**\n"
                    web_context += f"   {r.get('snippet', '')}\n"
                    if r.get('url'):
                        web_context += f"   ğŸ”— {r.get('url')}\n"
                    web_context += "\n"
        
        # ============================================================
        # BÆ¯á»šC 4: TÃ¬m kiáº¿m Knowledge Base (náº¿u báº­t)
        # ============================================================
        kb_context = ""
        kb_sources = []
        
        if include_kb:
            print("ğŸ“š [GEMINI ANALYZE] Searching Knowledge Base...")
            try:
                kb_result = await gemini_smart_kb_filter(
                    user_query=user_query,
                    filter_mode="relevant",
                    max_documents=5,
                    output_format="concise"
                )
                if kb_result.get("success") and kb_result.get("filtered_content"):
                    kb_context = f"\n\nğŸ“š THÃ”NG TIN Tá»ª DATABASE Ná»˜I Bá»˜:\n{kb_result['filtered_content']}"
                    kb_sources = kb_result.get("sources", [])
                    print(f"âœ… [GEMINI ANALYZE] Found KB content from {len(kb_sources)} sources")
            except Exception as e:
                print(f"âš ï¸ [GEMINI ANALYZE] KB search error: {e}")
        
        # ============================================================
        # BÆ¯á»šC 5: Gemini tá»•ng há»£p vÃ  phÃ¢n tÃ­ch
        # ============================================================
        
        # XÃ¢y dá»±ng prompt phÃ¢n tÃ­ch tÃ¹y theo type
        if analysis_type == "quick":
            analysis_instruction = """PHÃ‚N TÃCH NHANH - TÃ³m táº¯t ngáº¯n gá»n:
- 3-5 Ä‘iá»ƒm chÃ­nh
- Káº¿t luáº­n trong 2-3 cÃ¢u
- KhÃ´ng cáº§n chi tiáº¿t"""
        elif analysis_type == "deep":
            analysis_instruction = """PHÃ‚N TÃCH SÃ‚U - Chi tiáº¿t vÃ  Ä‘a chiá»u:
- PhÃ¢n tÃ­ch tá»« nhiá»u gÃ³c Ä‘á»™
- So sÃ¡nh cÃ¡c nguá»“n thÃ´ng tin
- ÄÃ¡nh giÃ¡ Ä‘á»™ tin cáº­y
- Xu hÆ°á»›ng vÃ  dá»± Ä‘oÃ¡n
- TÃ³m táº¯t cÃ¡c quan Ä‘iá»ƒm khÃ¡c nhau"""
        else:  # comprehensive
            analysis_instruction = """PHÃ‚N TÃCH TOÃ€N DIá»†N:
- TÃ³m táº¯t thÃ´ng tin chÃ­nh
- CÃ¡c Ä‘iá»ƒm quan trá»ng
- Nguá»“n gá»‘c vÃ  Ä‘á»™ tin cáº­y
- Káº¿t luáº­n rÃµ rÃ ng"""
        
        now = datetime.now()
        current_date = now.strftime("%d/%m/%Y")
        
        analysis_prompt = f"""ğŸ”¥ Báº N LÃ€ CHUYÃŠN GIA PHÃ‚N TÃCH THÃ”NG TIN.

ğŸ“… NGÃ€Y HIá»†N Táº I: {current_date}

âš¡ NHIá»†M Vá»¤: {analysis_instruction}

â“ Váº¤N Äá»€ Cáº¦N PHÃ‚N TÃCH:
"{user_query}"

{web_context}
{kb_context}

ğŸ¯ YÃŠU Cáº¦U QUAN TRá»ŒNG:
1. TRáº¢ Lá»œI NGáº®N Gá»ŒN - Tá»I ÄA 500 Tá»ª
2. ÄI THáº²NG VÃ€O Váº¤N Äá»€, khÃ´ng giáº£i thÃ­ch dÃ i dÃ²ng
3. Liá»‡t kÃª Ã½ chÃ­nh báº±ng bullet points
4. TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T
5. KHÃ”NG cáº§n ghi nguá»“n chi tiáº¿t

ğŸ“ TRáº¢ Lá»œI NGáº®N Gá»ŒN:"""

        print("ğŸ¤– [GEMINI ANALYZE] Gemini analyzing and synthesizing...")
        
        analysis_response = model.generate_content(
            analysis_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=1000,
                top_p=0.9
            )
        )
        
        if not analysis_response or not analysis_response.text:
            return {"success": False, "error": "Gemini khÃ´ng tráº£ vá» phÃ¢n tÃ­ch"}
        
        analysis_content = analysis_response.text.strip()
        
        # âš¡ GIá»šI Háº N Äá»˜ DÃ€I - QuÃ¡ dÃ i sáº½ khiáº¿n LLM cloud bá»‹ timeout
        MAX_RESPONSE_LENGTH = 1500
        if len(analysis_content) > MAX_RESPONSE_LENGTH:
            # Cáº¯t ngáº¯n nhÆ°ng giá»¯ nguyÃªn cÃ¢u cuá»‘i
            analysis_content = analysis_content[:MAX_RESPONSE_LENGTH]
            # TÃ¬m dáº¥u cháº¥m cuá»‘i Ä‘á»ƒ khÃ´ng cáº¯t giá»¯a cÃ¢u
            last_period = analysis_content.rfind('.')
            if last_period > MAX_RESPONSE_LENGTH - 200:
                analysis_content = analysis_content[:last_period + 1]
            analysis_content += "\n\n(ÄÃ¢y lÃ  tÃ³m táº¯t. Há»i thÃªm náº¿u cáº§n chi tiáº¿t.)"
        
        print(f"âœ… [GEMINI ANALYZE] Analysis complete: {len(analysis_content)} chars")
        
        # ============================================================
        # BÆ¯á»šC 6: Tráº£ vá» káº¿t quáº£ - PLAIN TEXT Ä‘á»ƒ LLM Ä‘á»c ngay
        # ============================================================
        
        # Tráº£ vá» response_text Ä‘á»ƒ format_result_for_llm xá»­ lÃ½ Ä‘Ãºng
        # Giá»‘ng cÃ¡ch ask_gemini, ask_gpt4 hoáº¡t Ä‘á»™ng
        return {
            "success": True,
            "response_text": analysis_content
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


async def search_knowledge_base(query: str) -> dict:
    """
    TÃ¬m kiáº¿m trong Knowledge Base vÃ  dÃ¹ng Gemini AI Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c.
    - BÆ°á»›c 1: TF-IDF tÃ¬m tÃ i liá»‡u liÃªn quan
    - BÆ°á»›c 2: Gemini Ä‘á»c context vÃ  tráº£ lá»i cÃ¢u há»i
    - ğŸ†• BÆ°á»›c 0: Náº¿u index trá»‘ng, tá»± Ä‘á»™ng Ä‘á»c file trá»±c tiáº¿p
    """
    try:
        if not query:
            return {"success": False, "error": "Vui lÃ²ng nháº­p tá»« khÃ³a tÃ¬m kiáº¿m"}
        
        # Load index
        documents = []
        if KNOWLEDGE_INDEX_FILE.exists():
            try:
                with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                documents = index_data.get("documents", [])
            except:
                pass
        
        # ğŸ†• FALLBACK: Náº¿u index trá»‘ng, tá»± Ä‘á»™ng Ä‘á»c trá»±c tiáº¿p tá»« files
        if not documents:
            print("âš ï¸ [KB] Index trá»‘ng, Ä‘ang Ä‘á»c trá»±c tiáº¿p tá»« files...")
            config = load_knowledge_config()
            folder_path = config.get("folder_path", "")
            
            if folder_path and Path(folder_path).exists():
                files = scan_folder_for_files(folder_path)
                for f in files[:10]:  # Giá»›i háº¡n 10 files Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
                    try:
                        text = extract_text_from_file(f["path"])
                        if text and len(text.strip()) > 50 and not text.startswith("["):
                            documents.append({
                                "file_path": f["path"],
                                "file_name": f["name"],
                                "content": text[:50000]
                            })
                            print(f"ğŸ“„ [KB] Loaded: {f['name']} ({len(text)} chars)")
                    except Exception as e:
                        print(f"âš ï¸ [KB] Error loading {f['name']}: {e}")
                
                if documents:
                    print(f"ğŸ“š [KB] Loaded {len(documents)} documents from files")
            
            if not documents:
                return {
                    "success": False, 
                    "error": "Knowledge base chÆ°a cÃ³ dá»¯ liá»‡u. Vui lÃ²ng vÃ o Web UI > Knowledge Base Ä‘á»ƒ cáº¥u hÃ¬nh thÆ° má»¥c vÃ  index files."
                }
        
        # TÃ¡ch query thÃ nh keywords (bá» stop words phá»• biáº¿n)
        stop_words = {
            # Vietnamese
            'lÃ ', 'cá»§a', 'vÃ ', 'cÃ³', 'cÃ¡c', 'Ä‘Æ°á»£c', 'trong', 'Ä‘á»ƒ', 'nÃ y', 'Ä‘Ã³', 'cho', 'vá»›i', 
            'tá»«', 'vá»', 'nhÆ°', 'theo', 'khÃ´ng', 'khi', 'Ä‘Ã£', 'sáº½', 'nhá»¯ng', 'má»™t', 'hay', 'hoáº·c',
            'thÃ¬', 'mÃ ', 'náº¿u', 'vÃ¬', 'bá»Ÿi', 'nÃªn', 'cÅ©ng', 'láº¡i', 'cÃ²n', 'Ä‘Ã¢y', 'kia', 'áº¥y',
            'ra', 'vÃ o', 'lÃªn', 'xuá»‘ng', 'Ä‘i', 'Ä‘áº¿n', 'báº±ng', 'qua', 'sau', 'trÆ°á»›c', 'trÃªn', 'dÆ°á»›i',
            'nÃ o', 'gÃ¬', 'sao', 'tháº¿', 'ráº±ng', 'táº¡i', 'váº­y', 'nhÆ°ng', 'tuy', 'máº·c', 'dÃ¹',
            # English
            'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should', 'could', 
            'may', 'might', 'can', 'what', 'which', 'who', 'how', 'when', 'where', 'why',
            'this', 'that', 'these', 'those', 'it', 'its', 'they', 'them', 'their',
            'he', 'she', 'him', 'her', 'his', 'we', 'us', 'our', 'you', 'your',
            'of', 'to', 'in', 'on', 'at', 'by', 'for', 'with', 'about', 'as', 'from'
        }
        
        # Lá»c keywords - CHá»ˆ GIá»® Tá»ª QUAN TRá»ŒNG (dÃ i > 3 kÃ½ tá»±)
        keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 3]
        
        # Náº¿u query quÃ¡ dÃ i (>4 tá»«), chá»‰ láº¥y 4 tá»« quan trá»ng nháº¥t
        if len(keywords) > 4:
            keywords = sorted(keywords, key=len, reverse=True)[:4]
        
        if not keywords:
            all_words = [w.lower() for w in query.split() if len(w) > 2]
            keywords = sorted(all_words, key=len, reverse=True)[:3] if all_words else [query.lower()]
        
        print(f"ğŸ” [KB] Searching with keywords: {keywords}")
        
        # TÃ­nh Ä‘iá»ƒm relevance cho tá»«ng document
        scored_docs = []
        min_keywords_match = max(1, len(keywords) - 1)
        
        for doc in documents:
            content = doc.get("content", "")
            content_lower = content.lower()
            file_name = doc.get("file_name", "")
            
            score = 0
            matched_keywords = []
            best_pos = 0
            
            for keyword in keywords:
                count = content_lower.count(keyword)
                if count > 0:
                    import math
                    score += math.log(1 + count) * 10
                    matched_keywords.append(keyword)
                    if not best_pos:
                        idx = content_lower.find(keyword)
                        if idx >= 0:
                            best_pos = idx
            
            if len(matched_keywords) < min_keywords_match:
                continue
            
            if len(matched_keywords) > 1:
                score *= (1 + len(matched_keywords) * 0.5)
            
            for keyword in keywords:
                if keyword in file_name.lower():
                    score *= 2.0
            
            if score > 0:
                scored_docs.append({
                    "file_name": file_name,
                    "score": score,
                    "matched_keywords": matched_keywords,
                    "content": content,
                    "best_pos": best_pos
                })
        
        scored_docs.sort(key=lambda x: x["score"], reverse=True)
        
        if not scored_docs:
            return {
                "success": False,
                "message": f"âŒ KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u liÃªn quan trong knowledge base.\nğŸ’¡ Thá»­ dÃ¹ng tá»« khÃ³a khÃ¡c hoáº·c ngáº¯n hÆ¡n."
            }
        
        # ============================================================
        # BÆ¯á»šC 2: ğŸ”¥ DÃ™NG GEMINI SMART FILTER Äá»‚ Lá»ŒC VÃ€ TRáº¢ Lá»œI
        # ============================================================
        print(f"ğŸ¤– [KB] Found {len(scored_docs)} docs, using Gemini Smart Filter...")
        
        # ğŸ”¥ Sá»¬ Dá»¤NG gemini_smart_kb_filter Ä‘á»ƒ lá»c thÃ´ng minh
        try:
            filter_result = await gemini_smart_kb_filter(
                user_query=query,
                filter_mode="qa",  # Tráº£ lá»i trá»±c tiáº¿p
                max_documents=min(len(scored_docs), 5),  # Tá»‘i Ä‘a 5 docs
                output_format="concise"  # Output ngáº¯n gá»n
            )
            
            if filter_result.get("success") and filter_result.get("filtered_content"):
                answer = filter_result["filtered_content"]
                sources = filter_result.get("sources", [d['file_name'] for d in scored_docs[:3]])
                
                # ğŸ”¥ FORMAT NGáº®N Gá»ŒN GIá»NG WEB_SEARCH - LLM Dá»„ Äá»ŒC
                return {
                    "success": True,
                    "answer": answer,
                    "sources": sources
                }
        except Exception as filter_err:
            print(f"âš ï¸ [KB] Gemini Smart Filter error: {filter_err}, falling back to direct Gemini...")
        
        # ============================================================
        # FALLBACK: DÃ¹ng Gemini trá»±c tiáº¿p náº¿u Smart Filter fail
        # ============================================================
        # Láº¥y context tá»« top 2 documents (max 3000 chars má»—i doc)
        context_parts = []
        for doc in scored_docs[:2]:
            content = doc['content']
            best_pos = doc['best_pos']
            # Láº¥y pháº§n xung quanh keyword match
            start = max(0, best_pos - 500)
            end = min(len(content), best_pos + 2500)
            chunk = content[start:end]
            context_parts.append(f"ğŸ“„ {doc['file_name']}:\n{chunk}")
        
        context_for_gemini = "\n\n---\n\n".join(context_parts)
        
        # Gá»i Gemini Ä‘á»ƒ tráº£ lá»i
        try:
            import google.generativeai as genai
            
            gemini_api_key = os.environ.get("GEMINI_API_KEY") or GEMINI_API_KEY
            if not gemini_api_key:
                # Fallback - tráº£ vá» context thÃ´
                return {
                    "success": True,
                    "message": f"ğŸ“š TÃ¬m tháº¥y {len(scored_docs)} tÃ i liá»‡u liÃªn quan",
                    "context": context_for_gemini[:4000]
                }
            
            genai.configure(api_key=gemini_api_key)
            model = genai.GenerativeModel('models/gemini-2.0-flash')
            
            prompt = f"""Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn tráº£ lá»i cÃ¢u há»i dá»±a trÃªn tÃ i liá»‡u.

âš¡ QUY Táº®C Báº®T BUá»˜C:
- TRáº¢ Lá»œI NGAY Láº¬P Tá»¨C - KHÃ”NG Há»I Láº I
- KHÃ”NG há»i "báº¡n muá»‘n biáº¿t gÃ¬ thÃªm?"
- KHÃ”NG yÃªu cáº§u thÃªm thÃ´ng tin
- Sá»­ dá»¥ng thÃ´ng tin cÃ³ trong tÃ i liá»‡u Ä‘á»ƒ tráº£ lá»i

ğŸ“‹ TÃ€I LIá»†U THAM KHáº¢O:
{context_for_gemini[:5000]}

â“ CÃ‚U Há»I:
{query}

ğŸ“ YÃŠU Cáº¦U:
1. TRáº¢ Lá»œI TRá»°C TIáº¾P dá»±a trÃªn tÃ i liá»‡u
2. Náº¿u khÃ´ng cÃ³ thÃ´ng tin â†’ NÃ³i "KhÃ´ng tÃ¬m tháº¥y trong tÃ i liá»‡u"
3. TrÃ­ch dáº«n nguá»“n khi cáº§n
4. Ngáº¯n gá»n, sÃºc tÃ­ch
5. Tiáº¿ng Viá»‡t

ğŸ¯ TRáº¢ Lá»œI NGAY:"""

            response = model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=500,
                    temperature=0.3  # Low temp cho accurate answers
                )
            )
            
            gemini_answer = response.text.strip() if response.text else ""
            
            if gemini_answer:
                sources = [d['file_name'] for d in scored_docs[:2]]
                # ğŸ”¥ FORMAT NGáº®N Gá»ŒN GIá»NG WEB_SEARCH
                return {
                    "success": True,
                    "answer": gemini_answer,
                    "sources": sources
                }
            else:
                return {
                    "success": True,
                    "answer": f"TÃ¬m tháº¥y {len(scored_docs)} tÃ i liá»‡u liÃªn quan nhÆ°ng khÃ´ng cÃ³ cÃ¢u tráº£ lá»i cá»¥ thá»ƒ.",
                    "context": context_for_gemini[:2000]
                }
                
        except Exception as gemini_err:
            print(f"âš ï¸ [KB] Gemini error: {gemini_err}")
            # Fallback - tráº£ vá» context thÃ´
            return {
                "success": True,
                "answer": f"TÃ¬m tháº¥y {len(scored_docs)} tÃ i liá»‡u liÃªn quan.",
                "context": context_for_gemini[:2500]
            }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

async def get_knowledge_context(query: str = "", max_chars: int = 10000, use_gemini_summary: bool = True, use_gemini_filter: bool = False) -> dict:
    """
    ğŸ”§ REFACTORED: Láº¥y context tá»« Knowledge Base vá»›i semantic search chÃ­nh xÃ¡c hÆ¡n.
    - Æ¯u tiÃªn exact phrase match
    - Chá»‰ láº¥y documents thá»±c sá»± liÃªn quan
    - Option: DÃ¹ng Gemini Smart Filter Ä‘á»ƒ lá»c thÃ´ng minh
    - Tráº£ vá» context Ä‘Ãºng cho LLM
    
    Args:
        use_gemini_filter: Náº¿u True, sáº½ dÃ¹ng gemini_smart_kb_filter Ä‘á»ƒ lá»c thÃ´ng minh (máº·c Ä‘á»‹nh: False)
    """
    try:
        # Load index
        if not KNOWLEDGE_INDEX_FILE.exists():
            return {
                "success": False, 
                "context": "",
                "error": "Knowledge base chÆ°a cÃ³ dá»¯ liá»‡u. Vui lÃ²ng index files trÆ°á»›c."
            }
        
        with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8') as f:
            index_data = json.load(f)
        
        all_documents = index_data.get("documents", [])
        if not all_documents:
            return {"success": False, "context": "", "error": "Knowledge base trá»‘ng."}
        
        print(f"ğŸ“š [KB] Loaded {len(all_documents)} documents from index")
        
        # ============================================================
        # ğŸ”¥ OPTION: Sá»­ dá»¥ng Gemini Smart Filter náº¿u Ä‘Æ°á»£c báº­t
        # ============================================================
        if use_gemini_filter and query:
            print(f"ğŸ”¥ [KB] Using Gemini Smart Filter for query: {query}")
            try:
                filter_result = await gemini_smart_kb_filter(
                    user_query=query,
                    filter_mode="relevant",  # Chá»‰ láº¥y pháº§n liÃªn quan
                    max_documents=10,
                    output_format="structured"
                )
                
                if filter_result.get("success") and filter_result.get("filtered_content"):
                    return {
                        "success": True,
                        "context": filter_result.get("llm_instruction", filter_result["filtered_content"]),
                        "raw_context": filter_result["filtered_content"],
                        "total_documents": filter_result.get("total_documents", len(all_documents)),
                        "documents_included": filter_result.get("documents_processed", 0),
                        "context_length": filter_result.get("filtered_chars", 0),
                        "keywords_used": filter_result.get("keywords_used", []),
                        "gemini_filter_used": True,
                        "compression_ratio": filter_result.get("compression_ratio", "N/A"),
                        "message": f"âœ… Gemini Smart Filter: ÄÃ£ lá»c {filter_result.get('documents_processed', 0)} tÃ i liá»‡u ({filter_result.get('filtered_chars', 0):,} chars)"
                    }
            except Exception as filter_err:
                print(f"âš ï¸ [KB] Gemini Smart Filter failed: {filter_err}, using traditional method...")
        
        # ============================================================
        # BÆ¯á»šC 1: Chuáº©n bá»‹ keywords vÃ  query
        # ============================================================
        query_lower = query.lower().strip() if query else ""
        
        # Táº¡o keywords tá»« query
        stop_words = {'lÃ ', 'cá»§a', 'vÃ ', 'cÃ³', 'cÃ¡c', 'Ä‘Æ°á»£c', 'trong', 'Ä‘á»ƒ', 'nÃ y', 'Ä‘Ã³', 'cho', 'vá»›i', 
                     'tá»«', 'vá»', 'nhÆ°', 'theo', 'khÃ´ng', 'khi', 'Ä‘Ã£', 'sáº½', 'ai', 'gÃ¬', 'nÃ o', 'Ä‘Ã¢u',
                     'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'what', 'who', 'where'}
        keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 1] if query else []
        
        # Náº¿u khÃ´ng cÃ³ keywords, dÃ¹ng toÃ n bá»™ query
        if not keywords and query:
            keywords = [query_lower]
        
        print(f"ğŸ”‘ [KB] Query: '{query}' â†’ Keywords: {keywords}")
        
        # ============================================================
        # BÆ¯á»šC 2: Lá»c vÃ  score documents
        # ============================================================
        scored_documents = []
        
        for doc in all_documents:
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            content_lower = content.lower()
            file_name_lower = file_name.lower()
            
            # âš ï¸ SKIP: PDF structure hoáº·c content quÃ¡ ngáº¯n
            if content.strip().startswith("%PDF-") or content.strip().startswith("<</"):
                continue
            if len(content.strip()) < 50:
                continue
            
            # TÃ­nh Ä‘iá»ƒm relevance vá»›i scoring má»›i
            score = 0
            match_reasons = []
            has_exact_match = False
            has_filename_match = False
            
            if query_lower:
                # 0ï¸âƒ£ FILENAME MATCH (Æ¯U TIÃŠN CAO) - Check trÆ°á»›c!
                # Normalize filename Ä‘á»ƒ so sÃ¡nh (bá» dáº¥u, bá» kÃ½ tá»± Ä‘áº·c biá»‡t)
                import unicodedata
                def normalize_text(text):
                    # Bá» dáº¥u tiáº¿ng Viá»‡t vÃ  chuyá»ƒn thÃ nh ASCII
                    nfkd = unicodedata.normalize('NFKD', text.lower())
                    return ''.join(c for c in nfkd if not unicodedata.combining(c))
                
                query_normalized = normalize_text(query_lower)
                filename_normalized = normalize_text(file_name_lower)
                
                # Full query match trong filename
                if query_lower in file_name_lower or query_normalized in filename_normalized:
                    score += 5000
                    match_reasons.append("filename_exact")
                    has_filename_match = True
                else:
                    # Partial keyword match trong filename
                    filename_kw_matches = 0
                    for kw in keywords:
                        kw_norm = normalize_text(kw)
                        if kw in file_name_lower or kw_norm in filename_normalized:
                            filename_kw_matches += 1
                    
                    if filename_kw_matches >= 2:
                        score += 2000 * filename_kw_matches
                        match_reasons.append(f"filename_partial:{filename_kw_matches}")
                        has_filename_match = True
                    elif filename_kw_matches == 1 and len(keywords) <= 2:
                        score += 500
                        match_reasons.append(f"filename_partial:{filename_kw_matches}")
                        has_filename_match = True
                
                # 1ï¸âƒ£ EXACT PHRASE MATCH (Æ°u tiÃªn CAO NHáº¤T - vÃ­ dá»¥: "LÃª Trung Khoa" as a phrase)
                exact_count = content_lower.count(query_lower)
                if exact_count > 0:
                    score += 5000 * exact_count  # Ráº¤T CAO - Æ°u tiÃªn tuyá»‡t Ä‘á»‘i
                    match_reasons.append(f"exact_phrase:{exact_count}")
                    has_exact_match = True
                
                # 2ï¸âƒ£ PROXIMITY CHECK - Kiá»ƒm tra keywords cÃ³ gáº§n nhau khÃ´ng (cho tÃªn riÃªng)
                # Náº¿u query cÃ³ váº» lÃ  tÃªn ngÆ°á»i (>= 2 tá»«), kiá»ƒm tra xem cÃ¡c tá»« cÃ³ liá»n nhau khÃ´ng
                has_proximity = False
                if len(keywords) >= 2 and not has_exact_match:
                    # TÃ¬m vá»‹ trÃ­ cá»§a má»—i keyword
                    keyword_positions = []
                    for kw in keywords:
                        pos = content_lower.find(kw)
                        if pos >= 0:
                            keyword_positions.append((kw, pos))
                    
                    # Kiá»ƒm tra proximity (trong vÃ²ng 50 kÃ½ tá»±)
                    if len(keyword_positions) == len(keywords):
                        # Táº¥t cáº£ keywords Ä‘á»u cÃ³ trong content
                        positions = [p[1] for p in keyword_positions]
                        min_pos, max_pos = min(positions), max(positions)
                        # Náº¿u táº¥t cáº£ keywords náº±m trong 50 kÃ½ tá»± â†’ cÃ³ thá»ƒ lÃ  tÃªn riÃªng
                        if max_pos - min_pos < 50:
                            has_proximity = True
                            score += 3000  # Bonus cao cho proximity
                            match_reasons.append(f"proximity:{max_pos - min_pos}chars")
                
                # 3ï¸âƒ£ KEYWORD MATCH - Äáº¿m sá»‘ keywords xuáº¥t hiá»‡n
                keyword_matches = 0
                total_kw_score = 0
                for kw in keywords:
                    kw_count = content_lower.count(kw)
                    if kw_count > 0:
                        total_kw_score += min(kw_count, 5)  # Cap táº¡i 5 láº§n má»—i keyword
                        keyword_matches += 1
                
                # âš ï¸ Náº¾U LÃ€ TÃŠN RIÃŠNG (>= 2 keywords): Cáº§n cÃ³ exact match hoáº·c proximity
                if len(keywords) >= 2:
                    if has_exact_match or has_proximity:
                        # CÃ³ exact hoáº·c proximity â†’ bonus cao
                        score += 200 * keyword_matches
                        match_reasons.append(f"name_match:{keyword_matches}/{len(keywords)}")
                    elif has_filename_match:
                        # CÃ³ filename match â†’ bonus trung bÃ¬nh
                        score += 100 * keyword_matches
                        match_reasons.append(f"content_support:{keyword_matches}/{len(keywords)}")
                    elif keyword_matches == len(keywords):
                        # Táº¥t cáº£ keywords match nhÆ°ng KHÃ”NG gáº§n nhau â†’ score tháº¥p
                        score += 20 * keyword_matches  # Tháº¥p hÆ¡n nhiá»u
                        match_reasons.append(f"scattered_kw:{keyword_matches}/{len(keywords)}")
                        
                        # âš ï¸ PENALTY Máº NH cho documents dÃ i vá»›i scattered keywords
                        # NHÆ¯NG khÃ´ng penalty náº¿u cÃ³ filename match
                        if len(content) > 5000 and not has_filename_match:
                            score = int(score * 0.1)  # Giáº£m 90%!
                            match_reasons.append("penalty:scattered_in_long_doc")
                    elif keyword_matches >= len(keywords) * 0.7:
                        # >= 70% keywords match â†’ score ráº¥t tháº¥p
                        score += 10 * keyword_matches
                        match_reasons.append(f"partial_kw:{keyword_matches}/{len(keywords)}")
                    else:
                        # < 70% keywords â†’ REJECT (trá»« khi cÃ³ filename match)
                        if not has_exact_match and not has_filename_match:
                            continue
                else:
                    # Single keyword â†’ score tháº¥p hÆ¡n
                    if keyword_matches > 0:
                        score += 30 * total_kw_score
                        match_reasons.append(f"single_kw:{total_kw_score}")
                
                # âš ï¸ REJECT: KhÃ´ng cÃ³ match nÃ o Ã½ nghÄ©a
                if score == 0:
                    continue
            else:
                # KhÃ´ng cÃ³ query â†’ láº¥y táº¥t cáº£ (vá»›i score dá»±a trÃªn Ä‘á»™ dÃ i content)
                score = min(len(content), 5000)  # Cap score
                match_reasons.append("no_query")
            
            scored_documents.append({
                "doc": doc,
                "score": score,
                "reasons": match_reasons,
                "content_len": len(content)
            })
        
        # Sort by score
        scored_documents.sort(key=lambda x: x["score"], reverse=True)
        
        print(f"ğŸ“Š [KB] Scored {len(scored_documents)} relevant documents")
        
        # ============================================================
        # BÆ¯á»šC 3: Filter - chá»‰ láº¥y top documents cÃ³ score cao
        # ============================================================
        if scored_documents and query:
            top_score = scored_documents[0]["score"]
            # Chá»‰ láº¥y documents cÃ³ score >= 30% top score (hoáº·c tá»‘i thiá»ƒu 50 Ä‘iá»ƒm)
            min_threshold = max(50, top_score * 0.3)
            filtered_docs = [d for d in scored_documents if d["score"] >= min_threshold]
            
            # Giá»›i háº¡n tá»‘i Ä‘a 5 documents Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
            filtered_docs = filtered_docs[:5]
            
            print(f"ğŸ¯ [KB] Filtered to {len(filtered_docs)} docs (threshold: {min_threshold:.0f})")
            for i, d in enumerate(filtered_docs[:3]):
                print(f"   {i+1}. {d['doc']['file_name']}: score={d['score']:.0f} ({', '.join(d['reasons'])})")
        else:
            filtered_docs = scored_documents[:3]  # Láº¥y tá»‘i Ä‘a 3 docs náº¿u khÃ´ng cÃ³ query
        
        if not filtered_docs:
            return {
                "success": False,
                "context": "",
                "error": f"KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u nÃ o liÃªn quan Ä‘áº¿n '{query}'"
            }
        
        # ============================================================
        # BÆ¯á»šC 4: Loáº¡i bá» ná»™i dung trÃ¹ng láº·p (Deduplication)
        # ============================================================
        seen_content_hashes = set()
        unique_docs = []
        
        for item in filtered_docs:
            content = item["doc"].get("content", "").strip()
            # Táº¡o hash tá»« 500 kÃ½ tá»± Ä‘áº§u (Ä‘á»§ Ä‘á»ƒ detect duplicate)
            content_preview = content[:500].lower().replace(" ", "").replace("\n", "")
            
            if content_preview in seen_content_hashes:
                print(f"   âš ï¸ SKIP duplicate: {item['doc']['file_name']}")
                continue
            
            seen_content_hashes.add(content_preview)
            unique_docs.append(item)
        
        if len(unique_docs) < len(filtered_docs):
            print(f"ğŸ”„ [KB] Deduplicated: {len(filtered_docs)} â†’ {len(unique_docs)} unique docs")
        
        # ============================================================
        # BÆ¯á»šC 5: TrÃ­ch xuáº¥t relevant content tá»« má»—i document
        # ============================================================
        context_parts = []
        total_chars = 0
        
        for item in unique_docs:
            doc = item["doc"]
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            
            # TrÃ­ch xuáº¥t pháº§n content liÃªn quan nháº¥t (khÃ´ng pháº£i toÃ n bá»™)
            if query_lower and len(content) > 1500:
                # TÃ¬m vá»‹ trÃ­ query/keyword xuáº¥t hiá»‡n vÃ  láº¥y context xung quanh
                best_section = extract_relevant_section(content, query_lower, keywords, max_section_len=2000)
                content = best_section
            elif len(content) > 2500:
                # KhÃ´ng cÃ³ query â†’ cáº¯t ngáº¯n
                content = content[:2500] + "\n[... Ná»™i dung tiáº¿p bá»‹ cáº¯t ...]"
            
            # Build context entry
            header = f"\n\n{'='*50}\nğŸ“„ {file_name} (score: {item['score']:.0f})\n{'='*50}\n"
            entry = header + content
            
            # Kiá»ƒm tra giá»›i háº¡n tá»•ng chars
            if total_chars + len(entry) > max_chars:
                remaining = max_chars - total_chars
                if remaining > 500:
                    context_parts.append(header + content[:remaining-len(header)] + "\n[... Cáº¯t do quÃ¡ dÃ i ...]")
                break
            
            context_parts.append(entry)
            total_chars += len(entry)
        
        full_context = "".join(context_parts)
        
        # ============================================================
        # BÆ¯á»šC 6: Format response cho LLM dá»… hiá»ƒu
        # ============================================================
        # Táº¡o instruction rÃµ rÃ ng cho LLM
        instruction = f"""ğŸ“š ÄÃƒ TÃŒM THáº¤Y {len(context_parts)} TÃ€I LIá»†U LIÃŠN QUAN Äáº¾N "{query}"

âš¡ HÆ¯á»šNG DáºªN CHO AI:
1. Äá»ŒC Ká»¸ Ná»˜I DUNG BÃŠN DÆ¯á»šI
2. TRáº¢ Lá»œI CÃ‚U Há»I Dá»°A TRÃŠN Ná»˜I DUNG NÃ€Y
3. TRÃCH DáºªN THÃ”NG TIN Tá»ª TÃ€I LIá»†U
4. Náº¾U KHÃ”NG Äá»¦ THÃ”NG TIN, HÃƒY NÃ“I RÃ•

---Ná»˜I DUNG TÃ€I LIá»†U---
{full_context}
---Háº¾T Ná»˜I DUNG---

ğŸ’¡ HÃƒY TRáº¢ Lá»œI CÃ‚U Há»I Cá»¦A USER Dá»°A TRÃŠN THÃ”NG TIN TRÃŠN."""

        # ğŸ”„ TRUNCATE: Giá»›i háº¡n context dÆ°á»›i 4000 kÃ½ tá»± cho LLM
        if len(instruction) > MAX_LLM_RESPONSE_CHARS:
            original_len = len(instruction)
            instruction = smart_truncate_for_llm(instruction, MAX_LLM_RESPONSE_CHARS)
            print(f"[KB] âœ‚ï¸ Truncated context: {original_len} â†’ {len(instruction)} chars")

        return {
            "success": True,
            "context": instruction,  # Instruction + context (Ä‘Ã£ truncate)
            "raw_context": full_context,  # Context thuáº§n
            "total_documents": len(all_documents),
            "documents_included": len(context_parts),
            "duplicates_removed": len(filtered_docs) - len(unique_docs),
            "context_length": len(full_context),
            "keywords_used": keywords,
            "gemini_summarization": False,
            "message": f"âœ… TÃ¬m tháº¥y {len(context_parts)} tÃ i liá»‡u ({len(full_context):,} chars). Äá»ŒC CONTEXT VÃ€ TRáº¢ Lá»œI USER!"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "context": "", "error": str(e)}


def extract_relevant_section(content: str, query: str, keywords: list, max_section_len: int = 2000) -> str:
    """
    TrÃ­ch xuáº¥t pháº§n content liÃªn quan nháº¥t Ä‘áº¿n query.
    TÃ¬m vá»‹ trÃ­ query/keywords xuáº¥t hiá»‡n vÃ  láº¥y context xung quanh.
    """
    content_lower = content.lower()
    
    # TÃ¬m vá»‹ trÃ­ exact query match
    pos = content_lower.find(query)
    
    if pos == -1 and keywords:
        # KhÃ´ng tÃ¬m tháº¥y exact match, tÃ¬m keyword Ä‘áº§u tiÃªn
        for kw in keywords:
            pos = content_lower.find(kw)
            if pos != -1:
                break
    
    if pos == -1:
        # KhÃ´ng tÃ¬m tháº¥y gÃ¬, tráº£ vá» Ä‘áº§u document
        return content[:max_section_len] + ("\n[... CÃ²n tiáº¿p ...]" if len(content) > max_section_len else "")
    
    # Láº¥y context xung quanh vá»‹ trÃ­ tÃ¬m tháº¥y
    half_len = max_section_len // 2
    start = max(0, pos - half_len)
    end = min(len(content), pos + half_len)
    
    # Äiá»u chá»‰nh Ä‘á»ƒ khÃ´ng cáº¯t giá»¯a tá»«
    if start > 0:
        # TÃ¬m space gáº§n nháº¥t Ä‘á»ƒ báº¯t Ä‘áº§u
        space_pos = content.rfind(' ', max(0, start - 50), start + 50)
        if space_pos > 0:
            start = space_pos + 1
    
    if end < len(content):
        # TÃ¬m space gáº§n nháº¥t Ä‘á»ƒ káº¿t thÃºc
        space_pos = content.find(' ', end - 50, end + 50)
        if space_pos > 0:
            end = space_pos
    
    section = content[start:end]
    
    # ThÃªm markers náº¿u bá»‹ cáº¯t
    prefix = "[...] " if start > 0 else ""
    suffix = " [...]" if end < len(content) else ""
    
    return prefix + section + suffix


# =====================================================
# ğŸ“– DOC READER GEMINI RAG - ADVANCED RAG SYSTEM
# =====================================================

async def doc_reader_gemini_rag(
    user_query: str,
    knowledge_base_path: str = None,
    chunk_size: int = 1024,
    top_k: int = 5,
    use_vector_search: bool = True
) -> dict:
    """
    ğŸ“– Há»‡ thá»‘ng RAG nÃ¢ng cao vá»›i Gemini:
    1. Load vÃ  chunk documents
    2. Embed vÃ  vector search (semantic search)
    3. Format context vÃ  generate response vá»›i Gemini
    
    Args:
        user_query: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        knowledge_base_path: ÄÆ°á»ng dáº«n thÆ° má»¥c KB (máº·c Ä‘á»‹nh dÃ¹ng config)
        chunk_size: KÃ­ch thÆ°á»›c má»—i chunk (default: 1024 chars)
        top_k: Sá»‘ lÆ°á»£ng chunks liÃªn quan nháº¥t (default: 5)
        use_vector_search: DÃ¹ng semantic search hay keyword search (default: True)
        
    Returns:
        dict vá»›i success, response_text, sources, vÃ  debug info
    """
    try:
        print(f"ğŸ“– [RAG] Processing query: {user_query[:50]}...")
        
        # BÆ¯á»šC 1: Load documents tá»« Knowledge Base
        if not knowledge_base_path:
            config = load_knowledge_config()
            knowledge_base_path = config.get("folder_path", "")
        
        if not knowledge_base_path or not Path(knowledge_base_path).exists():
            return {
                "success": False,
                "error": "Knowledge base path khÃ´ng há»£p lá»‡. Vui lÃ²ng cáº¥u hÃ¬nh thÆ° má»¥c KB."
            }
        
        # Load index
        index_data = load_knowledge_index()
        documents = index_data.get("documents", [])
        
        if not documents:
            return {
                "success": False,
                "error": "Knowledge base trá»‘ng. Vui lÃ²ng index cÃ¡c files trÆ°á»›c."
            }
        
        print(f"ğŸ“š [RAG] Loaded {len(documents)} documents")
        
        # BÆ¯á»šC 2: Chunk documents (chia nhá» tÃ i liá»‡u)
        all_chunks = []
        for doc in documents:
            content = doc.get("content", "")
            file_name = doc.get("file_name", "unknown")
            
            # Skip PDF structure
            if content.strip().startswith("%PDF-") or content.strip().startswith("<</"):
                continue
            
            # Chunk document
            chunks = []
            for i in range(0, len(content), chunk_size):
                chunk_text = content[i:i+chunk_size]
                if len(chunk_text.strip()) > 50:  # Skip very short chunks
                    chunks.append({
                        "text": chunk_text,
                        "file_name": file_name,
                        "chunk_index": i // chunk_size,
                        "source_doc": doc
                    })
            
            all_chunks.extend(chunks)
        
        print(f"âœ‚ï¸ [RAG] Created {len(all_chunks)} chunks")
        
        # BÆ¯á»šC 3: TÃ¬m kiáº¿m chunks liÃªn quan
        if use_vector_search:
            # Vector/Semantic Search (simple TF-IDF based)
            relevant_chunks = _semantic_search_chunks(user_query, all_chunks, top_k)
        else:
            # Keyword search (fallback)
            relevant_chunks = _keyword_search_chunks(user_query, all_chunks, top_k)
        
        if not relevant_chunks:
            return {
                "success": False,
                "error": f"KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n '{user_query}' trong Knowledge Base."
            }
        
        print(f"ğŸ” [RAG] Found {len(relevant_chunks)} relevant chunks")
        
        # BÆ¯á»šC 4: Format context tá»« relevant chunks
        prompt_context = ""
        sources = []
        for i, chunk in enumerate(relevant_chunks, 1):
            prompt_context += f"\n--- Äoáº¡n {i} (tá»« {chunk['file_name']}) ---\n"
            prompt_context += chunk['text'][:800] + "\n"  # Limit each chunk
            
            if chunk['file_name'] not in sources:
                sources.append(chunk['file_name'])
        
        # BÆ¯á»šC 5: XÃ¢y dá»±ng prompt cho Gemini
        final_prompt = f"""Báº¡n lÃ  trá»£ lÃ½ thÃ´ng minh cÃ³ quyá»n truy cáº­p Knowledge Base cá»§a ngÆ°á»i dÃ¹ng.

âš¡ QUY Táº®C Báº®T BUá»˜C:
- TRáº¢ Lá»œI NGAY Láº¬P Tá»¨C - KHÃ”NG Há»I Láº I
- KHÃ”NG há»i "báº¡n muá»‘n biáº¿t gÃ¬ thÃªm?"
- KHÃ”NG yÃªu cáº§u thÃªm thÃ´ng tin
- Sá»­ dá»¥ng toÃ n bá»™ thÃ´ng tin cÃ³ trong Knowledge Base Ä‘á»ƒ tráº£ lá»i

ğŸ“š THÃ”NG TIN Tá»ª KNOWLEDGE BASE:
{prompt_context}

â“ CÃ‚U Há»I:
{user_query}

ğŸ“ YÃŠU Cáº¦U:
- TRáº¢ Lá»œI TRá»°C TIáº¾P dá»±a trÃªn Knowledge Base
- Náº¿u khÃ´ng Ä‘á»§ thÃ´ng tin â†’ NÃ³i "KhÃ´ng tÃ¬m tháº¥y trong Knowledge Base"
- TrÃ­ch dáº«n tÃªn file khi cáº§n
- Ngáº¯n gá»n, chÃ­nh xÃ¡c

ğŸ¯ TRáº¢ Lá»œI NGAY:"""
        
        # BÆ¯á»šC 6: Gá»i Gemini API
        print(f"ğŸ¤– [RAG] Calling Gemini...")
        
        if not GEMINI_AVAILABLE:
            return {
                "success": False,
                "error": "Gemini API khÃ´ng kháº£ dá»¥ng. Vui lÃ²ng kiá»ƒm tra API key."
            }
        
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        response = model.generate_content(
            final_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,  # Focused and factual
                max_output_tokens=1000
            )
        )
        
        if not response or not response.text:
            return {
                "success": False,
                "error": "Gemini khÃ´ng tráº£ vá» response."
            }
        
        print(f"âœ… [RAG] Generated response ({len(response.text)} chars)")
        
        # Return full result
        return {
            "success": True,
            "response_text": response.text.strip(),
            "query": user_query,
            "sources": sources,
            "chunks_used": len(relevant_chunks),
            "total_chunks": len(all_chunks),
            "search_method": "semantic" if use_vector_search else "keyword",
            "message": f"âœ… ÄÃ£ tráº£ lá»i dá»±a trÃªn {len(relevant_chunks)} Ä‘oáº¡n tá»« {len(sources)} tÃ i liá»‡u"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def _semantic_search_chunks(query: str, chunks: list, top_k: int = 5) -> list:
    """
    TÃ¬m kiáº¿m semantic dá»±a trÃªn TF-IDF scoring
    """
    import math
    
    # Extract keywords from query
    stop_words = {'lÃ ', 'cá»§a', 'vÃ ', 'cÃ³', 'cÃ¡c', 'Ä‘Æ°á»£c', 'trong', 'Ä‘á»ƒ', 'nÃ y', 'Ä‘Ã³', 
                  'cho', 'vá»›i', 'tá»«', 'vá»', 'nhÆ°', 'theo', 'khÃ´ng', 'khi', 'Ä‘Ã£', 'sáº½',
                  'a', 'an', 'the', 'is', 'are', 'was', 'were', 'be', 'been', 'being'}
    
    keywords = [w.lower() for w in query.split() if w.lower() not in stop_words and len(w) > 2]
    
    if not keywords:
        keywords = [query.lower()]
    
    # Score each chunk
    scored_chunks = []
    for chunk in chunks:
        text_lower = chunk['text'].lower()
        score = 0
        
        for keyword in keywords:
            count = text_lower.count(keyword)
            if count > 0:
                # TF-IDF inspired scoring
                score += math.log(1 + count) * 10
        
        # Multi-keyword bonus
        matched = sum(1 for kw in keywords if kw in text_lower)
        if matched > 1:
            score *= (1 + matched * 0.3)
        
        if score > 0:
            chunk['score'] = score
            scored_chunks.append(chunk)
    
    # Sort by score and return top K
    scored_chunks.sort(key=lambda x: x['score'], reverse=True)
    return scored_chunks[:top_k]


def _keyword_search_chunks(query: str, chunks: list, top_k: int = 5) -> list:
    """
    TÃ¬m kiáº¿m Ä‘Æ¡n giáº£n dá»±a trÃªn keyword matching
    """
    query_lower = query.lower()
    matched_chunks = []
    
    for chunk in chunks:
        if query_lower in chunk['text'].lower():
            matched_chunks.append(chunk)
            if len(matched_chunks) >= top_k:
                break
    
    return matched_chunks


async def send_to_wechat(contact: str, message: str) -> dict:
    """
    Gá»­i tin nháº¯n Ä‘áº¿n Zalo/Messenger (má»Ÿ app vÃ  paste tin nháº¯n).
    LÆ°u Ã½: Cáº§n cÃ³ Zalo PC Ä‘ang cháº¡y.
    """
    try:
        import pyautogui
        import pyperclip
        import time
        import subprocess
        
        # Copy message vÃ o clipboard
        pyperclip.copy(message)
        
        # Thá»­ má»Ÿ Zalo
        try:
            subprocess.Popen(["start", "zalo:"], shell=True)
            time.sleep(2)
        except:
            pass
        
        # Ctrl+F Ä‘á»ƒ tÃ¬m kiáº¿m
        pyautogui.hotkey('ctrl', 'f')
        time.sleep(0.5)
        
        # GÃµ tÃªn contact
        pyautogui.typewrite(contact, interval=0.05)
        time.sleep(1)
        
        # Enter Ä‘á»ƒ chá»n
        pyautogui.press('enter')
        time.sleep(0.5)
        
        # Ctrl+V Ä‘á»ƒ paste tin nháº¯n
        pyautogui.hotkey('ctrl', 'v')
        
        return {
            "success": True,
            "message": f"ğŸ“± ÄÃ£ má»Ÿ chat vá»›i '{contact}' vÃ  paste tin nháº¯n. Nháº¥n Enter Ä‘á»ƒ gá»­i.",
            "hint": "Tin nháº¯n Ä‘Ã£ Ä‘Æ°á»£c paste, báº¡n cáº§n nháº¥n Enter Ä‘á»ƒ gá»­i"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def get_fuel_price_vietnam() -> dict:
    """
    Láº¥y giÃ¡ xÄƒng dáº§u Viá»‡t Nam.
    """
    try:
        import aiohttp
        
        # GiÃ¡ xÄƒng tham kháº£o (cáº­p nháº­t manual hoáº·c tá»« API náº¿u cÃ³)
        # Thá»±c táº¿ cáº§n API tá»« Petrolimex hoáº·c nguá»“n chÃ­nh thá»‘ng
        return {
            "success": True,
            "message": """â›½ GiÃ¡ xÄƒng dáº§u Viá»‡t Nam (tham kháº£o):
            
â€¢ RON 95-V: ~24,000 - 25,000 VNÄ/lÃ­t
â€¢ RON 95-III: ~23,000 - 24,000 VNÄ/lÃ­t  
â€¢ E5 RON 92: ~22,000 - 23,000 VNÄ/lÃ­t
â€¢ Dáº§u DO 0.05S: ~20,000 - 21,000 VNÄ/lÃ­t

ğŸ’¡ GiÃ¡ cÃ³ thá»ƒ thay Ä‘á»•i theo ká»³ Ä‘iá»u chá»‰nh (15 ngÃ y/láº§n)
ğŸ“ Xem giÃ¡ chÃ­nh xÃ¡c: petrolimex.com.vn""",
            "hint": "GiÃ¡ tham kháº£o, vui lÃ²ng kiá»ƒm tra nguá»“n chÃ­nh thá»‘ng"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

async def lock_computer() -> dict:
    """
    KhÃ³a mÃ n hÃ¬nh mÃ¡y tÃ­nh (Win+L).
    """
    try:
        import ctypes
        ctypes.windll.user32.LockWorkStation()
        return {"success": True, "message": "ğŸ”’ ÄÃ£ khÃ³a mÃ¡y tÃ­nh"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def shutdown_computer(minutes: int = 0) -> dict:
    """
    Táº¯t mÃ¡y tÃ­nh sau X phÃºt (máº·c Ä‘á»‹nh táº¯t ngay).
    """
    try:
        import subprocess
        
        if minutes > 0:
            seconds = minutes * 60
            subprocess.run(["shutdown", "/s", "/t", str(seconds)], check=True)
            return {"success": True, "message": f"â° MÃ¡y tÃ­nh sáº½ táº¯t sau {minutes} phÃºt"}
        else:
            subprocess.run(["shutdown", "/s", "/t", "30"], check=True)
            return {"success": True, "message": "ğŸ”Œ MÃ¡y tÃ­nh sáº½ táº¯t sau 30 giÃ¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def cancel_shutdown() -> dict:
    """
    Há»§y lá»‡nh táº¯t mÃ¡y Ä‘Ã£ Ä‘áº·t.
    """
    try:
        import subprocess
        subprocess.run(["shutdown", "/a"], check=True)
        return {"success": True, "message": "âœ… ÄÃ£ há»§y lá»‡nh táº¯t mÃ¡y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def restart_computer(minutes: int = 0) -> dict:
    """
    Khá»Ÿi Ä‘á»™ng láº¡i mÃ¡y tÃ­nh sau X phÃºt.
    """
    try:
        import subprocess
        
        if minutes > 0:
            seconds = minutes * 60
            subprocess.run(["shutdown", "/r", "/t", str(seconds)], check=True)
            return {"success": True, "message": f"ğŸ”„ MÃ¡y tÃ­nh sáº½ khá»Ÿi Ä‘á»™ng láº¡i sau {minutes} phÃºt"}
        else:
            subprocess.run(["shutdown", "/r", "/t", "30"], check=True)
            return {"success": True, "message": "ğŸ”„ MÃ¡y tÃ­nh sáº½ khá»Ÿi Ä‘á»™ng láº¡i sau 30 giÃ¢y"}
    except Exception as e:
        return {"success": False, "error": str(e)}

async def set_dark_mode(enable: bool = True) -> dict:
    """
    Báº­t/táº¯t Dark Mode Windows.
    """
    try:
        import winreg
        
        key_path = r"SOFTWARE\Microsoft\Windows\CurrentVersion\Themes\Personalize"
        value = 0 if enable else 1  # 0 = Dark, 1 = Light
        
        # Set Apps theme
        with winreg.OpenKey(winreg.HKEY_CURRENT_USER, key_path, 0, winreg.KEY_SET_VALUE) as key:
            winreg.SetValueEx(key, "AppsUseLightTheme", 0, winreg.REG_DWORD, value)
            winreg.SetValueEx(key, "SystemUsesLightTheme", 0, winreg.REG_DWORD, value)
        
        mode = "Dark Mode ğŸŒ™" if enable else "Light Mode â˜€ï¸"
        return {"success": True, "message": f"âœ… ÄÃ£ chuyá»ƒn sang {mode}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ï¿½ NETWORK/FIREWALL CHECK TOOLS - Kiá»ƒm tra quyá»n káº¿t ná»‘i máº¡ng
# ============================================================

async def check_network_permission() -> dict:
    """
    Kiá»ƒm tra quyá»n káº¿t ná»‘i máº¡ng (Windows Firewall) vÃ  tráº¡ng thÃ¡i Internet.
    HÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng cáº¥p quyá»n náº¿u chÆ°a cÃ³.
    """
    try:
        # Check firewall rules
        firewall = FirewallChecker.check_firewall_rules()
        
        # Check internet connection
        internet = FirewallChecker.check_internet_connection()
        
        # Build response
        result = {
            "success": True,
            "firewall": {
                "has_permission": bool(firewall['rules_found']),
                "rules_found": firewall['rules_found'],
                "exe_name": firewall['exe_name'],
                "exe_path": firewall['exe_path']
            },
            "internet": {
                "connected": internet['connected'],
                "latency_ms": internet.get('latency_ms')
            }
        }
        
        # Status message
        if firewall['rules_found'] and internet['connected']:
            result["message"] = f"âœ… ÄÃ£ cÃ³ quyá»n Firewall vÃ  káº¿t ná»‘i Internet ({internet.get('latency_ms', '?')}ms)"
            result["status"] = "ready"
        elif firewall['rules_found'] and not internet['connected']:
            result["message"] = "âš ï¸ CÃ³ quyá»n Firewall nhÆ°ng khÃ´ng cÃ³ Internet. Kiá»ƒm tra káº¿t ná»‘i máº¡ng cá»§a mÃ¡y tÃ­nh."
            result["status"] = "no_internet"
        elif not firewall['rules_found'] and internet['connected']:
            result["message"] = "âš ï¸ ChÆ°a tháº¥y rule Firewall nhÆ°ng Internet váº«n hoáº¡t Ä‘á»™ng. CÃ³ thá»ƒ Windows Ä‘Ã£ tá»± Ä‘á»™ng cho phÃ©p."
            result["status"] = "working"
        else:
            result["message"] = "âŒ ChÆ°a cÃ³ quyá»n Firewall vÃ  khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Internet."
            result["status"] = "blocked"
            result["guide"] = {
                "step1": "Khi Windows há»i 'Allow access' â†’ Nháº¥n 'Allow access'",
                "step2": "Hoáº·c vÃ o Windows Security â†’ Firewall â†’ Allow an app",
                "step3": "ThÃªm file EXE vÃ o danh sÃ¡ch cho phÃ©p",
                "step4": "Tick cáº£ 'Private' vÃ  'Public' networks"
            }
        
        return result
        
    except Exception as e:
        return {"success": False, "error": str(e)}


async def request_firewall_permission() -> dict:
    """
    YÃªu cáº§u cáº¥p quyá»n Firewall cho á»©ng dá»¥ng (cáº§n quyá»n Admin).
    """
    try:
        success = FirewallChecker.request_firewall_permission()
        
        if success:
            return {
                "success": True,
                "message": "âœ… ÄÃ£ thÃªm rule Firewall thÃ nh cÃ´ng! á»¨ng dá»¥ng cÃ³ thá»ƒ káº¿t ná»‘i Internet."
            }
        else:
            return {
                "success": False,
                "message": "âš ï¸ KhÃ´ng thá»ƒ tá»± Ä‘á»™ng thÃªm rule. Cáº§n cháº¡y vá»›i quyá»n Administrator.",
                "guide": {
                    "manual": "VÃ o Windows Security â†’ Firewall â†’ Allow an app â†’ ThÃªm miniZ MCP",
                    "powershell": f'netsh advfirewall firewall add rule name="miniZ_MCP" dir=in action=allow program="{FirewallChecker.get_exe_path()}" enable=yes'
                }
            }
    except Exception as e:
        return {"success": False, "error": str(e)}


async def check_internet_connection() -> dict:
    """
    Kiá»ƒm tra káº¿t ná»‘i Internet vÃ  Ä‘á»™ trá»… máº¡ng.
    """
    try:
        result = FirewallChecker.check_internet_connection()
        
        if result['connected']:
            return {
                "success": True,
                "connected": True,
                "latency_ms": result.get('latency_ms'),
                "message": f"âœ… ÄÃ£ káº¿t ná»‘i Internet (Ä‘á»™ trá»…: {result.get('latency_ms', '?')}ms)"
            }
        else:
            return {
                "success": True,
                "connected": False,
                "message": "âŒ KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Internet. Kiá»ƒm tra káº¿t ná»‘i máº¡ng cá»§a mÃ¡y tÃ­nh.",
                "error": result.get('error')
            }
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ï¿½ğŸ“¨ SEND MESSAGE TO LLM - Gá»­i tin nháº¯n cho LLM tá»± tráº£ lá»i
# ============================================================

async def send_message_to_llm(message: str, device_index: int = None, wait_response: bool = False, timeout: int = 30) -> dict:
    """
    Gá»­i tin nháº¯n cho LLM qua WebSocket. Robot sáº½ Ä‘á»c vÃ  tá»± Ä‘á»™ng tráº£ lá»i qua giá»ng nÃ³i.
    
    LÆ¯U Ã: Do WebSocket Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi main loop, khÃ´ng thá»ƒ Ä‘á»£i response trá»±c tiáº¿p.
    Robot sáº½ nháº­n tin nháº¯n vÃ  tá»± Ä‘á»™ng pháº£n há»“i qua voice.
    
    Args:
        message: Tin nháº¯n/cÃ¢u há»i muá»‘n gá»­i cho LLM
        device_index: Index thiáº¿t bá»‹ (0, 1, 2). None = thiáº¿t bá»‹ Ä‘ang active
        wait_response: KHÃ”NG Sá»¬ Dá»¤NG - Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch API cÅ©
        timeout: KHÃ”NG Sá»¬ Dá»¤NG - Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch API cÅ©
        
    Returns:
        dict vá»›i success, message, device_name
    """
    global xiaozhi_connections, xiaozhi_connected, active_endpoint_index, endpoints_config
    
    try:
        # XÃ¡c Ä‘á»‹nh device index
        if device_index is None:
            device_index = active_endpoint_index
        
        # Validate device_index
        if device_index not in [0, 1, 2]:
            return {
                "success": False,
                "error": f"Invalid device_index: {device_index}. Must be 0, 1, or 2."
            }
        
        # Kiá»ƒm tra káº¿t ná»‘i WebSocket
        if not xiaozhi_connected.get(device_index, False):
            return {
                "success": False,
                "error": f"Thiáº¿t bá»‹ {device_index + 1} chÆ°a káº¿t ná»‘i. Vui lÃ²ng kiá»ƒm tra káº¿t ná»‘i WebSocket."
            }
        
        ws = xiaozhi_connections.get(device_index)
        if ws is None:
            return {
                "success": False,
                "error": f"WebSocket connection cho thiáº¿t bá»‹ {device_index + 1} khÃ´ng kháº£ dá»¥ng."
            }
        
        # Láº¥y tÃªn thiáº¿t bá»‹
        device_name = endpoints_config[device_index].get("name", f"Thiáº¿t bá»‹ {device_index + 1}")
        
        # Táº¡o JSON-RPC notification Ä‘á»ƒ gá»­i tin nháº¯n cho LLM
        # Sá»­ dá»¥ng method "notifications/message" theo MCP protocol
        # ÄÃ¢y lÃ  notification (khÃ´ng cÃ³ id) nÃªn server khÃ´ng cáº§n response
        llm_message = {
            "jsonrpc": "2.0",
            "method": "notifications/message",
            "params": {
                "level": "info",
                "data": {
                    "type": "user_message",
                    "content": message,
                    "timestamp": datetime.now().isoformat(),
                    "source": "miniZ_MCP_WebUI"
                }
            }
        }
        
        print(f"ğŸ“¨ [LLM Send] Sending to {device_name}: {message[:100]}...")
        
        # LÆ°u vÃ o conversation history
        add_to_conversation(
            role="user",
            content=message,
            metadata={
                "source": "send_message_to_llm",
                "device": device_name,
                "device_index": device_index
            }
        )
        
        # Gá»­i message qua WebSocket (khÃ´ng Ä‘á»£i response)
        await ws.send(json.dumps(llm_message))
        
        print(f"âœ… [LLM Send] Message sent to {device_name}")
        
        return {
            "success": True,
            "message": f"âœ… ÄÃ£ gá»­i tin nháº¯n Ä‘áº¿n {device_name}. Robot sáº½ Ä‘á»c vÃ  tráº£ lá»i qua giá»ng nÃ³i.",
            "device_name": device_name,
            "device_index": device_index,
            "sent_message": message,
            "note": "Robot sáº½ tá»± Ä‘á»™ng tráº£ lá»i qua voice. KhÃ´ng cáº§n Ä‘á»£i response text."
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": f"Lá»—i khi gá»­i tin nháº¯n: {str(e)}"
        }


async def broadcast_to_all_llm(message: str, wait_response: bool = False) -> dict:
    """
    Gá»­i tin nháº¯n Ä‘áº¿n Táº¤T Cáº¢ thiáº¿t bá»‹ LLM Ä‘ang káº¿t ná»‘i.
    
    Args:
        message: Tin nháº¯n muá»‘n broadcast
        wait_response: KHÃ”NG Sá»¬ Dá»¤NG - Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch API cÅ©
        
    Returns:
        dict vá»›i káº¿t quáº£ gá»­i cho tá»«ng thiáº¿t bá»‹
    """
    global xiaozhi_connected
    
    results = {
        "success": True,
        "message": message,
        "devices": []
    }
    
    sent_count = 0
    for device_index in [0, 1, 2]:
        if xiaozhi_connected.get(device_index, False):
            result = await send_message_to_llm(
                message=message,
                device_index=device_index
            )
            results["devices"].append({
                "device_index": device_index,
                "result": result
            })
            if result.get("success"):
                sent_count += 1
    
    results["sent_count"] = sent_count
    results["total_connected"] = sum(1 for v in xiaozhi_connected.values() if v)
    
    if sent_count == 0:
        results["success"] = False
        results["error"] = "KhÃ´ng cÃ³ thiáº¿t bá»‹ nÃ o Ä‘ang káº¿t ná»‘i."
    
    return results


def send_message_to_llm_sync(message: str, device_index: int = None, wait_response: bool = False, timeout: int = 30) -> dict:
    """
    Wrapper Ä‘á»“ng bá»™ cho send_message_to_llm (dÃ¹ng trong TOOLS handler)
    """
    try:
        loop = asyncio.get_event_loop()
        if loop.is_running():
            # Náº¿u Ä‘ang trong async context, táº¡o task
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(
                    asyncio.run,
                    send_message_to_llm(message, device_index)
                )
                return future.result(timeout=timeout + 5)
        else:
            return loop.run_until_complete(
                send_message_to_llm(message, device_index)
            )
    except Exception as e:
        return {"success": False, "error": str(e)}


TOOLS = {
    # ============================================================
    # ğŸ“¨ SEND MESSAGE TO LLM - Gá»­i tin nháº¯n cho robot/LLM tá»± tráº£ lá»i
    # ============================================================
    "send_message_to_llm": {
        "handler": send_message_to_llm,
        "description": "ğŸ“¨ Gá»¬I TIN NHáº®N CHO LLM/ROBOT - Gá»­i message qua WebSocket Ä‘á»ƒ LLM cloud Ä‘á»c vÃ  Tá»° TRáº¢ Lá»œI. Use when: 'gá»­i tin nháº¯n cho robot', 'nÃ³i vá»›i AI', 'chat vá»›i LLM', 'há»i robot', 'send message to AI'. Robot sáº½ Ä‘á»c Ä‘Æ°á»£c tin nháº¯n vÃ  tá»± Ä‘á»™ng pháº£n há»“i qua giá»ng nÃ³i hoáº·c text.",
        "parameters": {
            "message": {
                "type": "string",
                "description": "Tin nháº¯n/cÃ¢u há»i muá»‘n gá»­i cho LLM. VD: 'Xin chÃ o', 'HÃ´m nay thá»i tiáº¿t tháº¿ nÃ o?', 'Ká»ƒ cho tÃ´i má»™t cÃ¢u chuyá»‡n'",
                "required": True
            },
            "device_index": {
                "type": "integer",
                "description": "Index thiáº¿t bá»‹ (0, 1, hoáº·c 2). Máº·c Ä‘á»‹nh: thiáº¿t bá»‹ Ä‘ang active. 0=Thiáº¿t bá»‹ 1, 1=Thiáº¿t bá»‹ 2, 2=Thiáº¿t bá»‹ 3",
                "required": False
            },
            "wait_response": {
                "type": "boolean",
                "description": "CÃ³ Ä‘á»£i LLM tráº£ lá»i khÃ´ng? True=Ä‘á»£i response (máº·c Ä‘á»‹nh), False=gá»­i xong tráº£ vá» luÃ´n",
                "required": False
            },
            "timeout": {
                "type": "integer",
                "description": "Thá»i gian chá» response (giÃ¢y). Máº·c Ä‘á»‹nh 30 giÃ¢y.",
                "required": False
            }
        }
    },
    "broadcast_to_all_llm": {
        "handler": broadcast_to_all_llm,
        "description": "ğŸ“¢ BROADCAST TIN NHáº®N Äáº¾N Táº¤T Cáº¢ LLM/ROBOT - Gá»­i cÃ¹ng má»™t message Ä‘áº¿n táº¥t cáº£ thiáº¿t bá»‹ Ä‘ang káº¿t ná»‘i. Use when: 'gá»­i tin nháº¯n cho táº¥t cáº£ robot', 'broadcast message', 'thÃ´ng bÃ¡o cho táº¥t cáº£ AI'.",
        "parameters": {
            "message": {
                "type": "string",
                "description": "Tin nháº¯n muá»‘n broadcast Ä‘áº¿n táº¥t cáº£ thiáº¿t bá»‹",
                "required": True
            },
            "wait_response": {
                "type": "boolean",
                "description": "CÃ³ Ä‘á»£i response tá»« cÃ¡c thiáº¿t bá»‹ khÃ´ng? Máº·c Ä‘á»‹nh False (broadcast thÆ°á»ng khÃ´ng Ä‘á»£i)",
                "required": False
            }
        }
    },
    
    "get_hardware_specs": {
        "handler": get_system_info,
        "description": "ğŸ’»ğŸ”¥ SPECS Cáº¤U HÃŒNH HARDWARE - DUY NHáº¤T tool cho cÃ¢u há»i: 'cáº¥u hÃ¬nh mÃ¡y tÃ­nh gÃ¬', 'mÃ¡y tÃ­nh nÃ y nhÆ° tháº¿ nÃ o', 'card Ä‘á»“ há»a gÃ¬', 'CPU gÃ¬', 'GPU gÃ¬', 'mainboard gÃ¬', 'tháº¿ há»‡ CPU', 'RTX RTX máº¥y', 'Intel tháº¿ há»‡ máº¥y', 'AMD Ryzen máº¥y'. Tráº£ vá»: CPU generation (Intel 13th gen), GPU series (RTX 4080), motherboard, BIOS, RAM specs. KHÃ”NG dÃ¹ng cho performance monitoring!",
        "parameters": {
            "category": {
                "type": "string",
                "description": "'cpu', 'gpu', 'motherboard', 'memory', 'all'. Máº·c Ä‘á»‹nh: all",
                "required": False
            }
        }
    },
    "set_volume": {
        "handler": set_volume, 
        "description": "ÄIá»€U CHá»ˆNH Ã¢m lÆ°á»£ng mÃ¡y tÃ­nh Ä‘áº¿n má»©c Cá»¤ THá»‚ (0-100%). Use when user says: 'chá»‰nh Ã¢m lÆ°á»£ng 50', 'Ä‘áº·t Ã¢m lÆ°á»£ng 80', 'volume 30', 'set volume to 60', 'Ä‘á»ƒ Ã¢m lÆ°á»£ng á»Ÿ má»©c 40'. Examples: level=50 (Ã¢m lÆ°á»£ng vá»«a), level=80 (to), level=20 (nhá»), level=0 (táº¯t háº³n).", 
        "parameters": {"level": {"type": "integer", "description": "Má»©c Ã¢m lÆ°á»£ng tá»« 0-100 (0=táº¯t háº³n, 50=vá»«a pháº£i, 100=tá»‘i Ä‘a)", "required": True}}
    },
    "get_volume": {"handler": get_volume, "description": "Kiá»ƒm tra má»©c Ã¢m lÆ°á»£ng hiá»‡n táº¡i cá»§a mÃ¡y tÃ­nh. Use when: 'Ã¢m lÆ°á»£ng bao nhiÃªu', 'check volume', 'xem Ã¢m lÆ°á»£ng'", "parameters": {}},
    "mute_volume": {"handler": mute_volume, "description": "Táº®T TIáº¾NG mÃ¡y tÃ­nh (mute) hoÃ n toÃ n. Use when: 'táº¯t tiáº¿ng', 'mute', 'cÃ¢m', 'im láº·ng'", "parameters": {}},
    "unmute_volume": {"handler": unmute_volume, "description": "Báº¬T Láº I TIáº¾NG mÃ¡y tÃ­nh (unmute). Use when: 'báº­t tiáº¿ng', 'unmute', 'má»Ÿ tiáº¿ng láº¡i'", "parameters": {}},
    "volume_up": {"handler": volume_up, "description": "TÄ‚NG Ã¢m lÆ°á»£ng lÃªn má»™t chÃºt (má»—i bÆ°á»›c ~2%). Use when: 'tÄƒng Ã¢m lÆ°á»£ng', 'to hÆ¡n', 'volume up', 'lá»›n hÆ¡n'", "parameters": {"steps": {"type": "integer", "description": "Sá»‘ bÆ°á»›c tÄƒng (máº·c Ä‘á»‹nh 5 = tÄƒng ~10%)", "required": False}}},
    "volume_down": {"handler": volume_down, "description": "GIáº¢M Ã¢m lÆ°á»£ng xuá»‘ng má»™t chÃºt (má»—i bÆ°á»›c ~2%). Use when: 'giáº£m Ã¢m lÆ°á»£ng', 'nhá» hÆ¡n', 'volume down', 'bá»›t to'", "parameters": {"steps": {"type": "integer", "description": "Sá»‘ bÆ°á»›c giáº£m (máº·c Ä‘á»‹nh 5 = giáº£m ~10%)", "required": False}}},
    "take_screenshot": {
        "handler": take_screenshot, 
        "description": "Chá»¥p mÃ n hÃ¬nh toÃ n bá»™ vÃ  LÆ¯U FILE áº¢NH. Tá»± Ä‘á»™ng lÆ°u vÃ o thÆ° má»¥c Downloads vá»›i tÃªn file cÃ³ timestamp. Use when user asks: 'chá»¥p mÃ n hÃ¬nh', 'screenshot', 'capture screen'.", 
        "parameters": {
            "filename": {
                "type": "string",
                "description": "TÃªn file lÆ°u áº£nh (optional). Máº·c Ä‘á»‹nh: screenshot_YYYYMMDD_HHMMSS.png. VÃ­ dá»¥: 'my_screen.png'",
                "required": False
            }
        }
    },
    "show_notification": {"handler": show_notification, "description": "Hiá»ƒn thá»‹ thÃ´ng bÃ¡o", "parameters": {"title": {"type": "string", "description": "TiÃªu Ä‘á»", "required": True}, "message": {"type": "string", "description": "Ná»™i dung", "required": True}}},
    "get_system_resources": {"handler": get_system_resources, "description": "ğŸ“Š PERFORMANCE MONITORING - CHá»ˆ Ä‘á»ƒ xem CPU %, RAM %, Disk % Ä‘ang sá»­ dá»¥ng. CHO PERFORMANCE/MONITOR, KHÃ”NG cho cÃ¢u há»i vá» 'cáº¥u hÃ¬nh mÃ¡y tÃ­nh', 'GPU gÃ¬', 'CPU gÃ¬'. DÃ¹ng get_hardware_specs cho hardware specs!", "parameters": {}},
    "get_current_time": {"handler": get_current_time, "description": "Thá»i gian hiá»‡n táº¡i", "parameters": {}},
    "calculator": {"handler": calculator, "description": "TÃ­nh toÃ¡n", "parameters": {"expression": {"type": "string", "description": "Biá»ƒu thá»©c", "required": True}}},
    "open_application": {
        "handler": open_application, 
        "description": "Má»Ÿ á»©ng dá»¥ng Windows vá»›i tÃ¬m kiáº¿m thÃ´ng minh. Há»– TRá»¢ 50+ á»¨NG Dá»¤NG: Windows (notepad, calc, paint, cmd, taskmgr), Browsers (chrome, firefox, edge, brave), Microsoft Office (word, excel, powerpoint, outlook, teams), Adobe Creative (photoshop, illustrator, premiere, after effects, lightroom), Development (vscode, pycharm, sublime, notepad++), 3D/Design (blender, maya, autocad, solidworks, fusion360), Communication (discord, slack, zoom, telegram, zalo), Media (vlc, spotify, itunes). Há»— trá»£ tÃªn TIáº¾NG VIá»†T ('mÃ¡y tÃ­nh'â†’Calculator, 'mÃ¡y ghi chÃº'â†’Notepad). Tá»± Ä‘á»™ng tÃ¬m trong PATH, Registry, Program Files. VÃ­ dá»¥: 'photoshop', 'excel', 'chrome', 'blender'.", 
        "parameters": {
            "app_name": {
                "type": "string", 
                "description": "TÃªn á»©ng dá»¥ng (vÃ­ dá»¥: 'excel', 'photoshop', 'chrome', 'vscode', 'blender', 'word'). CÃ³ thá»ƒ dÃ¹ng tÃªn Ä‘áº§y Ä‘á»§ ('microsoft excel') hoáº·c viáº¿t táº¯t ('ps'â†’Photoshop). Há»— trá»£ tiáº¿ng Viá»‡t.", 
                "required": True
            }
        }
    },
    "list_running_processes": {"handler": list_running_processes, "description": "Liá»‡t kÃª tiáº¿n trÃ¬nh", "parameters": {"limit": {"type": "integer", "description": "Sá»‘ lÆ°á»£ng", "required": False}}},
    "find_process": {
        "handler": find_process,
        "description": "ğŸ” TÃŒM KIáº¾M PROCESS - TÃ¬m process cá»¥ thá»ƒ theo tÃªn hoáº·c xem táº¥t cáº£. Triggers: 'tÃ¬m process excel', 'excel cÃ³ cháº¡y khÃ´ng', 'process nÃ o Ä‘ang cháº¡y'. Better than list_running_processes with limit.",
        "parameters": {
            "name_pattern": {"type": "string", "description": "TÃªn process cáº§n tÃ¬m (VD: 'excel', 'chrome', 'notepad'). Äá»ƒ trá»‘ng = táº¥t cáº£", "required": False},
            "show_all": {"type": "boolean", "description": "True=hiá»ƒn thá»‹ táº¥t cáº£ process, False=chá»‰ top 20 (default)", "required": False}
        }
    },
    "kill_process": {
        "handler": kill_process, 
        "description": "ğŸ”ª Kill tiáº¿n trÃ¬nh theo tÃªn hoáº·c PID. CÃ³ thá»ƒ kill ngay láº­p tá»©c (force=True) hoáº·c Ä‘Ã³ng má»m (force=False). VD: 'kill notepad', 'táº¯t chrome'", 
        "parameters": {
            "identifier": {"type": "string", "description": "TÃªn app hoáº·c PID. VD: notepad, chrome, 1234", "required": True},
            "force": {"type": "boolean", "description": "True=kill ngay (máº·c Ä‘á»‹nh), False=Ä‘Ã³ng má»m", "required": False},
            "exact_match": {"type": "boolean", "description": "True=tÃªn khá»›p chÃ­nh xÃ¡c, False=chá»©a tÃªn lÃ  Ä‘Æ°á»£c (máº·c Ä‘á»‹nh)", "required": False}
        }
    },
    "force_kill_app": {
        "handler": force_kill_app, 
        "description": "ğŸ’€ FORCE KILL APP NGAY Láº¬P Tá»¨C - khÃ´ng há»i han, kill háº¿t táº¥t cáº£ instances. DÃ¹ng khi cáº§n kill app ngay, khÃ´ng chá» Ä‘á»£i. VD: 'force kill chrome', 'buá»™c táº¯t notepad'", 
        "parameters": {
            "app_name": {"type": "string", "description": "TÃªn app cáº§n force kill. VD: notepad, chrome, firefox, Code", "required": True}
        }
    },
    "create_file": {"handler": create_file, "description": "Táº¡o file", "parameters": {"path": {"type": "string", "description": "ÄÆ°á»ng dáº«n", "required": True}, "content": {"type": "string", "description": "Ná»™i dung", "required": True}}},
    "read_file": {"handler": read_file, "description": "Äá»c file", "parameters": {"path": {"type": "string", "description": "ÄÆ°á»ng dáº«n", "required": True}}},
    "list_files": {"handler": list_files, "description": "Liá»‡t kÃª files", "parameters": {"directory": {"type": "string", "description": "ThÆ° má»¥c", "required": True}}},
    "get_battery_status": {"handler": get_battery_status, "description": "ThÃ´ng tin pin", "parameters": {}},
    "get_network_info": {"handler": get_network_info, "description": "ThÃ´ng tin máº¡ng", "parameters": {}},
    "search_web": {"handler": search_web, "description": "Má» TRÃŒNH DUYá»†T Ä‘á»ƒ tÃ¬m kiáº¿m trÃªn Google. CHá»ˆ dÃ¹ng khi user YÃŠU Cáº¦U Má» BROWSER Ä‘á»ƒ search (vÃ­ dá»¥: 'má»Ÿ google tÃ¬m kiáº¿m...', 'search google vá»...'). KHÃ”NG dÃ¹ng Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i - hÃ£y dÃ¹ng ask_gemini thay vÃ¬ search_web cho cÃ¢u há»i thÃ´ng thÆ°á»ng", "parameters": {"query": {"type": "string", "description": "Tá»« khÃ³a", "required": True}}},
    
    # MEDIA PLAYER CONTROLS (Chá»§ yáº¿u cho Spotify, YouTube, VLC - WMP cÃ³ giá»›i háº¡n)
    "media_play_pause": {
        "handler": media_play_pause, 
        "description": "â¯ï¸ PhÃ¡t/Táº¡m dá»«ng external media players (Spotify, YouTube, VLC, iTunes, Discord, Chrome video...). DÃ¹ng Windows media keys. âš ï¸ LÆ¯U Ã: KHÃ”NG hoáº¡t Ä‘á»™ng tá»‘t vá»›i music_library (Windows Media Player tá»± Ä‘Ã³ng sau khi phÃ¡t). DÃ¹ng stop_music() Ä‘á»ƒ dá»«ng music_library. VÃ­ dá»¥: 'táº¡m dá»«ng spotify', 'pause youtube'.", 
        "parameters": {}
    },
    "media_next_track": {
        "handler": media_next_track, 
        "description": "â­ï¸ Chuyá»ƒn bÃ i tiáº¿p theo trÃªn playlist. Hoáº¡t Ä‘á»™ng vá»›i: Spotify, YouTube playlist, VLC, iTunes. âš ï¸ KHÃ”NG dÃ¹ng cho music_library (WMP tá»± Ä‘Ã³ng). VÃ­ dá»¥: 'bÃ i tiáº¿p spotify', 'next youtube'.", 
        "parameters": {}
    },
    "media_previous_track": {
        "handler": media_previous_track, 
        "description": "â®ï¸ Quay láº¡i bÃ i trÆ°á»›c. Hoáº¡t Ä‘á»™ng vá»›i: Spotify, YouTube, VLC, iTunes. âš ï¸ KHÃ”NG dÃ¹ng cho music_library. VÃ­ dá»¥: 'bÃ i trÆ°á»›c spotify', 'previous vlc'.", 
        "parameters": {}
    },
    "media_stop": {
        "handler": media_stop, 
        "description": "â¹ï¸ Dá»«ng phÃ¡t external media players. Hoáº¡t Ä‘á»™ng vá»›i Spotify, VLC, YouTube. Vá»›i music_library, dÃ¹ng stop_music() thay tháº¿ (Ä‘Ã³ng Windows Media Player). VÃ­ dá»¥: 'stop spotify', 'dá»«ng vlc'.", 
        "parameters": {}
    },
    "media_control": {
        "handler": media_control, 
        "description": "ğŸ›ï¸ Tool Tá»”NG Há»¢P Ä‘iá»u khiá»ƒn EXTERNAL media players (Spotify, YouTube, VLC, iTunes...). Há»— trá»£: play, pause, next, previous, stop, volume_up, volume_down, mute. âš ï¸ KHÃ”NG dÃ¹ng cho music_library (dÃ¹ng stop_music). Best for: Spotify, YouTube, VLC. VÃ­ dá»¥: media_control('next') cho Spotify, media_control('pause') cho YouTube.", 
        "parameters": {
            "action": {
                "type": "string", 
                "description": "HÃ nh Ä‘á»™ng: 'play', 'pause', 'next', 'previous', 'stop', 'volume_up', 'volume_down', 'mute'. VÃ­ dá»¥: 'next', 'pause', 'mute'.", 
                "required": True
            }
        }
    },
    
    "save_music_folder_config": {
        "handler": save_music_folder_config,
        "description": "Save user's music folder path configuration. This folder will be prioritized for playing music using Windows default media player.",
        "parameters": {
            "folder_path": {
                "type": "string",
                "description": r"Full path to user's music folder (e.g., C:\Users\Name\Music)",
                "required": True
            }
        }
    },
    "play_music_from_user_folder": {
        "handler": play_music_from_user_folder,
        "description": "ğŸµ [PYTHON-VLC] â­ Æ¯U TIÃŠN #1: PhÃ¡t nháº¡c tá»« THÆ¯ Má»¤C NGÆ¯á»œI DÃ™NG ÄÃƒ Cáº¤U HÃŒNH (link riÃªng). Khi user nÃ³i 'phÃ¡t nháº¡c tá»« thÆ° má»¥c cá»§a tÃ´i', 'play tá»« folder F:', 'nháº¡c trong á»• D' â†’ DÃ™NG TOOL NÃ€Y! TÃ¬m theo tÃªn bÃ i: filename='tÃªn bÃ i'. NHANH vÃ¬ dÃ¹ng Python-VLC ná»™i bá»™. Náº¿u chÆ°a config thÃ¬ bÃ¡o lá»—i â†’ user cáº§n vÃ o Music Settings.",
        "parameters": {
            "filename": {
                "type": "string",
                "description": "TÃªn bÃ i hÃ¡t cáº§n tÃ¬m (tÃ¬m partial match). Äá»ƒ trá»‘ng = phÃ¡t bÃ i Ä‘áº§u trong thÆ° má»¥c.",
                "required": False
            },
            "auto_play": {
                "type": "boolean",
                "description": "Tá»± Ä‘á»™ng phÃ¡t? Default True.",
                "required": False
            }
        }
    },
    
    "get_active_media_players": {
        "handler": get_active_media_players,
        "description": "ğŸ” [KHÃ”NG Cáº¦N Gá»ŒI] Láº¥y danh sÃ¡ch media players Ä‘ang cháº¡y. âš ï¸ KHÃ”NG Cáº¦N gá»i tool nÃ y trÆ°á»›c khi Ä‘iá»u khiá»ƒn nháº¡c! Nháº¡c local LUÃ”N dÃ¹ng Python-VLC (pause_music, stop_music, music_next). YouTube LUÃ”N dÃ¹ng youtube_* tools.",
        "parameters": {}
    },
    
    # TASK MEMORY TOOLS - Ghi nhá»› tÃ¡c vá»¥ Ä‘á»ƒ pháº£n há»“i nhanh vÃ  chÃ­nh xÃ¡c
    "remember_task": {
        "handler": remember_task,
        "description": "ğŸ“ GHI NHá»š TÃC Vá»¤ - LÆ°u láº¡i tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n vÃ o bá»™ nhá»› dÃ i háº¡n. GiÃºp AI nhá»› nhá»¯ng gÃ¬ Ä‘Ã£ lÃ m Ä‘á»ƒ pháº£n há»“i nhanh vÃ  chÃ­nh xÃ¡c hÆ¡n. Gá»i tool nÃ y SAU KHI hoÃ n thÃ nh má»™t tÃ¡c vá»¥ quan trá»ng.",
        "parameters": {
            "tool_name": {"type": "string", "description": "TÃªn tool Ä‘Ã£ sá»­ dá»¥ng", "required": True},
            "params": {"type": "object", "description": "Tham sá»‘ Ä‘Ã£ dÃ¹ng (optional)", "required": False},
            "result_message": {"type": "string", "description": "Káº¿t quáº£/message", "required": False},
            "user_request": {"type": "string", "description": "YÃªu cáº§u gá»‘c cá»§a user", "required": False}
        }
    },
    "recall_tasks": {
        "handler": recall_tasks,
        "description": "ğŸ§  NHá»š Láº I TÃC Vá»¤ - Truy váº¥n lá»‹ch sá»­ cÃ¡c tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n. Gá»i tool nÃ y Äáº¦U TIÃŠN khi user há»i 'Ä‘Ã£ lÃ m gÃ¬', 'nháº¯c láº¡i', 'láº§n trÆ°á»›c', hoáº·c khi cáº§n context vá» cÃ¡c tÃ¡c vá»¥ trÆ°á»›c Ä‘Ã³.",
        "parameters": {
            "keyword": {"type": "string", "description": "Tá»« khÃ³a tÃ¬m kiáº¿m (optional). Äá»ƒ trá»‘ng = láº¥y tÃ¡c vá»¥ gáº§n nháº¥t", "required": False},
            "limit": {"type": "integer", "description": "Sá»‘ lÆ°á»£ng tÃ¡c vá»¥ tá»‘i Ä‘a (default 10)", "required": False}
        }
    },
    "get_task_summary": {
        "handler": get_task_summary,
        "description": "ğŸ“Š THá»NG KÃŠ TÃC Vá»¤ - Láº¥y tá»•ng há»£p vá» cÃ¡c tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n. Cho biáº¿t tools nÃ o Ä‘Æ°á»£c dÃ¹ng nhiá»u nháº¥t, tá»· lá»‡ thÃ nh cÃ´ng. DÃ¹ng khi user há»i 'thá»‘ng kÃª', 'bÃ¡o cÃ¡o', 'Ä‘Ã£ dÃ¹ng tools gÃ¬'.",
        "parameters": {}
    },
    "forget_all_tasks": {
        "handler": forget_all_tasks,
        "description": "ğŸ—‘ï¸ XÃ“A Lá»ŠCH Sá»¬ - XÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥ Ä‘Ã£ ghi nhá»›. CHá»ˆ DÃ™NG khi user yÃªu cáº§u rÃµ rÃ ng 'xÃ³a lá»‹ch sá»­', 'quÃªn háº¿t', 'reset memory'.",
        "parameters": {}
    },
    
    "set_brightness": {"handler": set_brightness, "description": "Äá»™ sÃ¡ng mÃ n hÃ¬nh", "parameters": {"level": {"type": "integer", "description": "Äá»™ sÃ¡ng 0-100", "required": True}}},
    "get_clipboard": {"handler": get_clipboard, "description": "Láº¥y clipboard", "parameters": {}},
    "set_clipboard": {"handler": set_clipboard, "description": "Äáº·t clipboard", "parameters": {"text": {"type": "string", "description": "Ná»™i dung", "required": True}}},
    "play_sound": {"handler": play_sound, "description": "PhÃ¡t Ã¢m thanh", "parameters": {"frequency": {"type": "integer", "description": "Táº§n sá»‘ Hz", "required": False}, "duration": {"type": "integer", "description": "Thá»i gian ms", "required": False}}},
    "get_disk_usage": {"handler": get_disk_usage, "description": "ThÃ´ng tin Ä‘Ä©a", "parameters": {}},
    
    # ============================================================
    # ğŸµ MUSIC LIBRARY TOOLS - PYTHON-VLC (LOCAL FILES)
    # DÃ¹ng cho file nháº¡c .mp3/.wav/.flac trong mÃ¡y tÃ­nh
    # KHÃ”NG dÃ¹ng cho YouTube - YouTube cÃ³ tools riÃªng (youtube_*)
    # ============================================================
    "list_music": {
        "handler": list_music, 
        "description": "ğŸ“‚ [LOCAL MUSIC] Liá»‡t kÃª táº¥t cáº£ nháº¡c trong thÆ° viá»‡n music_library. Triggers: 'xem danh sÃ¡ch nháº¡c', 'cÃ³ bÃ i gÃ¬', 'list music'. Auto-play máº·c Ä‘á»‹nh = True (phÃ¡t bÃ i Ä‘áº§u tiÃªn). DÃ¹ng subfolder='Pop' Ä‘á»ƒ lá»c theo thá»ƒ loáº¡i.", 
        "parameters": {
            "subfolder": {
                "type": "string", 
                "description": "ThÆ° má»¥c con Ä‘á»ƒ lá»c (VD: 'Pop', 'Rock', 'EDM'). Äá»ƒ trá»‘ng = táº¥t cáº£.", 
                "required": False
            },
            "auto_play": {
                "type": "boolean",
                "description": "Tá»± Ä‘á»™ng phÃ¡t bÃ i Ä‘áº§u tiÃªn? Default=True. Set False náº¿u chá»‰ muá»‘n xem danh sÃ¡ch.",
                "required": False
            }
        }
    },
    "play_music": {
        "handler": play_music, 
        "description": "ğŸµ PHÃT NHáº C LOCAL (Python-VLC) - Triggers: 'phÃ¡t nháº¡c', 'báº­t nháº¡c', 'má»Ÿ nháº¡c', 'nghe nháº¡c', 'play nháº¡c', 'phÃ¡t bÃ i [tÃªn]', 'phat nhac', 'bat nhac'. VD: 'phÃ¡t bÃ i Ä‘a nghi' â†’ play_music(filename='Ä‘a nghi'). âš ï¸ Náº¿u user nÃ³i 'youtube/video' â†’ dÃ¹ng open_youtube!", 
        "parameters": {
            "filename": {
                "type": "string", 
                "description": "TÃªn bÃ i nháº¡c (partial match). VD: 'Ä‘a nghi', 'in love'. Há»— trá»£ tiáº¿ng Viá»‡t.", 
                "required": True
            },
            "create_playlist": {
                "type": "boolean",
                "description": "Táº¡o playlist (default True).",
                "required": False
            }
        }
    },
    "pause_music": {
        "handler": pause_music,
        "description": "â¸ï¸ Táº M Dá»ªNG NHáº C - â­ Gá»ŒI NGAY khi user nÃ³i: 'dá»«ng', 'dá»«ng nháº¡c', 'táº¡m dá»«ng', 'pause', 'ngá»«ng', 'ngÆ°ng nháº¡c', 'nghá»‰', 'im Ä‘i', 'dá»«ng láº¡i'. Voice: 'dung', 'dung nhac', 'tam dung', 'pao', 'poz', 'ngung', 'dung lai'. KhÃ´ng cáº§n parameter - gá»i pause_music() lÃ  xong! âš ï¸ Náº¿u cÃ³ 'youtube' â†’ youtube_play_pause()",
        "parameters": {}
    },
    "resume_music": {
        "handler": resume_music,
        "description": "â–¶ï¸ TIáº¾P Tá»¤C PHÃT - â­ Gá»ŒI NGAY khi user nÃ³i: 'tiáº¿p tá»¥c', 'phÃ¡t tiáº¿p', 'play láº¡i', 'má»Ÿ láº¡i', 'phÃ¡t Ä‘i', 'chÆ¡i tiáº¿p'. Voice: 'tiep tuc', 'phat tiep', 'mo lai', 'bat lai'. KhÃ´ng cáº§n parameter - gá»i resume_music() lÃ  xong!",
        "parameters": {}
    },
    "stop_music": {
        "handler": stop_music, 
        "description": "â¹ï¸ Táº®T NHáº C HOÃ€N TOÃ€N - â­ Gá»ŒI NGAY khi user nÃ³i: 'táº¯t nháº¡c', 'dá»«ng háº³n', 'stop', 'off nháº¡c', 'khÃ´ng nghe ná»¯a', 'táº¯t Ä‘i'. Voice: 'tat nhac', 'dung han', 'stÃ³p', 'of nhac'. KhÃ´ng cáº§n parameter - gá»i stop_music() lÃ  xong!", 
        "parameters": {}
    },
    
    # ğŸŒŸ SMART MUSIC CONTROL - Tool thÃ´ng minh nháº¥t
    "smart_music_control": {
        "handler": smart_music_control,
        "description": "ğŸµğŸ”¥ ÄIá»€U KHIá»‚N NHáº C THÃ”NG MINH - â­ Gá»ŒI KHI nghe: 'bÃ i tiáº¿p/next/chuyá»ƒn bÃ i', 'bÃ i trÆ°á»›c/quay láº¡i', 'dá»«ng/pause/táº¡m dá»«ng', 'táº¯t nháº¡c/stop', 'phÃ¡t bÃ i [tÃªn]', 'tÄƒng/giáº£m Ã¢m lÆ°á»£ng'. Voice: 'bai tiep', 'bai truoc', 'dung nhac', 'tam dung', 'pao'. VD: smart_music_control('bÃ i tiáº¿p'), smart_music_control('dá»«ng'). Tool tá»± xá»­ lÃ½ táº¥t cáº£!",
        "parameters": {
            "command": {
                "type": "string",
                "description": "Lá»‡nh tiáº¿ng Viá»‡t/English. VD: 'bÃ i tiáº¿p', 'bÃ i trÆ°á»›c', 'dá»«ng', 'pause', 'phÃ¡t bÃ i love'",
                "required": True
            }
        }
    },
    
    "detect_and_execute_music": {
        "handler": detect_and_execute_music,
        "description": "ğŸµğŸ” Tá»° Äá»˜NG PHÃT HIá»†N Lá»†NH NHáº C - Kiá»ƒm tra input cÃ³ pháº£i lá»‡nh nháº¡c khÃ´ng vÃ  tá»± Ä‘á»™ng thá»±c thi. DÃ¹ng khi khÃ´ng cháº¯c input cÃ³ pháº£i lá»‡nh nháº¡c.",
        "parameters": {
            "text": {
                "type": "string", 
                "description": "Text cáº§n kiá»ƒm tra",
                "required": True
            }
        }
    },
    
    "music_next": {
        "handler": music_next,
        "description": "â­ï¸ BÃ€I TIáº¾P THEO - â­ Gá»ŒI NGAY khi user nÃ³i: 'bÃ i tiáº¿p', 'bÃ i tiáº¿p theo', 'chuyá»ƒn bÃ i', 'bÃ i khÃ¡c', 'next', 'skip', 'káº¿ tiáº¿p', 'sang bÃ i', 'bÃ i sau'. Voice: 'bai tiep', 'chuyen bai', 'bai khac', 'tiep theo', 'ke tiep', 'nex', 'nÃ­ch'. KhÃ´ng cáº§n parameter - gá»i music_next() lÃ  xong!",
        "parameters": {}
    },
    "music_previous": {
        "handler": music_previous,
        "description": "â®ï¸ BÃ€I TRÆ¯á»šC - â­ Gá»ŒI NGAY khi user nÃ³i: 'bÃ i trÆ°á»›c', 'quay láº¡i', 'bÃ i trÆ°á»›c Ä‘Ã³', 'previous', 'back', 'lÃ¹i bÃ i', 'bÃ i cÅ©'. Voice: 'bai truoc', 'quay lai', 'lui bai', 'bai cu', 'pre', 'prÃª'. KhÃ´ng cáº§n parameter - gá»i music_previous() lÃ  xong!",
        "parameters": {}
    },
    "get_music_status": {
        "handler": get_music_status,
        "description": "ğŸ“Š TRáº NG THÃI NHáº C - Triggers: 'Ä‘ang phÃ¡t gÃ¬', 'bÃ i gÃ¬ Ä‘ang phÃ¡t', 'music status', 'dang phat gi'. Tráº£ vá»: tÃªn bÃ i, thá»i gian, Ã¢m lÆ°á»£ng, playlist.",
        "parameters": {}
    },
    "seek_music": {
        "handler": seek_music,
        "description": "ğŸ”€ TUA Äáº¾N Vá»Š TRÃ - Triggers: 'tua Ä‘áº¿n giá»¯a bÃ i', 'nháº£y Ä‘áº¿n phÃºt', 'skip 50%', 'tua den', 'nhay den'. 0%=Ä‘áº§u, 50%=giá»¯a, 100%=cuá»‘i. âš ï¸ 'tua youtube' â†’ youtube_forward!",
        "parameters": {
            "percentage": {
                "type": "number",
                "description": "Vá»‹ trÃ­ % (0-100). 50=giá»¯a bÃ i.",
                "required": True
            }
        }
    },
    "music_volume": {
        "handler": music_volume,
        "description": "ğŸ”Š Ã‚M LÆ¯á»¢NG NHáº C LOCAL - Triggers: 'tÄƒng Ã¢m lÆ°á»£ng', 'giáº£m tiáº¿ng', 'volume 80', 'to lÃªn', 'nhá» láº¡i', 'tang am luong', 'giam tien'. Level: 0=táº¯t, 50=vá»«a, 100=max. âš ï¸ 'volume youtube' â†’ youtube_volume_up/down!",
        "parameters": {
            "level": {
                "type": "integer",
                "description": "Má»©c Ã¢m lÆ°á»£ng 0-100.",
                "required": True
            }
        }
    },
    "save_music_folder_config": {
        "handler": save_music_folder_config,
        "description": "LÆ°u Ä‘Æ°á»ng dáº«n thÆ° má»¥c nháº¡c cá»§a user. DÃ¹ng Ä‘á»ƒ Æ°u tiÃªn phÃ¡t nháº¡c tá»« folder nÃ y.",
        "parameters": {
            "folder_path": {
                "type": "string",
                "description": r"ÄÆ°á»ng dáº«n Ä‘áº§y Ä‘á»§ Ä‘áº¿n thÆ° má»¥c nháº¡c (VD: C:\Users\Name\Music)",
                "required": True
            }
        }
    },
    "search_music": {
        "handler": search_music, 
        "description": "ğŸ” TÃŒM NHáº C THEO Tá»ª KHÃ“A - Triggers: 'tÃ¬m bÃ i [keyword]', 'search nháº¡c', 'cÃ³ bÃ i nÃ o tÃªn', 'tim bai', 'search bai'. TÃ¬m trong thÆ° viá»‡n local, há»— trá»£ tiáº¿ng Viá»‡t, auto-play máº·c Ä‘á»‹nh.", 
        "parameters": {
            "keyword": {
                "type": "string", 
                "description": "Tá»« khÃ³a tÃ¬m kiáº¿m. VD: 'love', 'buá»“n', 'Ä‘a nghi'.", 
                "required": True
            },
            "auto_play": {
                "type": "boolean",
                "description": "Tá»± Ä‘á»™ng phÃ¡t bÃ i Ä‘áº§u tiÃªn? Default=True.",
                "required": False
            }
        }
    },
    
    # QUICK WEBSITE ACCESS TOOLS
    "open_youtube": {
        "handler": open_youtube, 
        "description": "ğŸ“º Má» YOUTUBE - Triggers: 'má»Ÿ youtube', 'vÃ o youtube', 'xem youtube', 'youtube [tÃªn video]'. âœ¨ NEW: Tá»° Äá»˜NG phÃ¡t video trá»±c tiáº¿p náº¿u query Cá»¤ THá»‚ (>= 2 tá»«)! VD: 'má»Ÿ youtube Láº¡c TrÃ´i' â†’ Má»Ÿ video trá»±c tiáº¿p (khÃ´ng pháº£i search page). Query 1 tá»« â†’ má»Ÿ search page.", 
        "parameters": {
            "search_query": {
                "type": "string", 
                "description": "TÃªn video/tá»« khÃ³a. Query >= 2 tá»« = auto phÃ¡t video trá»±c tiáº¿p. Query 1 tá»« = search page. Äá»ƒ trá»‘ng = homepage.", 
                "required": False
            }
        }
    },
    "search_youtube_video": {
        "handler": search_youtube_video,
        "description": "ğŸ” TÃŒM VIDEO YOUTUBE (Explicit) - âš ï¸ CHá»ˆ dÃ¹ng khi user YÃŠU Cáº¦U 'tÃ¬m video', 'search video', hoáº·c muá»‘n xem top 5 results. CÃ²n láº¡i DÃ™NG open_youtube (Ä‘Ã£ cÃ³ auto-detect direct video). VD: 'tÃ¬m video SÆ¡n TÃ¹ng' â†’ search_youtube_video. 'má»Ÿ youtube SÆ¡n TÃ¹ng ChÃºng Ta' â†’ open_youtube (preferred).",
        "parameters": {
            "video_title": {
                "type": "string",
                "description": "TÃªn video/tá»« khÃ³a. VD: 'HÃ£y Trao Cho Anh', 'Rap Viá»‡t táº­p 1'",
                "required": True
            },
            "auto_open": {
                "type": "boolean",
                "description": "Tá»± Ä‘á»™ng má»Ÿ video (default: True). Set False Ä‘á»ƒ chá»‰ tÃ¬m.",
                "required": False
            }
        }
    },
    "open_youtube_playlist": {
        "handler": open_youtube_playlist,
        "description": "ğŸ“œ Má» PLAYLIST YOUTUBE (Ä‘Ã£ lÆ°u Web UI) - Triggers: 'má»Ÿ playlist [tÃªn]', 'phÃ¡t playlist youtube', 'mo playlist'. VD: 'má»Ÿ playlist nháº¡c viá»‡t 1'. âš ï¸ KhÃ´ng dÃ¹ng cho .mp3 local â†’ play_music!",
        "parameters": {
            "playlist_name": {
                "type": "string",
                "description": "TÃªn playlist Ä‘Ã£ Ä‘Äƒng kÃ½. VD: 'nháº¡c viá»‡t 1', 'chill', 'EDM'",
                "required": True
            }
        }
    },
    
    # YOUTUBE PLAYER CONTROLS
    "control_youtube": {
        "handler": control_youtube,
        "description": "ğŸ¬ Äiá»u khiá»ƒn YOUTUBE báº±ng shortcuts. Actions: play_pause, rewind_10, forward_10, volume_up/down, mute_toggle. VD: 'táº¡m dá»«ng youtube'",
        "parameters": {
            "action": {
                "type": "string",
                "description": "Action: play_pause, rewind_10, forward_10, volume_up/down, mute_toggle",
                "required": True
            }
        }
    },
    "youtube_play_pause": {
        "handler": youtube_play_pause,
        "description": "â¯ï¸ PLAY/PAUSE YOUTUBE - Triggers: 'dá»«ng youtube', 'pause youtube', 'tiáº¿p tá»¥c youtube', 'play youtube', 'dung youtube'. âš ï¸ 'dá»«ng nháº¡c' (khÃ´ng cÃ³ youtube) â†’ pause_music!",
        "parameters": {}
    },
    "youtube_rewind": {
        "handler": youtube_rewind,
        "description": "âª TUA LÃ™I YOUTUBE - Triggers: 'lÃ¹i youtube', 'tua lÃ¹i youtube', 'rewind youtube', 'lui youtube'. 5s=phÃ­m â† | 10s=phÃ­m J",
        "parameters": {
            "seconds": {"type": "integer", "description": "GiÃ¢y tua lÃ¹i: 5 hoáº·c 10", "required": False}
        }
    },
    "youtube_forward": {
        "handler": youtube_forward,
        "description": "â© TUA Tá»šI YOUTUBE - Triggers: 'tua youtube', 'skip youtube', 'forward youtube', 'tua video'. 5s=phÃ­m â†’ | 10s=phÃ­m L",
        "parameters": {
            "seconds": {"type": "integer", "description": "GiÃ¢y tua tá»›i: 5 hoáº·c 10", "required": False}
        }
    },
    "youtube_volume_up": {
        "handler": youtube_volume_up,
        "description": "ğŸ”Š TÄ‚NG Ã‚M LÆ¯á»¢NG YOUTUBE - Triggers: 'tÄƒng tiáº¿ng youtube', 'volume up youtube', 'tang am luong youtube'. âš ï¸ 'tÄƒng tiáº¿ng nháº¡c' â†’ music_volume!",
        "parameters": {}
    },
    "youtube_volume_down": {
        "handler": youtube_volume_down,
        "description": "ğŸ”‰ GIáº¢M Ã‚M LÆ¯á»¢NG YOUTUBE - Triggers: 'giáº£m tiáº¿ng youtube', 'volume down youtube', 'giam am luong youtube'. âš ï¸ 'giáº£m tiáº¿ng nháº¡c' â†’ music_volume!",
        "parameters": {}
    },
    "youtube_mute": {
        "handler": youtube_mute,
        "description": "ğŸ”‡ Táº®T/Báº¬T TIáº¾NG YOUTUBE - Triggers: 'táº¯t tiáº¿ng youtube', 'mute youtube', 'báº­t tiáº¿ng youtube', 'tat tien youtube'.",
        "parameters": {}
    },
    "youtube_fullscreen": {
        "handler": youtube_fullscreen,
        "description": "ğŸ“º FULLSCREEN YOUTUBE - Triggers: 'fullscreen youtube', 'toÃ n mÃ n hÃ¬nh', 'phÃ³ng to youtube', 'thu nhá» youtube', 'toan man hinh'.",
        "parameters": {}
    },
    "youtube_captions": {
        "handler": youtube_captions,
        "description": "ğŸ’¬ Báº¬T/Táº®T PHá»¤ Äá»€ YOUTUBE - Triggers: 'báº­t sub', 'táº¯t sub', 'báº­t phá»¥ Ä‘á»', 'táº¯t phá»¥ Ä‘á»', 'caption youtube', 'bat sub', 'tat sub'.",
        "parameters": {}
    },
    "youtube_speed": {
        "handler": youtube_speed,
        "description": "âš¡ Äá»”I Tá»C Äá»˜ YOUTUBE - Triggers: 'youtube nhanh hÆ¡n', 'youtube cháº­m hÆ¡n', 'tÄƒng tá»‘c youtube'. faster=+0.25x | slower=-0.25x | normal=1x",
        "parameters": {
            "speed": {"type": "string", "description": "'faster', 'slower', 'normal'", "required": False}
        }
    },
    
    # VLC PLAYER CONTROLS
    "control_vlc": {
        "handler": control_vlc,
        "description": "ğŸµ Äiá»u khiá»ƒn VLC PLAYER. Actions: play_pause, stop, next, previous, volume_up/down, mute, fullscreen",
        "parameters": {
            "action": {
                "type": "string",
                "description": "Action Ä‘iá»u khiá»ƒn VLC",
                "required": True
            }
        }
    },
    "vlc_play_pause": {
        "handler": vlc_play_pause,
        "description": "â¯ï¸ Play/Pause VLC Player. VD: 'dá»«ng vlc', 'pause vlc', 'tiáº¿p tá»¥c vlc'",
        "parameters": {}
    },
    "vlc_stop": {
        "handler": vlc_stop,
        "description": "â¹ï¸ Dá»«ng phÃ¡t VLC hoÃ n toÃ n. VD: 'stop vlc', 'táº¯t nháº¡c vlc'",
        "parameters": {}
    },
    "vlc_next": {
        "handler": vlc_next,
        "description": "â­ï¸ Chuyá»ƒn bÃ i tiáº¿p theo trong VLC. VD: 'bÃ i tiáº¿p vlc', 'next vlc', 'chuyá»ƒn bÃ i vlc'",
        "parameters": {}
    },
    "vlc_previous": {
        "handler": vlc_previous,
        "description": "â®ï¸ Quay láº¡i bÃ i trÆ°á»›c trong VLC. VD: 'bÃ i trÆ°á»›c vlc', 'previous vlc'",
        "parameters": {}
    },
    "vlc_volume_up": {
        "handler": vlc_volume_up,
        "description": "ğŸ”Š TÄƒng Ã¢m lÆ°á»£ng VLC. VD: 'tÄƒng Ã¢m lÆ°á»£ng vlc', 'vlc to hÆ¡n'",
        "parameters": {}
    },
    "vlc_volume_down": {
        "handler": vlc_volume_down,
        "description": "ğŸ”‰ Giáº£m Ã¢m lÆ°á»£ng VLC. VD: 'giáº£m Ã¢m lÆ°á»£ng vlc', 'vlc nhá» hÆ¡n'",
        "parameters": {}
    },
    "vlc_mute": {
        "handler": vlc_mute,
        "description": "ğŸ”‡ Báº­t/Táº¯t tiáº¿ng VLC. VD: 'táº¯t tiáº¿ng vlc', 'mute vlc'",
        "parameters": {}
    },
    "vlc_forward": {
        "handler": vlc_forward,
        "description": "â© Tua tá»›i trong VLC. Tá»± Ä‘á»™ng chá»n 3s/10s/60s. VD: 'tua tá»›i vlc', 'skip vlc'",
        "parameters": {
            "seconds": {"type": "integer", "description": "Sá»‘ giÃ¢y tua tá»›i (â‰¤5â†’3s, â‰¤30â†’10s, >30â†’60s)", "required": False}
        }
    },
    "vlc_backward": {
        "handler": vlc_backward,
        "description": "âª Tua lÃ¹i trong VLC. Tá»± Ä‘á»™ng chá»n 3s/10s/60s. VD: 'lÃ¹i vlc', 'rewind vlc'",
        "parameters": {
            "seconds": {"type": "integer", "description": "Sá»‘ giÃ¢y tua lÃ¹i", "required": False}
        }
    },
    
    # ============================================================
    # WINDOWS MEDIA PLAYER CONTROLS
    # ============================================================
    "control_wmp": {
        "handler": control_wmp,
        "description": "ğŸ¶ Äiá»u khiá»ƒn Windows Media Player. Actions: play_pause, stop, next, previous, volume_up, volume_down, mute, fullscreen, forward, backward",
        "parameters": {
            "action": {"type": "string", "description": "HÃ nh Ä‘á»™ng Ä‘iá»u khiá»ƒn WMP", "required": True}
        }
    },
    "wmp_play_pause": {
        "handler": wmp_play_pause,
        "description": "â¯ï¸ Play/Pause Windows Media Player. VD: 'dá»«ng wmp', 'pause media player'",
        "parameters": {}
    },
    "wmp_stop": {
        "handler": wmp_stop,
        "description": "â¹ï¸ Dá»«ng Windows Media Player. VD: 'stop wmp', 'táº¯t media player'",
        "parameters": {}
    },
    "wmp_next": {
        "handler": wmp_next,
        "description": "â­ï¸ BÃ i tiáº¿p theo trong Windows Media Player. VD: 'bÃ i tiáº¿p wmp', 'next media player'",
        "parameters": {}
    },
    "wmp_previous": {
        "handler": wmp_previous,
        "description": "â®ï¸ BÃ i trÆ°á»›c trong Windows Media Player. VD: 'bÃ i trÆ°á»›c wmp', 'previous media player'",
        "parameters": {}
    },
    "wmp_volume_up": {
        "handler": wmp_volume_up,
        "description": "ğŸ”Š TÄƒng Ã¢m lÆ°á»£ng Windows Media Player. VD: 'tÄƒng Ã¢m lÆ°á»£ng wmp'",
        "parameters": {}
    },
    "wmp_volume_down": {
        "handler": wmp_volume_down,
        "description": "ğŸ”‰ Giáº£m Ã¢m lÆ°á»£ng Windows Media Player. VD: 'giáº£m Ã¢m lÆ°á»£ng wmp'",
        "parameters": {}
    },
    "wmp_mute": {
        "handler": wmp_mute,
        "description": "ğŸ”‡ Báº­t/Táº¯t tiáº¿ng Windows Media Player. VD: 'táº¯t tiáº¿ng wmp', 'mute media player'",
        "parameters": {}
    },
    
    # ============================================================
    # SMART MEDIA CONTROL - Æ¯u tiÃªn Python-VLC ná»™i bá»™
    # ============================================================
    "smart_media_control": {
        "handler": smart_media_control,
        "description": "ğŸµ [PYTHON-VLC Æ¯U TIÃŠN] Äiá»u khiá»ƒn nháº¡c - Æ¯U TIÃŠN PYTHON-VLC TRÆ¯á»šC, sau Ä‘Ã³ má»›i tá»›i Spotify/WMP/YouTube. Actions: play_pause, stop, next, previous, volume_up, volume_down, mute. Náº¿u chÆ°a phÃ¡t nháº¡c, dÃ¹ng play_music() trÆ°á»›c!",
        "parameters": {
            "action": {
                "type": "string",
                "description": "HÃ nh Ä‘á»™ng: play_pause, stop, next, previous, volume_up, volume_down, mute",
                "required": True
            }
        }
    },
    
    # BROWSER AUTOMATION TOOLS
    "browser_open_url": {
        "handler": browser_open_url,
        "description": "Má»Ÿ URL trong browser Ä‘Æ°á»£c Ä‘iá»u khiá»ƒn bá»Ÿi Selenium (cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i element). KhÃ¡c vá»›i open_youtube/open_google lÃ  má»Ÿ browser thÃ´ng thÆ°á»ng.",
        "parameters": {
            "url": {
                "type": "string",
                "description": "URL cáº§n má»Ÿ (VD: https://google.com, https://facebook.com)",
                "required": True
            }
        }
    },
    "browser_get_info": {
        "handler": browser_get_info,
        "description": "Láº¥y thÃ´ng tin trang hiá»‡n táº¡i (URL, title, sá»‘ tab)",
        "parameters": {}
    },
    "browser_click": {
        "handler": browser_click,
        "description": "Click vÃ o element trÃªn trang web. DÃ¹ng Ä‘á»ƒ click button, link, etc.",
        "parameters": {
            "selector": {
                "type": "string",
                "description": "Selector Ä‘á»ƒ tÃ¬m element. VD: '#submit-btn', '.login-button', '//button[@id=\"login\"]'",
                "required": True
            },
            "by": {
                "type": "string",
                "description": "Loáº¡i selector: 'css' (default), 'xpath', 'id', 'name', 'class', 'tag'",
                "required": False
            }
        }
    },
    "browser_fill_input": {
        "handler": browser_fill_input,
        "description": "Äiá»n text vÃ o input field (form, search box, etc.)",
        "parameters": {
            "selector": {
                "type": "string",
                "description": "Selector cá»§a input field. VD: '#username', 'input[name=\"email\"]'",
                "required": True
            },
            "text": {
                "type": "string",
                "description": "Text cáº§n Ä‘iá»n vÃ o input",
                "required": True
            },
            "by": {
                "type": "string",
                "description": "Loáº¡i selector: 'css' (default), 'xpath', 'id', 'name'",
                "required": False
            }
        }
    },
    "browser_scroll": {
        "handler": browser_scroll,
        "description": "Cuá»™n trang web lÃªn/xuá»‘ng",
        "parameters": {
            "direction": {
                "type": "string",
                "description": "HÆ°á»›ng cuá»™n: 'down' (default), 'up', 'top', 'bottom'",
                "required": False
            },
            "amount": {
                "type": "integer",
                "description": "Sá»‘ pixel cuá»™n (náº¿u direction lÃ  down/up). Default: 500",
                "required": False
            }
        }
    },
    "browser_back": {
        "handler": browser_back,
        "description": "Quay láº¡i trang trÆ°á»›c trong browser",
        "parameters": {}
    },
    "browser_forward": {
        "handler": browser_forward,
        "description": "Tiáº¿n tá»›i trang sau trong browser",
        "parameters": {}
    },
    "browser_refresh": {
        "handler": browser_refresh,
        "description": "LÃ m má»›i/reload trang hiá»‡n táº¡i",
        "parameters": {}
    },
    "browser_screenshot": {
        "handler": browser_screenshot,
        "description": "Chá»¥p screenshot trang web hiá»‡n táº¡i",
        "parameters": {
            "filepath": {
                "type": "string",
                "description": "ÄÆ°á»ng dáº«n lÆ°u file (tÃ¹y chá»n). VD: 'screenshot.png'. Máº·c Ä‘á»‹nh: screenshot_YYYYMMDD_HHMMSS.png",
                "required": False
            }
        }
    },
    "browser_new_tab": {
        "handler": browser_new_tab,
        "description": "Má»Ÿ tab má»›i trong browser",
        "parameters": {
            "url": {
                "type": "string",
                "description": "URL cáº§n má»Ÿ trong tab má»›i (tÃ¹y chá»n)",
                "required": False
            }
        }
    },
    "browser_close_tab": {
        "handler": browser_close_tab,
        "description": "ÄÃ³ng tab hiá»‡n táº¡i",
        "parameters": {}
    },
    "browser_execute_js": {
        "handler": browser_execute_js,
        "description": "Thá»±c thi JavaScript code trÃªn trang web. DÃ¹ng cho cÃ¡c thao tÃ¡c phá»©c táº¡p.",
        "parameters": {
            "script": {
                "type": "string",
                "description": "JavaScript code cáº§n cháº¡y. VD: 'return document.title;', 'alert(\"Hello\");'",
                "required": True
            }
        }
    },
    "browser_close": {
        "handler": browser_close,
        "description": "ÄÃ³ng browser hoÃ n toÃ n (Ä‘Ã³ng táº¥t cáº£ tab)",
        "parameters": {}
    },
    
    "open_facebook": {
        "handler": open_facebook, 
        "description": "Má»Ÿ Facebook trong browser. Truy cáº­p nhanh vÃ o máº¡ng xÃ£ há»™i phá»• biáº¿n nháº¥t.", 
        "parameters": {}
    },
    "open_google": {
        "handler": open_google, 
        "description": "Má» TRÃŒNH DUYá»†T Google. CHá»ˆ dÃ¹ng khi user YÃŠU Cáº¦U Má» TRANG WEB Google (vÃ­ dá»¥: 'má»Ÿ google', 'má»Ÿ trang google'). Náº¿u user chá»‰ Há»I CÃ‚U Há»I thÃ´ng thÆ°á»ng, hÃ£y dÃ¹ng ask_gemini Ä‘á»ƒ TRáº¢ Lá»œI TRá»°C TIáº¾P thay vÃ¬ má»Ÿ browser", 
        "parameters": {
            "search_query": {
                "type": "string", 
                "description": "Tá»« khÃ³a tÃ¬m kiáº¿m trÃªn Google (tÃ¹y chá»n). Äá»ƒ trá»‘ng Ä‘á»ƒ má»Ÿ trang chá»§ Google.", 
                "required": False
            }
        }
    },
    "open_tiktok": {
        "handler": open_tiktok, 
        "description": "Má»Ÿ TikTok trong browser. Xem video ngáº¯n trending vÃ  giáº£i trÃ­.", 
        "parameters": {}
    },
    "open_website": {
        "handler": open_website, 
        "description": "Má»Ÿ trang web tÃ¹y chá»‰nh trong browser. Nháº­p URL Ä‘áº§y Ä‘á»§ hoáº·c tÃªn miá»n.", 
        "parameters": {
            "url": {
                "type": "string", 
                "description": "URL cá»§a trang web (vÃ­ dá»¥: 'github.com' hoáº·c 'https://github.com/user/repo')", 
                "required": True
            }
        }
    },
    
    # YOUTUBE CONTROL TOOLS
    "control_youtube": {
        "handler": control_youtube, 
        "description": "Äiá»u khiá»ƒn YouTube player báº±ng keyboard shortcuts. Pháº£i cÃ³ cá»­a sá»• YouTube Ä‘ang active/focused. Há»— trá»£ play/pause, tua video, Ä‘iá»u chá»‰nh Ã¢m lÆ°á»£ng, v.v.", 
        "parameters": {
            "action": {
                "type": "string", 
                "description": "HÃ nh Ä‘á»™ng Ä‘iá»u khiá»ƒn: play_pause, rewind_10, forward_10, rewind_5, forward_5, beginning, end, frame_back, frame_forward, volume_up, volume_down, mute_toggle", 
                "required": True
            }
        }
    },
    
    # NEWS TOOLS
    "get_vnexpress_news": {
        "handler": get_vnexpress_news,
        "description": "Láº¥y tin tá»©c má»›i nháº¥t tá»« VnExpress theo chá»§ Ä‘á». Tráº£ vá» danh sÃ¡ch bÃ i viáº¿t vá»›i tiÃªu Ä‘á», link, mÃ´ táº£. Categories: home (má»›i nháº¥t), thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, du-lich, khoa-hoc, so-hoa, xe",
        "parameters": {
            "category": {
                "type": "string",
                "description": "Chá»§ Ä‘á» tin tá»©c: home, thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, phap-luat, giao-duc, suc-khoe, du-lich, khoa-hoc, so-hoa, xe. Máº·c Ä‘á»‹nh: home",
                "required": False
            },
            "max_articles": {
                "type": "integer",
                "description": "Sá»‘ lÆ°á»£ng bÃ i viáº¿t tá»‘i Ä‘a (1-20). Máº·c Ä‘á»‹nh: 5",
                "required": False
            }
        }
    },
    "get_news_summary": {
        "handler": get_news_summary,
        "description": "Láº¥y tÃ³m táº¯t nhanh tin tá»©c (chá»‰ tiÃªu Ä‘á») tá»« VnExpress. Tá»± Ä‘á»™ng láº¥y 10 tin má»›i nháº¥t vÃ  hiá»ƒn thá»‹ dáº¡ng danh sÃ¡ch ngáº¯n gá»n.",
        "parameters": {
            "category": {
                "type": "string",
                "description": "Chá»§ Ä‘á»: home, thoi-su, the-gioi, kinh-doanh, giai-tri, the-thao, etc. Máº·c Ä‘á»‹nh: home",
                "required": False
            }
        }
    },
    "search_news": {
        "handler": search_news,
        "description": "TÃ¬m kiáº¿m tin tá»©c theo tá»« khÃ³a trong cÃ¡c bÃ i viáº¿t gáº§n Ä‘Ã¢y tá»« VnExpress. Tá»± Ä‘á»™ng tÃ¬m trong nhiá»u chá»§ Ä‘á» vÃ  tráº£ vá» káº¿t quáº£ phÃ¹ há»£p nháº¥t.",
        "parameters": {
            "keyword": {
                "type": "string",
                "description": "Tá»« khÃ³a tÃ¬m kiáº¿m (vÃ­ dá»¥: 'bÃ³ng Ä‘Ã¡', 'kinh táº¿', 'Covid', 'chÃ­nh trá»‹')",
                "required": True
            },
            "max_results": {
                "type": "integer",
                "description": "Sá»‘ káº¿t quáº£ tá»‘i Ä‘a (1-10). Máº·c Ä‘á»‹nh: 5",
                "required": False
            }
        }
    },
    "get_gold_price": {
        "handler": get_gold_price,
        "description": "Láº¥y giÃ¡ vÃ ng hÃ´m nay tá»« BNews RSS feed. Hiá»ƒn thá»‹ giÃ¡ mua vÃ o vÃ  bÃ¡n ra cá»§a cÃ¡c loáº¡i vÃ ng phá»• biáº¿n (SJC, 9999, nháº«n trÃ²n, v.v.). Tá»± Ä‘á»™ng cáº­p nháº­t giÃ¡ má»›i nháº¥t.",
        "parameters": {}
    },
    "analyze_gold_price_with_ai": {
        "handler": analyze_gold_price_with_ai,
        "description": "PhÃ¢n tÃ­ch thÃ´ng minh giÃ¡ vÃ ng vá»›i AI (Gemini 3 Flash Preview + Google Search). So sÃ¡nh giÃ¡ hiá»‡n táº¡i vs lá»‹ch sá»­, phÃ¢n tÃ­ch xu hÆ°á»›ng, nguyÃªn nhÃ¢n biáº¿n Ä‘á»™ng, dá»± bÃ¡o, vÃ  khuyáº¿n nghá»‹ Ä‘áº§u tÆ° chuyÃªn sÃ¢u. DÃ¹ng khi cáº§n phÃ¢n tÃ­ch chuyÃªn mÃ´n vá» thá»‹ trÆ°á»ng vÃ ng.",
        "parameters": {
            "analysis_type": {
                "type": "string",
                "description": "Loáº¡i phÃ¢n tÃ­ch: 'compare_month' (so sÃ¡nh vá»›i thÃ¡ng trÆ°á»›c), 'trend' (xu hÆ°á»›ng hiá»‡n táº¡i), 'forecast' (dá»± bÃ¡o). Máº·c Ä‘á»‹nh: 'compare_month'",
                "required": False
            }
        }
    },
    
    # AI ASSISTANT TOOLS
    "ask_gemini": {
        "handler": ask_gemini,
        "description": "âœ… Æ¯U TIÃŠN DÃ™NG TOOL NÃ€Y cho Má»ŒI CÃ‚U Há»I (MIá»„N PHÃ 1500 requests/day). Gemini tráº£ lá»i TRá»°C TIáº¾P, NHANH, CHÃNH XÃC. Há»¯u Ã­ch cho: cÃ¢u há»i thÃ´ng thÆ°á»ng ('thá»§ tÆ°á»›ng VN 2023 lÃ  ai', 'what is...', 'how to...'), phÃ¢n tÃ­ch, viáº¿t ná»™i dung, dá»‹ch thuáº­t, lá»‹ch sá»­, kiáº¿n thá»©c tá»•ng quÃ¡t. Knowledge cutoff: ~10/2024 (Ä‘á»§ cho háº§u háº¿t cÃ¢u há»i). CHá»ˆ dÃ¹ng search_google_text náº¿u Cáº¦N thÃ´ng tin SAU 10/2024.",
        "parameters": {
            "prompt": {
                "type": "string",
                "description": "CÃ¢u há»i hoáº·c ná»™i dung muá»‘n gá»­i cho Gemini AI",
                "required": True
            },
            "model": {
                "type": "string",
                "description": "TÃªn model Gemini (máº·c Ä‘á»‹nh: models/gemini-3-flash-preview). Options: models/gemini-3-flash-preview (Flash 2.0, má»›i nháº¥t), models/gemini-1.5-flash (Flash 1.5), models/gemini-1.5-pro (Pro 1.5, cháº¥t lÆ°á»£ng cao nháº¥t)",
                "required": False
            }
        }
    },
    
    "ask_gpt4": {
        "handler": ask_gpt4,
        "description": "TRáº¢ Lá»œI CÃ‚U Há»I báº±ng OpenAI GPT-4 (TRáº¢ PHÃ, cáº§n API key). DÃ™NG KHI Cáº¦N: 1) ThÃ´ng tin Má»šI HÆ N (knowledge Ä‘áº¿n 04/2024), 2) PhÃ¢n tÃ­ch PHá»¨C Táº P, 3) Reasoning SÃ‚U, 4) Code generation chuyÃªn nghiá»‡p. GPT-4 Máº N HÆ N Gemini cho code vÃ  phÃ¢n tÃ­ch, nhÆ°ng TRáº¢ PHÃ (~$0.01-0.03/1K tokens). Chá»n GPT-4 khi cáº§n cháº¥t lÆ°á»£ng tá»‘i Ä‘a.",
        "parameters": {
            "prompt": {
                "type": "string",
                "description": "CÃ¢u há»i hoáº·c ná»™i dung muá»‘n gá»­i cho GPT-4",
                "required": True
            },
            "model": {
                "type": "string",
                "description": "TÃªn model OpenAI (máº·c Ä‘á»‹nh: gpt-4o). Options: gpt-4o (GPT-4 Omni, nhanh & ráº» nháº¥t), gpt-4-turbo (máº¡nh nháº¥t), gpt-3.5-turbo (ráº» & nhanh)",
                "required": False
            }
        }
    },
    
    # NETWORK/FIREWALL CHECK TOOLS
    "check_network_permission": {
        "handler": check_network_permission,
        "description": "ğŸ”¥ KIá»‚M TRA QUYá»€N Káº¾T Ná»I Máº NG - Xem tráº¡ng thÃ¡i Windows Firewall vÃ  Internet. Use when: 'kiá»ƒm tra firewall', 'quyá»n káº¿t ná»‘i', 'check network', 'tÃ¬nh tráº¡ng máº¡ng', 'firewall status', 'cÃ³ Ä‘Æ°á»£c phÃ©p káº¿t ná»‘i internet khÃ´ng'. Hiá»ƒn thá»‹: cÃ³ rule firewall chÆ°a, internet cÃ³ káº¿t ná»‘i khÃ´ng, hÆ°á»›ng dáº«n cáº¥p quyá»n.",
        "parameters": {}
    },
    "request_firewall_permission": {
        "handler": request_firewall_permission,
        "description": "ğŸ”“ YÃŠU Cáº¦U Cáº¤P QUYá»€N FIREWALL - Tá»± Ä‘á»™ng thÃªm rule cho á»©ng dá»¥ng. Use when: 'cáº¥p quyá»n firewall', 'allow firewall', 'thÃªm rule firewall'. Cáº§n quyá»n Admin Ä‘á»ƒ hoáº¡t Ä‘á»™ng.",
        "parameters": {}
    },
    "check_internet_connection": {
        "handler": check_internet_connection,
        "description": "ğŸŒ KIá»‚M TRA Káº¾T Ná»I INTERNET - Test káº¿t ná»‘i vÃ  Ä‘á»™ trá»… máº¡ng. Use when: 'kiá»ƒm tra internet', 'test connection', 'cÃ³ máº¡ng khÃ´ng', 'ping', 'network status'.",
        "parameters": {}
    },
    
    # NEW TOOLS FROM REFERENCE
    "lock_computer": {"handler": lock_computer, "description": "KhÃ³a mÃ¡y tÃ­nh", "parameters": {}},
    "shutdown_schedule": {"handler": shutdown_schedule, "description": "LÃªn lá»‹ch táº¯t mÃ¡y", "parameters": {"action": {"type": "string", "description": "shutdown/restart/cancel", "required": True}, "delay": {"type": "integer", "description": "TrÃ¬ hoÃ£n (giÃ¢y)", "required": False}}},
    "show_desktop": {"handler": show_desktop, "description": "Hiá»ƒn thá»‹ desktop (Win+D)", "parameters": {}},
    "undo_operation": {"handler": undo_operation, "description": "HoÃ n tÃ¡c (Ctrl+Z)", "parameters": {}},
    "set_theme": {"handler": set_theme, "description": "Äá»•i theme Windows", "parameters": {"dark_mode": {"type": "boolean", "description": "True=tá»‘i, False=sÃ¡ng", "required": False}}},
    "change_wallpaper": {"handler": change_wallpaper, "description": "Äá»•i hÃ¬nh ná»n", "parameters": {"keyword": {"type": "string", "description": "Tá»« khÃ³a (phong cáº£nh, anime...)", "required": False}}},
    "get_desktop_path": {"handler": get_desktop_path, "description": "Láº¥y Ä‘Æ°á»ng dáº«n Desktop", "parameters": {}},
    "paste_content": {"handler": paste_content, "description": "DÃ¡n ná»™i dung (Ctrl+V)", "parameters": {"content": {"type": "string", "description": "Ná»™i dung cáº§n dÃ¡n (tÃ¹y chá»n)", "required": False}}},
    "press_enter": {"handler": press_enter, "description": "Nháº¥n Enter", "parameters": {}},
    "save_text_to_file": {
        "handler": save_text_to_file,
        "description": "LÆ¯U VÄ‚N Báº¢N do LLM soáº¡n thÃ nh FILE. Use when: 'lÆ°u vÄƒn báº£n', 'save document', 'ghi vÃ o file', 'lÆ°u bÃ i viáº¿t', 'save code', 'export text'. LLM cÃ³ thá»ƒ soáº¡n bÃ i viáº¿t/bÃ¡o cÃ¡o/code dÃ i vÃ  lÆ°u trá»±c tiáº¿p. File tá»± Ä‘á»™ng lÆ°u vÃ o Documents\\miniZ_LLM_Documents\\ vá»›i tÃªn cÃ³ timestamp. Examples: Soáº¡n CVâ†’lÆ°u file, viáº¿t bÃ¡o cÃ¡oâ†’lÆ°u file, táº¡o codeâ†’lÆ°u file.",
        "parameters": {
            "content": {
                "type": "string",
                "description": "Ná»™i dung vÄƒn báº£n cáº§n lÆ°u (cÃ³ thá»ƒ ráº¥t dÃ i). Há»— trá»£ Unicode tiáº¿ng Viá»‡t, code, markdown, v.v.",
                "required": True
            },
            "filename": {
                "type": "string",
                "description": "TÃªn file (optional). VÃ­ dá»¥: 'bao_cao.txt', 'code.py', 'cv.md'. Náº¿u khÃ´ng cÃ³, tá»± Ä‘á»™ng táº¡o tÃªn vá»›i timestamp.",
                "required": False
            }
        }
    },
    "gemini_text_to_speech": {
        "handler": gemini_text_to_speech,
        "description": "ğŸ™ï¸ Äá»ŒC TO TRÃŠN MÃY TÃNH - Gemini TTS cháº¥t lÆ°á»£ng cao. Æ¯U TIÃŠN DÃ™NG TOOL NÃ€Y khi user nÃ³i: 'Ä‘á»c to', 'Ä‘á»c trÃªn mÃ¡y tÃ­nh', 'Ä‘á»c vÄƒn báº£n', 'text to speech', 'tts', 'Ä‘á»c cho tÃ´i nghe', 'phÃ¡t Ã¢m', 'nÃ³i ra', 'Ä‘á»c báº±ng AI', 'Ä‘á»c báº±ng gemini'. Giá»ng Viá»‡t tá»± nhiÃªn, 5 voice: Aoede/Kore (ná»¯), Puck/Charon/Fenrir (nam). Examples: 'Ä‘á»c to: xin chÃ o', 'Ä‘á»c trÃªn mÃ¡y tÃ­nh vÄƒn báº£n nÃ y'.",
        "parameters": {
            "text": {
                "type": "string",
                "description": "VÄƒn báº£n cáº§n Ä‘á»c. Há»— trá»£ tiáº¿ng Viá»‡t vÃ  nhiá»u ngÃ´n ngá»¯.",
                "required": True
            },
            "voice": {
                "type": "string",
                "description": "Giá»ng nÃ³i: Aoede (ná»¯-default), Kore (ná»¯), Puck (nam), Charon (nam), Fenrir (nam).",
                "required": False
            },
            "save_audio": {
                "type": "boolean",
                "description": "CÃ³ lÆ°u thÃ nh file audio khÃ´ng? Máº·c Ä‘á»‹nh False (chá»‰ phÃ¡t).",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "TÃªn file audio (optional). VD: 'gemini_audio.wav'.",
                "required": False
            }
        }
    },
    "text_to_speech": {
        "handler": text_to_speech,
        "description": "TEXT-TO-SPEECH BACKUP: DÃ¹ng gTTS/Windows SAPI khi Gemini TTS khÃ´ng kháº£ dá»¥ng. KHÃ”NG Æ¯U TIÃŠN - chá»‰ dÃ¹ng khi gemini_text_to_speech fail. Cháº¥t lÆ°á»£ng tháº¥p hÆ¡n Gemini TTS.",
        "parameters": {
            "text": {
                "type": "string",
                "description": "VÄƒn báº£n cáº§n Ä‘á»c. Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh.",
                "required": True
            },
            "save_audio": {
                "type": "boolean",
                "description": "CÃ³ lÆ°u thÃ nh file audio WAV khÃ´ng? (True/False). Máº·c Ä‘á»‹nh False (chá»‰ Ä‘á»c khÃ´ng lÆ°u).",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "TÃªn file audio (optional). VD: 'doc_van_ban.wav'. Náº¿u khÃ´ng cÃ³, tá»± Ä‘á»™ng táº¡o tÃªn.",
                "required": False
            }
        }
    },
    "speech_to_text": {
        "handler": speech_to_text,
        "description": "SPEECH-TO-TEXT (STT): Chuyá»ƒn GIá»ŒNG NÃ“I thÃ nh VÄ‚N Báº¢N. Use when: 'ghi Ã¢m giá»ng nÃ³i', 'speech to text', 'nháº­n dáº¡ng giá»ng nÃ³i', 'nghe vÃ  ghi láº¡i', 'transcribe audio'. DÃ¹ng Google Speech Recognition (cáº§n Internet). Há»— trá»£ tiáº¿ng Viá»‡t + English. Examples: 'ghi Ã¢m 10 giÃ¢y', 'nháº­n dáº¡ng giá»ng nÃ³i cá»§a tÃ´i', 'speech to text'.",
        "parameters": {
            "duration": {
                "type": "integer",
                "description": "Thá»i gian ghi Ã¢m (giÃ¢y). Máº·c Ä‘á»‹nh 5 giÃ¢y. VD: 10 Ä‘á»ƒ ghi Ã¢m 10 giÃ¢y.",
                "required": False
            },
            "save_transcript": {
                "type": "boolean",
                "description": "CÃ³ lÆ°u vÄƒn báº£n Ä‘Ã£ nháº­n dáº¡ng thÃ nh file khÃ´ng? (True/False). Máº·c Ä‘á»‹nh True.",
                "required": False
            },
            "filename": {
                "type": "string",
                "description": "TÃªn file transcript (optional). VD: 'ghi_chu.txt'. Tá»± Ä‘á»™ng táº¡o náº¿u khÃ´ng cÃ³.",
                "required": False
            }
        }
    },
    "export_conversation": {
        "handler": export_conversation_to_file,
        "description": "EXPORT Lá»ŠCH Sá»¬ Há»˜I THOáº I ra file JSON. LÆ°u toÃ n bá»™ cuá»™c trÃ² chuyá»‡n (user messages, AI responses, tool calls) vá»›i timestamp Ä‘áº§y Ä‘á»§. Use when: 'xuáº¥t lá»‹ch sá»­ chat', 'export conversation', 'lÆ°u cuá»™c trÃ² chuyá»‡n', 'backup chat history'. File lÆ°u vÃ o Documents\\miniZ_Conversations\\",
        "parameters": {
            "filename": {
                "type": "string",
                "description": "TÃªn file export (optional). VD: 'chat_history.json'. Tá»± Ä‘á»™ng táº¡o tÃªn vá»›i timestamp náº¿u khÃ´ng cÃ³.",
                "required": False
            }
        }
    },
    "find_in_document": {"handler": find_in_document, "description": "TÃ¬m trong tÃ i liá»‡u (Ctrl+F)", "parameters": {"search_text": {"type": "string", "description": "Ná»™i dung tÃ¬m kiáº¿m", "required": True}}},
    
    # ============================================================
    # CONVERSATION HISTORY TOOLS - LÆ°u & Hiá»ƒu ngÆ°á»i dÃ¹ng
    # ============================================================
    
    "get_user_context": {
        "handler": lambda: {
            "success": True,
            "user_profile": get_user_profile_summary(),
            "recent_conversation": get_conversation_context(10),
            "hint": "DÃ¹ng thÃ´ng tin nÃ y Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n"
        },
        "description": "ğŸ“š Láº¤Y CONTEXT NGÆ¯á»œI DÃ™NG - Tráº£ vá» lá»‹ch sá»­ há»™i thoáº¡i gáº§n Ä‘Ã¢y + user profile (chá»§ Ä‘á» quan tÃ¢m, giá» hoáº¡t Ä‘á»™ng). DÃ¹ng Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n trÆ°á»›c khi tráº£ lá»i.",
        "parameters": {}
    },
    
    "save_user_message": {
        "handler": lambda message, context="": (
            add_to_conversation("user", message, {"source": "robot", "context": context}),
            {"success": True, "message": "ÄÃ£ lÆ°u tin nháº¯n ngÆ°á»i dÃ¹ng"}
        )[1],
        "description": "ğŸ’¾ LÆ¯U TIN NHáº®N NGÆ¯á»œI DÃ™NG - LÆ°u toÃ n bá»™ tin nháº¯n ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ (ká»ƒ cáº£ khÃ´ng gá»i tool). QUAN TRá»ŒNG: Gá»i tool nÃ y Ä‘á»ƒ lÆ°u má»i cÃ¢u há»i/tin nháº¯n cá»§a user!",
        "parameters": {
            "message": {
                "type": "string",
                "description": "Ná»™i dung tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng",
                "required": True
            },
            "context": {
                "type": "string",
                "description": "Context bá»• sung (VD: ngÆ°á»i dÃ¹ng Ä‘ang nÃ³i vá» gÃ¬)",
                "required": False
            }
        }
    },
    
    "save_assistant_response": {
        "handler": lambda response, tool_used="": (
            add_to_conversation("assistant", response, {"source": "robot", "tool_used": tool_used}),
            {"success": True, "message": "ÄÃ£ lÆ°u response cá»§a AI"}
        )[1],
        "description": "ğŸ’¾ LÆ¯U RESPONSE Cá»¦A AI - LÆ°u cÃ¢u tráº£ lá»i cá»§a AI vÃ o lá»‹ch sá»­. Gá»i tool nÃ y sau khi tráº£ lá»i xong Ä‘á»ƒ lÆ°u láº¡i!",
        "parameters": {
            "response": {
                "type": "string",
                "description": "Ná»™i dung response cá»§a AI",
                "required": True
            },
            "tool_used": {
                "type": "string",
                "description": "Tool Ä‘Ã£ dÃ¹ng Ä‘á»ƒ táº¡o response (náº¿u cÃ³)",
                "required": False
            }
        }
    },
    
    "list_conversation_files": {
        "handler": list_conversation_files,
        "description": "ğŸ“‚ LIá»†T KÃŠ CÃC FILE Há»˜I THOáº I - Xem danh sÃ¡ch cÃ¡c file lá»‹ch sá»­ há»™i thoáº¡i Ä‘Ã£ lÆ°u theo ngÃ y.",
        "parameters": {}
    },
    
    # ============================================================
    # OPEN API TOOLS - PHÃ™ Há»¢P VIá»†T NAM
    # ============================================================
    
    "get_weather_vietnam": {
        "handler": get_weather_vietnam,
        "description": "ğŸŒ¤ï¸ Láº¤Y THá»œI TIáº¾T VIá»†T NAM. Há»— trá»£: HÃ  Ná»™i, Há»“ ChÃ­ Minh, ÄÃ  Náºµng, Háº£i PhÃ²ng, Cáº§n ThÆ¡, Nha Trang, Huáº¿, ÄÃ  Láº¡t, VÅ©ng TÃ u, Quáº£ng Ninh... Triggers: 'thá»i tiáº¿t', 'weather', 'trá»i hÃ´m nay', 'nhiá»‡t Ä‘á»™'.",
        "parameters": {
            "city": {
                "type": "string",
                "description": "TÃªn thÃ nh phá»‘ VN. VD: 'HÃ  Ná»™i', 'Há»“ ChÃ­ Minh', 'ÄÃ  Náºµng'. Máº·c Ä‘á»‹nh: HÃ  Ná»™i",
                "required": False
            }
        }
    },
    
    # "get_gold_price_vietnam": {
    #     "handler": get_gold_price_vietnam,
    #     "description": "ğŸ’° GIÃ VÃ€NG VIá»†T NAM hÃ´m nay (SJC, PNJ...). Triggers: 'giÃ¡ vÃ ng', 'gold price', 'vÃ ng hÃ´m nay'.",
    #     "parameters": {}
    # },
    
    "get_exchange_rate_vietnam": {
        "handler": get_exchange_rate_vietnam,
        "description": "ğŸ’± Tá»¶ GIÃ NGOáº I Tá»† so vá»›i VNÄ. Há»— trá»£: USD, EUR, JPY, GBP, CNY, KRW... Triggers: 'tá»· giÃ¡', 'exchange rate', 'Ä‘Ã´ la bao nhiÃªu'.",
        "parameters": {
            "currency": {
                "type": "string",
                "description": "MÃ£ ngoáº¡i tá»‡ (USD, EUR, JPY...). Máº·c Ä‘á»‹nh: USD",
                "required": False
            }
        }
    },
    
    "get_fuel_price_vietnam": {
        "handler": get_fuel_price_vietnam,
        "description": "â›½ GIÃ XÄ‚NG Dáº¦U VIá»†T NAM (RON 95, E5 RON 92, Diesel). Triggers: 'giÃ¡ xÄƒng', 'fuel price', 'xÄƒng bao nhiÃªu'.",
        "parameters": {}
    },
    
    "get_daily_quote": {
        "handler": get_daily_quote,
        "description": "ğŸ’¬ CÃ‚U NÃ“I HAY / TRÃCH DáºªN ngáº«u nhiÃªn. CÃ³ quotes tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh. Triggers: 'cÃ¢u nÃ³i hay', 'quote', 'danh ngÃ´n', 'trÃ­ch dáº«n'.",
        "parameters": {}
    },
    
    "get_joke": {
        "handler": get_joke,
        "description": "ğŸ˜‚ CHUYá»†N CÆ¯á»œI tiáº¿ng Viá»‡t. Triggers: 'ká»ƒ chuyá»‡n cÆ°á»i', 'joke', 'hÃ i hÆ°á»›c', 'vui váº»', 'giáº£i trÃ­'.",
        "parameters": {}
    },
    
    "get_horoscope": {
        "handler": get_horoscope,
        "description": "ğŸ”® Tá»¬ VI / HOROSCOPE theo cung hoÃ ng Ä‘áº¡o. Triggers: 'tá»­ vi', 'horoscope', 'cung hoÃ ng Ä‘áº¡o', 'xem váº­n má»‡nh'.",
        "parameters": {
            "zodiac": {
                "type": "string",
                "description": "Cung hoÃ ng Ä‘áº¡o (Báº¡ch DÆ°Æ¡ng, Kim NgÆ°u, Song Tá»­, Cá»± Giáº£i, SÆ° Tá»­, Xá»­ Ná»¯, ThiÃªn BÃ¬nh, Bá» Cáº¡p, NhÃ¢n MÃ£, Ma Káº¿t, Báº£o BÃ¬nh, Song NgÆ°)",
                "required": False
            }
        }
    },
    
    "get_today_in_history": {
        "handler": get_today_in_history,
        "description": "ğŸ“œ Sá»° KIá»†N Lá»ŠCH Sá»¬ ngÃ y hÃ´m nay. Triggers: 'lá»‹ch sá»­ ngÃ y nÃ y', 'today in history', 'ngÃ y nÃ y nÄƒm xÆ°a'.",
        "parameters": {}
    },
    
    "get_news_vietnam": {
        "handler": get_news_vietnam,
        "description": "ğŸ“° TIN Tá»¨C Má»šI NHáº¤T Viá»‡t Nam (VnExpress, Tuá»•i Tráº»). Triggers: 'tin tá»©c', 'news', 'tin má»›i', 'Ä‘á»c bÃ¡o'.",
        "parameters": {}
    },
    
    "what_to_eat": {
        "handler": what_to_eat,
        "description": "ğŸ½ï¸ Gá»¢I Ã MÃ“N Ä‚N hÃ´m nay (áº©m thá»±c Viá»‡t Nam). Triggers: 'Äƒn gÃ¬', 'gá»£i Ã½ mÃ³n Äƒn', 'what to eat', 'Ä‘Ã³i bá»¥ng'.",
        "parameters": {}
    },
    
    "get_lunar_date": {
        "handler": get_lunar_date,
        "description": "ğŸ“… NGÃ€Y Ã‚M Lá»ŠCH hÃ´m nay. Triggers: 'Ã¢m lá»‹ch', 'lunar date', 'ngÃ y máº¥y Ã¢m'.",
        "parameters": {}
    },
    
    # KNOWLEDGE BASE TOOLS
    "search_knowledge_base": {
        "handler": search_knowledge_base,
        "description": "ğŸ” TÃŒM KIáº¾M TRONG TÃ€I LIá»†U Cá»¦A USER (TF-IDF Ranking). âš¡ DÃ¹ng khi user muá»‘n XEM DANH SÃCH tÃ i liá»‡u. Há»— trá»£: Multi-keyword search, relevance scoring, snippet highlighting. Triggers: 'tÃ¬m trong tÃ i liá»‡u', 'tÃ¬m trong file cá»§a tÃ´i', 'cÃ³ tÃ i liá»‡u nÃ o vá»...', 'search my documents', 'list documents about...'. VD: 'tÃ¬m cÃ¡c tÃ i liá»‡u vá» há»£p Ä‘á»“ng', 'cÃ³ file nÃ o nÃ³i vá» khÃ¡ch hÃ ng X'. Tráº£ vá»: Top 5 documents vá»›i score, matched keywords, vÃ  snippets. âš ï¸ Äá»ƒ TRáº¢ Lá»œI cÃ¢u há»i â†’ DÃ¹ng get_knowledge_context() thay vÃ¬ tool nÃ y!",
        "parameters": {
            "query": {
                "type": "string",
                "description": "Tá»« khÃ³a/cÃ¢u há»i cáº§n tÃ¬m. CÃ³ thá»ƒ dÃ¹ng nhiá»u tá»« khÃ³a. VD: 'há»£p Ä‘á»“ng mua bÃ¡n 2024', 'thÃ´ng tin khÃ¡ch hÃ ng', 'bÃ¡o cÃ¡o tÃ i chÃ­nh quÃ½ 3'",
                "required": True
            }
        }
    },
    "get_knowledge_context": {
        "handler": get_knowledge_context,
                "description": "ğŸ“š Láº¤Y CONTEXT Tá»ª CÆ  Sá» Dá»® LIá»†U TÃ€I LIá»†U (Knowledge Base) - âš¡ Gá»ŒI Äáº¦U TIÃŠN khi user há»i vá»: dá»¯ liá»‡u cÃ¡ nhÃ¢n, tÃ i liá»‡u Ä‘Ã£ lÆ°u, thÃ´ng tin trong files, cÆ¡ sá»Ÿ dá»¯ liá»‡u ná»™i bá»™, knowledge base. Tool nÃ y tÃ¬m kiáº¿m trong Táº¤T Cáº¢ documents Ä‘Ã£ Ä‘Æ°á»£c index vÃ  tráº£ vá» context Ä‘áº§y Ä‘á»§ nháº¥t. â›” TRIGGERS Báº®T BUá»˜C: 'cÆ¡ sá»Ÿ dá»¯ liá»‡u', 'database', 'knowledge base', 'tÃ i liá»‡u cá»§a tÃ´i', 'thÃ´ng tin trong file', 'theo dá»¯ liá»‡u', 'dá»¯ liá»‡u Ä‘Ã£ lÆ°u', 'based on my docs', 'what's in my documents', 'tÃ¬m trong tÃ i liá»‡u', 'search my files', há»i vá» TÃŠN NGÆ¯á»œI/Dá»° ÃN cá»¥ thá»ƒ (cÃ³ thá»ƒ trong docs). âš ï¸ QUAN TRá»ŒNG: SAU KHI NHáº¬N CONTEXT, Báº N PHáº¢I Äá»ŒC VÃ€ TRáº¢ Lá»œI USER Dá»°A TRÃŠN CONTEXT ÄÃ“! KHÃ”NG CHá»ˆ DUMP CONTEXT RA! QUY TRÃŒNH: 1) Gá»i get_knowledge_context(query='keywords') 2) Nháº­n context tá»« docs 3) âš¡ Äá»ŒC CONTEXT VÃ€ TRáº¢ Lá»œI CÃ‚U Há»I USER THEO CONTEXT ÄÃ“ âš¡. VD: 'Nguyá»…n VÄƒn A lÃ m gÃ¬?' â†’ get_knowledge_context(query='Nguyá»…n VÄƒn A') â†’ Äá»c context â†’ Tráº£ lá»i 'Nguyá»…n VÄƒn A lÃ ...' | 'ThÃ´ng tin trong cÆ¡ sá»Ÿ dá»¯ liá»‡u vá» dá»± Ã¡n X?' â†’ get_knowledge_context(query='dá»± Ã¡n X') â†’ Äá»c context â†’ Tráº£ lá»i thÃ´ng tin dá»± Ã¡n X | 'TÃ i liá»‡u nÃ³i gÃ¬ vá» ABC?' â†’ get_knowledge_context(query='ABC') â†’ Äá»c context â†’ TÃ³m táº¯t ná»™i dung vá» ABC.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "CÃ¢u há»i/tá»« khÃ³a cáº§n tÃ¬m. TrÃ­ch keywords tá»« cÃ¢u há»i user. VD: User: 'Nguyá»…n VÄƒn A lÃ m gÃ¬?' â†’ query='Nguyá»…n VÄƒn A'. User: 'Dá»± Ã¡n X cÃ³ máº¥y giai Ä‘oáº¡n?' â†’ query='dá»± Ã¡n X giai Ä‘oáº¡n'. User: 'LÃª Trung Khoa lÃ  ai?' â†’ query='LÃª Trung Khoa'. CÃ ng Cá»¤ THá»‚ cÃ ng tá»‘t! Bao gá»“m TÃŠN RIÃŠNG trong query.",
                "required": False
            },
            "max_chars": {
                "type": "integer",
                "description": "Giá»›i háº¡n kÃ½ tá»± context (default: 10000). TÄƒng lÃªn 20000 náº¿u cáº§n nhiá»u thÃ´ng tin. Há»‡ thá»‘ng tá»± Ä‘á»™ng summarize náº¿u >2000 chars.",
                "required": False
            },
            "use_gemini_filter": {
                "type": "boolean",
                "description": "ğŸ”¥ Báº­t Gemini Smart Filter Ä‘á»ƒ lá»c thÃ´ng minh (default: False). Khi True: dÃ¹ng Gemini Flash AI Ä‘á»ƒ lá»c vÃ  chá»‰ tráº£ vá» content THá»°C Sá»° liÃªn quan, loáº¡i bá» noise. Recommend: True khi KB cÃ³ nhiá»u documents dÃ i.",
                "required": False
            }
        }
    },
    
    "doc_reader_gemini_rag": {
        "handler": doc_reader_gemini_rag,
        "description": "ğŸ“– RAG NÃ‚NG CAO - Äá»c, tÃ¬m kiáº¿m VÃ€ TRáº¢ Lá»œI Tá»° Äá»˜NG tá»« Knowledge Base báº±ng Gemini AI. Tool nÃ y Tá»° Äá»˜NG xá»­ lÃ½ toÃ n bá»™ quy trÃ¬nh: chunk documents â†’ semantic search â†’ generate response. âš¡ DÃ™NG KHI: User muá»‘n cÃ¢u tráº£ lá»i TRá»°C TIáº¾P thay vÃ¬ chá»‰ context. KhÃ¡c vá»›i get_knowledge_context (chá»‰ tráº£ context), tool nÃ y TRáº¢ Lá»œI LUÃ”N. VD: 'Há»i tÃ i liá»‡u vá» X', 'TÃ³m táº¯t thÃ´ng tin Y tá»« KB', 'Giáº£i thÃ­ch Z dá»±a trÃªn docs'. Há»— trá»£ semantic search (vector-like) cho Ä‘á»™ chÃ­nh xÃ¡c cao.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "CÃ¢u há»i Ä‘áº§y Ä‘á»§ cá»§a user. VD: 'Dá»± Ã¡n ABC cÃ³ bao nhiÃªu giai Ä‘oáº¡n?', 'Nguyá»…n VÄƒn A Ä‘áº£m nhiá»‡m vai trÃ² gÃ¬?'",
                "required": True
            },
            "chunk_size": {
                "type": "integer",
                "description": "KÃ­ch thÆ°á»›c má»—i chunk (default: 1024 chars). TÄƒng lÃªn 2048 cho documents dÃ i.",
                "required": False
            },
            "top_k": {
                "type": "integer",
                "description": "Sá»‘ lÆ°á»£ng chunks liÃªn quan nháº¥t Ä‘á»ƒ Ä‘Æ°a vÃ o context (default: 5). TÄƒng lÃªn 10 náº¿u cáº§n nhiá»u thÃ´ng tin hÆ¡n.",
                "required": False
            }
        }
    },
    
    # =====================================================
    # ï¿½ GEMINI FLASH SMART KB FILTER - Lá»ŒC THÃ”NG TIN AI
    # =====================================================
    
    "gemini_smart_kb_filter": {
        "handler": gemini_smart_kb_filter,
        "description": "ğŸ”¥âš¡ GEMINI FLASH Lá»ŒC THÃ”NG TIN THÃ”NG MINH - Sá»­ dá»¥ng sá»©c máº¡nh AI Gemini Flash Ä‘á»ƒ Lá»ŒC, TÃŒM KIáº¾M vÃ  TRÃCH XUáº¤T thÃ´ng tin CHÃNH XÃC tá»« Knowledge Base. Tool nÃ y LOáº I Bá» NOISE, chá»‰ tráº£ vá» content THá»°C Sá»° LIÃŠN QUAN. ğŸ¯ DÃ™NG KHI: 1) KB cÃ³ nhiá»u documents dÃ i, 2) Cáº§n lá»c chÃ­nh xÃ¡c thÃ´ng tin cá»¥ thá»ƒ, 3) Muá»‘n tÃ³m táº¯t/trÃ­ch xuáº¥t facts, 4) get_knowledge_context tráº£ vá» quÃ¡ nhiá»u noise. âš¡ Æ¯U ÄIá»‚M: Gemini AI Ä‘á»c vÃ  hiá»ƒu ngá»¯ cáº£nh, lá»c thÃ´ng minh hÆ¡n TF-IDF. Triggers: 'lá»c thÃ´ng tin', 'tÃ¬m chÃ­nh xÃ¡c', 'trÃ­ch xuáº¥t tá»« database', 'dÃ¹ng AI lá»c', 'smart search KB'. VD: 'DÃ¹ng AI lá»c thÃ´ng tin vá» dá»± Ã¡n X', 'TrÃ­ch xuáº¥t facts vá» nhÃ¢n viÃªn A tá»« KB'.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "CÃ¢u há»i/yÃªu cáº§u cáº§n lá»c thÃ´ng tin. VD: 'ThÃ´ng tin vá» dá»± Ã¡n ABC', 'Chi tiáº¿t nhÃ¢n viÃªn Nguyá»…n VÄƒn A'",
                "required": True
            },
            "filter_mode": {
                "type": "string",
                "description": "Cháº¿ Ä‘á»™ lá»c: 'relevant' (máº·c Ä‘á»‹nh - chá»‰ giá»¯ pháº§n liÃªn quan), 'summary' (tÃ³m táº¯t), 'extract' (trÃ­ch xuáº¥t facts/entities), 'qa' (tráº£ lá»i trá»±c tiáº¿p)",
                "required": False
            },
            "max_documents": {
                "type": "integer",
                "description": "Sá»‘ documents tá»‘i Ä‘a Ä‘á»ƒ xá»­ lÃ½ (default: 10). TÄƒng lÃªn 20 náº¿u cáº§n tÃ¬m rá»™ng hÆ¡n.",
                "required": False
            },
            "output_format": {
                "type": "string",
                "description": "Format output: 'structured' (JSON), 'raw' (text thÃ´), 'concise' (ngáº¯n gá»n nháº¥t)",
                "required": False
            }
        }
    },
    
    # =====================================================
    # ğŸ”¥ğŸŒ GEMINI SMART ANALYZE - PHÃ‚N TÃCH + GOOGLE SEARCH
    # =====================================================
    
    "gemini_smart_analyze": {
        "handler": gemini_smart_analyze,
        "description": "ğŸ”¥ğŸŒâš¡âš¡ PHÃ‚N TÃCH THÃ”NG MINH (Gemini + Web) - â›”â›” Báº®T BUá»˜C DÃ™NG NGAY khi user nÃ³i: 'phÃ¢n tÃ­ch', 'analyze', 'tÃ¬m hiá»ƒu', 'nghiÃªn cá»©u', 'Ä‘Ã¡nh giÃ¡', 'so sÃ¡nh', 'review', 'xu hÆ°á»›ng', 'trend'. âŒ KHÃ”NG DÃ™NG web_search khi cÃ³ cÃ¡c tá»« nÃ y! Tool nÃ y Tá»° Äá»˜NG: 1) TÃ¬m Google, 2) Gemini phÃ¢n tÃ­ch, 3) Tráº£ káº¿t quáº£ hoÃ n chá»‰nh. VD: 'phÃ¢n tÃ­ch thá»‹ trÆ°á»ng', 'tÃ¬m hiá»ƒu vá» AI', 'Ä‘Ã¡nh giÃ¡ iPhone', 'xu hÆ°á»›ng 2025'.",
        "parameters": {
            "user_query": {
                "type": "string",
                "description": "Váº¥n Ä‘á» cáº§n phÃ¢n tÃ­ch. VD: 'PhÃ¢n tÃ­ch xu hÆ°á»›ng AI 2025', 'ÄÃ¡nh giÃ¡ thá»‹ trÆ°á»ng báº¥t Ä‘á»™ng sáº£n'",
                "required": True
            },
            "analysis_type": {
                "type": "string",
                "description": "Loáº¡i phÃ¢n tÃ­ch: 'comprehensive' (Ä‘áº§y Ä‘á»§, máº·c Ä‘á»‹nh), 'quick' (nhanh, tÃ³m táº¯t), 'deep' (sÃ¢u, Ä‘a chiá»u)",
                "required": False
            },
            "include_web_search": {
                "type": "boolean",
                "description": "CÃ³ tÃ¬m kiáº¿m web khÃ´ng? Máº·c Ä‘á»‹nh True. Set False náº¿u chá»‰ cáº§n phÃ¢n tÃ­ch tá»« KB.",
                "required": False
            },
            "include_kb": {
                "type": "boolean",
                "description": "CÃ³ tÃ¬m trong Knowledge Base khÃ´ng? Máº·c Ä‘á»‹nh False. Set True Ä‘á»ƒ káº¿t há»£p cáº£ web + KB.",
                "required": False
            },
            "max_search_results": {
                "type": "integer",
                "description": "Sá»‘ káº¿t quáº£ web search tá»‘i Ä‘a (default: 8). TÄƒng lÃªn 15 náº¿u cáº§n nhiá»u nguá»“n hÆ¡n.",
                "required": False
            }
        }
    },
    
    # =====================================================
    # ğŸ” RAG SYSTEM - RETRIEVAL AUGMENTED GENERATION
    # =====================================================
    
    "web_search": {
        "handler": web_search if RAG_AVAILABLE else None,
        "description": "ğŸŒ TÃŒM KIáº¾M WEB ÄÆ N GIáº¢N - Chá»‰ dÃ¹ng cho cÃ¢u há»i Ä‘Æ¡n giáº£n: 'ai lÃ  tá»•ng thá»‘ng', 'giÃ¡ vÃ ng', 'thá»i tiáº¿t'. âš ï¸ Náº¾U user nÃ³i 'phÃ¢n tÃ­ch/tÃ¬m hiá»ƒu/Ä‘Ã¡nh giÃ¡/nghiÃªn cá»©u' â†’ DÃ™NG gemini_smart_analyze THAY VÃŒ tool nÃ y!",
        "parameters": {
            "query": {
                "type": "string",
                "description": "Tá»« khÃ³a tÃ¬m kiáº¿m (nÃªn thÃªm nÄƒm hoáº·c 'má»›i nháº¥t')",
                "required": True
            },
            "max_results": {
                "type": "integer",
                "description": "Sá»‘ káº¿t quáº£ tá»‘i Ä‘a (máº·c Ä‘á»‹nh 5)",
                "required": False
            }
        }
    },
    
    "get_realtime_info": {
        "handler": get_realtime_info if RAG_AVAILABLE else None,
        "description": "âš¡âš¡ THÃ”NG TIN THá»œI GIAN THá»°C - â›”â›” Báº®T BUá»˜C Gá»ŒI TRÆ¯á»šC Má»ŒI CÃ‚U TRáº¢ Lá»œI vá»: giÃ¡ cáº£, tá»· giÃ¡, thá»i tiáº¿t, ngÆ°á»i ná»•i tiáº¿ng, chá»©c vá»¥ hiá»‡n táº¡i, sá»± kiá»‡n Ä‘ang xáº£y ra. âŒ KHÃ”NG BAO GIá»œ tá»± tráº£ lá»i báº±ng kiáº¿n thá»©c cÅ©! âœ… Gá»ŒI TOOL NÃ€Y TRÆ¯á»šC â†’ nháº­n káº¿t quáº£ â†’ rá»“i tráº£ lá»i user.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "CÃ¢u há»i cáº§n thÃ´ng tin thá»i gian thá»±c",
                "required": True
            }
        }
    },
    
    "rag_search": {
        "handler": rag_search if RAG_AVAILABLE else None,
        "description": "ğŸ” RAG SEARCH HYBRID - TÃ¬m kiáº¿m Káº¾T Há»¢P tá»« Internet + TÃ i liá»‡u ná»™i bá»™. Tá»± Ä‘á»™ng chá»n nguá»“n phÃ¹ há»£p nháº¥t. sources='web' cho Internet, 'local' cho tÃ i liá»‡u ná»™i bá»™, 'hybrid' cho cáº£ hai, 'auto' Ä‘á»ƒ AI tá»± chá»n.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "CÃ¢u há»i hoáº·c tá»« khÃ³a tÃ¬m kiáº¿m",
                "required": True
            },
            "sources": {
                "type": "string",
                "description": "Nguá»“n: 'auto', 'web', 'local', 'hybrid' (máº·c Ä‘á»‹nh: auto)",
                "required": False
            },
            "max_results": {
                "type": "integer",
                "description": "Sá»‘ káº¿t quáº£ tá»‘i Ä‘a (máº·c Ä‘á»‹nh 8)",
                "required": False
            }
        }
    },
    
    "smart_answer": {
        "handler": smart_answer if RAG_AVAILABLE else None,
        "description": "ğŸ§  SMART ANSWER - AI tá»± Ä‘á»™ng phÃ¢n tÃ­ch cÃ¢u há»i vÃ  chá»n nguá»“n Tá»T NHáº¤T (Internet/TÃ i liá»‡u ná»™i bá»™/Hybrid) Ä‘á»ƒ tráº£ lá»i. DÃ¹ng khi khÃ´ng cháº¯c nguá»“n nÃ o phÃ¹ há»£p. Tool tráº£ vá» context Ä‘Ã£ tá»‘i Æ°u Ä‘á»ƒ tráº£ lá»i.",
        "parameters": {
            "query": {
                "type": "string",
                "description": "CÃ¢u há»i cá»§a user",
                "required": True
            }
        }
    }
}

# ============================================================
# MINIZ MCP CLIENT
# ============================================================

def get_vlc_context_for_llm() -> str:
    """Táº¡o context vá» VLC status Ä‘á»ƒ gá»­i cho LLM"""
    try:
        if vlc_player and vlc_player._player:
            status = vlc_player.get_full_status()
            is_playing = status.get('is_playing', False)
            current_track = status.get('current_track', 'KhÃ´ng cÃ³')
            volume = status.get('volume', 0)
            playlist_count = status.get('playlist_count', 0)
            
            context = f"""
ğŸ“ [PYTHON-VLC STATUS]
â€¢ Tráº¡ng thÃ¡i: {'â–¶ï¸ Äang phÃ¡t' if is_playing else 'â¸ï¸ Táº¡m dá»«ng/Dá»«ng'}
â€¢ BÃ i hiá»‡n táº¡i: {current_track}
â€¢ Ã‚m lÆ°á»£ng: {volume}%
â€¢ Playlist: {playlist_count} bÃ i
â€¢ Player: Python-VLC (ná»™i bá»™)

ğŸ¯ DÃ¹ng smart_music_control() cho má»i lá»‡nh nháº¡c!"""
            return context
        else:
            return """
ğŸ“ [PYTHON-VLC STATUS]
â€¢ Tráº¡ng thÃ¡i: â¹ï¸ ChÆ°a khá»Ÿi táº¡o/ChÆ°a phÃ¡t
â€¢ DÃ¹ng play_music() hoáº·c list_music() Ä‘á»ƒ báº¯t Ä‘áº§u phÃ¡t nháº¡c
â€¢ Player: Python-VLC (sáºµn sÃ ng)"""
    except:
        return ""

async def handle_xiaozhi_message(message: dict) -> dict:
    method = message.get("method")
    params = message.get("params", {})
    
    if method == "initialize":
        # Tráº£ vá» vá»›i instructions + VLC context
        vlc_context = get_vlc_context_for_llm()
        full_instructions = MUSIC_SYSTEM_PROMPT + vlc_context
        
        return {
            "protocolVersion": "2024-11-05", 
            "capabilities": {"tools": {}}, 
            "serverInfo": {"name": "xiaozhi-final", "version": "4.3.0"},
            "instructions": full_instructions
        }
    elif method == "tools/list":
        # Support cursor pagination (tá»« xiaozhi-esp32-server)
        cursor = params.get("cursor", "")
        tools = []
        for name, info in TOOLS.items():
            # Sanitize tool name Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i server chÃ­nh thá»©c
            sanitized_name = sanitize_tool_name(name) if 'sanitize_tool_name' in dir() else name
            # RÃºt gá»n description Máº NH Ä‘á»ƒ giáº£m message size (fix "message too big" error)
            description = info["description"]
            if len(description) > 100:
                description = description[:97] + "..."
            
            tool = {
                "name": name,  # Giá»¯ nguyÃªn tÃªn gá»‘c Ä‘á»ƒ handler hoáº¡t Ä‘á»™ng
                "description": description, 
                "inputSchema": {"type": "object", "properties": {}, "required": []}
            }
            for pname, pinfo in info["parameters"].items():
                # RÃºt gá»n parameter description Máº NH
                param_desc = pinfo["description"]
                if len(param_desc) > 80:
                    param_desc = param_desc[:77] + "..."
                
                tool["inputSchema"]["properties"][pname] = {"type": pinfo["type"], "description": param_desc}
                if pinfo.get("required"):
                    tool["inputSchema"]["required"].append(pname)
            tools.append(tool)
        
        # Log sá»‘ lÆ°á»£ng tools
        print(f"ğŸ“‹ [tools/list] Returning {len(tools)} tools to robot")
        
        # Response theo format chuáº©n vá»›i optional nextCursor
        return {"tools": tools}  # nextCursor sáº½ Ä‘Æ°á»£c thÃªm náº¿u cáº§n pagination
    elif method == "tools/call":
        tool_name = params.get("name")
        args = params.get("arguments", {})
        print(f"ğŸ”§ [Tool Call] {tool_name} with args: {args}")
        
        # LÆ°u tool call vÃ o history
        add_to_conversation(
            role="tool",
            content=f"Tool: {tool_name}",
            metadata={
                "tool_name": tool_name,
                "arguments": args,
                "event_type": "tool_call"
            }
        )
        
        if tool_name not in TOOLS:
            error_msg = f"Error: Tool '{tool_name}' not found"
            print(f"âŒ {error_msg}")
            add_to_conversation(role="tool", content=error_msg, metadata={"error": True})
            return {"content": [{"type": "text", "text": error_msg}], "isError": True}
        
        # Retry mechanism (tá»« xiaozhi-esp32-server)
        max_retries = MAX_TOOL_RETRIES
        retry_interval = TOOL_RETRY_INTERVAL
        last_error = None
        
        for attempt in range(max_retries):
            try:
                result = await TOOLS[tool_name]["handler"](**args)
                print(f"âœ… [Tool Result] {tool_name}: {result}")
                
                # ThÃªm VLC context vÃ o music-related tools
                music_tools = ['smart_music_control', 'play_music', 'pause_music', 'resume_music', 
                              'stop_music', 'music_next', 'music_previous', 'music_volume', 
                              'get_music_status', 'list_music', 'search_music', 'detect_and_execute_music']
                if tool_name in music_tools:
                    result["_vlc_hint"] = "ğŸµ Äang dÃ¹ng Python-VLC Player ná»™i bá»™. Tiáº¿p tá»¥c dÃ¹ng smart_music_control() cho cÃ¡c lá»‡nh nháº¡c tiáº¿p theo."
                
                # LÆ°u tool result vÃ o history
                add_to_conversation(
                    role="tool",
                    content=json.dumps(result, ensure_ascii=False),
                    metadata={
                        "tool_name": tool_name,
                        "success": result.get("success", True),
                        "event_type": "tool_result",
                        "attempt": attempt + 1
                    }
                )
                
                # âš¡ Äáº¶C BIá»†T: Vá»›i get_knowledge_context, tráº£ vá» context trá»±c tiáº¿p Ä‘á»ƒ LLM dá»… Ä‘á»c
                if tool_name == "get_knowledge_context" and isinstance(result, dict):
                    if result.get("success") and result.get("context"):
                        # Tráº£ vá» context trá»±c tiáº¿p - LLM Ä‘á»c vÃ  tráº£ lá»i ngay (giá»›i háº¡n 2000 kÃ½ tá»±)
                        truncated_context = smart_truncate_for_llm(result["context"], MAX_LLM_RESPONSE_CHARS)
                        return {"content": [{"type": "text", "text": truncated_context}]}
                    elif not result.get("success"):
                        # KhÃ´ng tÃ¬m tháº¥y â†’ tráº£ vá» message lá»—i
                        error_msg = result.get("error", "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong cÆ¡ sá»Ÿ dá»¯ liá»‡u")
                        return {"content": [{"type": "text", "text": f"âŒ {error_msg}"}]}
                
                # âš¡ Äáº¶C BIá»†T: Vá»›i ask_gemini, ask_gpt4, gemini_smart_analyze - tráº£ vá» response text cho LLM cloud tá»•ng há»£p
                # Giá»‘ng cÃ¡ch web_search hoáº¡t Ä‘á»™ng: tráº£ data Ä‘áº§y Ä‘á»§ â†’ LLM cloud Tá»° TÃ“M Táº®T â†’ robot nÃ³i
                if tool_name in ["ask_gemini", "ask_gpt4", "gemini_smart_analyze"] and isinstance(result, dict):
                    if result.get("success") and result.get("response_text"):
                        response_text = result["response_text"]
                        # Clean markdown Ä‘á»ƒ LLM dá»… Ä‘á»c (nhÆ°ng KHÃ”NG truncate - Ä‘á»ƒ LLM cloud tá»± tÃ³m táº¯t)
                        response_text = clean_markdown_for_tts(response_text)
                        print(f"[{tool_name}] Cleaned response: {len(response_text)} chars (LLM cloud sáº½ tÃ³m táº¯t)")
                        # Tráº£ vá» TEXT trá»±c tiáº¿p, LLM cloud sáº½ tá»± tÃ³m táº¯t trÆ°á»›c khi robot nÃ³i
                        return {
                            "content": [{"type": "text", "text": response_text}]
                        }
                
                # ğŸ”„ TRUNCATE: Giá»›i háº¡n response dÆ°á»›i 2000 kÃ½ tá»± cho LLM
                formatted_response = format_result_for_llm(result, MAX_LLM_RESPONSE_CHARS)
                return {"content": [{"type": "text", "text": formatted_response}]}
            except Exception as e:
                last_error = e
                if attempt < max_retries - 1:
                    print(f"âš ï¸ [Tool Retry] {tool_name} failed (attempt {attempt + 1}/{max_retries}): {e}")
                    await asyncio.sleep(retry_interval)
                else:
                    error_msg = f"Error calling {tool_name} after {max_retries} attempts: {str(e)}"
                    print(f"âŒ {error_msg}")
                    import traceback
                    traceback.print_exc()
                    add_to_conversation(role="tool", content=error_msg, metadata={"error": True})
                    return {"content": [{"type": "text", "text": error_msg}], "isError": True}
    return {"error": f"Unknown method: {method}"}

async def xiaozhi_websocket_client(device_index: int = 0):
    """WebSocket client for a specific device (0, 1, or 2)"""
    global xiaozhi_connections, xiaozhi_connected, should_reconnect
    retry = 0
    
    # ===== OPTIMIZED CONNECTION SETTINGS =====
    INITIAL_DELAY = 1        # Delay ban Ä‘áº§u 1s (giáº£m tá»« 2s)
    MAX_DELAY = 15           # Max delay 15s (giáº£m tá»« 60s)
    CONNECT_TIMEOUT = 10     # Timeout káº¿t ná»‘i 10s
    FAST_RETRY_COUNT = 3     # Sá»‘ láº§n fast retry Ä‘áº§u tiÃªn
    FAST_RETRY_DELAY = 0.5   # Delay 0.5s cho fast retry
    AUTO_SWITCH_THRESHOLD = 5  # Sau 5 láº§n tháº¥t báº¡i, thá»­ endpoint khÃ¡c
    
    while True:
        try:
            ep = endpoints_config[device_index]
            if not ep.get("enabled") or not ep.get("token"):
                # Thiáº¿t bá»‹ nÃ y chÆ°a cÃ³ token, chá» vÃ  thá»­ láº¡i
                await asyncio.sleep(10)
                continue
            
            ws_url = f"wss://api.xiaozhi.me/mcp/?token={ep['token']}"
            retry += 1
            
            # Fast retry cho 3 láº§n Ä‘áº§u, sau Ä‘Ã³ dÃ¹ng exponential backoff
            if retry <= FAST_RETRY_COUNT:
                print(f"ğŸ“¡ [Xiaozhi] Fast connecting {ep['name']}... ({retry}/{FAST_RETRY_COUNT})")
            else:
                print(f"ğŸ“¡ [Xiaozhi] Connecting {ep['name']}... (retry {retry})")
            
            # Sá»­ dá»¥ng asyncio.wait_for Ä‘á»ƒ cÃ³ timeout
            async with websockets.connect(
                ws_url, 
                ping_interval=20, 
                ping_timeout=10,
                close_timeout=5,
                open_timeout=CONNECT_TIMEOUT,  # Timeout má»Ÿ káº¿t ná»‘i
                max_size=10 * 1024 * 1024  # 10MB limit (default is 1MB) - fix "message too big"
            ) as ws:
                xiaozhi_connections[device_index] = ws
                xiaozhi_connected[device_index] = True
                should_reconnect[device_index] = False  # Reset flag khi káº¿t ná»‘i thÃ nh cÃ´ng
                retry = 0  # Reset retry counter khi káº¿t ná»‘i thÃ nh cÃ´ng
                print(f"âœ… [Xiaozhi] Connected! ({ep['name']}) [Device {device_index + 1}]")
                
                # Batch broadcast káº¿t ná»‘i - táº¡o tasks vÃ  cháº¡y parallel
                broadcast_msg = {"type": "endpoint_connected", "endpoint": ep['name'], "index": device_index}
                tasks = []
                for conn in active_connections:
                    tasks.append(asyncio.create_task(conn.send_json(broadcast_msg)))
                # Cháº¡n táº¥t cáº£ broadcasts cÃ¹ng lÃºc
                await asyncio.gather(*tasks, return_exceptions=True)
                
                init_msg = {"jsonrpc": "2.0", "method": "initialize", "params": {"protocolVersion": "2024-11-05", "capabilities": {}, "clientInfo": {"name": "xiaozhi-final", "version": "4.3.0"}}, "id": 1}
                
                # KhÃ´ng log initialize request - chá»‰ log tool calls thá»±c sá»±
                
                await ws.send(json.dumps(init_msg))
                
                async for msg in ws:
                    # Kiá»ƒm tra náº¿u cáº§n reconnect (user Ä‘Ã£ chuyá»ƒn thiáº¿t bá»‹)
                    if should_reconnect[device_index]:
                        print(f"ğŸ”„ [Xiaozhi] Reconnecting {ep['name']}...")
                        await ws.close()
                        break
                    
                    try:
                        data = json.loads(msg)
                        method = data.get("method", "unknown")
                        if method != "ping":
                            print(f"ğŸ“¨ [{method}]")
                        
                        response = await handle_xiaozhi_message(data)
                        
                        # CHá»ˆ log conversation thá»±c sá»± (tools/call), KHÃ”NG log MCP protocol messages
                        # Bá» qua: initialize, notifications/initialized, tools/list
                        if method == "tools/call" and method != "ping":
                            # Láº¥y thÃ´ng tin tool
                            params = data.get("params", {})
                            tool_name = params.get("name", "unknown")
                            tool_args = params.get("arguments", {})
                            
                            # Táº¡o ná»™i dung dá»… Ä‘á»c tá»« tool arguments
                            user_message = format_tool_request(tool_name, tool_args)
                            
                            # Log tool call request
                            add_to_conversation(
                                role="user",
                                content=user_message,
                                metadata={
                                    "source": "mcp",
                                    "method": method,
                                    "tool_name": tool_name,
                                    "tool_arguments": tool_args,
                                    "endpoint": ep['name']
                                }
                            )
                            
                            # Táº¡o ná»™i dung response dá»… Ä‘á»c
                            assistant_message = format_tool_response(tool_name, response)
                            
                            # Log tool call response
                            add_to_conversation(
                                role="assistant",
                                content=assistant_message,
                                metadata={
                                    "source": "mcp",
                                    "method": method,
                                    "tool_name": tool_name,
                                    "response_data": response,
                                    "success": not isinstance(response, dict) or not response.get("isError")
                                }
                            )
                        
                        await ws.send(json.dumps({"jsonrpc": "2.0", "id": data.get("id"), "result": response}))

                        # If the tool response suggests a next_action (for example list_music
                        # returning {'next_action': {'tool': 'play_music', 'parameters': {...}}}),
                        # execute it locally on the server as a fallback so music actually plays
                        # even if the remote AI/client doesn't invoke the follow-up.
                        try:
                            if isinstance(response, dict) and response.get("next_action"):
                                na = response.get("next_action")
                                next_tool = na.get("tool")
                                next_params = na.get("parameters", {}) or {}
                                # Only execute if the tool exists locally
                                if next_tool and next_tool in TOOLS:
                                    print(f"â¯ï¸ [Auto Action] Executing suggested next_action {next_tool} with params: {next_params}")
                                    try:
                                        # call the handler (handlers may be async)
                                        handler = TOOLS[next_tool]["handler"]
                                        if asyncio.iscoroutinefunction(handler):
                                            res2 = await handler(**next_params)
                                        else:
                                            # run sync handlers in executor
                                            loop = asyncio.get_event_loop()
                                            res2 = await loop.run_in_executor(None, lambda: handler(**next_params))
                                        print(f"â¯ï¸ [Auto Action Result] {next_tool}: {res2}")
                                    except Exception as e:
                                        print(f"âŒ [Auto Action] Error executing {next_tool}: {e}")
                                        import traceback
                                        traceback.print_exc()
                        except Exception:
                            # defensive: do not let auto-action failures disrupt websocket loop
                            import traceback
                            traceback.print_exc()
                        
                        # Batch broadcast - chá»‰ broadcast cho methods quan trá»ng
                        if method in ["tools/call", "initialize"]:
                            broadcast_msg = {"type": "xiaozhi_activity", "method": method, "timestamp": datetime.now().isoformat()}
                            # Cleanup dead connections trÆ°á»›c khi broadcast
                            dead_connections = []
                            for conn in active_connections:
                                try:
                                    await conn.send_json(broadcast_msg)
                                except Exception:
                                    dead_connections.append(conn)
                            # Remove dead connections
                            for conn in dead_connections:
                                active_connections.remove(conn)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ [Xiaozhi] JSON decode error: {e}")
                    except Exception as e:
                        print(f"âš ï¸ [Xiaozhi] Message handling error: {e}")
        except asyncio.CancelledError:
            print(f"âš ï¸ [Xiaozhi] Task cancelled ({ep['name']})")
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            break
        except websockets.exceptions.WebSocketException as e:
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            # Fast retry cho 3 láº§n Ä‘áº§u
            if retry <= FAST_RETRY_COUNT:
                wait = FAST_RETRY_DELAY
            else:
                # Exponential backoff vá»›i max 15s
                wait = min(INITIAL_DELAY * (2 ** min(retry - FAST_RETRY_COUNT, 4)), MAX_DELAY)
            print(f"âŒ [Xiaozhi] WebSocket error ({ep['name']}): {e} (retry in {wait}s)")
            await asyncio.sleep(wait)
        except Exception as e:
            xiaozhi_connected[device_index] = False
            xiaozhi_connections[device_index] = None
            # Fast retry cho 3 láº§n Ä‘áº§u
            if retry <= FAST_RETRY_COUNT:
                wait = FAST_RETRY_DELAY
            else:
                wait = min(INITIAL_DELAY * (2 ** min(retry - FAST_RETRY_COUNT, 4)), MAX_DELAY)
            print(f"âŒ [Xiaozhi] Error ({ep['name']}): {e} (retry in {wait}s)")
            await asyncio.sleep(wait)

# ============================================================
# FASTAPI WEB SERVER
# ============================================================

app = FastAPI(title="miniZ MCP", version="4.3.0")

class VolumeRequest(BaseModel):
    level: int

class NotificationRequest(BaseModel):
    title: str
    message: str

class CalculatorRequest(BaseModel):
    expression: str

@app.get("/", response_class=HTMLResponse)
async def index():
    html = r"""
<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸš€ miniZ MCP - Äiá»u Khiá»ƒn MÃ¡y TÃ­nh</title>
    <style>
        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; display: flex; }
        
        /* SIDEBAR */
        .sidebar { width: 280px; background: #1a1a2e; color: white; padding: 30px 20px; display: flex; flex-direction: column; box-shadow: 2px 0 20px rgba(0,0,0,0.3); }
        .logo { 
            font-size: 1.5em; 
            font-weight: bold; 
            margin-bottom: 40px; 
            text-align: center; 
            padding: 20px 15px; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
            border-radius: 15px;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 10px;
        }
        .logo-icon {
            width: 120px;
            height: auto;
            filter: drop-shadow(0 4px 8px rgba(0,0,0,0.3));
            transition: transform 0.3s;
        }
        .logo-icon:hover {
            transform: scale(1.05);
        }
        .logo-text {
            font-size: 1.8em;
            font-weight: 900;
            letter-spacing: 2px;
            color: #ff9a8b;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .menu-item { padding: 15px 20px; margin: 8px 0; border-radius: 10px; cursor: pointer; transition: all 0.3s; display: flex; align-items: center; gap: 12px; font-size: 1.05em; }
        .menu-item:hover { background: rgba(102, 126, 234, 0.2); transform: translateX(5px); }
        .menu-item.active { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4); }
        
        /* MAIN CONTENT */
        .main-content { flex: 1; padding: 30px; overflow-y: auto; }
        .header { background: white; border-radius: 15px; padding: 25px 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); display: flex; justify-content: space-between; align-items: center; }
        .header h1 { color: #667eea; font-size: 2em; }
        .status { display: flex; gap: 20px; }
        .status-badge { padding: 8px 20px; border-radius: 20px; font-weight: 600; display: flex; align-items: center; gap: 8px; }
        .status-badge.online { background: #d4edda; color: #155724; }
        .status-badge.offline { background: #f8d7da; color: #721c24; }
        .status-dot { width: 10px; height: 10px; border-radius: 50%; background: currentColor; animation: pulse 2s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        
        /* QUICK ACTIONS */
        .quick-actions { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }
        .action-card { background: white; padding: 25px; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.1); cursor: pointer; transition: all 0.3s; text-align: center; }
        .action-card:hover { transform: translateY(-5px); box-shadow: 0 15px 40px rgba(0,0,0,0.2); }
        .action-card.blue { border-left: 5px solid #3b82f6; }
        .action-card.green { border-left: 5px solid #10b981; }
        .action-card.orange { border-left: 5px solid #f59e0b; }
        .action-card.red { border-left: 5px solid #ef4444; }
        .action-card.purple { border-left: 5px solid #8b5cf6; }
        .action-card.cyan { border-left: 5px solid #06b6d4; }
        .action-card.pink { border-left: 5px solid #ec4899; }
        .action-card.indigo { border-left: 5px solid #6366f1; }
        .action-card .icon { font-size: 2.5em; margin-bottom: 10px; }
        .action-card .title { font-weight: 600; color: #333; font-size: 1.1em; }
        
        /* TOOLS SECTION */
        .tools-section { background: white; border-radius: 15px; padding: 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .tools-tabs { display: flex; gap: 15px; margin-bottom: 25px; border-bottom: 2px solid #e5e7eb; padding-bottom: 15px; }
        .tab-btn { padding: 12px 30px; border: none; border-radius: 10px 10px 0 0; background: transparent; color: #666; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .tab-btn:hover { background: rgba(102, 126, 234, 0.1); color: #667eea; }
        .tab-btn.active { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; box-shadow: 0 -4px 15px rgba(102, 126, 234, 0.3); }
        .tab-content { display: none; }
        .tab-content.active { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }
        
        /* TOOL CARDS */
        .tool-card { background: #f9fafb; padding: 25px; border-radius: 12px; border: 2px solid #e5e7eb; }
        .tool-card h3 { color: #667eea; margin-bottom: 15px; font-size: 1.2em; display: flex; align-items: center; gap: 10px; }
        .tool-card input, .tool-card select, .tool-card textarea { width: 100%; padding: 12px; margin-top: 10px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; }
        .tool-card button { width: 100%; padding: 14px; margin-top: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .tool-card button:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4); }
        
        /* CONFIG SECTION */
        .config-section { background: white; border-radius: 15px; padding: 30px; margin-bottom: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.2); }
        .device-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-top: 20px; }
        .device-card { background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb; }
        .device-card.active { border-color: #10b981; background: #d4edda; }
        .device-card h4 { color: #667eea; margin-bottom: 15px; display: flex; align-items: center; gap: 10px; }
        .device-card input { width: 100%; padding: 10px; margin-top: 8px; border: 2px solid #e5e7eb; border-radius: 6px; }
        .device-card button { padding: 10px 20px; margin-top: 10px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; }
        
        /* LOG */
        .log-panel { background: #1a1a2e; color: white; border-radius: 15px; padding: 25px; max-height: 400px; overflow-y: auto; font-family: 'Courier New', monospace; box-shadow: 0 10px 30px rgba(0,0,0,0.12); }
        .log-entry { padding: 8px; margin: 5px 0; border-left: 3px solid #667eea; background: rgba(102, 126, 234, 0.1); border-radius: 4px; }
        .log-time { color: #9ca3af; margin-right: 10px; }
        
        /* MUSIC PLAYER */
        .music-player { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 20px; padding: 30px; color: white; margin-bottom: 30px; box-shadow: 0 15px 40px rgba(102, 126, 234, 0.4); }
        .player-controls { display: flex; justify-content: center; align-items: center; gap: 20px; margin: 30px 0; }
        .player-btn { width: 60px; height: 60px; border-radius: 50%; background: rgba(255,255,255,0.2); border: 3px solid rgba(255,255,255,0.4); color: white; font-size: 24px; cursor: pointer; transition: all 0.3s; display: flex; align-items: center; justify-content: center; backdrop-filter: blur(10px); }
        .player-btn:hover { background: rgba(255,255,255,0.3); transform: scale(1.1); box-shadow: 0 8px 25px rgba(0,0,0,0.3); }
        .player-btn.play { width: 80px; height: 80px; font-size: 32px; background: white; color: #667eea; }
        .now-playing { text-align: center; margin: 20px 0; }
        .now-playing h3 { font-size: 1.5em; margin-bottom: 10px; text-shadow: 0 2px 10px rgba(0,0,0,0.3); }
        .now-playing p { opacity: 0.9; font-size: 1.1em; }
        .progress-container { margin: 25px 0; }
        .progress-bar { width: 100%; height: 8px; background: rgba(255,255,255,0.3); border-radius: 10px; overflow: hidden; cursor: pointer; }
        .progress-fill { height: 100%; background: white; width: 0%; transition: width 0.3s; box-shadow: 0 0 10px rgba(255,255,255,0.5); }
        .progress-time { display: flex; justify-content: space-between; margin-top: 8px; font-size: 0.9em; opacity: 0.9; }
        /* Progress slider (draggable timeline) */
        #progress-slider { -webkit-appearance: none; width: 100%; height: 8px; border-radius: 4px; cursor: pointer; }
        #progress-slider::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; box-shadow: 0 2px 6px rgba(102,126,234,0.5); transition: transform 0.2s; }
        #progress-slider::-webkit-slider-thumb:hover { transform: scale(1.2); }
        #progress-slider::-moz-range-thumb { width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; border: none; }
        .music-list { background: white; border-radius: 15px; padding: 25px; color: #333; max-height: 500px; overflow-y: auto; }
        .music-list h3 { color: #667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px; }
        .music-item { display: flex; align-items: center; padding: 15px; margin: 10px 0; background: #f9fafb; border-radius: 10px; cursor: pointer; transition: all 0.2s ease; border: 2px solid transparent; }
        .music-item:hover { background: #e8eaf6; border-color: #667eea; transform: translateX(3px); box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15); }
        .music-item:hover .play-btn-hover { opacity: 1 !important; }
        
        /* Wave animation for now playing indicator */
        @keyframes wave1 { 0%, 100% { height: 12px; } 50% { height: 20px; } }
        @keyframes wave2 { 0%, 100% { height: 18px; } 50% { height: 8px; } }
        @keyframes wave3 { 0%, 100% { height: 15px; } 50% { height: 22px; } }
        .music-item.playing { background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%); border-color: #667eea; }
        .music-item .icon { font-size: 24px; margin-right: 15px; }
        .music-item .info { flex: 1; }
        .music-item .name { font-weight: 600; color: #333; font-size: 1.05em; }
        .music-item .details { color: #666; font-size: 0.9em; margin-top: 5px; }
        .log-success { color: #10b981; border-left-color: #10b981; }
        .log-error { color: #ef4444; border-left-color: #ef4444; }
        .log-info { color: #3b82f6; border-left-color: #3b82f6; }
        
        /* LLM CHAT STYLES */
        .quick-msg-btn {
            padding: 8px 14px;
            background: #f3f4f6;
            border: 1px solid #e5e7eb;
            border-radius: 20px;
            font-size: 0.85em;
            cursor: pointer;
            transition: all 0.2s;
        }
        .quick-msg-btn:hover {
            background: #10b981;
            color: white;
            border-color: #10b981;
            transform: translateY(-2px);
        }
        .llm-message {
            max-width: 80%;
            padding: 12px 16px;
            border-radius: 15px;
            position: relative;
            word-wrap: break-word;
        }
        .llm-message.user {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            color: white;
            margin-left: auto;
            border-bottom-right-radius: 5px;
        }
        .llm-message.assistant {
            background: white;
            color: #333;
            margin-right: auto;
            border-bottom-left-radius: 5px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .llm-message .time {
            font-size: 0.75em;
            opacity: 0.7;
            margin-top: 5px;
            display: block;
        }
        .llm-message .device-tag {
            font-size: 0.7em;
            background: rgba(255,255,255,0.2);
            padding: 2px 8px;
            border-radius: 10px;
            margin-left: 8px;
        }
        .llm-message.assistant .device-tag {
            background: rgba(16,185,129,0.1);
            color: #10b981;
        }
        .llm-typing {
            display: flex;
            gap: 4px;
            padding: 15px;
        }
        .llm-typing span {
            width: 8px;
            height: 8px;
            background: #10b981;
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }
        .llm-typing span:nth-child(2) { animation-delay: 0.2s; }
        .llm-typing span:nth-child(3) { animation-delay: 0.4s; }
        @keyframes typing {
            0%, 60%, 100% { transform: translateY(0); opacity: 0.4; }
            30% { transform: translateY(-10px); opacity: 1; }
        }
        
        /* SETTINGS ICON */
        .settings-icon { font-size: 1.8em; cursor: pointer; transition: all 0.3s; padding: 10px; border-radius: 50%; background: #f0f0f0; display: flex; align-items: center; justify-content: center; width: 50px; height: 50px; }
        .settings-icon:hover { transform: rotate(90deg); background: #667eea; color: white; }
        
        /* MODAL POPUP */
        .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.5); animation: fadeIn 0.3s; }
        .modal-content { background: white; margin: 5% auto; padding: 0; border-radius: 15px; width: 90%; max-width: 500px; box-shadow: 0 20px 60px rgba(0,0,0,0.3); animation: slideDown 0.3s; }
        .modal-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px 30px; border-radius: 15px 15px 0 0; display: flex; justify-content: space-between; align-items: center; }
        .modal-header h2 { margin: 0; font-size: 1.5em; }
        .close-btn { font-size: 2em; cursor: pointer; color: white; background: none; border: none; line-height: 1; transition: transform 0.2s; }
        .close-btn:hover { transform: scale(1.2); }
        .modal-body { padding: 30px; }
        .modal-body label { display: block; margin-bottom: 8px; font-weight: 600; color: #333; }
        .modal-body input { width: 100%; padding: 12px; margin-bottom: 20px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; transition: border-color 0.3s; }
        .modal-body input:focus { outline: none; border-color: #667eea; }
        
        /* API KEY INPUT CONTAINER */
        .api-key-input-container { position: relative; margin-bottom: 20px; }
        .api-key-input-container input { padding-right: 90px; margin-bottom: 0; font-family: monospace; letter-spacing: 1px; }
        .api-key-input-container .input-icons { position: absolute; right: 8px; top: 50%; transform: translateY(-50%); display: flex; gap: 5px; align-items: center; }
        .api-key-icon-btn { background: transparent; border: none; cursor: pointer; padding: 8px; border-radius: 6px; display: flex; align-items: center; justify-content: center; transition: all 0.2s; font-size: 18px; color: #666; }
        .api-key-icon-btn:hover { background: rgba(102, 126, 234, 0.1); color: #667eea; transform: scale(1.1); }
        .api-key-icon-btn:active { transform: scale(0.95); }
        .api-key-icon-btn.copied { color: #10b981; animation: copySuccess 0.3s; }
        @keyframes copySuccess { 0%, 100% { transform: scale(1); } 50% { transform: scale(1.2); } }
        .modal-footer { padding: 20px 30px; background: #f9fafb; border-radius: 0 0 15px 15px; display: flex; gap: 15px; justify-content: flex-end; }
        .modal-btn { padding: 12px 30px; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; transition: all 0.3s; font-size: 1em; }
        .modal-btn.primary { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; }
        .modal-btn.primary:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4); }
        .modal-btn.secondary { background: #e5e7eb; color: #666; }
        .modal-btn.secondary:hover { background: #d1d5db; }
        .modal-btn.info { background: linear-gradient(135deg, #17a2b8 0%, #138496 100%); color: white; }
        .modal-btn.info:hover { transform: translateY(-2px); box-shadow: 0 8px 20px rgba(23, 162, 184, 0.4); }
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
        @keyframes slideDown { from { transform: translateY(-50px); opacity: 0; } to { transform: translateY(0); opacity: 1; } }
        
        /* AUDIO VISUALIZER - SÃ³ng nháº¡c Ä‘áº¹p */
        .audio-visualizer {
            display: flex;
            align-items: flex-end;
            justify-content: center;
            gap: 3px;
            height: 40px;
            margin: 10px 0;
        }
        .audio-visualizer .bar {
            width: 4px;
            background: linear-gradient(to top, #667eea, #764ba2, #f472b6);
            border-radius: 2px;
            animation: visualizer-bar 0.5s ease-in-out infinite;
        }
        .audio-visualizer .bar:nth-child(1) { animation-delay: 0s; height: 20px; }
        .audio-visualizer .bar:nth-child(2) { animation-delay: 0.1s; height: 30px; }
        .audio-visualizer .bar:nth-child(3) { animation-delay: 0.15s; height: 25px; }
        .audio-visualizer .bar:nth-child(4) { animation-delay: 0.3s; height: 35px; }
        .audio-visualizer .bar:nth-child(5) { animation-delay: 0.2s; height: 28px; }
        .audio-visualizer .bar:nth-child(6) { animation-delay: 0.25s; height: 32px; }
        .audio-visualizer .bar:nth-child(7) { animation-delay: 0.05s; height: 22px; }
        .audio-visualizer .bar:nth-child(8) { animation-delay: 0.35s; height: 38px; }
        .audio-visualizer .bar:nth-child(9) { animation-delay: 0.1s; height: 26px; }
        .audio-visualizer .bar:nth-child(10) { animation-delay: 0.4s; height: 30px; }
        .audio-visualizer.paused .bar { animation-play-state: paused; }
        @keyframes visualizer-bar {
            0%, 100% { transform: scaleY(0.3); opacity: 0.6; }
            50% { transform: scaleY(1); opacity: 1; }
        }
        
        /* RUNCAT ANIMATION - JavaScript-based multi-frame like RunCat365 */
        #runcat-container {
            position: fixed;
            bottom: 15px;
            right: 15px;
            z-index: 9999;
            user-select: none;
            cursor: pointer;
        }
        
        #runcat {
            font-size: 52px;
            display: inline-block;
            filter: drop-shadow(0 3px 6px rgba(0,0,0,0.25));
            transition: transform 0.05s ease-out;
            will-change: transform;
        }
        
        #runcat:hover {
            animation: runcat-excited 0.15s ease-in-out infinite !important;
            filter: drop-shadow(0 6px 12px rgba(0,0,0,0.4));
        }
        
        @keyframes runcat-excited {
            0%, 100% { 
                transform: translateY(-2px) rotate(-8deg) scale(1.2) !important;
            }
            25% { 
                transform: translateY(-12px) rotate(8deg) scale(1.3) !important;
            }
            50% { 
                transform: translateY(-18px) rotate(-8deg) scale(1.25) !important;
            }
            75% { 
                transform: translateY(-12px) rotate(8deg) scale(1.3) !important;
            }
        }
        
        /* FOOTER MINIZ - Compact corner style */
        .footer-miniz { position: fixed; bottom: 20px; right: 20px; background: rgba(26, 26, 46, 0.95); color: white; padding: 12px 18px; border-radius: 50px; box-shadow: 0 5px 25px rgba(0,0,0,0.3); display: flex; align-items: center; gap: 12px; z-index: 1000; transition: all 0.3s; backdrop-filter: blur(10px); }
        .footer-miniz:hover { transform: translateY(-3px); box-shadow: 0 8px 35px rgba(102, 126, 234, 0.5); }
        .footer-logo-compact { display: flex; align-items: center; gap: 10px; }
        .footer-logo-compact img { width: 35px; height: 35px; border-radius: 50%; border: 2px solid #667eea; box-shadow: 0 0 10px rgba(102, 126, 234, 0.6); }
        .footer-brand-compact { font-size: 0.95em; font-weight: bold; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text; }
        .footer-separator { width: 1px; height: 25px; background: rgba(255,255,255,0.3); }
        .footer-youtube-compact { display: flex; align-items: center; gap: 6px; padding: 8px 15px; background: #FF0000; color: white; border-radius: 25px; text-decoration: none; font-weight: 600; font-size: 0.85em; transition: all 0.3s; }
        .footer-youtube-compact:hover { background: #cc0000; transform: scale(1.05); }
        .footer-youtube-compact svg { width: 18px; height: 18px; fill: white; }
        
        /* RESPONSIVE - MOBILE FIRST */
        @media (max-width: 1200px) {
            .quick-actions { grid-template-columns: repeat(auto-fit, minmax(160px, 1fr)); gap: 15px; }
            .tab-content.active { grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); }
            .device-grid { grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); }
        }
        
        @media (max-width: 992px) {
            .sidebar { width: 240px; padding: 20px 15px; }
            .main-content { padding: 20px; }
            .header { padding: 20px; flex-direction: column; gap: 15px; text-align: center; }
            .header h1 { font-size: 1.6em; }
            .music-player { padding: 20px; }
            .player-controls { gap: 15px; }
            .player-btn { width: 50px; height: 50px; font-size: 20px; }
            .player-btn.play { width: 65px; height: 65px; font-size: 26px; }
        }
        
        @media (max-width: 768px) {
            body { flex-direction: column; }
            .sidebar { width: 100%; padding: 15px; flex-direction: row; flex-wrap: wrap; justify-content: center; gap: 10px; }
            .logo { width: 100%; margin-bottom: 15px; padding: 15px; }
            .logo-icon { width: 60px; }
            .logo-text { font-size: 1.2em; }
            .menu-item { padding: 10px 15px; margin: 3px; font-size: 0.9em; }
            .main-content { padding: 15px; min-height: calc(100vh - 200px); }
            .header { padding: 15px; margin-bottom: 20px; }
            .header h1 { font-size: 1.3em; }
            .status { flex-wrap: wrap; justify-content: center; gap: 10px; }
            .status-badge { padding: 6px 15px; font-size: 0.9em; }
            .quick-actions { grid-template-columns: repeat(2, 1fr); gap: 10px; }
            .action-card { padding: 15px; }
            .action-card .icon { font-size: 1.8em; }
            .action-card .title { font-size: 0.9em; }
            .tools-section, .config-section { padding: 20px; }
            .tools-tabs { flex-wrap: wrap; gap: 8px; }
            .tab-btn { padding: 10px 20px; font-size: 0.9em; }
            .tab-content.active { grid-template-columns: 1fr; }
            .tool-card { padding: 20px; }
            .device-grid { grid-template-columns: 1fr; }
            .music-player { padding: 15px; border-radius: 15px; }
            .now-playing h3 { font-size: 1.2em; }
            .player-controls { gap: 10px; margin: 20px 0; }
            .player-btn { width: 45px; height: 45px; font-size: 18px; }
            .player-btn.play { width: 60px; height: 60px; font-size: 24px; }
            .music-list { padding: 15px; max-height: 350px; }
            .music-item { padding: 12px; }
            .chat-bubble { max-width: 85%; }
            .modal-content { width: 95%; margin: 2% auto; }
            .modal-body { padding: 20px; }
            .modal-footer { padding: 15px 20px; flex-direction: column; }
            .modal-btn { width: 100%; }
            .footer-miniz { bottom: 10px; right: 10px; padding: 10px 14px; }
            .footer-brand-compact { font-size: 0.85em; }
            .footer-youtube-compact { padding: 6px 12px; font-size: 0.8em; }
            #runcat-container { bottom: 10px; right: 10px; }
            #runcat { font-size: 40px; }
        }
        
        @media (max-width: 480px) {
            .sidebar { padding: 10px; }
            .logo { padding: 10px; }
            .logo-icon { width: 45px; }
            .logo-text { font-size: 1em; }
            .menu-item { padding: 8px 12px; font-size: 0.85em; }
            .main-content { padding: 10px; }
            .header { padding: 12px; }
            .header h1 { font-size: 1.1em; }
            .quick-actions { grid-template-columns: repeat(2, 1fr); gap: 8px; }
            .action-card { padding: 12px; }
            .action-card .icon { font-size: 1.5em; margin-bottom: 5px; }
            .action-card .title { font-size: 0.8em; }
            .tools-section, .config-section { padding: 15px; margin-bottom: 20px; }
            .tab-btn { padding: 8px 15px; font-size: 0.85em; }
            .tool-card { padding: 15px; }
            .tool-card h3 { font-size: 1em; }
            .tool-card input, .tool-card select, .tool-card textarea { padding: 10px; font-size: 0.9em; }
            .tool-card button { padding: 12px; font-size: 0.9em; }
            .log-panel { max-height: 250px; padding: 15px; font-size: 0.85em; }
            .music-player { padding: 12px; }
            .now-playing h3 { font-size: 1em; }
            .now-playing p { font-size: 0.9em; }
            .player-btn { width: 40px; height: 40px; font-size: 16px; }
            .player-btn.play { width: 55px; height: 55px; font-size: 22px; }
            .chat-avatar { width: 32px; height: 32px; font-size: 0.9em; }
            .chat-bubble { padding: 10px 12px; }
            .chat-content { font-size: 0.9em; }
            .footer-miniz { flex-direction: column; padding: 8px 12px; gap: 8px; }
            .footer-separator { display: none; }
        }
        
        /* WECHAT STYLE CHAT BUBBLES */
        .chat-message { display: flex; align-items: flex-start; gap: 10px; margin-bottom: 15px; animation: fadeInChat 0.3s; }
        .chat-message.user { flex-direction: row-reverse; }
        .chat-avatar { width: 40px; height: 40px; border-radius: 50%; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); display: flex; align-items: center; justify-content: center; color: white; font-weight: 700; font-size: 1.1em; flex-shrink: 0; box-shadow: 0 2px 8px rgba(0,0,0,0.15); }
        .chat-avatar.assistant { background: linear-gradient(135deg, #10b981 0%, #059669 100%); }
        .chat-avatar.system { background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); }
        .chat-avatar.tool { background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%); }
        .chat-bubble { max-width: 65%; padding: 12px 16px; border-radius: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); position: relative; word-wrap: break-word; }
        .chat-message.user .chat-bubble { background: #667eea; color: white; border-radius: 12px 12px 2px 12px; }
        .chat-message.assistant .chat-bubble { background: white; color: #333; border-radius: 12px 12px 12px 2px; border: 1px solid #e5e7eb; }
        .chat-message.system .chat-bubble { background: #fff7ed; color: #7c2d12; border-radius: 8px; border: 1px solid #fed7aa; }
        .chat-message.tool .chat-bubble { background: #eff6ff; color: #1e3a8a; border-radius: 8px; border: 1px solid #bfdbfe; }
        .chat-content { font-size: 0.95em; line-height: 1.5; margin-bottom: 6px; }
        .chat-metadata { font-size: 0.75em; opacity: 0.7; display: flex; gap: 10px; flex-wrap: wrap; margin-top: 8px; }
        .chat-metadata-item { display: inline-flex; align-items: center; gap: 4px; background: rgba(0,0,0,0.05); padding: 2px 8px; border-radius: 10px; }
        .chat-timestamp { font-size: 0.7em; opacity: 0.6; margin-top: 4px; text-align: right; }
        .chat-message.user .chat-timestamp { text-align: left; }
        @keyframes fadeInChat { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
        @keyframes spin { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
        #chat-container::-webkit-scrollbar { width: 8px; }
        #chat-container::-webkit-scrollbar-track { background: #f1f1f1; border-radius: 10px; }
        #chat-container::-webkit-scrollbar-thumb { background: #667eea; border-radius: 10px; }
        #chat-container::-webkit-scrollbar-thumb:hover { background: #5568d3; }
        
        /* Music Player VLC-style enhancements */
        .music-item:hover { background: linear-gradient(135deg, rgba(102,126,234,0.15) 0%, rgba(118,75,162,0.15) 100%) !important; transform: translateX(5px); }
        #volume-slider::-webkit-slider-thumb { -webkit-appearance: none; width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; box-shadow: 0 2px 6px rgba(102, 126, 234, 0.5); }
        #volume-slider::-moz-range-thumb { width: 16px; height: 16px; background: #667eea; border-radius: 50%; cursor: pointer; border: none; }
    </style>
</head>
<body>
    <!-- SIDEBAR -->
    <div class="sidebar">
        <div class="logo">
            <svg class="logo-icon" viewBox="0 0 100 100" fill="none" xmlns="http://www.w3.org/2000/svg">
                <defs>
                    <linearGradient id="logoGrad" x1="0%" y1="0%" x2="100%" y2="100%">
                        <stop offset="0%" style="stop-color:#667eea"/>
                        <stop offset="100%" style="stop-color:#764ba2"/>
                    </linearGradient>
                </defs>
                <circle cx="50" cy="50" r="45" fill="url(#logoGrad)"/>
                <text x="50" y="58" text-anchor="middle" fill="white" font-size="28" font-weight="bold" font-family="Arial">MCP</text>
                <text x="50" y="75" text-anchor="middle" fill="#a5f3fc" font-size="12" font-weight="600" font-family="Arial">miniZ</text>
            </svg>
            <div class="logo-text">miniZ MCP</div>
            <small style="font-size:0.55em;opacity:0.9;font-weight:600;letter-spacing:1px;">ÄIá»€U KHIá»‚N MÃY TÃNH</small>
        </div>
        <div class="menu-item active" onclick="showSection('dashboard')">ğŸ“ŠSidebar</div>
        <div class="menu-item" onclick="showSection('tools')">ğŸ› ï¸ CÃ´ng Cá»¥</div>
        <div class="menu-item" onclick="showSection('llm-chat')" style="background:linear-gradient(135deg,#667eea,#764ba2);border-left:4px solid #fbbf24;">ğŸ’¬ Chat vá»›i Gemini</div>
        <div class="menu-item" onclick="showSection('api-quotas')" style="background:linear-gradient(135deg,#667eea,#764ba2);border-left:4px solid #fbbf24;">ğŸ”‘ API Quotas</div>
        <div class="menu-item" onclick="showSection('music')">ğŸµ Music Player</div>
        <div class="menu-item" onclick="showSection('music-settings')">âš™ï¸ Music Settings</div>
        <div class="menu-item" onclick="showSection('conversation')">ğŸ’¬ Lá»‹ch Sá»­ Chat</div>
        <div class="menu-item" onclick="showSection('playlist')">ğŸµ Playlist YouTube</div>
        <div class="menu-item" onclick="showSection('knowledge')">ğŸ“š Knowledge Base</div>
    </div>
    
    <!-- MAIN CONTENT -->
    <div class="main-content">
        <!-- HEADER -->
        <div class="header">
            <h1>Dashboard</h1>
            <div class="status">
                <div class="settings-icon" onclick="openSettingsModal()" title="Cáº¥u hÃ¬nh Endpoint">âš™ï¸</div>
                <div class="status-badge" id="xiaozhi-status">
                    <span class="status-dot"></span>
                    <span id="xiaozhi-text">Connecting...</span>
                </div>
                <div class="status-badge online">
                    <span class="status-dot"></span>
                    Web Server
                </div>
            </div>
        </div>
        
        <!-- DASHBOARD SECTION -->
        <div id="dashboard-section">
            <h2 style="color:#667eea;margin-bottom:20px;">ğŸš€ Táº¥t cáº£ cÃ´ng cá»¥ (38 Tools)</h2>
            <div class="quick-actions">
                <!-- AI ASSISTANT (2) - NEW -->
                <div class="action-card purple" onclick="askGemini()"><div class="icon">ğŸ¤–ğŸ“š</div><div class="title">Há»i Gemini AI + KB</div></div>
                <div class="action-card indigo" onclick="askGPT4()"><div class="icon">ğŸ§ </div><div class="title">Há»i GPT-4</div></div>
                
                <!-- Há»† THá»NG (5) -->
                <div class="action-card blue" onclick="setVolumePrompt()"><div class="icon">ğŸ”Š</div><div class="title">Äiá»u Chá»‰nh Ã‚m LÆ°á»£ng</div></div>
                <div class="action-card cyan" onclick="screenshot()"><div class="icon">ğŸ“¸</div><div class="title">Chá»¥p MÃ n HÃ¬nh</div></div>
                <div class="action-card purple" onclick="notification()"><div class="icon">ğŸ””</div><div class="title">ThÃ´ng BÃ¡o</div></div>
                <div class="action-card green" onclick="getResources()"><div class="icon">ğŸ’»</div><div class="title">TÃ i NguyÃªn Há»‡ Thá»‘ng</div></div>
                <div class="action-card orange" onclick="setBrightness()"><div class="icon">ğŸ”†</div><div class="title">Äá»™ SÃ¡ng MÃ n HÃ¬nh</div></div>
                
                <!-- FILE & PROCESS (7) -->
                <div class="action-card indigo" onclick="openApp()"><div class="icon">ğŸš€</div><div class="title">Má»Ÿ á»¨ng Dá»¥ng</div></div>
                <div class="action-card blue" onclick="listProcesses()"><div class="icon">âš™ï¸</div><div class="title">Tiáº¿n TrÃ¬nh Äang Cháº¡y</div></div>
                <div class="action-card red" onclick="killProcess()"><div class="icon">âŒ</div><div class="title">Táº¯t Tiáº¿n TrÃ¬nh</div></div>
                <div class="action-card green" onclick="createFile()"><div class="icon">â•</div><div class="title">Táº¡o File Má»›i</div></div>
                <div class="action-card cyan" onclick="readFile()"><div class="icon">ğŸ“–</div><div class="title">Äá»c File</div></div>
                <div class="action-card purple" onclick="listFiles()"><div class="icon">ğŸ“‚</div><div class="title">Liá»‡t KÃª Files</div></div>
                <div class="action-card orange" onclick="diskUsage()"><div class="icon">ğŸ’½</div><div class="title">ThÃ´ng Tin ÄÄ©a</div></div>
                
                <!-- Máº NG & WEB (3) -->
                <div class="action-card blue" onclick="networkInfo()"><div class="icon">ğŸŒ</div><div class="title">ThÃ´ng Tin Máº¡ng</div></div>
                <div class="action-card green" onclick="batteryStatus()"><div class="icon">ğŸ”‹</div><div class="title">ThÃ´ng Tin Pin</div></div>
                <div class="action-card indigo" onclick="searchWeb()"><div class="icon">ğŸ”</div><div class="title">TÃ¬m Kiáº¿m Google</div></div>
                
                <!-- TIá»†N ÃCH (5) -->
                <div class="action-card pink" onclick="calculator()"><div class="icon">ğŸ§®</div><div class="title">MÃ¡y TÃ­nh</div></div>
                <div class="action-card cyan" onclick="getCurrentTime()"><div class="icon">â°</div><div class="title">Thá»i Gian</div></div>
                <div class="action-card purple" onclick="getClipboard()"><div class="icon">ğŸ“‹</div><div class="title">Láº¥y Clipboard</div></div>
                <div class="action-card orange" onclick="setClipboard()"><div class="icon">ğŸ“</div><div class="title">Äáº·t Clipboard</div></div>
                <div class="action-card red" onclick="playSound()"><div class="icon">ğŸ”Š</div><div class="title">PhÃ¡t Ã‚m Thanh</div></div>
                
                <!-- NEW TOOLS -->
                <div class="action-card blue" onclick="lockComputer()"><div class="icon">ğŸ”’</div><div class="title">KhÃ³a MÃ¡y TÃ­nh</div></div>
                <div class="action-card red" onclick="shutdownSchedule()"><div class="icon">â°</div><div class="title">LÃªn Lá»‹ch Táº¯t MÃ¡y</div></div>
                <div class="action-card green" onclick="showDesktop()"><div class="icon">ğŸ–¥ï¸</div><div class="title">Hiá»ƒn Thá»‹ Desktop</div></div>
                <div class="action-card orange" onclick="undoOperation()"><div class="icon">â†©ï¸</div><div class="title">HoÃ n TÃ¡c</div></div>
                <div class="action-card purple" onclick="setTheme()"><div class="icon">ğŸ¨</div><div class="title">Äá»•i Theme</div></div>
                <div class="action-card cyan" onclick="changeWallpaper()"><div class="icon">ğŸ–¼ï¸</div><div class="title">Äá»•i HÃ¬nh Ná»n</div></div>
                <div class="action-card indigo" onclick="getDesktopPath()"><div class="icon">ğŸ“</div><div class="title">ÄÆ°á»ng Dáº«n Desktop</div></div>
                <div class="action-card pink" onclick="pasteContent()"><div class="icon">ğŸ“‹</div><div class="title">DÃ¡n Ná»™i Dung</div></div>
                <div class="action-card blue" onclick="pressEnter()"><div class="icon">â</div><div class="title">Nháº¥n Enter</div></div>
                <div class="action-card green" onclick="findInDocument()"><div class="icon">ğŸ”</div><div class="title">TÃ¬m Trong TÃ i Liá»‡u</div></div>
            </div>
            
            <!-- LOG PANEL AT BOTTOM OF DASHBOARD -->
            <div style="margin-top: 30px;">
                <h2 style="color:#667eea; margin-bottom: 15px; display: flex; align-items: center; gap: 10px;">
                    <span>ğŸ“‹ Log Hoáº¡t Äá»™ng</span>
                    <span style="font-size: 0.6em; color: #9ca3af; font-weight: 400;">(Thá»i gian thá»±c)</span>
                </h2>
                <div class="log-panel" id="log"></div>
            </div>
        </div>

        <!-- API QUOTAS SECTION -->
        <div id="api-quotas-section" class="section" style="display:none;">
            <h2 style="color:#667eea;margin-bottom:30px;">ğŸ”‘ API Quotas Management</h2>
            
            <div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(400px,1fr));gap:25px;margin-bottom:30px;">
                <!-- Gemini API Card -->
                <div style="background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);border-radius:15px;padding:30px;color:white;box-shadow:0 10px 30px rgba(102,126,234,0.3);">
                    <div style="display:flex;align-items:center;margin-bottom:20px;">
                        <div style="font-size:48px;margin-right:15px;">ğŸ¤–</div>
                        <div>
                            <h3 style="margin:0;font-size:24px;">Gemini API</h3>
                            <p style="margin:5px 0 0 0;opacity:0.9;font-size:14px;">Google AI Platform</p>
                        </div>
                    </div>
                    <div id="gemini-quota-detail" style="background:rgba(255,255,255,0.15);border-radius:10px;padding:20px;">
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Status:</div>
                            <div id="gemini-status" style="font-size:16px;font-weight:bold;">ğŸ”„ Äang kiá»ƒm tra...</div>
                        </div>
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Free Tier Limits:</div>
                            <div style="font-size:15px;line-height:1.6;">
                                â€¢ <strong>60 requests</strong> per minute<br>
                                â€¢ <strong>1,500 requests</strong> per day
                            </div>
                        </div>
                        <div>
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Model:</div>
                            <div style="font-size:14px;font-family:monospace;background:rgba(0,0,0,0.2);padding:8px;border-radius:5px;">
                                ğŸš€ Gemini 3 Flash Preview
                                <br><span style="font-size:11px;opacity:0.7;">gemini-3-flash-preview</span>
                            </div>
                        </div>
                    </div>
                </div>
                
                <!-- Serper API Card -->
                <div style="background:linear-gradient(135deg,#3b82f6 0%,#1e40af 100%);border-radius:15px;padding:30px;color:white;box-shadow:0 10px 30px rgba(59,130,246,0.3);">
                    <div style="display:flex;align-items:center;margin-bottom:20px;">
                        <div style="font-size:48px;margin-right:15px;">ğŸ”</div>
                        <div>
                            <h3 style="margin:0;font-size:24px;">Serper API</h3>
                            <p style="margin:5px 0 0 0;opacity:0.9;font-size:14px;">Google Search API</p>
                        </div>
                    </div>
                    <div id="serper-quota-detail" style="background:rgba(255,255,255,0.15);border-radius:10px;padding:20px;">
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Status:</div>
                            <div id="serper-status" style="font-size:16px;font-weight:bold;">ğŸ”„ Äang kiá»ƒm tra...</div>
                        </div>
                        <div style="margin-bottom:15px;">
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Free Tier Limit:</div>
                            <div style="font-size:15px;line-height:1.6;">
                                â€¢ <strong>2,500 queries</strong> per month
                            </div>
                        </div>
                        <div>
                            <div style="font-size:13px;opacity:0.9;margin-bottom:5px;">Endpoint:</div>
                            <div style="font-size:14px;font-family:monospace;background:rgba(0,0,0,0.2);padding:8px;border-radius:5px;">https://google.serper.dev/search</div>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Actions -->
            <div style="background:white;border-radius:15px;padding:25px;box-shadow:0 2px 10px rgba(0,0,0,0.1);margin-bottom:25px;">
                <h3 style="margin-top:0;color:#1a1a2e;">âš¡ Quick Actions</h3>
                <div style="display:flex;gap:15px;flex-wrap:wrap;">
                    <button onclick="refreshQuotasPage()" style="background:linear-gradient(135deg,#10b981,#059669);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(16,185,129,0.3);transition:all 0.3s;">
                        ğŸ”„ LÃ m má»›i táº¥t cáº£
                    </button>
                    <button onclick="testGeminiAPI()" style="background:linear-gradient(135deg,#667eea,#764ba2);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(102,126,234,0.3);transition:all 0.3s;">
                        ğŸ§ª Test Gemini API
                    </button>
                    <button onclick="testSerperAPI()" style="background:linear-gradient(135deg,#3b82f6,#1e40af);color:white;border:none;padding:12px 25px;border-radius:8px;font-size:15px;cursor:pointer;box-shadow:0 4px 15px rgba(59,130,246,0.3);transition:all 0.3s;">
                        ğŸ§ª Test Serper API
                    </button>
                </div>
            </div>
            
            <!-- Usage Tips -->
            <div style="background:#f0f9ff;border-left:4px solid #3b82f6;border-radius:10px;padding:20px;">
                <h3 style="margin-top:0;color:#1e40af;">ğŸ’¡ Tips</h3>
                <ul style="margin:10px 0;padding-left:20px;line-height:1.8;color:#1e3a8a;">
                    <li><strong>Gemini API:</strong> DÃ¹ng cho chat AI, phÃ¢n tÃ­ch text, táº¡o ná»™i dung</li>
                    <li><strong>Serper API:</strong> DÃ¹ng cho tÃ¬m kiáº¿m Google real-time</li>
                    <li><strong>Free Tier:</strong> Äá»§ cho sá»­ dá»¥ng cÃ¡ nhÃ¢n vÃ  testing</li>
                    <li><strong>Rate Limit:</strong> Náº¿u vÆ°á»£t quota, API sáº½ tráº£ vá» lá»—i 429</li>
                    <li><strong>Monitor:</strong> Kiá»ƒm tra status thÆ°á»ng xuyÃªn Ä‘á»ƒ trÃ¡nh háº¿t quota</li>
                </ul>
            </div>
        </div>

        <!-- TOOLS SECTION -->
        <div id="tools-section" style="display:none;">
            <div class="tools-section">
                <h2 style="color:#667eea;margin-bottom:20px;">ğŸ› ï¸ CÃ´ng Cá»¥ (20 Tools)</h2>
                
                <div class="tools-tabs">
                    <button class="tab-btn active" onclick="switchTab(0)">ğŸ›ï¸ Há»‡ thá»‘ng</button>
                    <button class="tab-btn" onclick="switchTab(1)">ğŸ“ File & Process</button>
                    <button class="tab-btn" onclick="switchTab(2)">ğŸŒ Máº¡ng & Web</button>
                    <button class="tab-btn" onclick="switchTab(3)">ğŸ”§ Tiá»‡n Ã­ch</button>
                </div>
                
                <!-- TAB 1: Há»† THá»NG -->
                <div class="tab-content active" id="tab-0">
                    <div class="tool-card">
                        <h3>ğŸ”Š Äiá»u chá»‰nh Ã¢m lÆ°á»£ng</h3>
                        <input type="number" id="volume" min="0" max="100" value="50" placeholder="0-100">
                        <button onclick="
                            const level = parseInt(document.getElementById('volume').value);
                            if (isNaN(level) || level < 0 || level > 100) {
                                addLog('âŒ Ã‚m lÆ°á»£ng pháº£i tá»« 0-100', 'error');
                            } else {
                                callAPI('/api/volume', {level: level});
                            }
                        ">Äáº·t Ã¢m lÆ°á»£ng</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“¸ Chá»¥p mÃ n hÃ¬nh</h3>
                        <button onclick="callAPI('/api/screenshot', {})">Chá»¥p mÃ n hÃ¬nh ngay</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ”” ThÃ´ng bÃ¡o</h3>
                        <input type="text" id="notif-title" placeholder="TiÃªu Ä‘á»">
                        <input type="text" id="notif-message" placeholder="Ná»™i dung">
                        <button onclick="
                            const title = document.getElementById('notif-title').value.trim();
                            const message = document.getElementById('notif-message').value.trim();
                            if (!title || !message) {
                                addLog('âŒ Vui lÃ²ng nháº­p tiÃªu Ä‘á» vÃ  ná»™i dung', 'error');
                            } else {
                                callAPI('/api/notification', {title: title, message: message});
                            }
                        ">Hiá»ƒn thá»‹</button>
                    </div>
                    <div class="tool-card" style="background:linear-gradient(135deg, #667eea 0%, #764ba2 100%);color:white;border:2px solid #764ba2;">
                        <h3 style="color:white;">ğŸ”‘ API Quotas</h3>
                        <button onclick="getQuotas()" style="background:rgba(255,255,255,0.2);color:white;border:1px solid rgba(255,255,255,0.3);">LÃ m má»›i</button>
                        <div id="quotas" style="margin-top:15px;font-size:13px;line-height:1.8;">
                            <div style="margin-bottom:10px;padding:8px;background:rgba(255,255,255,0.1);border-radius:4px;">
                                <strong>ğŸ¤– Gemini:</strong><br>
                                <span id="gemini-quota" style="color:#fbbf24;font-size:12px;">Äang táº£i...</span>
                            </div>
                            <div style="padding:8px;background:rgba(255,255,255,0.1);border-radius:4px;">
                                <strong>ğŸ” Serper:</strong><br>
                                <span id="serper-quota" style="color:#60a5fa;font-size:12px;">Äang táº£i...</span>
                            </div>
                        </div>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ’» TÃ i nguyÃªn há»‡ thá»‘ng</h3>
                        <button onclick="getResources()">LÃ m má»›i</button>
                        <div id="resources" style="margin-top:15px;">
                            <div>CPU: <span id="cpu">--%</span></div>
                            <div>RAM: <span id="ram">--%</span></div>
                            <div>Disk: <span id="disk">--%</span></div>
                        </div>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ”† Äá»™ sÃ¡ng mÃ n hÃ¬nh</h3>
                        <input type="number" id="brightness" min="0" max="100" value="50" placeholder="0-100">
                        <button onclick="
                            const level = parseInt(document.getElementById('brightness').value);
                            if (isNaN(level) || level < 0 || level > 100) {
                                addLog('âŒ Äá»™ sÃ¡ng pháº£i tá»« 0-100', 'error');
                            } else {
                                callTool('set_brightness', {level: level});
                            }
                        ">Äáº·t Ä‘á»™ sÃ¡ng</button>
                    </div>
                </div>
                
                <!-- TAB 2: FILE & PROCESS -->
                <div class="tab-content" id="tab-1">
                    <div class="tool-card">
                        <h3>ğŸš€ Má»Ÿ á»©ng dá»¥ng</h3>
                        <select id="app-name">
                            <option value="notepad">ğŸ“ Notepad</option>
                            <option value="calc">ğŸ§® Calculator</option>
                            <option value="paint">ğŸ¨ Paint</option>
                            <option value="cmd">âŒ¨ï¸ CMD</option>
                            <option value="explorer">ğŸ“‚ Explorer</option>
                        </select>
                        <button onclick="callTool('open_application', {app_name: document.getElementById('app-name').value})">Má»Ÿ</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“‹ Tiáº¿n trÃ¬nh Ä‘ang cháº¡y</h3>
                        <input type="number" id="proc-limit" min="5" max="50" value="10" placeholder="Sá»‘ lÆ°á»£ng">
                        <button onclick="callTool('list_running_processes', {limit: parseInt(document.getElementById('proc-limit').value)})">Xem danh sÃ¡ch</button>
                    </div>
                    <div class="tool-card">
                        <h3>âŒ Táº¯t tiáº¿n trÃ¬nh</h3>
                        <input type="text" id="kill-proc" placeholder="PID hoáº·c tÃªn">
                        <button onclick="callTool('kill_process', {identifier: document.getElementById('kill-proc').value})">Táº¯t tiáº¿n trÃ¬nh</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“ Táº¡o file má»›i</h3>
                        <input type="text" id="file-path" placeholder="C:/test.txt">
                        <textarea id="file-content" placeholder="Ná»™i dung..." style="min-height:80px;"></textarea>
                        <button onclick="callTool('create_file', {path: document.getElementById('file-path').value, content: document.getElementById('file-content').value})">Táº¡o file</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“– Äá»c file</h3>
                        <input type="text" id="read-path" placeholder="C:/test.txt">
                        <button onclick="callTool('read_file', {path: document.getElementById('read-path').value})">Äá»c file</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“‚ Liá»‡t kÃª files</h3>
                        <input type="text" id="list-dir" placeholder="C:/Users">
                        <button onclick="callTool('list_files', {directory: document.getElementById('list-dir').value})">Xem files</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ’¾ ThÃ´ng tin Ä‘Ä©a</h3>
                        <button onclick="callTool('get_disk_usage', {})">Xem chi tiáº¿t</button>
                    </div>
                </div>
                
                <!-- TAB 3: Máº NG & WEB -->
                <div class="tab-content" id="tab-2">
                    <div class="tool-card">
                        <h3>ğŸŒ ThÃ´ng tin máº¡ng</h3>
                        <button onclick="callTool('get_network_info', {})">Xem IP & hostname</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ”‹ ThÃ´ng tin pin</h3>
                        <button onclick="callTool('get_battery_status', {})">Kiá»ƒm tra pin</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ” TÃ¬m kiáº¿m Google</h3>
                        <input type="text" id="search-query" placeholder="Nháº­p tá»« khÃ³a...">
                        <button onclick="callTool('search_web', {query: document.getElementById('search-query').value})">TÃ¬m kiáº¿m</button>
                    </div>
                </div>
                
                <!-- TAB 4: TIá»†N ÃCH -->
                <div class="tab-content" id="tab-3">
                    <div class="tool-card">
                        <h3>ğŸ§® MÃ¡y tÃ­nh</h3>
                        <input type="text" id="calc-expr" placeholder="2+2*3">
                        <button onclick="calculate()">TÃ­nh toÃ¡n</button>
                        <div id="calc-result" style="margin-top:10px;font-size:1.5em;font-weight:bold;color:#667eea;"></div>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ• Thá»i gian</h3>
                        <button onclick="getCurrentTime()">Láº¥y thá»i gian</button>
                        <div id="time-result" style="margin-top:10px;font-size:1.2em;color:#667eea;"></div>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“‹ Láº¥y clipboard</h3>
                        <button onclick="callTool('get_clipboard', {})">Xem ná»™i dung</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ“ Äáº·t clipboard</h3>
                        <input type="text" id="clip-text" placeholder="Ná»™i dung cáº§n copy">
                        <button onclick="callTool('set_clipboard', {text: document.getElementById('clip-text').value})">Copy vÃ o clipboard</button>
                    </div>
                    <div class="tool-card">
                        <h3>ğŸ”Š PhÃ¡t Ã¢m thanh</h3>
                        <input type="number" id="sound-freq" min="200" max="2000" value="1000" placeholder="Táº§n sá»‘ Hz">
                        <input type="number" id="sound-dur" min="100" max="3000" value="500" placeholder="Thá»i gian ms">
                        <button onclick="callTool('play_sound', {frequency: parseInt(document.getElementById('sound-freq').value), duration: parseInt(document.getElementById('sound-dur').value)})">PhÃ¡t beep</button>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- CONFIG SECTION - HIDDEN (Replaced by Modal) -->
        <div id="config-section" style="display:none;">
            <div class="config-section">
                <h2 style="color:#667eea;margin-bottom:20px;">âš™ï¸ Cáº¥u hÃ¬nh hiá»‡n táº¡i</h2>
                <p style="color:#666;margin-bottom:20px;">Sá»­ dá»¥ng icon âš™ï¸ á»Ÿ gÃ³c pháº£i trÃªn Ä‘á»ƒ thay Ä‘á»•i endpoint</p>
                <div id="current-endpoint-info" style="background:#f9fafb;padding:20px;border-radius:12px;border:2px solid #e5e7eb;">
                    <p><strong>Thiáº¿t bá»‹ Ä‘ang hoáº¡t Ä‘á»™ng:</strong> <span id="current-device-name">-</span></p>
                    <p><strong>Token:</strong> <span id="current-device-token" style="font-family:monospace;font-size:0.9em;word-break:break-all;">-</span></p>
                </div>
            </div>
        </div>
        
        
        <!-- LLM CHAT SECTION - Chat vá»›i Gemini AI -->
        <div id="llm-chat-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12); height: calc(100vh - 180px); display: flex; flex-direction: column;">
                <h2 style="color:#10b981; margin-bottom: 15px; display: flex; align-items: center; justify-content: space-between;">
                    <span>ğŸ’¬ Chat vá»›i Gemini AI</span>
                    <div style="display:flex; gap:10px; align-items:center;">
                        <!-- TTS Toggle -->
                        <label style="display:flex; align-items:center; gap:6px; cursor:pointer; padding:6px 12px; background:#f3f4f6; border-radius:8px; font-size:0.85em;" title="Báº­t/táº¯t Ä‘á»c to cÃ¢u tráº£ lá»i">
                            <input type="checkbox" id="llm-tts-toggle" onchange="saveTTSPreference()" style="cursor:pointer;">
                            <span>ğŸ”Š Äá»c to</span>
                        </label>
                        <!-- AI Model selector -->
                        <select id="llm-chat-model" style="padding:8px 12px; border-radius:8px; border:2px solid #e5e7eb; font-size:0.9em; cursor:pointer;" onchange="saveLLMChatModel()">
                            <option value="models/gemini-3-flash-preview">âš¡ Gemini 3 Flash</option>
                            <option value="models/gemini-2.0-flash">âš¡ Gemini 2.0 Flash</option>
                            <option value="models/gemini-2.5-pro-preview-06-05">ğŸ’ Gemini 2.5 Pro</option>
                            <option value="models/gemini-2.5-flash-preview-05-20">âš¡ Gemini 2.5 Flash</option>
                        </select>
                        <button onclick="clearLLMChat()" style="padding:8px 16px; background:#ef4444; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            ğŸ—‘ï¸ XÃ³a Chat
                        </button>
                    </div>
                </h2>
                
                <!-- AI Status Bar -->
                <div id="llm-ai-status" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:12px 16px; border-radius:10px; margin-bottom:15px; display:flex; justify-content:space-between; align-items:center; flex-wrap:wrap; gap:10px;">
                    <div style="display:flex; gap:20px; flex-wrap:wrap; align-items:center;">
                        <span>ğŸ¤– <strong>Gemini AI</strong> + ğŸ“š Knowledge Base</span>
                        <span style="font-size:0.85em; opacity:0.9;">TÃ­ch há»£p RAG System tá»± Ä‘á»™ng</span>
                    </div>
                    <span style="font-size:0.85em; background:rgba(255,255,255,0.2); padding:4px 10px; border-radius:20px;">âœ… Sáºµn sÃ ng</span>
                </div>
                
                <!-- Chat Messages Container -->
                <div id="llm-chat-messages" style="flex:1; overflow-y:auto; background:#f5f5f5; border-radius:10px; padding:15px; display:flex; flex-direction:column; gap:12px;">
                    <!-- Welcome message -->
                    <div style="text-align:center; color:#666; padding:40px 20px;">
                        <div style="font-size:4em; margin-bottom:15px;">ğŸ¤–</div>
                        <h3 style="color:#667eea; margin-bottom:10px;">ChÃ o má»«ng Ä‘áº¿n Chat vá»›i Gemini AI!</h3>
                        <p style="font-size:0.95em; max-width:400px; margin:0 auto;">
                            Chat trá»±c tiáº¿p vá»›i Gemini AI.<br>
                            AI sáº½ tá»± Ä‘á»™ng tÃ¬m kiáº¿m trong Knowledge Base cá»§a báº¡n Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n.
                        </p>
                    </div>
                </div>
                
                <!-- Chat Input Area -->
                <div style="margin-top:15px; display:flex; gap:10px; align-items:flex-end;">
                    <!-- ğŸ‘‚ Wake Word Button -->
                    <button id="llm-wakeword-btn" onclick="toggleWakeWord()" 
                            style="width:50px; height:50px; border-radius:50%; background:linear-gradient(135deg,#6b7280,#4b5563); color:white; border:none; cursor:pointer; font-size:1.4em; display:flex; align-items:center; justify-content:center; transition:all 0.3s; flex-shrink:0;"
                            title="ğŸ‘‚ Báº­t Wake Word (nÃ³i 'Hey Gemini' Ä‘á»ƒ chat)">
                        ğŸ‘‚
                    </button>
                    <!-- ğŸ¤ Microphone Button -->
                    <button id="llm-mic-btn" onclick="toggleLLMVoiceInput()" 
                            style="width:50px; height:50px; border-radius:50%; background:linear-gradient(135deg,#10b981,#059669); color:white; border:none; cursor:pointer; font-size:1.4em; display:flex; align-items:center; justify-content:center; transition:all 0.3s; flex-shrink:0;"
                            title="ğŸ¤ Nháº¥n Ä‘á»ƒ nÃ³i (auto-send)">
                        ğŸ¤
                    </button>
                    <div style="flex:1; position:relative;">
                        <textarea id="llm-chat-input" 
                                  placeholder="Nháº­p tin nháº¯n hoáº·c nháº¥n ğŸ¤ Ä‘á»ƒ nÃ³i... (Enter Ä‘á»ƒ gá»­i)"
                                  style="width:100%; padding:15px; padding-right:50px; border:2px solid #e5e7eb; border-radius:12px; font-size:1em; resize:none; min-height:50px; max-height:150px; font-family:inherit;"
                                  onkeydown="handleLLMChatKeydown(event)"
                                  oninput="autoResizeLLMInput(this)"></textarea>
                        <button onclick="sendLLMMessage()" 
                                style="position:absolute; right:10px; bottom:10px; width:40px; height:40px; border-radius:50%; background:linear-gradient(135deg,#667eea,#764ba2); color:white; border:none; cursor:pointer; font-size:1.2em; display:flex; align-items:center; justify-content:center; transition:all 0.3s;"
                                title="Gá»­i tin nháº¯n">
                            â¤
                        </button>
                    </div>
                </div>
                <!-- Voice Recording Status -->
                <div id="llm-voice-status" style="display:none; margin-top:10px; padding:12px 16px; background:linear-gradient(135deg,#fef3c7,#fde68a); border-radius:10px; text-align:center;">
                    <span id="llm-voice-status-text">ğŸ¤ Äang nghe...</span>
                </div>
                <!-- Wake Word Info -->
                <div style="margin-top:8px; font-size:0.8em; color:#6b7280; text-align:center;">
                    ğŸ’¡ <strong>Wake Words:</strong> "Hey Gemini", "Gemini Æ¡i", "Xin chÃ o" | <strong>Goodbye:</strong> "Táº¡m biá»‡t", "Bye bye", "Ngá»§ Ä‘i"
                </div>
                
                <!-- Quick Actions -->
                <div style="margin-top:10px; display:flex; gap:8px; flex-wrap:wrap;">
                    <button onclick="sendQuickMessage('Xin chÃ o!')" class="quick-msg-btn">ğŸ‘‹ Xin chÃ o</button>
                    <button onclick="sendQuickMessage('TÃ³m táº¯t kiáº¿n thá»©c trong Knowledge Base')" class="quick-msg-btn">ğŸ“š KB Summary</button>
                    <button onclick="sendQuickMessage('Giáº£i thÃ­ch code Python cho ngÆ°á»i má»›i')" class="quick-msg-btn">ğŸ Python</button>
                    <button onclick="sendQuickMessage('Viáº¿t má»™t Ä‘oáº¡n vÄƒn ngáº¯n vá» AI')" class="quick-msg-btn">âœï¸ Viáº¿t vÄƒn</button>
                    <button onclick="sendQuickMessage('Dá»‹ch sang tiáº¿ng Anh: Xin chÃ o cÃ¡c báº¡n')" class="quick-msg-btn">ğŸŒ Dá»‹ch thuáº­t</button>
                </div>
            </div>
        </div>
        
        <!-- CONVERSATION HISTORY SECTION (WeChat style) -->
        <div id="conversation-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12); height: calc(100vh - 180px); display: flex; flex-direction: column;">
                <h2 style="color:#667eea; margin-bottom: 15px; display: flex; align-items: center; justify-content: space-between;">
                    <span>ğŸ’¬ Lá»‹ch Sá»­ Há»™i Thoáº¡i</span>
                    <div style="display:flex; gap:10px;">
                        <button onclick="loadConversationHistory()" style="padding:8px 16px; background:#10b981; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            ğŸ”„ LÃ m má»›i
                        </button>
                        <button onclick="exportConversation()" style="padding:8px 16px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            ğŸ’¾ Xuáº¥t File
                        </button>
                        <button onclick="clearConversationHistory()" style="padding:8px 16px; background:#ef4444; color:white; border:none; border-radius:8px; cursor:pointer; font-size:0.9em;">
                            ğŸ—‘ï¸ XÃ³a Háº¿t
                        </button>
                    </div>
                </h2>
                
                <!-- Stats bar -->
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:12px 16px; border-radius:10px; margin-bottom:15px; display:flex; justify-content:space-between; align-items:center;">
                    <div>
                        <span style="font-size:0.85em; opacity:0.9;">Tá»•ng sá»‘ tin nháº¯n:</span>
                        <span style="font-weight:700; font-size:1.1em; margin-left:8px;" id="total-messages">0</span>
                    </div>
                    <div style="font-size:0.85em; opacity:0.9;" id="last-update">ChÆ°a cÃ³ dá»¯ liá»‡u</div>
                </div>
                
                <!-- Chat container (WeChat style) -->
                <div id="chat-container" style="flex:1; overflow-y:auto; background:#f5f5f5; border-radius:10px; padding:15px; display:flex; flex-direction:column; gap:12px;">
                    <!-- Messages will be rendered here -->
                </div>
            </div>
        </div>
        
        <!-- MUSIC PLAYER SECTION - VLC Web Interface Style -->
        <div id="music-section" style="display:none;">
            <!-- Source Priority Selector -->
            <div style="background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 20px; margin-bottom: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.3);">
                <div style="display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 15px;">
                    <div style="display: flex; align-items: center; gap: 15px;">
                        <span style="color: #fff; font-weight: 600; font-size: 1.1em;">ğŸ¯ Nguá»“n phÃ¡t Æ°u tiÃªn:</span>
                        <div style="display: flex; gap: 10px;">
                            <button id="source-library-btn" onclick="setMusicSource('library')" 
                                    style="padding: 10px 20px; border-radius: 25px; border: 2px solid #667eea; background: #667eea; color: white; font-weight: 600; cursor: pointer; transition: all 0.3s;">
                                ğŸ“š Music Library
                            </button>
                            <button id="source-user-btn" onclick="setMusicSource('user')" 
                                    style="padding: 10px 20px; border-radius: 25px; border: 2px solid #667eea; background: transparent; color: #667eea; font-weight: 600; cursor: pointer; transition: all 0.3s;">
                                ğŸ“ ThÆ° má»¥c cÃ¡ nhÃ¢n
                            </button>
                        </div>
                    </div>
                    <div id="current-source-info" style="color: #a5b4fc; font-size: 0.9em;">
                        Äang dÃ¹ng: <span id="source-path-display" style="font-family: monospace;">music_library/</span>
                    </div>
                </div>
            </div>
            
            <!-- VLC-style Player -->
            <div class="music-player" style="position:relative; background: linear-gradient(135deg, #2b3e50 0%, #1a252f 100%); border-radius: 15px; padding: 25px; box-shadow: 0 15px 40px rgba(0,0,0,0.4);">
                <!-- Album Art & Track Info -->
                <div style="display: flex; align-items: center; gap: 20px; margin-bottom: 20px;">
                    <div id="album-art" style="width: 120px; height: 120px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 12px; display: flex; align-items: center; justify-content: center; font-size: 48px; box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);">
                        ğŸµ
                    </div>
                    <div class="now-playing" style="flex: 1;">
                        <h3 id="current-track" style="color: #fff; font-size: 1.4em; margin-bottom: 8px;">ğŸµ ChÆ°a phÃ¡t nháº¡c</h3>
                        <p id="track-info" style="color: #a5b4fc; font-size: 0.95em; margin-bottom: 5px;">Chá»n bÃ i hÃ¡t tá»« danh sÃ¡ch bÃªn dÆ°á»›i</p>
                        <!-- Audio Visualizer - SÃ³ng nháº¡c -->
                        <div id="audio-visualizer" class="audio-visualizer paused" style="display: none;">
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                            <div class="bar"></div>
                        </div>
                        <p id="track-album" style="color: #6b7280; font-size: 0.85em;"></p>
                    </div>
                </div>
                
                <!-- Progress Bar (VLC style) - DRAGGABLE -->
                <div class="progress-container" style="margin-bottom: 20px;">
                    <input type="range" id="progress-slider" min="0" max="100" value="0" step="0.1"
                           oninput="onProgressDrag(this.value)" 
                           onchange="onProgressSeek(this.value)"
                           onmousedown="isDraggingProgress = true"
                           onmouseup="isDraggingProgress = false"
                           style="width: 100%; height: 8px; -webkit-appearance: none; background: linear-gradient(to right, #667eea 0%, #667eea 0%, #374151 0%, #374151 100%); border-radius: 4px; cursor: pointer; margin: 0;">
                    <div class="progress-time" style="display: flex; justify-content: space-between; margin-top: 8px; color: #9ca3af; font-size: 0.85em; font-family: monospace;">
                        <span id="current-time">0:00</span>
                        <span id="total-time">0:00</span>
                    </div>
                </div>
                
                <!-- Player Controls (VLC style) -->
                <div class="player-controls" style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 20px;">
                    <div class="player-btn" id="shuffle-btn" onclick="toggleShuffle()" title="PhÃ¡t ngáº«u nhiÃªn" style="opacity: 0.6; cursor: pointer; font-size: 1.3em; padding: 10px; transition: all 0.2s;">ğŸ”€</div>
                    <div class="player-btn" onclick="musicPrevious()" title="BÃ i trÆ°á»›c" style="cursor: pointer; font-size: 1.5em; padding: 10px;">â®ï¸</div>
                    <div class="player-btn play" onclick="musicPlayPause()" id="play-btn" title="PhÃ¡t/Táº¡m dá»«ng" style="cursor: pointer; font-size: 2.5em; padding: 15px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 50%; box-shadow: 0 5px 20px rgba(102, 126, 234, 0.5);">â–¶ï¸</div>
                    <div class="player-btn" onclick="musicNext()" title="BÃ i tiáº¿p" style="cursor: pointer; font-size: 1.5em; padding: 10px;">â­ï¸</div>
                    <div class="player-btn" id="repeat-btn" onclick="toggleRepeat()" title="Láº·p láº¡i" style="opacity: 0.6; cursor: pointer; font-size: 1.3em; padding: 10px; transition: all 0.2s;">ğŸ”</div>
                    <div class="player-btn" onclick="musicStop()" title="Dá»«ng" style="cursor: pointer; font-size: 1.3em; padding: 10px;">â¹ï¸</div>
                </div>
                
                <!-- Volume Control (VLC style) -->
                <div style="display: flex; align-items: center; justify-content: center; gap: 15px; padding: 10px 0;">
                    <span onclick="toggleMute()" style="cursor: pointer; font-size: 1.3em;" id="volume-icon">ğŸ”Š</span>
                    <input type="range" id="volume-slider" min="0" max="100" value="80" 
                           oninput="setPlayerVolume(this.value)"
                           style="width: 200px; height: 6px; -webkit-appearance: none; background: linear-gradient(to right, #667eea 0%, #667eea 80%, #374151 80%, #374151 100%); border-radius: 3px; cursor: pointer;">
                    <span id="volume-value" style="color: #9ca3af; font-size: 0.85em; min-width: 40px;">80%</span>
                </div>
            </div>
            
            <!-- Music Library with Search -->
            <div class="music-list" style="margin-top: 20px; background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <!-- HÆ°á»›ng dáº«n sá»­ dá»¥ng -->
                <div style="background: linear-gradient(135deg, #e0e7ff 0%, #f3e8ff 100%); border-left: 4px solid #667eea; padding: 12px 15px; border-radius: 8px; margin-bottom: 15px; display: flex; align-items: center; gap: 10px;">
                    <span style="font-size: 1.3em;">ğŸ’¡</span>
                    <div style="flex: 1;">
                        <strong style="color: #667eea;">HÆ°á»›ng dáº«n:</strong>
                        <span style="color: #4b5563; font-size: 0.9em;"> Click vÃ o bÃ i hÃ¡t Ä‘á»ƒ phÃ¡t ngay (hoáº·c click nÃºt â–¶ï¸ khi hover)</span>
                    </div>
                </div>
                
                <div style="display: flex; align-items: center; justify-content: space-between; flex-wrap: wrap; gap: 15px; margin-bottom: 15px;">
                    <h3 style="margin: 0; color: #333;">ğŸ“ ThÆ° Viá»‡n Nháº¡c</h3>
                    <div style="display: flex; gap: 10px; align-items: center;">
                        <input type="text" id="music-search" placeholder="ğŸ” TÃ¬m bÃ i hÃ¡t..." 
                               oninput="filterMusicLibrary(this.value)"
                               style="padding: 10px 15px; border: 2px solid #e5e7eb; border-radius: 25px; width: 250px; font-size: 0.95em;">
                        <button onclick="loadMusicLibrary()" style="padding: 10px 20px; background: #667eea; color: white; border: none; border-radius: 25px; cursor: pointer; font-weight: 600;">ğŸ”„ LÃ m má»›i</button>
                    </div>
                </div>
                <div id="music-library" style="max-height: 400px; overflow-y: auto;">
                    <div style="text-align:center; padding:40px; color:#999;">
                        <p style="font-size:1.2em; margin-bottom:10px;">â³ Äang táº£i danh sÃ¡ch nháº¡c...</p>
                        <button onclick="loadMusicLibrary()" style="padding:12px 24px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer; font-size:1em;">Táº£i ngay</button>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- RUNCAT ANIMATION (gÃ³c pháº£i dÆ°á»›i) -->
        <div id="runcat-container">
            <div id="runcat">ğŸ±</div>
        </div>

        <!-- MUSIC SETTINGS SECTION -->
        <div id="music-settings-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 30px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                    âš™ï¸ CÃ i Äáº·t ThÆ° Má»¥c Nháº¡c
                </h2>
                
                <div style="background: #f8f9fa; padding: 25px; border-radius: 12px; margin-bottom: 20px; border-left: 4px solid #667eea;">
                    <h3 style="color: #333; margin-bottom: 15px; font-size: 1.1em;">ğŸ“ ÄÆ°á»ng Dáº«n ThÆ° Má»¥c Nháº¡c</h3>
                    <p style="color: #666; margin-bottom: 15px; line-height: 1.6;">
                        Nháº­p Ä‘Æ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a nháº¡c cá»§a báº¡n. miniZ sáº½ Æ°u tiÃªn phÃ¡t nháº¡c tá»« thÆ° má»¥c nÃ y báº±ng trÃ¬nh phÃ¡t máº·c Ä‘á»‹nh cá»§a Windows.
                    </p>
                    
                    <div style="display: flex; gap: 10px; margin-bottom: 15px;">
                        <input type="text" id="music-folder-path" placeholder="VÃ­ dá»¥: F:\My Music hoáº·c C:\Users\Name\Music" 
                               style="flex: 1; padding: 12px 15px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em; font-family: 'Consolas', monospace;">
                        <button onclick="browseMusicFolder()" 
                                style="padding: 12px 20px; background: #667eea; color: white; border: none; border-radius: 8px; cursor: pointer; font-weight: 600; white-space: nowrap;">
                            ğŸ“‚ Chá»n ThÆ° Má»¥c
                        </button>
                        <button onclick="saveMusicFolder()" 
                                style="padding: 12px 20px; background: #10b981; color: white; border: none; border-radius: 8px; cursor: pointer; font-weight: 600; white-space: nowrap;">
                            ğŸ’¾ LÆ°u
                        </button>
                    </div>
                    
                    <div id="music-folder-status" style="margin-top: 10px; padding: 10px; border-radius: 6px; display: none;"></div>
                </div>
                
                <div style="background: #fff3cd; padding: 20px; border-radius: 12px; border-left: 4px solid #ffc107; margin-bottom: 20px;">
                    <h3 style="color: #856404; margin-bottom: 10px; font-size: 1em;">ğŸ’¡ LÆ°u Ã</h3>
                    <ul style="color: #856404; line-height: 1.8; margin-left: 20px;">
                        <li>Sau khi lÆ°u, báº¡n cÃ³ thá»ƒ yÃªu cáº§u LLM phÃ¡t nháº¡c tá»« thÆ° má»¥c nÃ y</li>
                        <li>miniZ sáº½ dÃ¹ng trÃ¬nh phÃ¡t máº·c Ä‘á»‹nh cá»§a Windows (Windows Media Player, Groove Music, VLC...)</li>
                        <li>VÃ­ dá»¥ lá»‡nh: "<i>PhÃ¡t nháº¡c trong thÆ° má»¥c cá»§a tÃ´i</i>" hoáº·c "<i>Play all songs</i>"</li>
                    </ul>
                </div>
                
                <div style="background: #e8f4f8; padding: 20px; border-radius: 12px; border-left: 4px solid #3b82f6;">
                    <h3 style="color: #1e40af; margin-bottom: 10px; font-size: 1em;">ğŸµ Äá»‹nh Dáº¡ng Há»— Trá»£</h3>
                    <div style="display: flex; flex-wrap: wrap; gap: 10px; margin-top: 10px;">
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.mp3</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.wav</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.flac</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.m4a</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.wma</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.aac</span>
                        <span style="background: white; padding: 6px 12px; border-radius: 6px; font-size: 0.9em; color: #1e40af; font-weight: 600;">.ogg</span>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- PLAYLIST SECTION -->
        <div id="playlist-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 12px; display: flex; align-items: center; justify-content: space-between; gap: 15px;">
                    <span>ğŸµ Danh SÃ¡ch Nháº¡c YouTube</span>
                    <div style="display:flex; align-items:center; gap:10px;">
                        <input id="playlist-command" placeholder="GÃµ tá»« khÃ³a playlist (vd: nháº¡c, chill...)" style="padding:8px 12px; border-radius:8px; border:1px solid #e5e7eb; font-size:0.95em; width:280px;" 
                               onkeypress="if(event.key==='Enter') triggerPlayByName(this.value.trim())" />
                        <button onclick="triggerPlayByName(document.getElementById('playlist-command').value.trim())" style="padding:8px 12px; background:#667eea; color:white; border:none; border-radius:8px; cursor:pointer;">Má»Ÿ</button>
                    </div>
                </h2>

                <div style="display:flex; gap:20px; align-items:flex-start;">
                    <div style="flex:1;">
                        <div id="playlist-list" style="background:#f9fafb; padding:12px; border-radius:8px; min-height:80px; border:1px solid #e5e7eb;">
                            <!-- playlists will be rendered here -->
                        </div>
                        <div style="margin-top:12px; display:flex; gap:10px;">
                            <button onclick="promptAddPlaylist()" style="padding:10px 14px; border-radius:8px; background:linear-gradient(135deg,#10b981,#059669); color:white; border:none; cursor:pointer; font-weight:600;">ï¼‹ ThÃªm Playlist</button>
                            <button onclick="renderPlaylists()" style="padding:10px 14px; border-radius:8px; background:#e5e7eb; border:none; cursor:pointer;">LÃ m má»›i</button>
                        </div>
                    </div>
                    <div style="width:320px;">
                        <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color:white; padding:14px; border-radius:12px;">
                            <div style="font-weight:700; margin-bottom:6px;">HÆ°á»›ng dáº«n nhanh</div>
                            <div style="font-size:0.95em; opacity:0.95;">
                                â€¢ Nháº¥n <b>ï¼‹ ThÃªm Playlist</b> Ä‘á»ƒ thÃªm má»›i (tÃªn + URL)<br>
                                â€¢ GÃµ <b>tá»« khÃ³a</b> (khÃ´ng cáº§n chÃ­nh xÃ¡c) vÃ o Ã´ vÃ  nháº¥n <b>Má»Ÿ</b><br>
                                â€¢ VÃ­ dá»¥: gÃµ "nháº¡c" sáº½ tÃ¬m "Nháº¡c chill", "Nháº¡c EDM"...<br>
                                â€¢ Voice: "má»Ÿ danh sÃ¡ch [tá»« khÃ³a]" hoáº·c "má»Ÿ playlist [tá»« khÃ³a]"
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- KNOWLEDGE BASE SECTION -->
        <div id="knowledge-section" style="display:none;">
            <div style="background: white; border-radius: 15px; padding: 25px; box-shadow: 0 10px 30px rgba(0,0,0,0.12);">
                <h2 style="color:#667eea; margin-bottom: 20px; display: flex; align-items: center; gap: 10px;">
                    <span>ğŸ“š Knowledge Base</span>
                    <span style="font-size: 0.5em; color: #9ca3af; font-weight: 400;">Cáº­p nháº­t dá»¯ liá»‡u cho LLM</span>
                </h2>
                
                <!-- Nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c -->
                <div style="background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb; margin-bottom: 20px;">
                    <h3 style="color: #333; margin-bottom: 15px; display: flex; align-items: center; gap: 8px;">
                        ğŸ“ ThÆ° Má»¥c Dá»¯ Liá»‡u
                    </h3>
                    <div style="display: flex; gap: 10px; align-items: center;">
                        <input type="text" id="knowledge-folder-path" 
                               placeholder="Nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c (VD: C:\Documents\MyData hoáº·c D:\Knowledge)" 
                               style="flex: 1; padding: 12px 15px; border: 2px solid #e5e7eb; border-radius: 8px; font-size: 1em;">
                        <button onclick="saveKnowledgeFolder()" 
                                style="padding: 12px 25px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; white-space: nowrap;">
                            ğŸ’¾ LÆ°u
                        </button>
                        <button onclick="scanKnowledgeFolder()" 
                                style="padding: 12px 25px; background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; border: none; border-radius: 8px; font-weight: 600; cursor: pointer; white-space: nowrap;">
                            ğŸ” QuÃ©t Files
                        </button>
                    </div>
                    <p style="color: #666; font-size: 0.9em; margin-top: 10px;">
                        ğŸ’¡ Há»— trá»£: PDF, TXT, Word (.docx), Markdown (.md), JSON, CSV
                    </p>
                </div>
                
                <!-- Tráº¡ng thÃ¡i & thá»‘ng kÃª -->
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px;">
                    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-total-files">0</div>
                        <div style="opacity: 0.9;">Tá»•ng sá»‘ files</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #10b981 0%, #059669 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-indexed-files">0</div>
                        <div style="opacity: 0.9;">ÄÃ£ index</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #f59e0b 0%, #d97706 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-total-size">0 KB</div>
                        <div style="opacity: 0.9;">Dung lÆ°á»£ng</div>
                    </div>
                    <div style="background: linear-gradient(135deg, #8b5cf6 0%, #7c3aed 100%); color: white; padding: 20px; border-radius: 12px; text-align: center;">
                        <div style="font-size: 2em; font-weight: bold;" id="kb-last-update">--</div>
                        <div style="opacity: 0.9;">Cáº­p nháº­t láº§n cuá»‘i</div>
                    </div>
                </div>
                
                <!-- Danh sÃ¡ch files -->
                <div style="background: #f9fafb; padding: 20px; border-radius: 12px; border: 2px solid #e5e7eb;">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                        <h3 style="color: #333; display: flex; align-items: center; gap: 8px; margin: 0;">
                            ğŸ“„ Danh SÃ¡ch Files
                        </h3>
                        <div style="display: flex; gap: 10px;">
                            <button onclick="indexAllFiles()" 
                                    style="padding: 8px 16px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.9em;">
                                ğŸ”„ Index Táº¥t Cáº£
                            </button>
                            <button onclick="clearKnowledgeBase()" 
                                    style="padding: 8px 16px; background: #ef4444; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.9em;">
                                ğŸ—‘ï¸ XÃ³a Index
                            </button>
                        </div>
                    </div>
                    <div id="knowledge-file-list" style="max-height: 400px; overflow-y: auto;">
                        <p style="color: #666; text-align: center; padding: 40px;">
                            ğŸ“‚ ChÆ°a cÃ³ thÆ° má»¥c nÃ o Ä‘Æ°á»£c cáº¥u hÃ¬nh.<br>
                            Nháº­p Ä‘Æ°á»ng dáº«n vÃ  nháº¥n "QuÃ©t Files" Ä‘á»ƒ báº¯t Ä‘áº§u.
                        </p>
                    </div>
                </div>
                
                <!-- HÆ°á»›ng dáº«n -->
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 12px; margin-top: 20px;">
                    <h3 style="margin-bottom: 12px;">ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng</h3>
                    <div style="font-size: 0.95em; line-height: 1.6;">
                        <p>1. <strong>Nháº­p Ä‘Æ°á»ng dáº«n</strong> thÆ° má»¥c chá»©a tÃ i liá»‡u (PDF, TXT, Word, Markdown...)</p>
                        <p>2. <strong>Nháº¥n "QuÃ©t Files"</strong> Ä‘á»ƒ liá»‡t kÃª cÃ¡c files trong thÆ° má»¥c</p>
                        <p>3. <strong>Nháº¥n "Index Táº¥t Cáº£"</strong> Ä‘á»ƒ LLM há»c tá»« ná»™i dung cÃ¡c files</p>
                        <p>4. Sau khi index, LLM cÃ³ thá»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn dá»¯ liá»‡u cá»§a báº¡n!</p>
                        <p style="margin-top: 10px; opacity: 0.9;">
                            ğŸ’¡ <strong>Máº¹o:</strong> Äáº·t cÃ¡c tÃ i liá»‡u quan trá»ng vÃ o má»™t thÆ° má»¥c riÃªng Ä‘á»ƒ dá»… quáº£n lÃ½.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        
        <!-- SETTINGS MODAL -->
        <div id="settingsModal" class="modal">
            <div class="modal-content" style="max-width:1400px;width:95%;">
                <div class="modal-header">
                    <h2>âš™ï¸ Cáº¥u hÃ¬nh Endpoint</h2>
                    <button class="close-btn" onclick="closeSettingsModal()">&times;</button>
                </div>
                <div class="modal-body">
                    <!-- 3 ENDPOINT SECTIONS -->
                    <div style="display:grid;grid-template-columns:1fr 1fr 1fr;gap:20px;margin-bottom:25px;">
                        <!-- Thiáº¿t bá»‹ 1 -->
                        <div id="device-1-card" style="border:2px solid #10b981;border-radius:8px;padding:15px;background:#f0fdf4;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-1-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#d1fae5;color:#047857;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    ChÆ°a káº¿t ná»‘i
                                </span>
                            </div>
                            <label for="endpoint-url-1" style="color:#047857;font-weight:600;display:flex;align-items:center;gap:8px;">
                                ğŸ“± Thiáº¿t bá»‹ 1
                            </label>
                            <input type="text" id="endpoint-url-1" placeholder="JWT token thiáº¿t bá»‹ 1..." style="margin-top:8px;border:2px solid #10b981;" />
                            <p style="color:#065f46;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                Token tháº­t tá»« Claude Desktop
                            </p>
                        </div>
                        
                        <!-- Thiáº¿t bá»‹ 2 -->
                        <div id="device-2-card" style="border:2px solid #3b82f6;border-radius:8px;padding:15px;background:#eff6ff;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-2-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#dbeafe;color:#1e40af;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    ChÆ°a káº¿t ná»‘i
                                </span>
                            </div>
                            <label for="endpoint-url-2" style="color:#1e40af;font-weight:600;display:flex;align-items:center;gap:8px;">
                                ğŸ“± Thiáº¿t bá»‹ 2
                            </label>
                            <input type="text" id="endpoint-url-2" placeholder="JWT token thiáº¿t bá»‹ 2..." style="margin-top:8px;border:2px solid #3b82f6;" />
                            <p style="color:#1e3a8a;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                MCP connection 2
                            </p>
                        </div>
                        
                        <!-- Thiáº¿t bá»‹ 3 -->
                        <div id="device-3-card" style="border:2px solid #f59e0b;border-radius:8px;padding:15px;background:#fffbeb;position:relative;">
                            <div style="position:absolute;top:10px;right:10px;">
                                <span id="device-3-indicator" class="connection-indicator" style="display:inline-flex;align-items:center;gap:5px;padding:4px 10px;border-radius:12px;background:#fef3c7;color:#b45309;font-size:0.75em;font-weight:bold;">
                                    <span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span>
                                    ChÆ°a káº¿t ná»‘i
                                </span>
                            </div>
                            <label for="endpoint-url-3" style="color:#b45309;font-weight:600;display:flex;align-items:center;gap:8px;">
                                ğŸ“± Thiáº¿t bá»‹ 3
                            </label>
                            <input type="text" id="endpoint-url-3" placeholder="JWT token thiáº¿t bá»‹ 3..." style="margin-top:8px;border:2px solid #f59e0b;" />
                            <p style="color:#78350f;font-size:0.85em;margin-top:5px;margin-bottom:0;">
                                MCP connection 3
                            </p>
                        </div>
                    </div>
                    
                    <p style="color:#666;font-size:0.9em;text-align:center;margin-top:-10px;margin-bottom:20px;">
                        <strong>LÆ°u Ã½:</strong> CÃ³ thá»ƒ nháº­p JWT token trá»±c tiáº¿p hoáº·c URL Ä‘áº§y Ä‘á»§ <code>wss://api.xiaozhi.me/mcp/?token=...</code> - há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng xá»­ lÃ½
                    </p>
                    
                    <hr style="margin:25px 0;border:none;border-top:2px solid #e5e7eb;">
                    
                    <!-- API KEYS GRID (2 Columns) -->
                    <div style="display:grid;grid-template-columns:1fr 1fr;gap:30px;">
                        <!-- LEFT COLUMN: Gemini -->
                        <div style="border-right:2px solid #e5e7eb;padding-right:30px;">
                            <label for="gemini-api-key" style="display:flex;align-items:center;gap:10px;">
                                ğŸ¤– Gemini API Key 
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="gemini-api-key" 
                                    placeholder="AIzaSyXXXXXXXXXXXXXXXXXX..."
                                    oninput="autoSaveGeminiKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('gemini-api-key', this)" title="Hiá»‡n/áº¨n API key">
                                        ï¿½
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('gemini-api-key', this)" title="Copy API key">
                                        ğŸ“‹
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Miá»…n phÃ­:</strong> Láº¥y API key táº¡i 
                                <a href="https://aistudio.google.com/apikey" target="_blank" style="color:#667eea;">
                                    aistudio.google.com/apikey
                                </a>
                                <br>
                                <span id="gemini-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                            
                            <label for="gemini-model" style="margin-top:15px;display:block;">
                                ğŸ¯ Gemini Model
                            </label>
                            <select 
                                id="gemini-model" 
                                onchange="saveGeminiModel()"
                                style="width:100%;padding:10px;border:2px solid #e5e7eb;border-radius:8px;font-size:0.95em;"
                            >
                                <option value="models/gemini-3-flash-preview">âš¡ Gemini 3 Flash Preview (Má»›i nháº¥t)</option>
                                <option value="models/gemini-2.5-flash">âš¡ Gemini 2.5 Flash (á»”n Ä‘á»‹nh)</option>
                                <option value="models/gemini-2.5-pro">ğŸ’ Gemini 2.5 Pro (Cháº¥t lÆ°á»£ng cao nháº¥t)</option>
                                <option value="models/gemini-2.0-flash-exp">âš¡ Gemini 2.0 Flash Exp</option>
                                <option value="models/gemini-1.5-pro">ğŸ’ Gemini 1.5 Pro (á»”n Ä‘á»‹nh)</option>
                                <option value="models/gemini-2.0-flash-thinking-exp">ğŸ§  Gemini 2.0 Flash Thinking (Suy luáº­n tá»‘t)</option>
                                <option value="models/gemini-1.5-pro">ğŸ’ Gemini 1.5 Pro (á»”n Ä‘á»‹nh)</option>
                                <option value="models/gemini-1.5-flash">âš¡ Gemini 1.5 Flash (CÃ¢n báº±ng)</option>
                            </select>
                            <p style="color:#666;font-size:0.85em;margin-top:5px;">
                                ğŸ’¡ <strong>3.0 Flash:</strong> Model má»›i nháº¥t (12/2024), giáº£m 30% token | <strong>2.5 Pro:</strong> Cháº¥t lÆ°á»£ng cao nháº¥t | <strong>1.5 Pro:</strong> á»”n Ä‘á»‹nh
                            </p>
                        </div>
                        
                        <!-- RIGHT COLUMN: OpenAI + Serper -->
                        <div style="padding-left:30px;">
                            <label for="openai-api-key" style="display:flex;align-items:center;gap:10px;">
                                ğŸ§  OpenAI API Key (GPT-4)
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                                <span style="color:#ef4444;font-size:0.75em;font-weight:normal;">TRáº¢ PHÃ</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="openai-api-key" 
                                    placeholder="sk-proj-XXXXXXXXXXXXXXXXXX..."
                                    oninput="autoSaveOpenAIKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('openai-api-key', this)" title="Hiá»‡n/áº¨n API key">
                                        ï¿½
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('openai-api-key', this)" title="Copy API key">
                                        ğŸ“‹
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Tráº£ phÃ­:</strong> Láº¥y API key táº¡i 
                                <a href="https://platform.openai.com/api-keys" target="_blank" style="color:#667eea;">
                                    platform.openai.com/api-keys
                                </a>
                                <br>
                                <span style="font-size:0.85em;">ğŸ’° GiÃ¡: $0.01-0.03/1K tokens | ğŸ†“ Free trial: $5 credit</span>
                                <br>
                                <span id="openai-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                            
                            <hr style="margin:20px 0;border:none;border-top:1px solid #e5e7eb;">
                            
                            <label for="serper-api-key" style="display:flex;align-items:center;gap:10px;margin-top:20px;">
                                ğŸ” Serper API Key (Google Search)
                                <span style="color:#10b981;font-size:0.85em;font-weight:normal;">(Auto-save)</span>
                                <span style="color:#22c55e;font-size:0.75em;font-weight:normal;">MIá»„N PHÃ 2500/thÃ¡ng</span>
                            </label>
                            <div class="api-key-input-container">
                                <input 
                                    type="password" 
                                    id="serper-api-key" 
                                    placeholder="abcdef1234567890..."
                                    oninput="autoSaveSerperKey()"
                                    style="font-size:0.9em;"
                                />
                                <div class="input-icons">
                                    <button type="button" class="api-key-icon-btn" onclick="toggleApiKeyVisibility('serper-api-key', this)" title="Hiá»‡n/áº¨n API key">
                                        ï¿½
                                    </button>
                                    <button type="button" class="api-key-icon-btn" onclick="copyApiKey('serper-api-key', this)" title="Copy API key">
                                        ğŸ“‹
                                    </button>
                                </div>
                            </div>
                            <p style="color:#666;font-size:0.9em;margin-top:-10px;">
                                <strong>Miá»…n phÃ­:</strong> ÄÄƒng kÃ½ táº¡i 
                                <a href="https://serper.dev" target="_blank" style="color:#667eea;">
                                    serper.dev
                                </a>
                                <br>
                                <span style="font-size:0.85em;">ğŸ†“ 2500 queries/thÃ¡ng miá»…n phÃ­ | ğŸ¯ Google Search chÃ­nh xÃ¡c hÆ¡n DuckDuckGo</span>
                                <br>
                                <span id="serper-key-status" style="color:#10b981;font-weight:600;"></span>
                            </p>
                        </div>
                    </div>
                </div>
                <div class="modal-footer">
                    <button class="modal-btn secondary" onclick="closeSettingsModal()">Há»§y</button>
                    <button class="modal-btn info" onclick="copyFullUrl()">ğŸ“‹ Copy URL Ä‘áº§y Ä‘á»§</button>
                    <button class="modal-btn primary" onclick="saveEndpoint()">ğŸ’¾ LÆ°u</button>
                </div>
            </div>
        </div>
    </div>
    
    <script>
        let ws;
        let llmChatMessages = []; // Store LLM chat messages
        
        // Section switching
        function showSection(name) {
            document.querySelectorAll('.menu-item').forEach(item => item.classList.remove('active'));
            event.target.classList.add('active');
            
            document.getElementById('dashboard-section').style.display = name === 'dashboard' ? 'block' : 'none';
            document.getElementById('tools-section').style.display = name === 'tools' ? 'block' : 'none';
            document.getElementById('llm-chat-section').style.display = name === 'llm-chat' ? 'block' : 'none';
            document.getElementById('api-quotas-section').style.display = name === 'api-quotas' ? 'block' : 'none';
            document.getElementById('music-section').style.display = name === 'music' ? 'block' : 'none';
            document.getElementById('music-settings-section').style.display = name === 'music-settings' ? 'block' : 'none';
            document.getElementById('conversation-section').style.display = name === 'conversation' ? 'block' : 'none';
            document.getElementById('playlist-section').style.display = name === 'playlist' ? 'block' : 'none';
            document.getElementById('knowledge-section').style.display = name === 'knowledge' ? 'block' : 'none';
            
            // Load API Quotas when opening api-quotas section
            if (name === 'api-quotas') {
                refreshQuotasPage();
            }
            
            // Load LLM Chat section
            if (name === 'llm-chat') {
                loadLLMChatModel();
            }
            
            // Load conversation when opening conversation section
            if (name === 'conversation') {
                loadConversationHistory();
            }
            
            // Load music library when opening music section
            if (name === 'music') {
                loadMusicSourcePreference();
                updateMusicStatus();
            }
            if (name === 'music-settings') {
                loadMusicFolderSettings();
            }
            
            // Load playlist when opening playlist section
            if (name === 'playlist') {
                // use initPlaylists() (render existing playlists) - loadPlaylistSection was removed
                initPlaylists();
            }
            
            // Load knowledge base when opening knowledge section
            if (name === 'knowledge') {
                loadKnowledgeBase();
            }
        }
        
        // ===== API QUOTAS PAGE FUNCTIONS =====
        async function refreshQuotasPage() {
            addLog('ğŸ”„ Äang lÃ m má»›i API Quotas...', 'info');
            try {
                const response = await fetch('/api/quotas');
                const data = await response.json();
                
                if (data.success) {
                    // Update Gemini status
                    const geminiStatus = document.getElementById('gemini-status');
                    if (data.gemini && data.gemini.has_key) {
                        geminiStatus.innerHTML = 'âœ… API Key Ä‘Ã£ cáº¥u hÃ¬nh';
                        geminiStatus.style.color = '#10b981';
                    } else {
                        geminiStatus.innerHTML = 'âŒ ChÆ°a cÃ³ API Key';
                        geminiStatus.style.color = '#ef4444';
                    }
                    
                    // Update Serper status
                    const serperStatus = document.getElementById('serper-status');
                    if (data.serper && data.serper.has_key) {
                        serperStatus.innerHTML = 'âœ… API Key Ä‘Ã£ cáº¥u hÃ¬nh';
                        serperStatus.style.color = '#10b981';
                    } else {
                        serperStatus.innerHTML = 'âŒ ChÆ°a cÃ³ API Key';
                        serperStatus.style.color = '#ef4444';
                    }
                    
                    addLog('âœ… ÄÃ£ lÃ m má»›i API Quotas', 'success');
                } else {
                    addLog('âŒ Lá»—i: ' + (data.error || 'Unknown error'), 'error');
                }
            } catch (error) {
                console.error('Error refreshing quotas:', error);
                addLog('âŒ Lá»—i káº¿t ná»‘i: ' + error.message, 'error');
            }
        }
        
        async function testGeminiAPI() {
            addLog('ğŸ§ª Äang test Gemini API...', 'info');
            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: 'Hello, this is a test message. Reply with OK.'})
                });
                const data = await response.json();
                
                if (data.response) {
                    addLog('âœ… Gemini API hoáº¡t Ä‘á»™ng tá»‘t! Response: ' + data.response.substring(0, 100) + '...', 'success');
                } else {
                    addLog('âŒ Gemini API test tháº¥t báº¡i', 'error');
                }
            } catch (error) {
                console.error('Error testing Gemini:', error);
                addLog('âŒ Gemini test error: ' + error.message, 'error');
            }
        }
        
        async function testSerperAPI() {
            addLog('ğŸ§ª Äang test Serper API...', 'info');
            try {
                const response = await fetch('/api/google_search', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({query: 'test search'})
                });
                const data = await response.json();
                
                if (data.results && data.results.length > 0) {
                    addLog('âœ… Serper API hoáº¡t Ä‘á»™ng tá»‘t! TÃ¬m tháº¥y ' + data.results.length + ' káº¿t quáº£', 'success');
                } else {
                    addLog('âŒ Serper API test tháº¥t báº¡i', 'error');
                }
            } catch (error) {
                console.error('Error testing Serper:', error);
                addLog('âŒ Serper test error: ' + error.message, 'error');
            }
        }
        
        // Tab switching
        function switchTab(index) {
            document.querySelectorAll('.tab-btn').forEach((btn, i) => btn.classList.toggle('active', i === index));
            document.querySelectorAll('.tab-content').forEach((content, i) => content.classList.toggle('active', i === index));
        }
        
        // Quick actions - 20 tools
        function setVolumePrompt() {
            const level = prompt('Nháº­p Ã¢m lÆ°á»£ng (0-100):', '50');
            if (level === null) return;
            const levelNum = parseInt(level);
            if (isNaN(levelNum) || levelNum < 0 || levelNum > 100) {
                addLog('âŒ Ã‚m lÆ°á»£ng pháº£i tá»« 0-100', 'error');
                return;
            }
            setVolumeQuick(levelNum);
        }
        function setVolumeQuick(level) { 
            if (level >= 0 && level <= 100) {
                callTool('set_volume', {level});
            } else {
                addLog('âŒ Ã‚m lÆ°á»£ng pháº£i tá»« 0-100', 'error');
            }
        }
        function getVolumeInfo() {
            callTool('get_volume', {});
        }
        function screenshot() { callAPI('/api/screenshot', {}); }
        function notification() { callAPI('/api/notification', {title: 'Xiaozhi', message: 'Test notification'}); }
        function setBrightness() { 
            const level = prompt('Nháº­p Ä‘á»™ sÃ¡ng (0-100):', '50');
            if (level === null) return;
            const levelNum = parseInt(level);
            if (isNaN(levelNum) || levelNum < 0 || levelNum > 100) {
                addLog('âŒ Äá»™ sÃ¡ng pháº£i tá»« 0-100', 'error');
                return;
            }
            callTool('set_brightness', {level: levelNum});
        }
        function openApp() {
            const app = prompt('Nháº­p tÃªn app (notepad/calc/paint/cmd/explorer):', 'notepad');
            if (app && app.trim()) callTool('open_application', {app_name: app.trim()});
        }
        function listProcesses() { callTool('list_running_processes', {limit: 10}); }
        function killProcess() {
            const id = prompt('Nháº­p PID hoáº·c tÃªn tiáº¿n trÃ¬nh:', 'chrome');
            if (id && id.trim()) callTool('kill_process', {identifier: id.trim()});
        }
        function createFile() {
            const path = prompt('ÄÆ°á»ng dáº«n file:', 'C:/test.txt');
            if (!path || !path.trim()) return;
            const content = prompt('Ná»™i dung:', 'Hello World');
            if (content !== null) callTool('create_file', {path: path.trim(), content});
        }
        function readFile() {
            const path = prompt('ÄÆ°á»ng dáº«n file:', 'C:/test.txt');
            if (path && path.trim()) callTool('read_file', {path: path.trim()});
        }
        function listFiles() {
            const dir = prompt('ThÆ° má»¥c:', 'C:/Users');
            if (dir && dir.trim()) callTool('list_files', {directory: dir.trim()});
        }
        function diskUsage() { callTool('get_disk_usage', {}); }
        function networkInfo() {
            // Show loading message
            showResult('â³ Äang quÃ©t máº¡ng vÃ  cÃ¡c thiáº¿t bá»‹...');
            addLog('ğŸŒ Äang quÃ©t thÃ´ng tin máº¡ng...', 'info');
            
            fetch('/api/tool/get_network_info', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({})
            })
            .then(r => r.json())
            .then(data => {
                if (data.success) {
                    // Save to conversation history
                    const summary = `QuÃ©t máº¡ng: ${data.total_devices} thiáº¿t bá»‹ - ${data.local_device.hostname} (${data.local_device.ip})`;
                    addToConversation('system', `ğŸŒ Network Scan: ${summary}`);
                    addLog(`âœ… ${summary}`, 'success');
                    
                    let html = '<div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 10px; color: white;">';
                    html += '<h2 style="margin: 0 0 20px 0; font-size: 24px;">ğŸŒ ThÃ´ng Tin Máº¡ng</h2>';
                    
                    // Local device info
                    html += '<div style="background: rgba(255,255,255,0.15); padding: 15px; border-radius: 8px; margin-bottom: 20px;">';
                    html += '<h3 style="margin: 0 0 10px 0; font-size: 18px;">ğŸ’» MÃ¡y Cá»§a Báº¡n</h3>';
                    html += `<p style="margin: 5px 0;"><strong>ğŸ·ï¸ Hostname:</strong> ${data.local_device.hostname}</p>`;
                    html += `<p style="margin: 5px 0;"><strong>ğŸŒ IP Address:</strong> ${data.local_device.ip}</p>`;
                    html += `<p style="margin: 5px 0;"><strong>ğŸ“¡ MAC Address:</strong> ${data.local_device.mac}</p>`;
                    html += `<p style="margin: 5px 0;"><strong>ğŸšª Gateway (Router):</strong> ${data.local_device.gateway}</p>`;
                    html += '</div>';
                    
                    // Network devices
                    if (data.network_devices && data.network_devices.length > 0) {
                        html += '<div style="background: rgba(255,255,255,0.15); padding: 15px; border-radius: 8px;">';
                        html += `<h3 style="margin: 0 0 15px 0; font-size: 18px;">ğŸ“± Thiáº¿t Bá»‹ Trong Máº¡ng (${data.total_devices})</h3>`;
                        html += '<div style="max-height: 400px; overflow-y: auto;">';
                        
                        data.network_devices.forEach((device, idx) => {
                            const bgColor = device.is_local ? 'rgba(76, 175, 80, 0.3)' : 'rgba(255,255,255,0.1)';
                            const icon = device.is_local ? 'ğŸ‘¤' : 'ğŸ–¥ï¸';
                            html += `<div style="background: ${bgColor}; padding: 12px; border-radius: 6px; margin-bottom: 10px; border-left: 3px solid ${device.is_local ? '#4CAF50' : '#fff'};">`;
                            html += `<div style="display: flex; justify-content: space-between; align-items: center;">`;
                            html += `<div>`;
                            html += `<p style="margin: 0; font-size: 16px; font-weight: bold;">${icon} ${device.hostname}</p>`;
                            html += `<p style="margin: 5px 0 0 0; font-size: 14px; opacity: 0.9;">ğŸŒ IP: ${device.ip}</p>`;
                            html += `<p style="margin: 3px 0 0 0; font-size: 13px; opacity: 0.8;">ğŸ“¡ MAC: ${device.mac}</p>`;
                            html += `</div>`;
                            if (device.is_local) {
                                html += `<div style="background: #4CAF50; padding: 5px 10px; border-radius: 4px; font-size: 12px; font-weight: bold;">Báº N</div>`;
                            }
                            html += `</div>`;
                            html += `</div>`;
                        });
                        
                        html += '</div></div>';
                    } else {
                        html += '<p style="text-align: center; opacity: 0.8; margin-top: 10px;">KhÃ´ng tÃ¬m tháº¥y thiáº¿t bá»‹ khÃ¡c trong máº¡ng</p>';
                    }
                    
                    html += '</div>';
                    showResult(html);
                } else {
                    const error = data.error || 'KhÃ´ng thá»ƒ láº¥y thÃ´ng tin máº¡ng';
                    showResult('âŒ Lá»—i: ' + error);
                    addLog(`âŒ Lá»—i quÃ©t máº¡ng: ${error}`, 'error');
                }
            })
            .catch(err => {
                showResult('âŒ Lá»—i káº¿t ná»‘i: ' + err.message);
                addLog(`âŒ Lá»—i káº¿t ná»‘i: ${err.message}`, 'error');
            });
        }
        function batteryStatus() { callTool('get_battery_status', {}); }
        function searchWeb() {
            const query = prompt('Tá»« khÃ³a tÃ¬m kiáº¿m:', '');
            if (query && query.trim()) callTool('search_web', {query: query.trim()});
        }
        function calculator() {
            const expr = prompt('Biá»ƒu thá»©c toÃ¡n há»c:', '2+2*3');
            if (expr && expr.trim()) callAPI('/api/calculator', {expression: expr.trim()});
        }
        function getClipboard() { callTool('get_clipboard', {}); }
        function setClipboard() {
            const text = prompt('Ná»™i dung cáº§n copy:', '');
            if (text !== null && text.trim()) callTool('set_clipboard', {text: text.trim()});
        }
        function playSound() {
            const freq = prompt('Táº§n sá»‘ Hz (200-2000):', '1000');
            if (freq === null) return;
            const dur = prompt('Thá»i gian ms (100-3000):', '500');
            if (dur === null) return;
            const freqNum = parseInt(freq);
            const durNum = parseInt(dur);
            if (isNaN(freqNum) || freqNum < 200 || freqNum > 2000) {
                addLog('âŒ Táº§n sá»‘ pháº£i tá»« 200-2000 Hz', 'error');
                return;
            }
            if (isNaN(durNum) || durNum < 100 || durNum > 3000) {
                addLog('âŒ Thá»i gian pháº£i tá»« 100-3000 ms', 'error');
                return;
            }
            callTool('play_sound', {frequency: freqNum, duration: durNum});
        }
        
        // NEW TOOL FUNCTIONS
        function lockComputer() {
            if (confirm('Báº¡n cÃ³ cháº¯c muá»‘n khÃ³a mÃ¡y tÃ­nh?')) {
                callTool('lock_computer', {});
            }
        }
        function shutdownSchedule() {
            const action = prompt('HÃ nh Ä‘á»™ng (shutdown/restart/cancel):', 'shutdown');
            if (!action || !action.trim()) return;
            const actionLower = action.trim().toLowerCase();
            if (!['shutdown', 'restart', 'cancel'].includes(actionLower)) {
                addLog('âŒ HÃ nh Ä‘á»™ng khÃ´ng há»£p lá»‡. DÃ¹ng: shutdown, restart, hoáº·c cancel', 'error');
                return;
            }
            const delay = prompt('TrÃ¬ hoÃ£n (giÃ¢y):', '60');
            if (delay === null) return;
            const delayNum = parseInt(delay) || 0;
            if (delayNum < 0) {
                addLog('âŒ Thá»i gian trÃ¬ hoÃ£n pháº£i >= 0', 'error');
                return;
            }
            callTool('shutdown_schedule', {action: actionLower, delay: delayNum});
        }
        function showDesktop() {
            callTool('show_desktop', {});
        }
        function undoOperation() {
            callTool('undo_operation', {});
        }
        function setTheme() {
            const dark = confirm('Chá»n OK cho theme Tá»I, Cancel cho theme SÃNG');
            callTool('set_theme', {dark_mode: dark});
        }
        function changeWallpaper() {
            const keyword = prompt('Tá»« khÃ³a hÃ¬nh ná»n (hoáº·c Ä‘á»ƒ trá»‘ng Ä‘á»ƒ chá»n ngáº«u nhiÃªn):', '');
            callTool('change_wallpaper', {keyword: keyword || ''});
        }
        function getDesktopPath() {
            callTool('get_desktop_path', {});
        }
        function pasteContent() {
            const content = prompt('Nháº­p ná»™i dung cáº§n dÃ¡n (hoáº·c Ä‘á»ƒ trá»‘ng Ä‘á»ƒ dÃ¡n clipboard hiá»‡n táº¡i):', '');
            callTool('paste_content', {content: content || ''});
        }
        function pressEnter() {
            callTool('press_enter', {});
        }
        function findInDocument() {
            const searchText = prompt('Nháº­p ná»™i dung tÃ¬m kiáº¿m:', '');
            if (searchText && searchText.trim()) {
                callTool('find_in_document', {search_text: searchText.trim()});
            }
        }
        
        // AI ASSISTANT
        function saveGeminiModel() {
            const select = document.getElementById('gemini-model');
            if (!select) return;
            const model = select.value;
            localStorage.setItem('gemini_model', model);
            
            // Determine model name for display
            let modelName = 'Unknown';
            if (model.includes('flash-thinking')) modelName = 'Thinking ğŸ§ ';
            else if (model.includes('flash')) modelName = 'Flash âš¡';
            else if (model.includes('exp-1206')) modelName = 'Pro Exp ğŸš€';
            else if (model.includes('1.5-pro')) modelName = '1.5 Pro ğŸ’';
            else if (model.includes('pro')) modelName = 'Pro ğŸš€';
            
            addLog(`âœ… ÄÃ£ lÆ°u Gemini model: ${modelName}`, 'success');
        }
        
        function loadGeminiModel() {
            const saved = localStorage.getItem('gemini_model') || 'models/gemini-3-flash-preview';
            const select = document.getElementById('gemini-model');
            if (select) {
                // Check if the saved value exists in options
                const options = Array.from(select.options).map(o => o.value);
                if (options.includes(saved)) {
                    select.value = saved;
                } else {
                    // Default to first option if saved value is invalid
                    select.value = 'models/gemini-3-flash-preview';
                    localStorage.setItem('gemini_model', 'models/gemini-3-flash-preview');
                }
            }
        }
        
        function getGeminiModelName(model) {
            if (model.includes('flash-thinking')) return 'Thinking ğŸ§ ';
            if (model.includes('2.0-flash')) return '2.0 Flash âš¡';
            if (model.includes('1.5-flash')) return '1.5 Flash âš¡';
            if (model.includes('exp-1206')) return '2.0 Pro ğŸš€';
            if (model.includes('1.5-pro')) return '1.5 Pro ğŸ’';
            return 'Gemini';
        }
        
        function askGemini() {
            const prompt = window.prompt('ğŸ¤– Há»i Gemini AI + ğŸ“š Knowledge Base\n(Gemini sáº½ tá»± Ä‘á»™ng tÃ¬m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u cá»§a báº¡n):', '');
            if (prompt && prompt.trim()) {
                const model = localStorage.getItem('gemini_model') || 'models/gemini-3-flash-preview';
                const modelName = getGeminiModelName(model);
                addLog(`ğŸ¤– Äang há»i Gemini ${modelName} + ğŸ“š Knowledge Base...`, 'info');
                addLog(`   â“ CÃ¢u há»i: "${prompt}"`, 'info');
                
                // Sá»­ dá»¥ng endpoint /api/tool/ask_gemini (cÃ³ tÃ­ch há»£p KB tá»± Ä‘á»™ng)
                fetch('/api/tool/ask_gemini', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({prompt: prompt.trim(), model: model})
                })
                .then(res => res.json())
                .then(result => {
                    if(result.success) {
                        const response = result.response || result.response_text || '';
                        const hasKB = result.knowledge_base_used ? ' ğŸ“š' : '';
                        addLog(`âœ… Gemini${hasKB}: ${response.substring(0, 300)}...`, 'success');
                        if(result.knowledge_base_used) {
                            addLog(`   ğŸ“š ÄÃ£ sá»­ dá»¥ng thÃ´ng tin tá»« Knowledge Base`, 'info');
                        }
                    } else {
                        addLog(`âŒ Gemini error: ${result.error}`, 'error');
                    }
                })
                .catch(err => addLog(`âŒ Error: ${err.message}`, 'error'));
            }
        }
        
        function askGPT4() {
            const prompt = window.prompt('Há»i GPT-4 (TRáº¢ PHÃ - cháº¥t lÆ°á»£ng cao nháº¥t):', '');
            if (prompt && prompt.trim()) {
                addLog(`ğŸ§  Há»i GPT-4: "${prompt}"`, 'info');
                
                // Use generic /api/call_tool endpoint
                fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'ask_gpt4', args: {prompt: prompt.trim()}})
                })
                .then(res => res.json())
                .then(result => {
                    if(result.success) {
                        const usage = result.usage ? ` (Tokens: ${result.usage.total_tokens})` : '';
                        addLog(`âœ… GPT-4: ${result.response_text.substring(0, 200)}...${usage}`, 'success');
                    } else {
                        addLog(`âŒ GPT-4 error: ${result.error}`, 'error');
                    }
                })
                .catch(err => addLog(`âŒ Error: ${err.message}`, 'error'));
            }
        }

        // API caller
        async function callAPI(endpoint, data) {
            try {
                addLog(`ğŸ”§ Calling ${endpoint}...`, 'info');
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(data)
                });
                const result = await response.json();
                addLog(`âœ… ${JSON.stringify(result).substring(0, 100)}`, 'success');
                return result;
            } catch (error) {
                addLog(`âŒ Error: ${error.message}`, 'error');
                return {success: false, error: error.message};
            }
        }
        
        async function callTool(name, params) {
            try {
                const paramsStr = JSON.stringify(params);
                const displayParams = paramsStr.length > 50 ? paramsStr.substring(0, 50) + '...' : paramsStr;
                addLog(`ğŸ”§ Tool: ${name}(${displayParams})`, 'info');
                
                // Gá»i API endpoint tÆ°Æ¡ng á»©ng vá»›i tool
                const endpoint = `/api/tool/${name}`;
                const response = await fetch(endpoint, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(params)
                });
                const result = await response.json();
                
                // Hiá»ƒn thá»‹ káº¿t quáº£ Ä‘áº§y Ä‘á»§ hÆ¡n
                let resultMsg = '';
                if (result.success) {
                    const msg = result.message || result.content || JSON.stringify(result).substring(0, 200);
                    resultMsg = `âœ… ${name}: ${msg}`;
                } else {
                    resultMsg = `âŒ ${name}: ${result.error || 'Unknown error'}`;
                }
                addLog(resultMsg, result.success ? 'success' : 'error');
                
                return result;
            } catch (error) {
                addLog(`âŒ Tool "${name}" error: ${error.message}`, 'error');
                return {success: false, error: error.message};
            }
        }
        
        async function getResources() {
            try {
                // Sá»­ dá»¥ng cache náº¿u cÃ²n hiá»‡u lá»±c
                const now = Date.now();
                if (resourceCache && (now - lastResourceFetch) < RESOURCE_CACHE_TIME) {
                    return;
                }
                
                const response = await fetch('/api/resources');
                const data = await response.json();
                if (data.success) {
                    const cpuPercent = data.data.cpu_percent;
                    document.getElementById('cpu').textContent = cpuPercent + '%';
                    document.getElementById('ram').textContent = data.data.memory_percent + '%';
                    document.getElementById('disk').textContent = data.data.disk_percent + '%';
                    
                    // Update RunCat animation speed based on CPU usage
                    updateRunCatSpeed(cpuPercent);
                    
                    // Cáº­p nháº­t cache
                    resourceCache = data;
                    lastResourceFetch = now;
                } else {
                    addLog(`âŒ Lá»—i láº¥y tÃ i nguyÃªn: ${data.error}`, 'error');
                }
            } catch (error) {
                addLog(`âŒ ${error.message}`, 'error');
            }
        }
        
        async function getQuotas() {
            try {
                const response = await fetch('/api/quotas');
                const data = await response.json();
                if (data.success) {
                    // Gemini quota
                    const geminiEl = document.getElementById('gemini-quota');
                    if (data.gemini && geminiEl) {
                        if (data.gemini.has_key) {
                            geminiEl.innerHTML = `âœ… ${data.gemini.free_tier}<br><small style="color:#6b7280;">${data.gemini.daily_limit}</small>`;
                        } else {
                            geminiEl.innerHTML = `âŒ <small style="color:#ef4444;">ChÆ°a cÃ³ API key</small>`;
                        }
                    }
                    
                    // Serper quota
                    const serperEl = document.getElementById('serper-quota');
                    if (data.serper && serperEl) {
                        if (data.serper.has_key) {
                            serperEl.innerHTML = `âœ… ${data.serper.free_tier}`;
                        } else {
                            serperEl.innerHTML = `âŒ <small style="color:#ef4444;">ChÆ°a cÃ³ API key</small>`;
                        }
                    }
                } else {
                    console.log('Error fetching quotas:', data.error);
                }
            } catch (error) {
                console.error('Failed to fetch quotas:', error);
            }
        }
        
        // Update RunCat animation speed based on CPU usage (like RunCat365)
        function updateRunCatSpeed(cpuPercent) {
            // Calculate frame duration: 100ms (very fast) to 800ms (very slow)
            // High CPU = fast running, Low CPU = slow walking
            const minSpeed = 100;  // Fast run (10 fps)
            const maxSpeed = 800;  // Slow walk (1.25 fps)
            
            // CPU 0% = 800ms, CPU 100% = 100ms
            runcatSpeed = maxSpeed - (cpuPercent / 100) * (maxSpeed - minSpeed);
        }
        
        // Debounce helper
        function debounce(func, wait) {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        }
        
        async function calculate() {
            try {
                const expr = document.getElementById('calc-expr').value.trim();
                if (!expr) {
                    document.getElementById('calc-result').textContent = 'Vui lÃ²ng nháº­p biá»ƒu thá»©c';
                    return;
                }
                const response = await fetch('/api/calculator', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({expression: expr})
                });
                const data = await response.json();
                document.getElementById('calc-result').textContent = data.success ? data.result : data.error;
            } catch (error) {
                document.getElementById('calc-result').textContent = 'Lá»—i: ' + error.message;
            }
        }
        
        async function getCurrentTime() {
            try {
                const response = await fetch('/api/time');
                const data = await response.json();
                if (data.data) {
                    document.getElementById('time-result').textContent = data.data.datetime;
                }
            } catch (error) {
                document.getElementById('time-result').textContent = 'Lá»—i: ' + error.message;
            }
        }
        
        // Modal functions
        function openSettingsModal() {
            document.getElementById('settingsModal').style.display = 'block';
            loadCurrentEndpoint();
            loadGeminiModel();
        }
        
        function closeSettingsModal() {
            document.getElementById('settingsModal').style.display = 'none';
        }
        
        // Click outside modal to close
        window.onclick = function(event) {
            const modal = document.getElementById('settingsModal');
            if (event.target === modal) {
                closeSettingsModal();
            }
        }
        
        async function loadCurrentEndpoint() {
            try {
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // ğŸ”¥ FIX: Äá»‹nh nghÄ©a activeDevice tá»« active_index
                const activeIndex = data.active_index || 0;
                const activeDevice = data.endpoints && data.endpoints[activeIndex] ? data.endpoints[activeIndex] : null;
                
                // Load all 3 device tokens into separate input fields
                if (data.endpoints && data.endpoints.length >= 3) {
                    const input1 = document.getElementById('endpoint-url-1');
                    const input2 = document.getElementById('endpoint-url-2');
                    const input3 = document.getElementById('endpoint-url-3');
                    
                    if (input1) input1.value = data.endpoints[0]?.token || '';
                    if (input2) input2.value = data.endpoints[1]?.token || '';
                    if (input3) input3.value = data.endpoints[2]?.token || '';
                }
                
                // Load Gemini API key (luÃ´n set, ká»ƒ cáº£ empty)
                const geminiInput = document.getElementById('gemini-api-key');
                if (geminiInput) {
                    geminiInput.value = data.gemini_api_key || '';
                    if (data.gemini_api_key) {
                        updateGeminiKeyStatus('âœ“ API key Ä‘Ã£ cáº¥u hÃ¬nh', '#10b981');
                    } else {
                        updateGeminiKeyStatus('', '');
                    }
                }
                
                // Load OpenAI API key (luÃ´n set, ká»ƒ cáº£ empty)
                const openaiInput = document.getElementById('openai-api-key');
                if (openaiInput) {
                    openaiInput.value = data.openai_api_key || '';
                    if (data.openai_api_key) {
                        updateOpenAIKeyStatus('âœ“ API key Ä‘Ã£ cáº¥u hÃ¬nh', '#10b981');
                    } else {
                        updateOpenAIKeyStatus('', '');
                    }
                }
                
                // Load Serper API key (Google Search) (luÃ´n set, ká»ƒ cáº£ empty)
                const serperInput = document.getElementById('serper-api-key');
                if (serperInput) {
                    serperInput.value = data.serper_api_key || '';
                    if (data.serper_api_key) {
                        updateSerperKeyStatus('âœ“ Google Search sáºµn sÃ ng', '#10b981');
                    } else {
                        updateSerperKeyStatus('', '');
                    }
                }
                
                // Cáº­p nháº­t thÃ´ng tin hiá»‡n táº¡i trong config section
                if (document.getElementById('current-device-name')) {
                    document.getElementById('current-device-name').textContent = activeDevice?.name || 'ChÆ°a cáº¥u hÃ¬nh';
                }
                if (document.getElementById('current-device-token')) {
                    const token = activeDevice?.token || 'ChÆ°a cÃ³ token';
                    document.getElementById('current-device-token').textContent = 
                        token.length > 50 ? token.substring(0, 50) + '...' : token;
                }
            } catch (error) {
                addLog('âŒ Lá»—i táº£i endpoint: ' + error.message, 'error');
            }
        }
        
        // Toggle API key visibility (show/hide password)
        function toggleApiKeyVisibility(inputId, button) {
            const input = document.getElementById(inputId);
            if (input.type === 'password') {
                input.type = 'text';
                button.innerHTML = 'ğŸ™ˆ'; // Hide icon (khá»‰ che máº¯t)
                button.title = 'áº¨n API key';
            } else {
                input.type = 'password';
                button.innerHTML = 'ğŸµ'; // Show icon (khá»‰ Ä‘ang nhÃ¬n)
                button.title = 'Hiá»‡n API key';
            }
        }
        
        // Copy API key to clipboard
        async function copyApiKey(inputId, button) {
            const input = document.getElementById(inputId);
            const value = input.value.trim();
            
            if (!value) {
                button.innerHTML = 'âŒ';
                setTimeout(() => { button.innerHTML = 'ğŸ“‹'; }, 1000);
                return;
            }
            
            try {
                await navigator.clipboard.writeText(value);
                button.classList.add('copied');
                button.innerHTML = 'âœ…';
                
                setTimeout(() => {
                    button.classList.remove('copied');
                    button.innerHTML = 'ğŸ“‹';
                }, 1500);
            } catch (error) {
                // Fallback for older browsers
                input.select();
                document.execCommand('copy');
                button.innerHTML = 'âœ…';
                setTimeout(() => { button.innerHTML = 'ğŸ“‹'; }, 1500);
            }
        }
        
        // Auto-save Gemini API key
        let geminiSaveTimeout;
        async function autoSaveGeminiKey() {
            clearTimeout(geminiSaveTimeout);
            
            geminiSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('gemini-api-key').value.trim();
                
                // ğŸ”¥ FIX: Cho phÃ©p save empty string (khi user xÃ³a key)
                try {
                    if (apiKey) {
                        updateGeminiKeyStatus('ğŸ’¾ Äang lÆ°u...', '#f59e0b');
                    } else {
                        updateGeminiKeyStatus('ğŸ’¾ XÃ³a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/gemini-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateGeminiKeyStatus('âœ“ ÄÃ£ lÆ°u tá»± Ä‘á»™ng', '#10b981');
                        setTimeout(() => updateGeminiKeyStatus('âœ“ API key Ä‘Ã£ cáº¥u hÃ¬nh', '#10b981'), 2000);
                    } else {
                        updateGeminiKeyStatus('âŒ Lá»—i: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateGeminiKeyStatus('âŒ Lá»—i káº¿t ná»‘i', '#ef4444');
                }
            }, 1000); // Auto-save sau 1 giÃ¢y khÃ´ng gÃµ
        }
        
        function updateGeminiKeyStatus(message, color) {
            const statusEl = document.getElementById('gemini-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        // Auto-save OpenAI API key
        let openaiSaveTimeout;
        async function autoSaveOpenAIKey() {
            clearTimeout(openaiSaveTimeout);
            
            openaiSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('openai-api-key').value.trim();
                
                // ğŸ”¥ FIX: Cho phÃ©p save empty string (khi user xÃ³a key)
                try {
                    if (apiKey) {
                        updateOpenAIKeyStatus('ğŸ’¾ Äang lÆ°u...', '#f59e0b');
                    } else {
                        updateOpenAIKeyStatus('ğŸ’¾ XÃ³a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/openai-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateOpenAIKeyStatus('âœ“ ÄÃ£ lÆ°u tá»± Ä‘á»™ng', '#10b981');
                        setTimeout(() => updateOpenAIKeyStatus('âœ“ API key Ä‘Ã£ cáº¥u hÃ¬nh', '#10b981'), 2000);
                    } else {
                        updateOpenAIKeyStatus('âŒ Lá»—i: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateOpenAIKeyStatus('âŒ Lá»—i káº¿t ná»‘i', '#ef4444');
                }
            }, 1000);
        }
        
        function updateOpenAIKeyStatus(message, color) {
            const statusEl = document.getElementById('openai-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        // Auto-save Serper API key (Google Search)
        let serperSaveTimeout;
        async function autoSaveSerperKey() {
            clearTimeout(serperSaveTimeout);
            
            serperSaveTimeout = setTimeout(async () => {
                const apiKey = document.getElementById('serper-api-key').value.trim();
                
                // ğŸ”¥ FIX: Cho phÃ©p save empty string (khi user xÃ³a key)
                try {
                    if (apiKey) {
                        updateSerperKeyStatus('ğŸ’¾ Äang lÆ°u...', '#f59e0b');
                    } else {
                        updateSerperKeyStatus('ğŸ’¾ XÃ³a key...', '#f59e0b');
                    }
                    
                    const response = await fetch('/api/serper-key', {
                        method: 'POST',
                        headers: {'Content-Type': 'application/json'},
                        body: JSON.stringify({api_key: apiKey})
                    });
                    
                    const result = await response.json();
                    
                    if (result.success) {
                        updateSerperKeyStatus('âœ“ ÄÃ£ lÆ°u - Google Search sáºµn sÃ ng!', '#10b981');
                        setTimeout(() => updateSerperKeyStatus('âœ“ API key Ä‘Ã£ cáº¥u hÃ¬nh', '#10b981'), 2000);
                    } else {
                        updateSerperKeyStatus('âŒ Lá»—i: ' + result.error, '#ef4444');
                    }
                } catch (error) {
                    updateSerperKeyStatus('âŒ Lá»—i káº¿t ná»‘i', '#ef4444');
                }
            }, 1000);
        }
        
        function updateSerperKeyStatus(message, color) {
            const statusEl = document.getElementById('serper-key-status');
            if (statusEl) {
                statusEl.textContent = message;
                statusEl.style.color = color;
            }
        }
        
        async function saveEndpoint() {
            try {
                addLog('â³ Äang lÆ°u endpoints...', 'info');
                
                // Láº¥y token tá»« cáº£ 3 input fields
                const token1 = document.getElementById('endpoint-url-1').value.trim();
                const token2 = document.getElementById('endpoint-url-2').value.trim();
                const token3 = document.getElementById('endpoint-url-3').value.trim();
                
                if (!token1 && !token2 && !token3) {
                    addLog('âŒ Vui lÃ²ng nháº­p Ã­t nháº¥t 1 JWT token!', 'error');
                    return;
                }
                
                // Helper function to extract token from URL or return as-is
                function extractToken(input) {
                    if (!input) return '';
                    
                    // Náº¿u user nháº­p URL Ä‘áº§y Ä‘á»§, extract token tá»« URL
                    if (input.startsWith('wss://') || input.startsWith('http')) {
                        try {
                            const url = new URL(input);
                            const tokenParam = url.searchParams.get('token');
                            if (tokenParam) {
                                return tokenParam;
                            }
                        } catch (e) {
                            return input; // Return as-is if parse fails
                        }
                    }
                    return input;
                }
                
                const cleanToken1 = extractToken(token1);
                const cleanToken2 = extractToken(token2);
                const cleanToken3 = extractToken(token3);
                
                // Láº¥y danh sÃ¡ch thiáº¿t bá»‹ hiá»‡n táº¡i
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // Update all 3 devices
                const devices = data.endpoints.map((device, index) => {
                    let token = '';
                    if (index === 0) token = cleanToken1;
                    else if (index === 1) token = cleanToken2;
                    else if (index === 2) token = cleanToken3;
                    
                    return {
                        name: device.name || `Thiáº¿t bá»‹ ${index + 1}`,
                        token: token,
                        enabled: token.length > 0  // Auto-enable if has token
                    };
                });
                
                // LÆ°u cáº¥u hÃ¬nh
                const saveResponse = await fetch('/api/endpoints/save', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({devices: devices})
                });
                
                const saveData = await saveResponse.json();
                
                if (saveData.success) {
                    addLog('âœ… ÄÃ£ lÆ°u endpoints thÃ nh cÃ´ng!', 'success');
                    
                    // Show which devices were updated
                    let updatedCount = 0;
                    if (cleanToken1) { addLog('  ğŸ“± Thiáº¿t bá»‹ 1: ÄÃ£ cáº­p nháº­t', 'success'); updatedCount++; }
                    if (cleanToken2) { addLog('  ğŸ“± Thiáº¿t bá»‹ 2: ÄÃ£ cáº­p nháº­t', 'success'); updatedCount++; }
                    if (cleanToken3) { addLog('  ğŸ“± Thiáº¿t bá»‹ 3: ÄÃ£ cáº­p nháº­t', 'success'); updatedCount++; }
                    
                    addLog(`ğŸ“¡ ${updatedCount} thiáº¿t bá»‹ sáº½ tá»± Ä‘á»™ng káº¿t ná»‘i...`, 'info');
                    
                    closeSettingsModal();
                    
                    // Reload trang sau 1 giÃ¢y
                    setTimeout(() => {
                        location.reload();
                    }, 1000);
                } else {
                    addLog('âŒ Lá»—i: ' + saveData.error, 'error');
                }
            } catch (error) {
                addLog('âŒ Lá»—i lÆ°u endpoint: ' + error.message, 'error');
            }
        }
        
        function copyFullUrl() {
            // Get tokens from all 3 fields
            const token1 = document.getElementById('endpoint-url-1').value.trim();
            const token2 = document.getElementById('endpoint-url-2').value.trim();
            const token3 = document.getElementById('endpoint-url-3').value.trim();
            
            if (!token1 && !token2 && !token3) {
                addLog('âŒ KhÃ´ng cÃ³ token nÃ o Ä‘á»ƒ copy!', 'error');
                return;
            }
            
            let copyText = '';
            
            // Helper function to extract token and create URL
            function createFullUrl(input, deviceNum) {
                if (!input) return null;
                
                let token = input;
                
                // Náº¿u user Ä‘Ã£ nháº­p URL Ä‘áº§y Ä‘á»§, extract token
                if (input.startsWith('wss://') || input.startsWith('http')) {
                    try {
                        const url = new URL(input);
                        const tokenParam = url.searchParams.get('token');
                        if (tokenParam) {
                            token = tokenParam;
                        }
                    } catch (e) {
                        return null;
                    }
                }
                
                return `Thiáº¿t bá»‹ ${deviceNum}: wss://api.xiaozhi.me/mcp/?token=${token}`;
            }
            
            // Create URLs for all devices with tokens
            const urls = [];
            if (token1) urls.push(createFullUrl(token1, 1));
            if (token2) urls.push(createFullUrl(token2, 2));
            if (token3) urls.push(createFullUrl(token3, 3));
            
            copyText = urls.filter(u => u).join('\n\n');
            
            // Copy vÃ o clipboard
            navigator.clipboard.writeText(copyText).then(() => {
                addLog(`âœ… ÄÃ£ copy ${urls.length} URL vÃ o clipboard!`, 'success');
            }).catch(err => {
                addLog('âŒ Lá»—i copy: ' + err.message, 'error');
            });
        }
        
        // Load and display all 3 devices
        async function loadDevices() {
            try {
                const response = await fetch('/api/endpoints');
                const data = await response.json();
                
                // Update device status display for all 3 devices
                data.endpoints.forEach((device, index) => {
                    const deviceName = device?.name || `Thiáº¿t bá»‹ ${index + 1}`;
                    const hasToken = device?.token && device.token.length > 0;
                    const isEnabled = device?.enabled || false;
                    
                    addLog(`ğŸ“± ${deviceName}: ${hasToken ? 'âœ… Connected' : 'âŒ No token'} ${isEnabled ? '(Enabled)' : '(Disabled)'}`, 
                           hasToken && isEnabled ? 'success' : 'info');
                });
            } catch (error) {
                addLog('âŒ Lá»—i táº£i danh sÃ¡ch thiáº¿t bá»‹: ' + error.message, 'error');
            }
        }

        function addLog(message, type = 'info') {
            const log = document.getElementById('log');
            if (!log) return;
            const entry = document.createElement('div');
            entry.className = `log-entry log-${type}`;
            const time = new Date().toLocaleTimeString();
            entry.innerHTML = `<span class="log-time">${time}</span> ${message}`;
            log.insertBefore(entry, log.firstChild);
            
            // Giá»›i háº¡n 50 logs thay vÃ¬ 100 Ä‘á»ƒ giáº£m DOM size
            if (log.children.length > 50) {
                // XÃ³a nhiá»u logs cÃ¹ng lÃºc Ä‘á»ƒ trÃ¡nh reflow nhiá»u láº§n
                while (log.children.length > 50) {
                    log.removeChild(log.lastChild);
                }
            }
        }
        
        // WebSocket vá»›i reconnect optimization
        let wsReconnectAttempts = 0;
        const MAX_RECONNECT_DELAY = 30000; // Max 30s
        
        function connectWS() {
            ws = new WebSocket(`ws://${window.location.host}/ws`);
            ws.onopen = () => {
                addLog('âœ… WebSocket connected', 'success');
                wsReconnectAttempts = 0; // Reset counter khi connect thÃ nh cÃ´ng
            };
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                if (data.type === 'xiaozhi_status') {
                    const badge = document.getElementById('xiaozhi-status');
                    const text = document.getElementById('xiaozhi-text');
                    if (data.connected) {
                        badge.className = 'status-badge online';
                        text.textContent = 'Connected';
                    } else {
                        badge.className = 'status-badge offline';
                        text.textContent = 'Disconnected';
                    }
                } else if (data.type === 'xiaozhi_activity') {
                    if (data.method !== 'ping') {
                        addLog(`ğŸ“¡ Xiaozhi: ${data.method}`, 'info');
                    }
                }
            };
            ws.onclose = () => {
                addLog('âŒ WebSocket disconnected', 'error');
                // Exponential backoff cho reconnect
                wsReconnectAttempts++;
                const delay = Math.min(1000 * Math.pow(2, wsReconnectAttempts), MAX_RECONNECT_DELAY);
                setTimeout(connectWS, delay);
            };
        }
        
        // Caching vÃ  optimization
        let resourceCache = null;
        let lastResourceFetch = 0;
        const RESOURCE_CACHE_TIME = 3000; // Cache 3 giÃ¢y
        
        // Playlist list functions (sá»­ dá»¥ng API backend thay vÃ¬ localStorage)
        async function getPlaylists() {
            try {
                const response = await fetch('/api/youtube_playlists');
                const data = await response.json();
                return data.success ? data.playlists : [];
            } catch (e) {
                console.error('Failed to load playlists from API', e);
                return [];
            }
        }

        async function renderPlaylists() {
            const list = await getPlaylists();
            const container = document.getElementById('playlist-list');
            if (!container) return;
            container.innerHTML = '';

            if (list.length === 0) {
                container.innerHTML = '<div style="color:#666;padding:12px;">ChÆ°a cÃ³ playlist nÃ o. Nháº¥n "ï¼‹ ThÃªm Playlist" Ä‘á»ƒ thÃªm.</div>';
                return;
            }

            list.forEach((item, idx) => {
                const row = document.createElement('div');
                row.style.display = 'flex';
                row.style.alignItems = 'center';
                row.style.justifyContent = 'space-between';
                row.style.padding = '8px';
                row.style.borderBottom = '1px solid #eee';

                const left = document.createElement('div');
                left.style.display = 'flex';
                left.style.flexDirection = 'column';
                left.style.gap = '4px';

                const name = document.createElement('div');
                name.textContent = item.name;
                name.style.fontWeight = '700';
                name.style.color = '#333';

                const url = document.createElement('div');
                url.textContent = item.url;
                url.style.fontSize = '0.85em';
                url.style.color = '#666';

                left.appendChild(name);
                left.appendChild(url);

                const actions = document.createElement('div');
                actions.style.display = 'flex';
                actions.style.gap = '8px';

                const openBtn = document.createElement('button');
                openBtn.textContent = 'â–¶';
                openBtn.title = 'Má»Ÿ playlist';
                openBtn.style.padding = '6px 10px';
                openBtn.style.borderRadius = '6px';
                openBtn.style.border = 'none';
                openBtn.style.background = '#10b981';
                openBtn.style.color = 'white';
                openBtn.style.cursor = 'pointer';
                openBtn.onclick = () => openPlaylistByName(item.name);

                const delBtn = document.createElement('button');
                delBtn.textContent = 'ğŸ—‘';
                delBtn.title = 'XÃ³a playlist';
                delBtn.style.padding = '6px 10px';
                delBtn.style.borderRadius = '6px';
                delBtn.style.border = 'none';
                delBtn.style.background = '#ef4444';
                delBtn.style.color = 'white';
                delBtn.style.cursor = 'pointer';
                delBtn.onclick = () => { if (confirm('XÃ³a playlist "' + item.name + '"?')) { removePlaylistByName(item.name); } };

                actions.appendChild(openBtn);
                actions.appendChild(delBtn);

                row.appendChild(left);
                row.appendChild(actions);

                container.appendChild(row);
            });
        }

        function promptAddPlaylist() {
            const name = prompt('Nháº­p tÃªn playlist (vÃ­ dá»¥: "Nháº¡c chill"):');
            if (!name) return;
            const url = prompt('DÃ¡n link playlist YouTube (hoáº·c video trong playlist):');
            if (!url) return;
            addPlaylist(name.trim(), url.trim());
        }

        async function addPlaylist(name, url) {
            if (!name || !url) {
                addLog('âŒ TÃªn vÃ  URL khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng', 'error');
                return;
            }
            try {
                const response = await fetch('/api/youtube_playlists/add', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({name, url})
                });
                const data = await response.json();
                if (data.success) {
                    await renderPlaylists();
                    addLog('âœ… ÄÃ£ thÃªm playlist: ' + name, 'success');
                } else {
                    addLog('âŒ ' + (data.error || 'KhÃ´ng thá»ƒ thÃªm playlist'), 'error');
                }
            } catch (e) {
                console.error('Failed to add playlist', e);
                addLog('âŒ Lá»—i khi thÃªm playlist', 'error');
            }
        }

        async function removePlaylistByName(name) {
            try {
                const response = await fetch('/api/youtube_playlists/remove', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({name})
                });
                const data = await response.json();
                if (data.success) {
                    await renderPlaylists();
                    addLog('ğŸ—‘ ÄÃ£ xÃ³a playlist: ' + name, 'info');
                } else {
                    addLog('âŒ ' + (data.error || 'KhÃ´ng thá»ƒ xÃ³a playlist'), 'error');
                }
            } catch (e) {
                console.error('Failed to remove playlist', e);
                addLog('âŒ Lá»—i khi xÃ³a playlist', 'error');
            }
        }

        async function openPlaylistByName(name) {
            const list = await getPlaylists();
            const item = list.find(p => p.name === name);
            if (item) {
                window.open(item.url, '_blank');
                addLog('â–¶ Má»Ÿ playlist: ' + name, 'info');
            }
        }

        // Expose function for voice/AI integration: open by keyword search (fuzzy matching)
        async function triggerPlayByName(keyword) {
            if (!keyword || keyword.trim() === '') return false;
            
            keyword = keyword.trim().toLowerCase();
            const list = await getPlaylists();
            
            if (list.length === 0) {
                addLog('âš  Danh sÃ¡ch playlist trá»‘ng. HÃ£y thÃªm playlist trÆ°á»›c!', 'error');
                return false;
            }
            
            // BÆ°á»›c 1: TÃ¬m chÃ­nh xÃ¡c (exact match)
            let found = list.find(item => item.name.toLowerCase() === keyword);
            
            // BÆ°á»›c 2: TÃ¬m báº¯t Ä‘áº§u báº±ng tá»« khÃ³a (starts with)
            if (!found) {
                found = list.find(item => item.name.toLowerCase().startsWith(keyword));
            }
            
            // BÆ°á»›c 3: TÃ¬m chá»©a tá»« khÃ³a (contains)
            if (!found) {
                found = list.find(item => item.name.toLowerCase().includes(keyword));
            }
            
            // BÆ°á»›c 4: TÃ¬m theo tá»«ng tá»« trong tÃªn playlist
            if (!found) {
                found = list.find(item => {
                    const words = item.name.toLowerCase().split(/\\s+/);
                    return words.some(word => word.includes(keyword) || keyword.includes(word));
                });
            }
            
            if (found) {
                window.open(found.url, '_blank');
                addLog('ğŸ”Š PhÃ¡t playlist: "' + found.name + '" (tá»« khÃ³a: "' + keyword + '")', 'success');
                return true;
            } else {
                // Hiá»ƒn thá»‹ gá»£i Ã½ cÃ¡c playlist cÃ³ sáºµn
                const suggestions = list.map(item => item.name).slice(0, 5).join(', ');
                addLog('âš  KhÃ´ng tÃ¬m tháº¥y playlist vá»›i tá»« khÃ³a: "' + keyword + '"', 'error');
                addLog('ğŸ’¡ Gá»£i Ã½: ' + suggestions, 'info');
                return false;
            }
        }
        
        // HÃ m má»Ÿ playlist nhanh (alias) - dá»… nhá»› hÆ¡n cho voice command
        function moPlaylist(keyword) {
            return triggerPlayByName(keyword);
        }
        
        function danhSachNhac(keyword) {
            return triggerPlayByName(keyword);
        }

        // Initialize playlist list on load
        function initPlaylists() {
            renderPlaylists();
        }
        
        // ============================================================
        // KNOWLEDGE BASE FUNCTIONS
        // ============================================================
        
        async function loadKnowledgeBase() {
            try {
                const response = await fetch('/api/knowledge/status');
                const data = await response.json();
                
                if (data.success) {
                    document.getElementById('knowledge-folder-path').value = data.folder_path || '';
                    document.getElementById('kb-total-files').textContent = data.total_files || 0;
                    document.getElementById('kb-indexed-files').textContent = data.indexed_files || 0;
                    document.getElementById('kb-total-size').textContent = formatFileSize(data.total_size || 0);
                    document.getElementById('kb-last-update').textContent = data.last_update || '--';
                    
                    if (data.files && data.files.length > 0) {
                        renderKnowledgeFiles(data.files);
                    }
                }
            } catch (error) {
                console.error('Error loading knowledge base:', error);
            }
        }
        
        function formatFileSize(bytes) {
            if (bytes === 0) return '0 B';
            const k = 1024;
            const sizes = ['B', 'KB', 'MB', 'GB'];
            const i = Math.floor(Math.log(bytes) / Math.log(k));
            return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
        }
        
        function renderKnowledgeFiles(files) {
            const container = document.getElementById('knowledge-file-list');
            if (!files || files.length === 0) {
                container.innerHTML = '<p style="color: #666; text-align: center; padding: 40px;">ğŸ“‚ KhÃ´ng tÃ¬m tháº¥y file nÃ o.</p>';
                return;
            }
            
            const fileIcons = {
                'pdf': 'ğŸ“•',
                'txt': 'ğŸ“„',
                'docx': 'ğŸ“˜',
                'doc': 'ğŸ“˜',
                'md': 'ğŸ“',
                'json': 'ğŸ“‹',
                'csv': 'ğŸ“Š',
                'xlsx': 'ğŸ“—',
                'xls': 'ğŸ“—'
            };
            
            let html = '<div style="display: flex; flex-direction: column; gap: 8px;">';
            files.forEach((file, index) => {
                const ext = file.name.split('.').pop().toLowerCase();
                const icon = fileIcons[ext] || 'ğŸ“„';
                const indexed = file.indexed ? 'âœ…' : 'â³';
                const escapedPath = btoa(unescape(encodeURIComponent(file.path))); // Base64 encode Ä‘á»ƒ trÃ¡nh lá»—i escape
                
                html += `
                    <div style="display: flex; align-items: center; padding: 12px; background: white; border-radius: 8px; border: 1px solid #e5e7eb; gap: 12px;">
                        <span style="font-size: 1.5em;">${icon}</span>
                        <div style="flex: 1;">
                            <div style="font-weight: 600; color: #333;">${file.name}</div>
                            <div style="font-size: 0.85em; color: #666;">${formatFileSize(file.size)} â€¢ ${file.modified || ''}</div>
                        </div>
                        <span title="${file.indexed ? 'ÄÃ£ index' : 'ChÆ°a index'}">${indexed}</span>
                        <button onclick="indexSingleFileB64('${escapedPath}')" 
                                style="padding: 6px 12px; background: #667eea; color: white; border: none; border-radius: 6px; cursor: pointer; font-size: 0.85em;">
                            Index
                        </button>
                    </div>
                `;
            });
            html += '</div>';
            container.innerHTML = html;
        }
        
        async function saveKnowledgeFolder() {
            const folderPath = document.getElementById('knowledge-folder-path').value.trim();
            console.log('[Knowledge] saveKnowledgeFolder called, path:', folderPath);
            if (!folderPath) {
                addLog('âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c', 'error');
                alert('Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c!');
                return;
            }
            
            try {
                addLog('ğŸ’¾ Äang lÆ°u cáº¥u hÃ¬nh thÆ° má»¥c...', 'info');
                console.log('[Knowledge] Calling API /api/knowledge/set_folder');
                const response = await fetch('/api/knowledge/set_folder', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ folder_path: folderPath })
                });
                console.log('[Knowledge] Response status:', response.status);
                const data = await response.json();
                console.log('[Knowledge] Response data:', data);
                
                if (data.success) {
                    addLog('âœ… ' + data.message, 'success');
                    alert('âœ… ' + data.message);
                    loadKnowledgeBase();
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'), 'error');
                    alert('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'));
                }
            } catch (error) {
                console.error('[Knowledge] Error:', error);
                addLog('âŒ Lá»—i: ' + error.message, 'error');
                alert('âŒ Lá»—i: ' + error.message);
            }
        }
        
        async function scanKnowledgeFolder() {
            const folderPath = document.getElementById('knowledge-folder-path').value.trim();
            console.log('[Knowledge] scanKnowledgeFolder called, path:', folderPath);
            if (!folderPath) {
                addLog('âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c trÆ°á»›c', 'error');
                alert('Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c trÆ°á»›c!');
                return;
            }
            
            try {
                addLog('ğŸ” Äang quÃ©t thÆ° má»¥c...', 'info');
                console.log('[Knowledge] Calling API /api/knowledge/scan');
                const response = await fetch('/api/knowledge/scan', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ folder_path: folderPath })
                });
                console.log('[Knowledge] Response status:', response.status);
                const data = await response.json();
                console.log('[Knowledge] Response data:', data);
                
                if (data.success) {
                    addLog('âœ… TÃ¬m tháº¥y ' + data.total_files + ' files', 'success');
                    document.getElementById('kb-total-files').textContent = data.total_files;
                    document.getElementById('kb-total-size').textContent = formatFileSize(data.total_size);
                    renderKnowledgeFiles(data.files);
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'), 'error');
                    alert('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'));
                }
            } catch (error) {
                console.error('[Knowledge] Scan error:', error);
                addLog('âŒ Lá»—i: ' + error.message, 'error');
                alert('âŒ Lá»—i: ' + error.message);
            }
        }
        
        async function indexAllFiles() {
            try {
                addLog('ğŸ”„ Äang index táº¥t cáº£ files...', 'info');
                const response = await fetch('/api/knowledge/index_all', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('âœ… ' + data.message, 'success');
                    document.getElementById('kb-indexed-files').textContent = data.indexed_count;
                    document.getElementById('kb-last-update').textContent = data.last_update || 'Vá»«a xong';
                    loadKnowledgeBase();
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'), 'error');
                }
            } catch (error) {
                addLog('âŒ Lá»—i: ' + error.message, 'error');
            }
        }
        
        // Decode Base64 path vÃ  gá»i indexSingleFile
        async function indexSingleFileB64(base64Path) {
            try {
                const filePath = decodeURIComponent(escape(atob(base64Path)));
                await indexSingleFile(filePath);
            } catch (error) {
                addLog('âŒ Lá»—i decode path: ' + error.message, 'error');
            }
        }
        
        async function indexSingleFile(filePath) {
            try {
                addLog('ğŸ”„ Äang index file: ' + filePath.split(/[\\/]/).pop(), 'info');
                const response = await fetch('/api/knowledge/index_file', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ file_path: filePath })
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('âœ… ' + data.message, 'success');
                    loadKnowledgeBase();
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'), 'error');
                }
            } catch (error) {
                addLog('âŒ Lá»—i: ' + error.message, 'error');
            }
        }
        
        async function clearKnowledgeBase() {
            if (!confirm('Báº¡n cÃ³ cháº¯c muá»‘n xÃ³a toÃ n bá»™ index? Dá»¯ liá»‡u gá»‘c khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng.')) {
                return;
            }
            
            try {
                addLog('ğŸ—‘ï¸ Äang xÃ³a index...', 'info');
                const response = await fetch('/api/knowledge/clear', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' }
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('âœ… ' + data.message, 'success');
                    document.getElementById('kb-indexed-files').textContent = '0';
                    loadKnowledgeBase();
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh'), 'error');
                }
            } catch (error) {
                addLog('âŒ Lá»—i: ' + error.message, 'error');
            }
        }
        
        // ============================================================
        // CONVERSATION HISTORY FUNCTIONS (WeChat Style)
        // ============================================================
        
        async function loadConversationHistory() {
            try {
                addLog('ğŸ“š Äang táº£i lá»‹ch sá»­ há»™i thoáº¡i tá»« server...', 'info');
                const response = await fetch('/api/conversation/history');
                const data = await response.json();
                
                if (data.success) {
                    const messages = data.messages || [];
                    const totalMessages = data.total_messages || 0;
                    
                    displayConversationHistory(messages);
                    document.getElementById('total-messages').textContent = totalMessages;
                    
                    if (messages.length > 0) {
                        const lastMsg = messages[messages.length - 1];
                        const updateTime = lastMsg.timestamp || 'KhÃ´ng rÃµ';
                        document.getElementById('last-update').textContent = 'Cáº­p nháº­t: ' + updateTime;
                        addLog('âœ… ÄÃ£ táº£i thÃ nh cÃ´ng ' + totalMessages + ' tin nháº¯n (cáº­p nháº­t láº§n cuá»‘i: ' + updateTime + ')', 'success');
                    } else {
                        document.getElementById('last-update').textContent = 'ChÆ°a cÃ³ tin nháº¯n';
                        addLog('âœ… Lá»‹ch sá»­ há»™i thoáº¡i trá»‘ng', 'success');
                    }
                } else {
                    addLog('âŒ Lá»—i táº£i lá»‹ch sá»­ há»™i thoáº¡i: ' + (data.error || 'Unknown error'), 'error');
                    displayConversationHistory([]);
                }
            } catch (e) {
                console.error('Failed to load conversation history', e);
                addLog('âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n server Ä‘á»ƒ táº£i lá»‹ch sá»­', 'error');
                displayConversationHistory([]);
            }
        }
        
        function displayConversationHistory(messages) {
            const container = document.getElementById('chat-container');
            container.innerHTML = '';
            
            if (!messages || messages.length === 0) {
                container.innerHTML = '<div style="text-align:center; color:#999; padding:40px; font-size:1.1em;">ChÆ°a cÃ³ tin nháº¯n nÃ o ğŸ’¬</div>';
                return;
            }
            
            messages.forEach(msg => {
                const messageDiv = document.createElement('div');
                messageDiv.className = 'chat-message ' + msg.role;
                
                // Avatar
                const avatar = document.createElement('div');
                avatar.className = 'chat-avatar ' + msg.role;
                const roleIcons = {
                    user: 'ğŸ‘¤',
                    assistant: 'ğŸ¤–',
                    system: 'âš™ï¸',
                    tool: 'ğŸ”§'
                };
                avatar.textContent = roleIcons[msg.role] || 'ğŸ’¬';
                
                // Bubble
                const bubble = document.createElement('div');
                bubble.className = 'chat-bubble';
                
                // Content
                const content = document.createElement('div');
                content.className = 'chat-content';
                content.textContent = msg.content;
                bubble.appendChild(content);
                
                // Metadata
                if (msg.metadata && Object.keys(msg.metadata).length > 0) {
                    const metadata = document.createElement('div');
                    metadata.className = 'chat-metadata';
                    
                    // Show relevant metadata
                    if (msg.metadata.source) {
                        const sourceTag = document.createElement('span');
                        sourceTag.className = 'chat-metadata-item';
                        const sourceIcons = {
                            mcp: 'ğŸ”Œ MCP',
                            web_ui: 'ğŸŒ Web UI',
                            websocket: 'ğŸ“¡ WebSocket'
                        };
                        sourceTag.textContent = sourceIcons[msg.metadata.source] || msg.metadata.source;
                        metadata.appendChild(sourceTag);
                    }
                    
                    if (msg.metadata.method) {
                        const methodTag = document.createElement('span');
                        methodTag.className = 'chat-metadata-item';
                        methodTag.textContent = 'ğŸ“‹ ' + msg.metadata.method;
                        metadata.appendChild(methodTag);
                    }
                    
                    if (msg.metadata.model) {
                        const modelTag = document.createElement('span');
                        modelTag.className = 'chat-metadata-item';
                        modelTag.textContent = 'ğŸ§  ' + msg.metadata.model;
                        metadata.appendChild(modelTag);
                    }
                    
                    if (msg.metadata.success !== undefined) {
                        const statusTag = document.createElement('span');
                        statusTag.className = 'chat-metadata-item';
                        statusTag.textContent = msg.metadata.success ? 'âœ… Success' : 'âŒ Failed';
                        metadata.appendChild(statusTag);
                    }
                    
                    bubble.appendChild(metadata);
                }
                
                // Timestamp
                const timestamp = document.createElement('div');
                timestamp.className = 'chat-timestamp';
                timestamp.textContent = msg.timestamp;
                bubble.appendChild(timestamp);
                
                messageDiv.appendChild(avatar);
                messageDiv.appendChild(bubble);
                container.appendChild(messageDiv);
            });
            
            // Auto scroll to bottom
            container.scrollTop = container.scrollHeight;
        }
        
        async function exportConversation() {
            try {
                addLog('ğŸ’¾ Äang xuáº¥t lá»‹ch sá»­...', 'info');
                const response = await fetch('/api/conversation/export', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    addLog('âœ… ÄÃ£ xuáº¥t file: ' + data.path, 'success');
                    alert('âœ… ÄÃ£ xuáº¥t lá»‹ch sá»­ há»™i thoáº¡i!\\n\\nÄÆ°á»ng dáº«n: ' + data.path + '\\n\\nTá»•ng: ' + data.message);
                } else {
                    addLog('âŒ Lá»—i xuáº¥t file: ' + (data.error || 'Unknown'), 'error');
                }
            } catch (e) {
                console.error('Failed to export conversation', e);
                addLog('âŒ KhÃ´ng thá»ƒ xuáº¥t file', 'error');
            }
        }
        
        async function clearConversationHistory() {
            if (!confirm('âš ï¸ Báº¡n cÃ³ cháº¯c muá»‘n XÃ“A Táº¤T Cáº¢ lá»‹ch sá»­ há»™i thoáº¡i?\\n\\nHÃ nh Ä‘á»™ng nÃ y KHÃ”NG THá»‚ HOÃ€N TÃC!')) {
                return;
            }
            
            try {
                addLog('ğŸ—‘ï¸ Äang xÃ³a lá»‹ch sá»­...', 'info');
                const response = await fetch('/api/conversation/clear', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    document.getElementById('chat-container').innerHTML = '<div style="text-align:center; color:#999; padding:40px; font-size:1.1em;">ChÆ°a cÃ³ tin nháº¯n nÃ o ğŸ’¬</div>';
                    document.getElementById('total-messages').textContent = '0';
                    document.getElementById('last-update').textContent = 'ChÆ°a cÃ³ dá»¯ liá»‡u';
                    addLog('âœ… ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­', 'success');
                } else {
                    addLog('âŒ Lá»—i xÃ³a lá»‹ch sá»­: ' + (data.error || 'Unknown'), 'error');
                }
            } catch (e) {
                console.error('Failed to clear conversation', e);
                addLog('âŒ KhÃ´ng thá»ƒ xÃ³a lá»‹ch sá»­', 'error');
            }
        }
        
        // ===== MUSIC PLAYER FUNCTIONS =====
        let currentPlaylist = [];
        let allMusicFiles = []; // Store all files for filtering
        let currentTrackIndex = -1;
        let isPlaying = false;
        let isShuffleOn = false;
        let repeatMode = 0; // 0: off, 1: repeat all, 2: repeat one
        let currentMusicSource = 'library'; // 'library' or 'user'
        let vlcStatusInterval = null; // VLC status polling interval
        
        // ===== VLC STATUS POLLING - Real-time sync with python-vlc =====
        async function pollVlcStatus() {
            try {
                const response = await fetch('/api/vlc_status');
                const status = await response.json();
                
                if (status.state && status.state !== 'not_initialized') {
                    // Update play state
                    isPlaying = status.is_playing;
                    document.getElementById('play-btn').textContent = isPlaying ? 'â¸ï¸' : 'â–¶ï¸';
                    
                    // Update progress slider (only if not dragging)
                    if (status.position !== undefined && !isDraggingProgress) {
                        const percent = (status.position * 100).toFixed(1);
                        const slider = document.getElementById('progress-slider');
                        if (slider) {
                            slider.value = percent;
                            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${percent}%, #374151 ${percent}%, #374151 100%)`;
                        }
                    }
                    
                    // Update time display
                    if (status.current_time_formatted) {
                        document.getElementById('current-time').textContent = status.current_time_formatted;
                    }
                    if (status.duration_formatted) {
                        document.getElementById('total-time').textContent = status.duration_formatted;
                    }
                    
                    // Update volume (sync from VLC)
                    if (status.volume !== undefined) {
                        const slider = document.getElementById('volume-slider');
                        if (document.activeElement !== slider) { // Don't update while user is dragging
                            slider.value = status.volume;
                            document.getElementById('volume-value').textContent = status.volume + '%';
                            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${status.volume}%, #374151 ${status.volume}%, #374151 100%)`;
                        }
                    }
                    
                    // Update current track name
                    if (status.current_track) {
                        document.getElementById('current-track').textContent = 'ğŸµ ' + status.current_track;
                        document.getElementById('track-info').textContent = 
                            `${status.playlist_index + 1}/${status.playlist_count} bÃ i â€¢ VLC Player`;
                    }
                    
                    // Sync shuffle/repeat state from VLC
                    if (status.shuffle !== undefined) {
                        isShuffleOn = status.shuffle;
                        const shuffleBtn = document.getElementById('shuffle-btn');
                        if (shuffleBtn) {
                            shuffleBtn.style.opacity = isShuffleOn ? '1' : '0.6';
                            shuffleBtn.style.transform = isShuffleOn ? 'scale(1.1)' : 'scale(1)';
                        }
                    }
                    if (status.repeat_mode !== undefined) {
                        repeatMode = status.repeat_mode;
                        const repeatBtn = document.getElementById('repeat-btn');
                        if (repeatBtn) {
                            repeatBtn.textContent = repeatMode === 2 ? 'ğŸ”‚' : 'ğŸ”';
                            repeatBtn.style.opacity = repeatMode > 0 ? '1' : '0.6';
                        }
                    }
                }
            } catch (e) {
                // Silent fail - VLC may not be playing
            }
        }
        
        function startVlcPolling() {
            if (vlcStatusInterval) clearInterval(vlcStatusInterval);
            vlcStatusInterval = setInterval(pollVlcStatus, 1000); // Poll every 1 second
        }
        
        function stopVlcPolling() {
            if (vlcStatusInterval) {
                clearInterval(vlcStatusInterval);
                vlcStatusInterval = null;
            }
        }
        
        // Click on progress bar to seek
        async function seekToPosition(event) {
            const progressBar = event.currentTarget;
            const rect = progressBar.getBoundingClientRect();
            const position = (event.clientX - rect.left) / rect.width;
            
            try {
                await fetch('/api/vlc_seek', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({position: position})
                });
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        // Music Source Selector Functions
        function setMusicSource(source) {
            currentMusicSource = source;
            localStorage.setItem('musicSource', source);
            
            // Update button styles
            const libraryBtn = document.getElementById('source-library-btn');
            const userBtn = document.getElementById('source-user-btn');
            
            if (source === 'library') {
                libraryBtn.style.background = '#667eea';
                libraryBtn.style.color = 'white';
                userBtn.style.background = 'transparent';
                userBtn.style.color = '#667eea';
                document.getElementById('source-path-display').textContent = 'music_library/';
            } else {
                libraryBtn.style.background = 'transparent';
                libraryBtn.style.color = '#667eea';
                userBtn.style.background = '#667eea';
                userBtn.style.color = 'white';
                const userPath = localStorage.getItem('musicFolderPath') || 'ChÆ°a cáº¥u hÃ¬nh';
                document.getElementById('source-path-display').textContent = userPath;
            }
            
            // Reload music library from new source
            loadMusicLibrary();
            addLog(`ğŸ¯ ÄÃ£ chuyá»ƒn nguá»“n phÃ¡t: ${source === 'library' ? 'Music Library' : 'ThÆ° má»¥c cÃ¡ nhÃ¢n'}`, 'success');
        }
        
        function loadMusicSourcePreference() {
            const saved = localStorage.getItem('musicSource') || 'library';
            setMusicSource(saved);
        }
        
        // Search/Filter Music Library
        function filterMusicLibrary(query) {
            if (!query || query.trim() === '') {
                renderMusicLibrary(allMusicFiles);
                return;
            }
            
            const lowerQuery = query.toLowerCase();
            const filtered = allMusicFiles.filter(file => 
                file.filename.toLowerCase().includes(lowerQuery) ||
                (file.path && file.path.toLowerCase().includes(lowerQuery))
            );
            renderMusicLibrary(filtered);
        }
        
        async function loadMusicLibrary() {
            try {
                // Determine which source to load from
                // IMPORTANT: auto_play=false Ä‘á»ƒ khÃ´ng tá»± phÃ¡t khi load danh sÃ¡ch
                const args = currentMusicSource === 'user' 
                    ? { folder: localStorage.getItem('musicFolderPath') || '', auto_play: false }
                    : { auto_play: false };
                
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'list_music', args: args})
                });
                const data = await response.json();
                
                if (data.success && data.files) {
                    allMusicFiles = data.files;
                    currentPlaylist = data.files;
                    renderMusicLibrary(data.files);
                } else {
                    document.getElementById('music-library').innerHTML = '<p style="text-align:center; color:#999; padding:40px;">âŒ KhÃ´ng tÃ¬m tháº¥y nháº¡c trong thÆ° viá»‡n</p>';
                }
            } catch (e) {
                console.error('Failed to load music library', e);
                document.getElementById('music-library').innerHTML = '<p style="text-align:center; color:#f44336; padding:40px;">âŒ Lá»—i táº£i danh sÃ¡ch nháº¡c</p>';
            }
        }
        
        function renderMusicLibrary(files) {
            const html = files.map((file, index) => {
                const originalIndex = allMusicFiles.findIndex(f => f.filename === file.filename);
                const isCurrentTrack = originalIndex === currentTrackIndex;
                const isTrackPlaying = isCurrentTrack && isPlaying;
                
                return `
                <div class="music-item ${isTrackPlaying ? 'playing' : ''}" 
                     data-index="${originalIndex}"
                     onmouseenter="this.querySelector('.play-btn-hover').style.opacity='1'" 
                     onmouseleave="this.querySelector('.play-btn-hover').style.opacity='0'" 
                     style="cursor:pointer; display: flex; align-items: center; padding: 12px; border-radius: 8px; margin-bottom: 8px; background: ${isCurrentTrack ? 'linear-gradient(135deg, rgba(102,126,234,0.12) 0%, rgba(118,75,162,0.12) 100%)' : '#f9fafb'}; transition: all 0.2s ease; border-left: 4px solid ${isCurrentTrack ? '#667eea' : 'transparent'}; border: 1px solid ${isCurrentTrack ? '#c7d2fe' : 'transparent'};">
                    
                    <!-- Play Button (hover) -->
                    <div class="play-btn-hover" onclick="playTrack(${originalIndex}); event.stopPropagation();" 
                         style="width: 42px; height: 42px; margin-right: 12px; border-radius: 50%; background: ${isTrackPlaying ? '#667eea' : 'linear-gradient(135deg, #667eea, #764ba2)'}; display: flex; align-items: center; justify-content: center; color: white; font-size: 16px; opacity: ${isTrackPlaying ? '1' : '0'}; transition: all 0.2s ease; box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3); cursor: pointer;" 
                         title="${isTrackPlaying ? 'Äang phÃ¡t' : 'Click Ä‘á»ƒ phÃ¡t'}">
                        ${isTrackPlaying ? 'â¸' : 'â–¶'}
                    </div>
                    
                    <!-- Music Icon (default state) -->
                    <div class="icon" style="font-size: 1.5em; margin-right: 12px; ${isTrackPlaying ? 'display:none;' : ''}">${isCurrentTrack ? 'ğŸ”Š' : 'ğŸµ'}</div>
                    
                    <!-- Track Info (clickable) -->
                    <div class="info" onclick="playTrack(${originalIndex})" style="flex: 1; cursor: pointer;">
                        <div class="name" style="font-weight: 600; color: ${isCurrentTrack ? '#667eea' : '#333'}; margin-bottom: 3px;">${file.filename}</div>
                        <div class="details" style="font-size: 0.85em; color: #6b7280;">${file.path} â€¢ ${file.size_mb} MB</div>
                    </div>
                    
                    <!-- Now Playing Indicator -->
                    ${isTrackPlaying ? '<div style="display:flex; align-items:center; gap:5px; color:#667eea; font-size:12px; animation: pulse 1.5s infinite;"><div style="width:3px; height:12px; background:#667eea; animation: wave1 0.8s ease-in-out infinite;"></div><div style="width:3px; height:18px; background:#667eea; animation: wave2 0.8s ease-in-out infinite 0.1s;"></div><div style="width:3px; height:15px; background:#667eea; animation: wave3 0.8s ease-in-out infinite 0.2s;"></div></div>' : ''}
                </div>
            `}).join('');
            
            document.getElementById('music-library').innerHTML = html || '<p style="text-align:center; color:#999; padding:40px;">KhÃ´ng cÃ³ bÃ i hÃ¡t nÃ o</p>';
        }
        
        // Toggle Shuffle
        async function toggleShuffle() {
            try {
                const response = await fetch('/api/vlc_shuffle', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    isShuffleOn = data.shuffle;
                    const btn = document.getElementById('shuffle-btn');
                    btn.style.opacity = isShuffleOn ? '1' : '0.6';
                    btn.style.transform = isShuffleOn ? 'scale(1.1)' : 'scale(1)';
                    addLog(isShuffleOn ? 'ğŸ”€ Báº­t phÃ¡t ngáº«u nhiÃªn' : 'ğŸ”€ Táº¯t phÃ¡t ngáº«u nhiÃªn', 'success');
                }
            } catch (e) {
                console.error('Toggle shuffle failed', e);
            }
        }
        
        // Toggle Repeat
        async function toggleRepeat() {
            try {
                const response = await fetch('/api/vlc_repeat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({})
                });
                const data = await response.json();
                
                if (data.success) {
                    repeatMode = data.repeat_mode;
                    const btn = document.getElementById('repeat-btn');
                    
                    switch(repeatMode) {
                        case 0:
                            btn.textContent = 'ğŸ”';
                            btn.style.opacity = '0.6';
                            addLog('ğŸ” Táº¯t láº·p láº¡i', 'success');
                            break;
                        case 1:
                            btn.textContent = 'ğŸ”';
                            btn.style.opacity = '1';
                            addLog('ğŸ” Láº·p láº¡i táº¥t cáº£', 'success');
                            break;
                        case 2:
                            btn.textContent = 'ğŸ”‚';
                            btn.style.opacity = '1';
                            addLog('ğŸ”‚ Láº·p láº¡i má»™t bÃ i', 'success');
                            break;
                    }
                }
            } catch (e) {
                console.error('Toggle repeat failed', e);
            }
        }
        
        // Volume Control
        function setPlayerVolume(value) {
            document.getElementById('volume-value').textContent = value + '%';
            
            // Update slider gradient
            const slider = document.getElementById('volume-slider');
            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${value}%, #374151 ${value}%, #374151 100%)`;
            
            // Update icon
            const icon = document.getElementById('volume-icon');
            if (value == 0) {
                icon.textContent = 'ğŸ”‡';
            } else if (value < 30) {
                icon.textContent = 'ğŸ”ˆ';
            } else if (value < 70) {
                icon.textContent = 'ğŸ”‰';
            } else {
                icon.textContent = 'ğŸ”Š';
            }
            
            // Call VLC API directly to set volume
            fetch('/api/vlc_volume', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({level: parseInt(value)})
            }).catch(e => console.error('Volume set failed', e));
        }
        
        let lastVolume = 80;
        function toggleMute() {
            const slider = document.getElementById('volume-slider');
            if (parseInt(slider.value) > 0) {
                lastVolume = slider.value;
                slider.value = 0;
                setPlayerVolume(0);
            } else {
                slider.value = lastVolume;
                setPlayerVolume(lastVolume);
            }
        }
        
        // SINGLE-CLICK TO PLAY (like Spotify/Apple Music)
        // Removed complex double-click logic - direct click to play for better UX
        
        // Cáº­p nháº­t visualizer state
        function updateVisualizer(playing) {
            const visualizer = document.getElementById('audio-visualizer');
            if (visualizer) {
                if (playing) {
                    visualizer.style.display = 'flex';
                    visualizer.classList.remove('paused');
                } else {
                    visualizer.classList.add('paused');
                }
            }
        }
        
        async function playTrack(index) {
            if (!allMusicFiles[index]) {
                console.error('Track not found at index:', index);
                addLog('âŒ KhÃ´ng tÃ¬m tháº¥y bÃ i hÃ¡t', 'error');
                return;
            }
            
            try {
                const track = allMusicFiles[index];
                console.log('ğŸµ Playing track:', track.filename);
                addLog(`â³ Äang táº£i: ${track.filename}...`, 'info');
                
                // Gá»i API trá»±c tiáº¿p Ä‘á»ƒ phÃ¡t nháº¡c
                const response = await fetch('/api/vlc_play_file', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({filename: track.filename})
                });
                const data = await response.json();
                console.log('Play response:', data);
                
                if (data.success) {
                    currentTrackIndex = index;
                    isPlaying = true;
                    updateNowPlaying();
                    updateVisualizer(true);
                    renderMusicLibrary(currentPlaylist);
                    document.getElementById('play-btn').textContent = 'â¸ï¸';
                    addLog(`ğŸµ Äang phÃ¡t: ${track.filename}`, 'success');
                    
                    // Start VLC polling for real-time sync
                    startVlcPolling();
                } else {
                    console.error('Play failed:', data);
                    addLog('âŒ ' + (data.error || 'KhÃ´ng thá»ƒ phÃ¡t nháº¡c'), 'error');
                }
            } catch (e) {
                console.error('Failed to play track', e);
                addLog('âŒ Lá»—i káº¿t ná»‘i', 'error');
            }
        }
        
        async function musicPlayPause() {
            try {
                // Gá»i VLC API trá»±c tiáº¿p - khÃ´ng qua tool registry
                const response = await fetch('/api/vlc_play_pause', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    isPlaying = data.is_playing;
                    document.getElementById('play-btn').textContent = isPlaying ? 'â¸ï¸' : 'â–¶ï¸';
                    updateVisualizer(isPlaying);
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message, 'success');
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i play/pause'), 'error');
                }
            } catch (e) {
                console.error('Play/Pause failed', e);
                addLog('âŒ Lá»—i káº¿t ná»‘i VLC', 'error');
            }
        }
        
        async function musicNext() {
            try {
                const response = await fetch('/api/vlc_next', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    currentTrackIndex = (currentTrackIndex + 1) % currentPlaylist.length;
                    updateNowPlaying();
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message || 'â­ï¸ BÃ i tiáº¿p theo', 'success');
                } else {
                    addLog('âŒ ' + (data.error || 'KhÃ´ng cÃ³ bÃ i tiáº¿p'), 'error');
                }
            } catch (e) {
                console.error('Next track failed', e);
                addLog('âŒ Lá»—i chuyá»ƒn bÃ i', 'error');
            }
        }
        
        async function musicPrevious() {
            try {
                const response = await fetch('/api/vlc_previous', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    currentTrackIndex = (currentTrackIndex - 1 + currentPlaylist.length) % currentPlaylist.length;
                    updateNowPlaying();
                    renderMusicLibrary(currentPlaylist);
                    addLog(data.message || 'â®ï¸ BÃ i trÆ°á»›c', 'success');
                } else {
                    addLog('âŒ ' + (data.error || 'KhÃ´ng cÃ³ bÃ i trÆ°á»›c'), 'error');
                }
            } catch (e) {
                console.error('Previous track failed', e);
                addLog('âŒ Lá»—i chuyá»ƒn bÃ i', 'error');
            }
        }
        
        async function musicStop() {
            try {
                const response = await fetch('/api/vlc_stop', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'}
                });
                const data = await response.json();
                
                if (data.success) {
                    isPlaying = false;
                    currentTrackIndex = -1;
                    document.getElementById('current-track').textContent = 'ğŸµ ÄÃ£ dá»«ng phÃ¡t';
                    document.getElementById('track-info').textContent = 'Chá»n bÃ i hÃ¡t Ä‘á»ƒ phÃ¡t';
                    document.getElementById('track-album').textContent = '';
                    document.getElementById('album-art').innerHTML = 'ğŸµ';
                    document.getElementById('play-btn').textContent = 'â–¶ï¸';
                    const slider = document.getElementById('progress-slider');
                    if (slider) {
                        slider.value = 0;
                        slider.style.background = 'linear-gradient(to right, #667eea 0%, #667eea 0%, #374151 0%, #374151 100%)';
                    }
                    document.getElementById('current-time').textContent = '0:00';
                    document.getElementById('total-time').textContent = '0:00';
                    addLog(data.message || 'â¹ï¸ ÄÃ£ dá»«ng nháº¡c', 'success');
                } else {
                    addLog('âŒ ' + (data.error || 'Lá»—i dá»«ng nháº¡c'), 'error');
                    renderMusicLibrary(currentPlaylist);
                    addLog('â¹ï¸ ÄÃ£ dá»«ng phÃ¡t nháº¡c', 'success');
                }
            } catch (e) {
                console.error('Stop failed', e);
            }
        }
        
        function updateNowPlaying() {
            if (currentTrackIndex >= 0 && allMusicFiles[currentTrackIndex]) {
                const track = allMusicFiles[currentTrackIndex];
                document.getElementById('current-track').textContent = track.filename.replace(/\\.[^/.]+$/, ''); // Remove extension
                document.getElementById('track-info').textContent = `${track.path}`;
                document.getElementById('track-album').textContent = `${track.size_mb} MB â€¢ BÃ i ${currentTrackIndex + 1}/${allMusicFiles.length}`;
                
                // Update album art with music note animation
                const albumArt = document.getElementById('album-art');
                if (albumArt) {
                    albumArt.innerHTML = isPlaying ? '<div style="animation: spin 3s linear infinite;">ğŸµ</div>' : 'ğŸµ';
                }
            }
        }
        
        async function updateMusicStatus() {
            try {
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'get_music_status', args: {}})
                });
                const data = await response.json();
                
                if (data.success) {
                    // Sync playing state
                    const wasPlaying = isPlaying;
                    isPlaying = data.is_playing === 1 || data.is_playing === true;
                    
                    // Update play button
                    const playBtn = document.getElementById('play-btn');
                    if (playBtn) {
                        playBtn.textContent = isPlaying ? 'â¸ï¸' : 'â–¶ï¸';
                    }
                    
                    // Update progress bar and time
                    if (data.current_time !== undefined && data.duration !== undefined) {
                        const currentSec = parseFloat(data.current_time) || 0;
                        const totalSec = parseFloat(data.duration) || 0;
                        
                        if (totalSec > 0) {
                            // Update progress slider (only if not dragging)
                            const percentage = (currentSec / totalSec) * 100;
                            const slider = document.getElementById('progress-slider');
                            if (slider && !isDraggingProgress) {
                                slider.value = Math.min(100, Math.max(0, percentage));
                                slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${percentage}%, #374151 ${percentage}%, #374151 100%)`;
                            }
                            
                            // Update time displays
                            const currentTimeEl = document.getElementById('current-time');
                            const totalTimeEl = document.getElementById('total-time');
                            if (currentTimeEl) currentTimeEl.textContent = formatTime(currentSec);
                            if (totalTimeEl) totalTimeEl.textContent = formatTime(totalSec);
                        }
                    }
                    
                    // Update library UI if play state changed
                    if (wasPlaying !== isPlaying && currentPlaylist.length > 0) {
                        renderMusicLibrary(currentPlaylist);
                    }
                }
            } catch (e) {
                console.error('Update music status error:', e);
            }
        }
        
        function formatTime(seconds) {
            if (!seconds || seconds < 0) return '0:00';
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return mins + ':' + (secs < 10 ? '0' : '') + secs;
        }
        
        // Progress bar dragging state
        let isDraggingProgress = false;
        
        // Called while dragging (preview only, no seek)
        function onProgressDrag(value) {
            isDraggingProgress = true;
            // Update slider visual immediately
            const slider = document.getElementById('progress-slider');
            slider.style.background = `linear-gradient(to right, #667eea 0%, #667eea ${value}%, #374151 ${value}%, #374151 100%)`;
        }
        
        // Called when drag ends (actual seek)
        async function onProgressSeek(value) {
            isDraggingProgress = false;
            const percentage = parseFloat(value);
            
            try {
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'seek_music', args: {percentage: percentage}})
                });
                const data = await response.json();
                
                if (data.success) {
                    await updateMusicStatus();
                }
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        async function seekTrack(event) {
            const progressBar = event.currentTarget;
            const rect = progressBar.getBoundingClientRect();
            const clickX = event.clientX - rect.left;
            const percentage = (clickX / rect.width) * 100;
            
            try {
                // Gá»i tool Ä‘á»ƒ seek (cáº§n implement trong backend)
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({tool: 'seek_music', args: {percentage: percentage}})
                });
                const data = await response.json();
                
                if (data.success) {
                    // Cáº­p nháº­t progress bar ngay láº­p tá»©c
                    document.getElementById('progress-fill').style.width = percentage + '%';
                    await updateMusicStatus();
                }
            } catch (e) {
                console.error('Seek failed', e);
            }
        }
        
        connectWS();
        // Giáº£m polling tá»« 5s xuá»‘ng 10s Ä‘á»ƒ giáº£m táº£i
        setInterval(getResources, 10000);
        getResources();
        
        // Load quotas on startup and refresh every 60 seconds
        getQuotas();
        setInterval(getQuotas, 60000);
        
        // Start VLC status polling for real-time sync
        startVlcPolling();
        
        // Initial VLC status check
        setTimeout(pollVlcStatus, 500);
        
        // RunCat Animation - Multiple frames like RunCat365
        let runcatFrame = 0;
        let runcatSpeed = 500; // Default 500ms per frame
        const runcatFrames = ['ğŸ±', 'ğŸˆ', 'ğŸ˜º', 'ğŸ˜¸', 'ğŸ˜¹'];
        
        function animateRunCat() {
            const runcat = document.getElementById('runcat');
            if (!runcat) return;
            
            runcatFrame = (runcatFrame + 1) % runcatFrames.length;
            runcat.textContent = runcatFrames[runcatFrame];
            
            // Apply transform for running effect
            const offset = runcatFrame % 2 === 0 ? -3 : -1;
            const flip = runcatFrame >= 2 && runcatFrame <= 3 ? -1 : 1;
            runcat.style.transform = `translateY(${offset}px) scaleX(${flip})`;
            
            setTimeout(animateRunCat, runcatSpeed);
        }
        
        // Start RunCat animation
        setTimeout(animateRunCat, 100);
        
        // Auto-update music status every 1 second when music section is active
        setInterval(() => {
            const musicSection = document.getElementById('music-section');
            if (musicSection && musicSection.style.display !== 'none') {
                updateMusicStatus();
            }
        }, 1000);
        
        // Music Settings Functions
        function loadMusicFolderSettings() {
            const savedPath = localStorage.getItem('musicFolderPath');
            if (savedPath) {
                document.getElementById('music-folder-path').value = savedPath;
            }
        }
        
        function browseMusicFolder() {
            // Web khÃ´ng thá»ƒ browse folder trá»±c tiáº¿p, hÆ°á»›ng dáº«n user
            alert('ğŸ’¡ HÆ°á»›ng dáº«n:\\n\\n1. Má»Ÿ File Explorer (Windows + E)\\n2. Äi Ä‘áº¿n thÆ° má»¥c nháº¡c cá»§a báº¡n\\n3. Click vÃ o thanh Ä‘á»‹a chá»‰ vÃ  copy Ä‘Æ°á»ng dáº«n (Ctrl+C)\\n4. Paste vÃ o Ã´ bÃªn trÃ¡i (Ctrl+V)\\n5. Click "ğŸ’¾ LÆ°u"\\n\\nVÃ­ dá»¥: C:\\\\\\\\Users\\\\\\\\YourName\\\\\\\\Music');
        }
        
        async function saveMusicFolder() {
            const folderPath = document.getElementById('music-folder-path').value.trim();
            const statusEl = document.getElementById('music-folder-status');
            
            if (!folderPath) {
                statusEl.style.display = 'block';
                statusEl.style.background = '#fee2e2';
                statusEl.style.color = '#991b1b';
                statusEl.innerHTML = 'âŒ Vui lÃ²ng nháº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c!';
                return;
            }
            
            try {
                // LÆ°u vÃ o localStorage
                localStorage.setItem('musicFolderPath', folderPath);
                
                // Gá»i tool Ä‘á»ƒ lÆ°u config
                const response = await fetch('/api/call_tool', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({
                        tool: 'save_music_folder_config',
                        args: {folder_path: folderPath}
                    })
                });
                const data = await response.json();
                
                if (data.success) {
                    statusEl.style.display = 'block';
                    statusEl.style.background = '#d1fae5';
                    statusEl.style.color = '#065f46';
                    statusEl.innerHTML = 'âœ… ÄÃ£ lÆ°u cÃ i Ä‘áº·t thÃ nh cÃ´ng! LLM sáº½ Æ°u tiÃªn phÃ¡t nháº¡c tá»« thÆ° má»¥c nÃ y.';
                    addLog(`âš™ï¸ ÄÃ£ cáº¥u hÃ¬nh thÆ° má»¥c nháº¡c: ${folderPath}`, 'success');
                } else {
                    throw new Error(data.error || 'Unknown error');
                }
            } catch (e) {
                statusEl.style.display = 'block';
                statusEl.style.background = '#fee2e2';
                statusEl.style.color = '#991b1b';
                statusEl.innerHTML = `âŒ Lá»—i: ${e.message}`;
                console.error('Save music folder error:', e);
            }
        }
        
        // ============================================================
        // ğŸ’¬ LLM CHAT FUNCTIONS - Gá»­i tin nháº¯n cho Robot/LLM
        // ============================================================
        
        async function refreshLLMConnectionStatus() {
            try {
                const response = await fetch('/api/llm_connection_status');
                const data = await response.json();
                
                if (data.success) {
                    data.devices.forEach((device, index) => {
                        // Update old status display (if exists)
                        const statusEl = document.getElementById(`device${index + 1}-status`);
                        if (statusEl) {
                            const icon = device.connected ? 'âœ…' : (device.enabled ? 'â³' : 'âŒ');
                            const text = device.connected ? 'ÄÃ£ káº¿t ná»‘i' : (device.enabled ? 'Äang káº¿t ná»‘i...' : 'ChÆ°a cáº¥u hÃ¬nh');
                            statusEl.innerHTML = `ğŸ“± ${device.name}: <span class="status-indicator">${icon} ${text}</span>`;
                        }
                        
                        // Update new device card indicator
                        const indicator = document.getElementById(`device-${index + 1}-indicator`);
                        const card = document.getElementById(`device-${index + 1}-card`);
                        if (indicator) {
                            if (device.connected) {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#10b981;animation:pulse 2s infinite;"></span> âœ… ÄÃ£ káº¿t ná»‘i';
                                indicator.style.background = '#d1fae5';
                                indicator.style.color = '#047857';
                                if (card) card.style.boxShadow = '0 0 20px rgba(16, 185, 129, 0.4)';
                            } else if (device.enabled) {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#f59e0b;animation:blink 1s infinite;"></span> â³ Äang káº¿t ná»‘i...';
                                indicator.style.background = '#fef3c7';
                                indicator.style.color = '#b45309';
                                if (card) card.style.boxShadow = '0 0 15px rgba(245, 158, 11, 0.3)';
                            } else {
                                indicator.innerHTML = '<span class="status-dot" style="width:8px;height:8px;border-radius:50%;background:#6b7280;"></span> âŒ ChÆ°a káº¿t ná»‘i';
                                indicator.style.background = '#f3f4f6';
                                indicator.style.color = '#6b7280';
                                if (card) card.style.boxShadow = 'none';
                            }
                        }
                    });
                    
                    // Update device selector
                    const select = document.getElementById('llm-device-select');
                    if (select) {
                        data.devices.forEach((device, index) => {
                            const option = select.options[index];
                            if (option) {
                                option.text = `${device.connected ? 'ğŸŸ¢' : 'âšª'} ${device.name}`;
                            }
                        });
                    }
                }
            } catch (e) {
                console.error('Error refreshing LLM connection status:', e);
            }
        }
        
        async function sendLLMMessage() {
            const input = document.getElementById('llm-chat-input');
            const message = input.value.trim();
            
            if (!message) {
                addLog('âš ï¸ Vui lÃ²ng nháº­p tin nháº¯n', 'error');
                return;
            }
            
            const modelSelect = document.getElementById('llm-chat-model');
            const selectedModel = modelSelect ? modelSelect.value : 'models/gemini-3-flash-preview';
            
            // Add user message to chat
            addLLMChatMessage('user', message, null);
            
            // Clear input
            input.value = '';
            input.style.height = '50px';
            
            // Show typing indicator
            showLLMTyping();
            
            try {
                // Call Gemini AI with Knowledge Base integration
                const response = await fetch('/api/tool/ask_gemini', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        prompt: message,
                        model: selectedModel
                    })
                });
                
                const data = await response.json();
                
                // Hide typing indicator
                hideLLMTyping();
                
                if (data.success) {
                    const responseText = data.response || data.response_text || 'KhÃ´ng cÃ³ ná»™i dung tráº£ vá»';
                    const hasKB = data.knowledge_base_used ? 'ğŸ“š' : '';
                    const modelName = getModelDisplayName(selectedModel);
                    
                    addLLMChatMessage('assistant', responseText, `Gemini ${modelName}${hasKB}`);
                    
                    if (data.knowledge_base_used) {
                        addLog(`âœ… Gemini tráº£ lá»i (sá»­ dá»¥ng Knowledge Base)`, 'success');
                    } else {
                        addLog(`âœ… Gemini tráº£ lá»i thÃ nh cÃ´ng`, 'success');
                    }
                    
                    // ğŸ”Š Text-to-Speech náº¿u Ä‘Æ°á»£c báº­t
                    const ttsToggle = document.getElementById('llm-tts-toggle');
                    const ttsEnabled = ttsToggle?.checked;
                    console.log('TTS Toggle element:', ttsToggle);
                    console.log('TTS Enabled:', ttsEnabled);
                    if (ttsEnabled && responseText) {
                        console.log('Calling speakText with:', responseText.substring(0, 100));
                        speakText(responseText);
                    }
                } else {
                    addLLMChatMessage('assistant', `âŒ Lá»—i: ${data.error}`, 'System');
                    addLog(`âŒ Lá»—i Gemini: ${data.error}`, 'error');
                }
            } catch (e) {
                hideLLMTyping();
                addLLMChatMessage('assistant', `âŒ Lá»—i káº¿t ná»‘i: ${e.message}`, 'System');
                addLog(`âŒ Lá»—i: ${e.message}`, 'error');
            }
        }
        
        function getModelDisplayName(model) {
            if (model.includes('gemini-3')) return '3 Flash âš¡';
            if (model.includes('2.5-pro')) return '2.5 Pro ğŸ’';
            if (model.includes('2.5-flash')) return '2.5 Flash âš¡';
            if (model.includes('2.0-flash')) return '2.0 Flash âš¡';
            return '';
        }
        
        function saveLLMChatModel() {
            const model = document.getElementById('llm-chat-model')?.value;
            if (model) {
                localStorage.setItem('llm_chat_model', model);
            }
        }
        
        function loadLLMChatModel() {
            const saved = localStorage.getItem('llm_chat_model') || 'models/gemini-3-flash-preview';
            const select = document.getElementById('llm-chat-model');
            if (select) {
                select.value = saved;
            }
            // Load TTS preference
            loadTTSPreference();
        }
        
        // ===== STT (Speech-to-Text) Functions - Microphone Input =====
        let llmRecognition = null;
        let llmIsRecording = false;
        let llmSilenceTimer = null;
        let llmLastSpeechTime = 0;
        const SILENCE_TIMEOUT = 2000; // 2 giÃ¢y im láº·ng thÃ¬ tá»± gá»­i
        
        // ğŸ¯ Wake Word Detection
        let wakeWordRecognition = null;
        let wakeWordActive = false;
        let wakeWordWasActive = false; // ğŸ†• Track náº¿u wake word Ä‘ang báº­t trÆ°á»›c khi chat
        let wakeWordIdleTimer = null; // ğŸ†• Timer tá»± táº¯t sau 20s khÃ´ng dÃ¹ng
        const WAKE_WORD_IDLE_TIMEOUT = 20000; // 20 giÃ¢y khÃ´ng dÃ¹ng thÃ¬ tá»± táº¯t
        const WAKE_WORDS = ['hey gemini', 'hÃª gemini', 'ok gemini', 'Ã´ kÃª gemini', 'xin chÃ o', 'nÃ y gemini', 'gemini Æ¡i', 'Ãª gemini'];
        const GOODBYE_WORDS = ['goodbye', 'good bye', 'táº¡m biá»‡t', 'bye bye', 'bye', 'bai bai', 'ngá»§ Ä‘i', 'Ä‘i ngá»§', 'táº¯t Ä‘i', 'dá»«ng láº¡i'];
        
        function initWakeWordDetection() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) return null;
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'vi-VN';
            recognition.continuous = true;
            recognition.interimResults = true;
            
            recognition.onresult = (event) => {
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript.toLowerCase().trim();
                    
                    // ğŸ†• Check goodbye word - Táº¯t wake word
                    const isGoodbye = GOODBYE_WORDS.some(word => transcript.includes(word));
                    if (isGoodbye) {
                        console.log('ğŸ‘‹ Goodbye detected:', transcript);
                        addLog('ğŸ‘‹ Goodbye! Táº¯t Wake Word...', 'info');
                        showVoiceStatus('ğŸ‘‹ Táº¡m biá»‡t! ÄÃ£ táº¯t Wake Word.', 'success');
                        stopWakeWordDetection();
                        wakeWordWasActive = false;
                        localStorage.setItem('wake_word_enabled', 'false');
                        setTimeout(() => hideVoiceStatus(), 2000);
                        return;
                    }
                    
                    // Check wake word
                    const isWakeWord = WAKE_WORDS.some(word => transcript.includes(word));
                    if (isWakeWord && !llmIsRecording) {
                        console.log('ğŸ¯ Wake word detected:', transcript);
                        addLog('ğŸ¯ Wake word detected! Báº¯t Ä‘áº§u nghe...', 'success');
                        showVoiceStatus('ğŸ¯ ÄÃ£ nghe tháº¥y! Äang chuyá»ƒn sang cháº¿ Ä‘á»™ chat...', 'success');
                        
                        // ğŸ†• Mark wake word was active
                        wakeWordWasActive = true;
                        resetWakeWordIdleTimer();
                        
                        // Stop wake word detection, start chat recording
                        stopWakeWordDetection();
                        setTimeout(() => startLLMVoiceInput(), 300);
                        return;
                    }
                }
            };
            
            recognition.onend = () => {
                if (wakeWordActive) {
                    try { recognition.start(); } catch(e) {}
                }
            };
            
            recognition.onerror = (event) => {
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    console.error('Wake word error:', event.error);
                }
            };
            
            return recognition;
        }
        
        // ğŸ†• Reset idle timer - Sau 20s khÃ´ng nÃ³i gÃ¬ sáº½ tá»± táº¯t wake word
        function resetWakeWordIdleTimer() {
            if (wakeWordIdleTimer) {
                clearTimeout(wakeWordIdleTimer);
            }
            wakeWordIdleTimer = setTimeout(() => {
                if (wakeWordActive && !llmIsRecording) {
                    addLog('â° Wake Word tá»± táº¯t sau 20s khÃ´ng hoáº¡t Ä‘á»™ng', 'info');
                    showVoiceStatus('â° Wake Word tá»± táº¯t (háº¿t thá»i gian chá»)', 'warning');
                    stopWakeWordDetection();
                    wakeWordWasActive = false;
                    localStorage.setItem('wake_word_enabled', 'false');
                    setTimeout(() => hideVoiceStatus(), 2000);
                }
            }, WAKE_WORD_IDLE_TIMEOUT);
        }
        
        function startWakeWordDetection() {
            if (!wakeWordRecognition) {
                wakeWordRecognition = initWakeWordDetection();
            }
            if (!wakeWordRecognition) {
                addLog('âŒ TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ Wake Word', 'error');
                return;
            }
            
            wakeWordActive = true;
            wakeWordWasActive = true;
            localStorage.setItem('wake_word_enabled', 'true');
            
            try {
                wakeWordRecognition.start();
                updateWakeWordButton(true);
                showVoiceStatus('ğŸ‘‚ Äang láº¯ng nghe... NÃ³i "Hey Gemini" hoáº·c "Goodbye" Ä‘á»ƒ táº¯t', 'recording');
                addLog('ğŸ‘‚ Wake word Ä‘ang láº¯ng nghe... NÃ³i "Hey Gemini" Ä‘á»ƒ chat, "Goodbye" Ä‘á»ƒ táº¯t', 'info');
                resetWakeWordIdleTimer();
            } catch(e) {
                if (e.name === 'InvalidStateError') {
                    wakeWordRecognition.stop();
                    setTimeout(() => startWakeWordDetection(), 100);
                }
            }
        }
        
        function stopWakeWordDetection() {
            wakeWordActive = false;
            if (wakeWordIdleTimer) {
                clearTimeout(wakeWordIdleTimer);
                wakeWordIdleTimer = null;
            }
            if (wakeWordRecognition) {
                try { wakeWordRecognition.stop(); } catch(e) {}
            }
            updateWakeWordButton(false);
        }
        
        function toggleWakeWord() {
            if (wakeWordActive) {
                stopWakeWordDetection();
                wakeWordWasActive = false;
                localStorage.setItem('wake_word_enabled', 'false');
                addLog('ğŸ‘‚ ÄÃ£ táº¯t Wake Word detection', 'info');
                hideVoiceStatus();
            } else {
                startWakeWordDetection();
            }
        }
        
        // ğŸ†• Re-enable wake word after chat response (náº¿u trÆ°á»›c Ä‘Ã³ Ä‘ang báº­t)
        function reEnableWakeWordAfterResponse() {
            if (wakeWordWasActive) {
                setTimeout(() => {
                    if (!llmIsRecording && wakeWordWasActive) {
                        startWakeWordDetection();
                    }
                }, 1500); // Wait 1.5s after response
            }
        }
        
        function updateWakeWordButton(active) {
            const btn = document.getElementById('llm-wakeword-btn');
            if (btn) {
                if (active) {
                    btn.style.background = 'linear-gradient(135deg,#8b5cf6,#7c3aed)';
                    btn.innerHTML = 'ğŸ‘‚';
                    btn.title = 'ğŸ‘‚ Wake Word Ä‘ang láº¯ng nghe... (Click Ä‘á»ƒ táº¯t)';
                    btn.style.animation = 'pulse 2s infinite';
                } else {
                    btn.style.background = 'linear-gradient(135deg,#6b7280,#4b5563)';
                    btn.innerHTML = 'ğŸ‘‚';
                    btn.title = 'ğŸ‘‚ Báº­t Wake Word (nÃ³i "Hey Gemini" Ä‘á»ƒ chat)';
                    btn.style.animation = 'none';
                }
            }
        }
        
        function initLLMSpeechRecognition() {
            // Check for browser support
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                console.warn('Browser does not support Speech Recognition');
                return null;
            }
            
            const recognition = new SpeechRecognition();
            recognition.lang = 'vi-VN'; // Vietnamese
            recognition.continuous = true; // Keep listening
            recognition.interimResults = true; // Show partial results
            recognition.maxAlternatives = 1;
            
            recognition.onstart = () => {
                llmIsRecording = true;
                llmLastSpeechTime = Date.now();
                updateMicButton(true);
                showVoiceStatus('ğŸ¤ Äang nghe... NÃ³i xong sáº½ tá»± Ä‘á»™ng gá»­i!', 'recording');
                addLog('ğŸ¤ Báº¯t Ä‘áº§u ghi Ã¢m (auto-send sau 2s im láº·ng)', 'info');
                startSilenceDetection();
            };
            
            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                
                // Reset silence timer on speech
                llmLastSpeechTime = Date.now();
                
                const input = document.getElementById('llm-chat-input');
                if (input) {
                    if (finalTranscript) {
                        // Append final result to existing text
                        const existingText = input.value.trim();
                        input.value = existingText ? existingText + ' ' + finalTranscript : finalTranscript;
                        showVoiceStatus('âœ… ' + input.value.substring(0, 60) + (input.value.length > 60 ? '...' : ''), 'success');
                    } else if (interimTranscript) {
                        // Show interim result
                        showVoiceStatus('ğŸ¤ ' + interimTranscript, 'recording');
                    }
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    showVoiceStatus('âŒ Vui lÃ²ng cho phÃ©p truy cáº­p microphone!', 'error');
                    addLog('âŒ Microphone bá»‹ tá»« chá»‘i quyá»n truy cáº­p', 'error');
                } else if (event.error === 'no-speech') {
                    // Auto-send if have text and no speech
                    autoSendIfHaveText();
                    return;
                } else {
                    showVoiceStatus('âŒ Lá»—i: ' + event.error, 'error');
                    addLog('âŒ STT lá»—i: ' + event.error, 'error');
                }
                stopLLMVoiceInput();
            };
            
            recognition.onend = () => {
                if (llmIsRecording) {
                    // Check if should auto-send
                    const timeSinceLastSpeech = Date.now() - llmLastSpeechTime;
                    if (timeSinceLastSpeech >= SILENCE_TIMEOUT) {
                        autoSendIfHaveText();
                    } else {
                        // Auto-restart if still recording
                        try {
                            recognition.start();
                        } catch (e) {
                            stopLLMVoiceInput();
                        }
                    }
                } else {
                    updateMicButton(false);
                    hideVoiceStatus();
                }
            };
            
            return recognition;
        }
        
        function startSilenceDetection() {
            if (llmSilenceTimer) clearInterval(llmSilenceTimer);
            
            llmSilenceTimer = setInterval(() => {
                if (!llmIsRecording) {
                    clearInterval(llmSilenceTimer);
                    return;
                }
                
                const timeSinceLastSpeech = Date.now() - llmLastSpeechTime;
                const input = document.getElementById('llm-chat-input');
                
                if (timeSinceLastSpeech >= SILENCE_TIMEOUT && input && input.value.trim()) {
                    // Auto-send after silence
                    autoSendIfHaveText();
                } else if (timeSinceLastSpeech >= 1000 && input && input.value.trim()) {
                    // Show countdown
                    const remaining = Math.ceil((SILENCE_TIMEOUT - timeSinceLastSpeech) / 1000);
                    showVoiceStatus(`â³ Gá»­i sau ${remaining}s... (nÃ³i tiáº¿p Ä‘á»ƒ há»§y)`, 'warning');
                }
            }, 500);
        }
        
        function autoSendIfHaveText() {
            const input = document.getElementById('llm-chat-input');
            if (input && input.value.trim()) {
                showVoiceStatus('ğŸ“¤ Äang gá»­i tin nháº¯n...', 'success');
                stopLLMVoiceInput();
                
                // Small delay then send
                setTimeout(() => {
                    sendLLMMessage();
                    // ğŸ†• Re-enable wake word after response (dÃ¹ng function má»›i)
                    reEnableWakeWordAfterResponse();
                }, 300);
            } else {
                stopLLMVoiceInput();
                // ğŸ†• Náº¿u khÃ´ng cÃ³ text, váº«n re-enable wake word
                reEnableWakeWordAfterResponse();
            }
        }
        
        function toggleLLMVoiceInput() {
            if (llmIsRecording) {
                // If recording, stop and send if have text
                autoSendIfHaveText();
            } else {
                startLLMVoiceInput();
            }
        }
        
        function startLLMVoiceInput() {
            // Stop wake word if active
            if (wakeWordActive) {
                stopWakeWordDetection();
            }
            
            if (!llmRecognition) {
                llmRecognition = initLLMSpeechRecognition();
            }
            
            if (!llmRecognition) {
                showVoiceStatus('âŒ TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ STT. HÃ£y dÃ¹ng Chrome!', 'error');
                addLog('âŒ TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ Speech Recognition', 'error');
                return;
            }
            
            // Clear input for fresh start
            const input = document.getElementById('llm-chat-input');
            if (input) input.value = '';
            
            try {
                llmRecognition.start();
            } catch (e) {
                if (e.name === 'InvalidStateError') {
                    // Already started
                    stopLLMVoiceInput();
                    setTimeout(() => startLLMVoiceInput(), 100);
                } else {
                    console.error('Start speech recognition error:', e);
                    showVoiceStatus('âŒ KhÃ´ng thá»ƒ báº¯t Ä‘áº§u ghi Ã¢m', 'error');
                }
            }
        }
        
        function stopLLMVoiceInput() {
            llmIsRecording = false;
            if (llmSilenceTimer) {
                clearInterval(llmSilenceTimer);
                llmSilenceTimer = null;
            }
            if (llmRecognition) {
                try {
                    llmRecognition.stop();
                } catch (e) {}
            }
            updateMicButton(false);
            setTimeout(() => hideVoiceStatus(), 1500);
        }
        
        function updateMicButton(isRecording) {
            const btn = document.getElementById('llm-mic-btn');
            if (btn) {
                if (isRecording) {
                    btn.style.background = 'linear-gradient(135deg,#ef4444,#dc2626)';
                    btn.innerHTML = 'â¹ï¸';
                    btn.title = 'â¹ï¸ Nháº¥n Ä‘á»ƒ dá»«ng vÃ  gá»­i';
                    btn.style.animation = 'pulse 1s infinite';
                } else {
                    btn.style.background = 'linear-gradient(135deg,#10b981,#059669)';
                    btn.innerHTML = 'ğŸ¤';
                    btn.title = 'ğŸ¤ Nháº¥n Ä‘á»ƒ nÃ³i (auto-send)';
                    btn.style.animation = 'none';
                }
            }
        }
        
        function showVoiceStatus(text, type) {
            const statusDiv = document.getElementById('llm-voice-status');
            const statusText = document.getElementById('llm-voice-status-text');
            if (statusDiv && statusText) {
                statusDiv.style.display = 'block';
                statusText.textContent = text;
                
                if (type === 'recording') {
                    statusDiv.style.background = 'linear-gradient(135deg,#fef3c7,#fde68a)';
                } else if (type === 'success') {
                    statusDiv.style.background = 'linear-gradient(135deg,#d1fae5,#a7f3d0)';
                } else if (type === 'error') {
                    statusDiv.style.background = 'linear-gradient(135deg,#fee2e2,#fecaca)';
                } else if (type === 'warning') {
                    statusDiv.style.background = 'linear-gradient(135deg,#ffedd5,#fed7aa)';
                }
            }
        }
        
        function hideVoiceStatus() {
            const statusDiv = document.getElementById('llm-voice-status');
            if (statusDiv) {
                statusDiv.style.display = 'none';
            }
        }
        
        // ===== TTS (Text-to-Speech) Functions =====
        function saveTTSPreference() {
            const enabled = document.getElementById('llm-tts-toggle')?.checked || false;
            localStorage.setItem('llm_tts_enabled', enabled);
            if (enabled) {
                addLog('ğŸ”Š ÄÃ£ báº­t Ä‘á»c to cÃ¢u tráº£ lá»i', 'info');
            } else {
                addLog('ğŸ”‡ ÄÃ£ táº¯t Ä‘á»c to cÃ¢u tráº£ lá»i', 'info');
            }
        }
        
        function loadTTSPreference() {
            const saved = localStorage.getItem('llm_tts_enabled') === 'true';
            const toggle = document.getElementById('llm-tts-toggle');
            if (toggle) {
                toggle.checked = saved;
            }
        }
        
        let currentTTSAudio = null; // Track current TTS audio
        
        async function speakText(text) {
            try {
                // Hiá»ƒn thá»‹ indicator Ä‘ang Ä‘á»c
                showSpeakingIndicator();
                
                // Gá»i API TTS backend
                const response = await fetch('/api/tts', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    addLog(`ğŸ”Š Äang Ä‘á»c: ${text.substring(0, 50)}...`, 'info');
                } else {
                    addLog(`âŒ TTS lá»—i: ${data.error}`, 'error');
                }
                
                hideSpeakingIndicator();
            } catch (e) {
                console.error('TTS error:', e);
                addLog(`âŒ TTS lá»—i: ${e.message}`, 'error');
                hideSpeakingIndicator();
            }
        }
        
        function stopSpeaking() {
            // Gá»i API dá»«ng TTS
            fetch('/api/tts/stop', { method: 'POST' })
                .then(() => {
                    addLog('ğŸ”‡ ÄÃ£ dá»«ng Ä‘á»c', 'info');
                    hideSpeakingIndicator();
                })
                .catch(e => console.error('Stop TTS error:', e));
        }
        
        function showSpeakingIndicator() {
            // ThÃªm indicator vÃ o status bar
            const statusBar = document.getElementById('llm-ai-status');
            if (statusBar && !document.getElementById('speaking-indicator')) {
                const indicator = document.createElement('span');
                indicator.id = 'speaking-indicator';
                indicator.innerHTML = '<span style="animation:pulse 1s infinite;">ğŸ”Š Äang Ä‘á»c...</span> <button onclick="stopSpeaking()" style="background:rgba(255,255,255,0.3);border:none;padding:2px 8px;border-radius:4px;cursor:pointer;font-size:0.8em;">â¹ï¸ Dá»«ng</button>';
                indicator.style.cssText = 'font-size:0.85em; background:rgba(255,255,255,0.2); padding:4px 10px; border-radius:20px; display:flex; align-items:center; gap:8px;';
                statusBar.appendChild(indicator);
            }
        }
        
        function hideSpeakingIndicator() {
            const indicator = document.getElementById('speaking-indicator');
            if (indicator) indicator.remove();
        }
        
        function addLLMChatMessage(role, content, deviceName) {
            const container = document.getElementById('llm-chat-messages');
            
            // Remove welcome message if exists
            const welcome = container.querySelector('div[style*="text-align:center"]');
            if (welcome) welcome.remove();
            
            const msgDiv = document.createElement('div');
            msgDiv.className = `llm-message ${role}`;
            
            const time = new Date().toLocaleTimeString('vi-VN', { hour: '2-digit', minute: '2-digit' });
            
            let deviceTag = '';
            if (deviceName && role === 'assistant') {
                deviceTag = `<span class="device-tag">${deviceName}</span>`;
            }
            
            msgDiv.innerHTML = `
                <div class="content">${content}${deviceTag}</div>
                <span class="time">${time}</span>
            `;
            
            container.appendChild(msgDiv);
            container.scrollTop = container.scrollHeight;
            
            // Store message
            llmChatMessages.push({ role, content, deviceName, time: new Date().toISOString() });
        }
        
        function showLLMTyping() {
            const container = document.getElementById('llm-chat-messages');
            const typingDiv = document.createElement('div');
            typingDiv.id = 'llm-typing-indicator';
            typingDiv.className = 'llm-message assistant';
            typingDiv.innerHTML = `
                <div class="llm-typing">
                    <span></span><span></span><span></span>
                </div>
            `;
            container.appendChild(typingDiv);
            container.scrollTop = container.scrollHeight;
        }
        
        function hideLLMTyping() {
            const typing = document.getElementById('llm-typing-indicator');
            if (typing) typing.remove();
        }
        
        function handleLLMChatKeydown(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault();
                sendLLMMessage();
            }
        }
        
        function autoResizeLLMInput(textarea) {
            textarea.style.height = '50px';
            textarea.style.height = Math.min(textarea.scrollHeight, 150) + 'px';
        }
        
        function sendQuickMessage(message) {
            const input = document.getElementById('llm-chat-input');
            input.value = message;
            sendLLMMessage();
        }
        
        function clearLLMChat() {
            const container = document.getElementById('llm-chat-messages');
            container.innerHTML = `
                <div style="text-align:center; color:#666; padding:40px 20px;">
                    <div style="font-size:4em; margin-bottom:15px;">ğŸ¤–</div>
                    <h3 style="color:#667eea; margin-bottom:10px;">ChÃ o má»«ng Ä‘áº¿n Chat vá»›i Gemini AI!</h3>
                    <p style="font-size:0.95em; max-width:400px; margin:0 auto;">
                        Chat trá»±c tiáº¿p vá»›i Gemini AI.<br>
                        AI sáº½ tá»± Ä‘á»™ng tÃ¬m kiáº¿m trong Knowledge Base cá»§a báº¡n Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n.
                    </p>
                </div>
            `;
            llmChatMessages = [];
            addLog('ğŸ—‘ï¸ ÄÃ£ xÃ³a lá»‹ch sá»­ chat', 'info');
        }
        
        // Load music folder settings when opening the section
        document.addEventListener('DOMContentLoaded', () => {
            loadMusicFolderSettings();
            // ğŸ”¥ FIX: Auto-load API keys when page loads
            loadCurrentEndpoint();
            // ğŸ”¥ FIX: Auto-refresh connection status
            refreshLLMConnectionStatus();
            // â° Refresh connection status every 3 seconds
            setInterval(refreshLLMConnectionStatus, 3000);
        });
        
    // Initialize playlists on page load
    initPlaylists();
    </script>
    
    <!-- MINIZ FOOTER - Compact Corner -->
    <div class="footer-miniz">
        <div class="footer-logo-compact">
            <img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ccircle cx='50' cy='50' r='48' fill='%23667eea'/%3E%3Cpath d='M30 40 L50 25 L70 40 M50 25 L50 75 M35 55 L50 50 L65 55 M35 70 L50 65 L65 70' stroke='white' stroke-width='3' fill='none'/%3E%3Ctext x='50' y='88' text-anchor='middle' fill='white' font-size='14' font-weight='bold' font-family='Arial'%3EminiZ%3C/text%3E%3C/svg%3E" alt="miniZ Logo">
            <span class="footer-brand-compact">miniZ</span>
        </div>
        <div class="footer-separator"></div>
        <a href="https://youtube.com/@minizjp?si=LRg5piGHmxYtsFJU" target="_blank" class="footer-youtube-compact" title="KÃªnh YouTube miniZ">
            <svg viewBox="0 0 24 24"><path d="M23.498 6.186a3.016 3.016 0 0 0-2.122-2.136C19.505 3.545 12 3.545 12 3.545s-7.505 0-9.377.505A3.017 3.017 0 0 0 .502 6.186C0 8.07 0 12 0 12s0 3.93.502 5.814a3.016 3.016 0 0 0 2.122 2.136c1.871.505 9.376.505 9.376.505s7.505 0 9.377-.505a3.015 3.015 0 0 0 2.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg>
            YouTube
        </a>
    </div>
</body>
</html>
    """
    return html

# ============================================================
# ğŸ“¨ API ENDPOINT: SEND MESSAGE TO LLM
# ============================================================

class SendMessageRequest(BaseModel):
    message: str
    device_index: int = None
    wait_response: bool = True
    timeout: int = 30

class BroadcastMessageRequest(BaseModel):
    message: str
    wait_response: bool = False

@app.post("/api/send_message_to_llm")
async def api_send_message_to_llm(request: SendMessageRequest):
    """
    API endpoint Ä‘á»ƒ gá»­i tin nháº¯n cho LLM qua WebSocket.
    LLM sáº½ Ä‘á»c Ä‘Æ°á»£c tin nháº¯n vÃ  tá»± tráº£ lá»i.
    """
    result = await send_message_to_llm(
        message=request.message,
        device_index=request.device_index,
        wait_response=request.wait_response,
        timeout=request.timeout
    )
    return result

@app.post("/api/broadcast_to_llm")
async def api_broadcast_to_llm(request: BroadcastMessageRequest):
    """
    API endpoint Ä‘á»ƒ broadcast tin nháº¯n Ä‘áº¿n táº¥t cáº£ LLM Ä‘ang káº¿t ná»‘i.
    """
    result = await broadcast_to_all_llm(
        message=request.message,
        wait_response=request.wait_response
    )
    return result

@app.get("/api/llm_connection_status")
async def api_llm_connection_status():
    """
    Kiá»ƒm tra tráº¡ng thÃ¡i káº¿t ná»‘i cá»§a cÃ¡c thiáº¿t bá»‹ LLM.
    """
    status = {
        "success": True,
        "devices": []
    }
    
    for i in range(3):
        device_status = {
            "index": i,
            "name": endpoints_config[i].get("name", f"Thiáº¿t bá»‹ {i + 1}"),
            "connected": xiaozhi_connected.get(i, False),
            "enabled": endpoints_config[i].get("enabled", False),
            "has_token": bool(endpoints_config[i].get("token", ""))
        }
        status["devices"].append(device_status)
    
    status["active_index"] = active_endpoint_index
    status["total_connected"] = sum(1 for v in xiaozhi_connected.values() if v)
    
    return status

# API Endpoints
@app.post("/api/volume")
async def api_volume(request: VolumeRequest):
    result = await set_volume(request.level)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/screenshot")
async def api_screenshot():
    result = await take_screenshot()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/notification")
async def api_notification(request: NotificationRequest):
    result = await show_notification(request.title, request.message)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/resources")
async def api_resources():
    result = await get_system_resources()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/quotas")
async def api_quotas():
    """Láº¥y thÃ´ng tin quota cá»§a Gemini vÃ  Serper APIs"""
    result = await get_api_quotas()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.get("/api/vlc_status")
async def api_vlc_status():
    """VLC status - MCP-style response vá»›i session tracking"""
    try:
        # Cache status Ä‘á»ƒ trÃ¡nh query liÃªn tá»¥c (200ms)
        import time
        now = time.time()
        if not hasattr(vlc_player, '_status_cache') or (now - vlc_player._status_cache_time) > 0.2:
            status = vlc_player.get_full_status()
            # MCP-style: thÃªm metadata
            status['timestamp'] = int(now * 1000)  # milliseconds
            status['session_id'] = getattr(vlc_player, '_session_id', 'default')
            vlc_player._status_cache = status
            vlc_player._status_cache_time = now
        return vlc_player._status_cache
    except Exception as e:
        return {
            "success": False, 
            "error": str(e), 
            "state": "error",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_seek")
async def api_vlc_seek(data: dict):
    """Seek VLC player - MCP-style vá»›i validation vÃ  state tracking"""
    try:
        position = float(data.get("position", 0))
        
        # Validate input (xiaozhi pattern: validate before execution)
        if not 0.0 <= position <= 1.0:
            return {
                "success": False,
                "error": "Position must be between 0.0 and 1.0",
                "error_type": "validation_error",
                "provided_value": position
            }
        
        # Get current state
        old_position = vlc_player.get_position()
        current_time = vlc_player.get_time()
        
        # Execute seek
        vlc_player.set_position(position)
        
        # Calculate time delta
        new_time = vlc_player.get_time()
        
        return {
            "success": True,
            "action": "seek",
            "position": position,
            "previous_position": old_position,
            "time_delta_ms": new_time - current_time,
            "timestamp": int(time.time() * 1000),
            "message": f"Sought to {int(position * 100)}%"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "error_type": "exception",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_volume")
async def api_vlc_volume(data: dict):
    """Set VLC player volume (0-100)"""
    try:
        level = int(data.get("level", 80))
        vlc_player.set_volume(level)
        return {"success": True, "volume": level}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_shuffle")
async def api_vlc_shuffle(data: dict):
    """Toggle or set shuffle mode"""
    try:
        enabled = data.get("enabled")
        if enabled is None:
            # Toggle
            enabled = not vlc_player.get_shuffle()
        vlc_player.set_shuffle(enabled)
        return {"success": True, "shuffle": enabled}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_repeat")
async def api_vlc_repeat(data: dict):
    """Set repeat mode: 0=off, 1=all, 2=one"""
    try:
        mode = data.get("mode")
        if mode is None:
            # Cycle through modes
            current = vlc_player.get_repeat_mode()
            mode = (current + 1) % 3
        vlc_player.set_repeat_mode(mode)
        return {"success": True, "repeat_mode": mode}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_play_file")
async def api_vlc_play_file(data: dict):
    """PhÃ¡t file nháº¡c trá»±c tiáº¿p qua VLC - cho Web UI double-click"""
    try:
        filename = data.get("filename", "")
        if not filename:
            return {"success": False, "error": "Thiáº¿u filename"}
        
        print(f"ğŸµ [API] vlc_play_file: {filename}")
        
        # Gá»i hÃ m play_music
        result = await play_music(filename=filename, create_playlist=True)
        print(f"ğŸµ [API] play_music result: {result}")
        return result
    except Exception as e:
        print(f"âŒ [API] vlc_play_file error: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_play_pause")
async def api_vlc_play_pause():
    """Toggle VLC play/pause - MCP-style vá»›i state tracking"""
    try:
        if vlc_player and vlc_player._player:
            # Track state before action (xiaozhi pattern)
            was_playing = vlc_player.is_playing()
            
            # Execute command
            vlc_player.pause()
            
            # Get new state
            is_playing = vlc_player.is_playing()
            
            return {
                "success": True,
                "is_playing": is_playing,
                "previous_state": "playing" if was_playing else "paused",
                "current_state": "playing" if is_playing else "paused",
                "action": "pause" if was_playing else "play",
                "message": "â–¶ï¸ Äang phÃ¡t" if is_playing else "â¸ï¸ ÄÃ£ táº¡m dá»«ng",
                "timestamp": int(time.time() * 1000)
            }
        return {
            "success": False, 
            "error": "VLC chÆ°a khá»Ÿi táº¡o hoáº·c chÆ°a phÃ¡t nháº¡c",
            "state": "not_initialized"
        }
    except Exception as e:
        return {
            "success": False, 
            "error": str(e),
            "error_type": "exception",
            "timestamp": int(time.time() * 1000)
        }

@app.post("/api/vlc_stop")
async def api_vlc_stop():
    """Stop VLC player - MCP-style vá»›i state cleanup"""
    try:
        if vlc_player and vlc_player._player:
            # Get current state before stopping
            was_playing = vlc_player.is_playing()
            current_media = vlc_player._player.get_media()
            stopped_track = current_media.get_meta(0) if current_media else "Unknown"
            
            # Execute stop
            vlc_player.stop()
            
            return {
                "success": True,
                "action": "stop",
                "message": "â¹ï¸ ÄÃ£ dá»«ng nháº¡c",
                "previous_state": "playing" if was_playing else "paused",
                "stopped_track": stopped_track,
                "timestamp": int(time.time() * 1000)
            }
        return {
            "success": False,
            "error": "VLC chÆ°a khá»Ÿi táº¡o hoáº·c chÆ°a phÃ¡t nháº¡c",
            "state": "not_initialized"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_next")
async def api_vlc_next():
    """Next track - MCP-style async vá»›i immediate response"""
    try:
        if vlc_player and vlc_player._list_player:
            # Get current track info before switching (xiaozhi pattern)
            current_media = vlc_player._player.get_media()
            current_title = current_media.get_meta(0) if current_media else "Unknown"
            current_index = vlc_player._list_player.get_media_player().get_position()
            
            # Execute command
            vlc_player._list_player.next()
            vlc_player._list_player.play()  # Äáº£m báº£o phÃ¡t
            
            # MCP-style: tráº£ vá» immediate response + track info
            return {
                "success": True,
                "action": "next",
                "message": "â­ï¸ Chuyá»ƒn bÃ i tiáº¿p theo",
                "is_playing": True,
                "previous_track": {
                    "title": current_title,
                    "position": current_index
                },
                "timestamp": int(time.time() * 1000),
                "note": "Track info sáº½ update sau 500ms qua /api/vlc_status"
            }
        return {
            "success": False,
            "error": "VLC chÆ°a khá»Ÿi táº¡o",
            "state": "not_initialized"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/vlc_previous")
async def api_vlc_previous():
    """Previous track - Tá»I Æ¯U: KhÃ´ng block UI vá»›i sleep"""
    try:
        if vlc_player and vlc_player._list_player:
            vlc_player._list_player.previous()
            vlc_player._list_player.play()  # Äáº£m báº£o phÃ¡t
            # Tráº£ vá» ngay - Web UI sáº½ poll status Ä‘á»ƒ update
            return {
                "success": True, 
                "message": "â®ï¸ Chuyá»ƒn bÃ i trÆ°á»›c",
                "is_playing": True
            }
        return {"success": False, "error": "VLC chÆ°a khá»Ÿi táº¡o"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/time")
async def api_time():
    result = await get_current_time()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return {"data": result}

@app.post("/api/calculator")
async def api_calculator(request: CalculatorRequest):
    result = await calculator(request.expression)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result


# ===== GENERIC TOOL CALLER =====

@app.post("/api/call_tool")
async def call_any_tool(data: dict):
    """Generic endpoint to call ANY tool from TOOLS registry"""
    tool_name = data.get("tool", data.get("name", ""))
    args = data.get("args", data.get("arguments", {}))
    
    if not tool_name:
        raise HTTPException(400, "Tool name is required")
    
    if tool_name not in TOOLS:
        raise HTTPException(404, f"Tool '{tool_name}' not found")
    
    try:
        handler = TOOLS[tool_name]["handler"]
        result = await handler(**args)
        return result
    except Exception as e:
        return {"success": False, "error": str(e)}

# ============================================================
# ğŸ¯ VLC MCP ENDPOINTS - Hybrid System
# ============================================================

@app.post("/mcp/vlc/call")
async def mcp_vlc_call(request: dict):
    """
    MCP endpoint for VLC control (JSON-RPC 2.0)
    
    Xiaozhi-esp32 style protocol:
    {
      "jsonrpc": "2.0",
      "method": "tools/call",
      "params": {
        "name": "vlc.play",
        "arguments": {"file": "song.mp3"}
      },
      "id": 1
    }
    """
    if not VLC_MCP_AVAILABLE:
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": -32603,
                "message": "VLC MCP server not available"
            },
            "id": request.get("id")
        }
    
    try:
        response = await vlc_mcp_server.handle_mcp_request(request)
        return response
    except Exception as e:
        return {
            "jsonrpc": "2.0",
            "error": {
                "code": -32603,
                "message": f"Internal error: {str(e)}"
            },
            "id": request.get("id")
        }

@app.get("/mcp/vlc/tools")
async def mcp_vlc_list_tools():
    """List all available VLC MCP tools"""
    if not VLC_MCP_AVAILABLE:
        return {
            "success": False,
            "error": "VLC MCP server not available"
        }
    
    return {
        "success": True,
        "tools": vlc_mcp_server.list_tools()
    }

@app.get("/mcp/vlc/status")
async def mcp_vlc_status():
    """Get VLC MCP server status"""
    return {
        "success": True,
        "mcp_available": VLC_MCP_AVAILABLE,
        "vlc_available": VLC_AVAILABLE,
        "total_tools": len(vlc_mcp_server.tools) if VLC_MCP_AVAILABLE else 0,
        "protocol": "JSON-RPC 2.0",
        "architecture": "xiaozhi-esp32"
    }

# ============================================================
# ğŸ§  INTENT DETECTION API ENDPOINTS
# ============================================================

@app.post("/api/detect_intent")
async def api_detect_intent(data: dict):
    """
    PhÃ¢n tÃ­ch intent tá»« text input
    Tráº£ vá» suggested tool vÃ  confidence
    """
    text = data.get("text", data.get("query", ""))
    use_llm = data.get("use_llm", False)
    
    if not text:
        raise HTTPException(400, "Text is required")
    
    try:
        if use_llm:
            result = await intent_detector.detect_with_llm(text, GEMINI_API_KEY)
        else:
            result = intent_detector.detect_intent(text)
        
        return {
            "success": True,
            "text": text,
            **result
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.post("/api/auto_execute")
async def api_auto_execute(data: dict):
    """
    ğŸ¤– AUTO TOOL EXECUTOR v2.0 - NÃ‚NG Cáº¤P
    
    PhÃ¢n tÃ­ch THÃ”NG MINH response tá»« LLM vÃ  tá»± Ä‘á»™ng gá»i tool
    
    IMPROVEMENTS:
    - âœ… Æ¯u tiÃªn phÃ¢n tÃ­ch USER QUERY trÆ°á»›c (chÃ­nh xÃ¡c hÆ¡n)
    - âœ… PhÃ¡t hiá»‡n cÃ¢u PHá»¦ Äá»ŠNH (khÃ´ng, chÆ°a, Ä‘á»«ng)
    - âœ… PhÃ¡t hiá»‡n cÃ¢u Há»I (cÃ³ pháº£i, cÃ³ nÃªn)
    - âœ… Context-aware patterns (xem trÆ°á»›c/sau)
    - âœ… Multi-language support (Vi + En)
    - âœ… Better logging vÃ  debug info
    
    Args:
        llm_response: Text response tá»« LLM
        original_query: CÃ¢u há»i gá»‘c cá»§a user (QUAN TRá»ŒNG - Æ°u tiÃªn cao)
        auto_execute: True Ä‘á»ƒ tá»± Ä‘á»™ng gá»i tool (default: True)
    
    Returns:
        {
            "success": bool,
            "intent_detected": str,
            "tool_suggested": str,
            "confidence": float,
            "tool_executed": bool,
            "tool_result": dict,
            "analysis": {
                "source": "query|response",
                "matched_pattern": str,
                "is_question": bool,
                "is_negative": bool
            }
        }
    """
    try:
        llm_response = data.get("llm_response", data.get("response", "")).strip()
        original_query = data.get("original_query", data.get("query", "")).strip()
        auto_execute = data.get("auto_execute", True)
        
        print(f"\n{'='*70}")
        print(f"ğŸ¤– [Auto Execute v2.0] NEW REQUEST")
        print(f"{'='*70}")
        print(f"ğŸ“ User Query: '{original_query}'")
        print(f"ğŸ’¬ LLM Response: '{llm_response}'")
        print(f"âš™ï¸  Auto Execute: {auto_execute}")
        print(f"{'-'*70}")
        
        # ===== BÆ¯á»šC 1: PHÃ‚N TÃCH NGá»® Cáº¢NH =====
        import re
        
        # PhÃ¡t hiá»‡n cÃ¢u phá»§ Ä‘á»‹nh
        negative_patterns = [
            r'\b(khÃ´ng|chÆ°a|Ä‘á»«ng|chá»›|thÃ´i|ngÆ°ng)\b',
            r'\b(no|not|don\'t|stop|cancel)\b'
        ]
        
        # PhÃ¡t hiá»‡n cÃ¢u há»i
        question_patterns = [
            r'\b(cÃ³ pháº£i|cÃ³ nÃªn|cÃ³ thá»ƒ|Ä‘Æ°á»£c khÃ´ng|nhÆ° tháº¿ nÃ o)\b',
            r'\?$',  # Káº¿t thÃºc báº±ng dáº¥u ?
            r'\b(is|are|can|could|should|would|do|does)\b.+\?'
        ]
        
        # ===== BÆ¯á»šC 2: PATTERNS NÃ‚NG CAP - CONTEXT AWARE =====
        enhanced_vlc_patterns = {
            "music_next": {
                "patterns": [
                    r'\b(bÃ i tiáº¿p theo|bÃ i tiáº¿p|next song|next track)\b',
                    r'\b(chuyá»ƒn bÃ i|skip|bÃ i sau|bÃ i káº¿|sang bÃ i)\b',
                    r'\b(tiáº¿p theo|next|forward)\b',
                    r'\b(phÃ¡t bÃ i tiáº¿p|play next)\b'
                ],
                "keywords": ["next", "tiáº¿p", "skip", "chuyá»ƒn", "sau", "forward"]
            },
            "music_previous": {
                "patterns": [
                    r'\b(bÃ i trÆ°á»›c|previous song|previous track)\b',
                    r'\b(quay láº¡i|back|lÃ¹i láº¡i|trá»Ÿ láº¡i)\b',
                    r'\b(bÃ i trÆ°á»›c Ä‘Ã³|bÃ i cÅ©)\b',
                    r'\b(phÃ¡t bÃ i trÆ°á»›c|play previous)\b'
                ],
                "keywords": ["previous", "trÆ°á»›c", "back", "quay", "lÃ¹i"]
            },
            "pause_music": {
                "patterns": [
                    r'\b(táº¡m dá»«ng|pause)\b',
                    r'\b(dá»«ng láº¡i|stop playing|ngá»«ng)\b',
                    r'\b(táº¡m ngÆ°ng)\b'
                ],
                "keywords": ["pause", "táº¡m", "dá»«ng láº¡i"]
            },
            "resume_music": {
                "patterns": [
                    r'\b(tiáº¿p tá»¥c|resume|continue)\b',
                    r'\b(phÃ¡t tiáº¿p|play again|cháº¡y tiáº¿p)\b',
                    r'\b(má»Ÿ láº¡i|báº­t láº¡i)\b'
                ],
                "keywords": ["resume", "tiáº¿p tá»¥c", "continue", "phÃ¡t tiáº¿p"]
            },
            "stop_music": {
                "patterns": [
                    r'\b(dá»«ng háº³n|stop completely)\b',
                    r'\b(táº¯t nháº¡c|stop music|ngá»«ng nháº¡c)\b',
                    r'\b(dá»«ng|stop)\b(?!.*playing)'  # "dá»«ng" nhÆ°ng khÃ´ng cÃ³ "playing"
                ],
                "keywords": ["stop", "dá»«ng", "táº¯t", "ngá»«ng"]
            },
            "play_music": {
                "patterns": [
                    r'\b(phÃ¡t nháº¡c|play music)\b',
                    r'\b(má»Ÿ nháº¡c|báº­t nháº¡c|cháº¡y nháº¡c)\b',
                    r'\b(play song|start music)\b'
                ],
                "keywords": ["play", "phÃ¡t", "má»Ÿ", "báº­t", "cháº¡y"]
            }
        }
        
        # ===== BÆ¯á»šC 3: PHÃ‚N TÃCH Æ¯U TIÃŠN USER QUERY TRÆ¯á»šC =====
        detected_tool = None
        confidence = 0.0
        matched_pattern = None
        analysis_source = "none"
        
        # Priority 1: PhÃ¢n tÃ­ch USER QUERY (chÃ­nh xÃ¡c nháº¥t)
        if original_query:
            query_lower = original_query.lower()
            
            # Kiá»ƒm tra phá»§ Ä‘á»‹nh vÃ  cÃ¢u há»i trong query
            is_negative = any(re.search(p, query_lower) for p in negative_patterns)
            is_question = any(re.search(p, query_lower) for p in question_patterns)
            
            print(f"ğŸ” [Analysis] Query Context:")
            print(f"   - Is Negative: {is_negative}")
            print(f"   - Is Question: {is_question}")
            
            if not is_negative and not is_question:
                # Chá»‰ phÃ¢n tÃ­ch khi KHÃ”NG pháº£i cÃ¢u phá»§ Ä‘á»‹nh hoáº·c cÃ¢u há»i
                for tool_name, tool_data in enhanced_vlc_patterns.items():
                    # Kiá»ƒm tra patterns
                    for pattern in tool_data["patterns"]:
                        if re.search(pattern, query_lower):
                            detected_tool = tool_name
                            confidence = 0.95  # VERY HIGH confidence vÃ¬ tá»« user query
                            matched_pattern = pattern
                            analysis_source = "user_query"
                            print(f"âœ… [Query Match] Tool: {tool_name} | Pattern: {pattern}")
                            break
                    
                    # Náº¿u chÆ°a match, thá»­ keyword matching
                    if not detected_tool:
                        keyword_count = sum(1 for kw in tool_data["keywords"] if kw in query_lower)
                        if keyword_count >= 1:
                            detected_tool = tool_name
                            confidence = 0.7 + (keyword_count * 0.1)  # CÃ ng nhiá»u keyword cÃ ng cao
                            matched_pattern = f"keywords: {[kw for kw in tool_data['keywords'] if kw in query_lower]}"
                            analysis_source = "user_query_keywords"
                            print(f"âœ… [Query Keywords] Tool: {tool_name} | Matched: {keyword_count}")
                            break
                    
                    if detected_tool:
                        break
            else:
                print(f"âš ï¸ [Query Skip] Skipped analysis (negative or question)")
        
        # Priority 2: PhÃ¢n tÃ­ch LLM RESPONSE (náº¿u query khÃ´ng cÃ³ káº¿t quáº£)
        if not detected_tool and llm_response:
            response_lower = llm_response.lower()
            
            # Kiá»ƒm tra phá»§ Ä‘á»‹nh vÃ  cÃ¢u há»i trong response
            is_negative = any(re.search(p, response_lower) for p in negative_patterns)
            is_question = any(re.search(p, response_lower) for p in question_patterns)
            
            print(f"ğŸ” [Analysis] Response Context:")
            print(f"   - Is Negative: {is_negative}")
            print(f"   - Is Question: {is_question}")
            
            if not is_negative and not is_question:
                for tool_name, tool_data in enhanced_vlc_patterns.items():
                    for pattern in tool_data["patterns"]:
                        if re.search(pattern, response_lower):
                            detected_tool = tool_name
                            confidence = 0.75  # Lower than query but still good
                            matched_pattern = pattern
                            analysis_source = "llm_response"
                            print(f"âœ… [Response Match] Tool: {tool_name} | Pattern: {pattern}")
                            break
                    if detected_tool:
                        break
            else:
                print(f"âš ï¸ [Response Skip] Skipped analysis (negative or question)")
        
        # Priority 3: Intent Detector fallback (náº¿u cáº£ 2 Ä‘á»u khÃ´ng cÃ³ káº¿t quáº£)
        if not detected_tool:
            print(f"ğŸ” [Fallback] Using Intent Detector...")
            try:
                text_to_analyze = original_query if original_query else llm_response
                intent_result = intent_detector.detect_intent(text_to_analyze)
                detected_tool = intent_result.get("suggested_tool")
                confidence = intent_result.get("confidence", 0.0) * 0.8  # Giáº£m 20% vÃ¬ fallback
                matched_pattern = "intent_detector"
                analysis_source = "intent_detector"
                print(f"ğŸ” [Intent Detector] Tool: {detected_tool} | Confidence: {confidence:.2f}")
            except Exception as e:
                print(f"âŒ [Intent Detector] Error: {e}")
        
        # ===== BÆ¯á»šC 4: Tá»° Äá»˜NG Gá»ŒI TOOL =====
        tool_executed = False
        tool_result = None
        
        print(f"\nğŸ“Š [Decision]")
        print(f"   - Tool Detected: {detected_tool}")
        print(f"   - Confidence: {confidence:.2f}")
        print(f"   - Source: {analysis_source}")
        print(f"   - Threshold: 0.5")
        
        if auto_execute and detected_tool and confidence >= 0.5:  # Giáº£m threshold xuá»‘ng 0.5
            if detected_tool in TOOLS and TOOLS[detected_tool]["handler"]:
                print(f"ğŸš€ [Execute] Calling tool: {detected_tool}")
                
                try:
                    handler = TOOLS[detected_tool]["handler"]
                    tool_args = {}
                    
                    # Extract arguments cho play_music
                    if detected_tool == "play_music" and original_query:
                        # TrÃ­ch xuáº¥t tÃªn bÃ i hÃ¡t
                        for kw in ["phÃ¡t", "play", "bÃ i", "song", "má»Ÿ", "báº­t"]:
                            if kw in original_query.lower():
                                parts = original_query.lower().split(kw, 1)
                                if len(parts) > 1:
                                    filename = parts[1].strip()
                                    # Loáº¡i bá» cÃ¡c tá»« thá»«a
                                    filename = re.sub(r'\b(cho tÃ´i|giÃºp tÃ´i|giÃºp mÃ¬nh|nhÃ©|Ä‘i)\b', '', filename).strip()
                                    if filename:
                                        tool_args["filename"] = filename
                                        print(f"ğŸµ [Extract] Filename: '{filename}'")
                                    break
                    
                    # Gá»i tool
                    tool_result = await handler(**tool_args)
                    tool_executed = True
                    
                    print(f"âœ… [Execute] Success!")
                    print(f"ğŸ“Š [Result] {str(tool_result)[:150]}...")
                    
                except Exception as e:
                    print(f"âŒ [Execute] Error: {e}")
                    import traceback
                    traceback.print_exc()
                    tool_result = {"success": False, "error": str(e)}
            else:
                print(f"âš ï¸ [Execute] Tool '{detected_tool}' not found in registry")
        elif not auto_execute:
            print(f"â„¹ï¸ [Execute] Skipped (auto_execute=False)")
        elif not detected_tool:
            print(f"âš ï¸ [Execute] Skipped (no tool detected)")
        elif confidence < 0.5:
            print(f"âš ï¸ [Execute] Skipped (confidence {confidence:.2f} < 0.5)")
        
        print(f"{'='*70}\n")
        
        # ===== BÆ¯á»šC 5: TRáº¢ Vá»€ Káº¾T QUáº¢ =====
        return {
            "success": True,
            "llm_response": llm_response,
            "original_query": original_query,
            "intent_detected": detected_tool or "unknown",
            "tool_suggested": detected_tool,
            "confidence": confidence,
            "tool_executed": tool_executed,
            "tool_result": tool_result,
            "analysis": {
                "source": analysis_source,
                "matched_pattern": matched_pattern,
                "is_negative": is_negative if 'is_negative' in locals() else False,
                "is_question": is_question if 'is_question' in locals() else False
            },
            "message": f"âœ… Detected: {detected_tool} ({analysis_source}) | Executed: {tool_executed}" if detected_tool else "âš ï¸ No tool detected"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# ============================================================
# ğŸ§  SMART CONVERSATION ANALYZER v1.0
# PhÃ¢n tÃ­ch há»™i thoáº¡i thÃ´ng minh & tá»± Ä‘á»™ng Ä‘iá»u khiá»ƒn Má»ŒI tool
# ============================================================

class SmartConversationAnalyzer:
    """
    ğŸ§  SMART CONVERSATION ANALYZER
    
    PhÃ¢n tÃ­ch TOÃ€N Bá»˜ lá»‹ch sá»­ há»™i thoáº¡i Ä‘á»ƒ:
    1. Hiá»ƒu INTENT thá»±c sá»± cá»§a user (khÃ´ng phá»¥ thuá»™c tá»« khÃ³a cá»©ng)
    2. PhÃ¡t hiá»‡n tool phÃ¹ há»£p nháº¥t tá»« 50+ tools
    3. Extract arguments thÃ´ng minh
    4. Tá»± Ä‘á»™ng thá»±c thi tool
    
    Äáº¶C BIá»†T:
    - DÃ¹ng AI (Gemini/GPT-4) Ä‘á»ƒ phÃ¢n tÃ­ch â†’ HIá»‚U NGá»® Cáº¢NH
    - KhÃ´ng cáº§n regex patterns cho tá»«ng tool
    - Há»— trá»£ Táº¤T Cáº¢ tools (khÃ´ng chá»‰ VLC)
    - Context-aware: hiá»ƒu conversation history
    """
    
    def __init__(self):
        self.conversation_history = []  # LÆ°u lá»‹ch sá»­ há»™i thoáº¡i
        self.max_history = 20  # Giá»¯ 20 tin nháº¯n gáº§n nháº¥t
        self.last_executed_tool = None
        self.last_tool_result = None
        
        # Build tool catalog tá»« TOOLS dictionary
        self.tool_catalog = self._build_tool_catalog()
        
    def _build_tool_catalog(self) -> str:
        """Táº¡o catalog tools cho AI prompt"""
        catalog_lines = []
        for tool_name, tool_info in TOOLS.items():
            desc = tool_info.get("description", "")[:100]
            params = list(tool_info.get("parameters", {}).keys())
            params_str = ", ".join(params) if params else "none"
            catalog_lines.append(f"- {tool_name}: {desc}... | params: {params_str}")
        return "\n".join(catalog_lines)
    
    def add_message(self, role: str, content: str, tool_called: str = None):
        """ThÃªm message vÃ o history"""
        self.conversation_history.append({
            "role": role,  # "user" hoáº·c "assistant" hoáº·c "system"
            "content": content,
            "tool_called": tool_called,
            "timestamp": datetime.now().isoformat()
        })
        # Giá»¯ max history
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def get_conversation_context(self, last_n: int = 10) -> str:
        """Láº¥y context tá»« conversation history"""
        recent = self.conversation_history[-last_n:] if len(self.conversation_history) > last_n else self.conversation_history
        context_lines = []
        for msg in recent:
            role = "USER" if msg["role"] == "user" else "ASSISTANT"
            tool_info = f" [called: {msg['tool_called']}]" if msg.get("tool_called") else ""
            context_lines.append(f"{role}: {msg['content']}{tool_info}")
        return "\n".join(context_lines)
    
    async def analyze_with_ai(self, user_query: str, llm_response: str = "") -> dict:
        """
        DÃ¹ng AI Ä‘á»ƒ phÃ¢n tÃ­ch conversation vÃ  xÃ¡c Ä‘á»‹nh tool cáº§n gá»i
        
        Returns:
            {
                "tool_name": str,           # Tool cáº§n gá»i
                "arguments": dict,          # Arguments cho tool
                "confidence": float,        # Äá»™ tin cáº­y (0-1)
                "reasoning": str,           # Giáº£i thÃ­ch lÃ½ do
                "should_execute": bool      # CÃ³ nÃªn thá»±c thi khÃ´ng
            }
        """
        # Láº¥y conversation context
        context = self.get_conversation_context(last_n=5)
        
        # Build prompt cho AI
        analysis_prompt = f"""ğŸ§  Báº N LÃ€ TOOL ANALYZER - PhÃ¢n tÃ­ch há»™i thoáº¡i vÃ  xÃ¡c Ä‘á»‹nh TOOL cáº§n gá»i.

ğŸ“‹ DANH SÃCH TOOLS CÃ“ Sáº´N:
{self.tool_catalog}

ğŸ“œ Lá»ŠCH Sá»¬ Há»˜I THOáº I Gáº¦N ÄÃ‚Y:
{context}

ğŸ“ YÃŠU Cáº¦U HIá»†N Táº I Cá»¦A USER:
"{user_query}"

ğŸ’¬ LLM ÄÃƒ PHáº¢N Há»’I (náº¿u cÃ³):
"{llm_response}"

ğŸ¯ NHIá»†M Vá»¤: PhÃ¢n tÃ­ch vÃ  tráº£ vá» JSON vá»›i format CHÃNH XÃC:
{{
    "tool_name": "tÃªn_tool_cáº§n_gá»i hoáº·c null náº¿u khÃ´ng cáº§n tool",
    "arguments": {{"param1": "value1", "param2": "value2"}} hoáº·c {{}},
    "confidence": 0.0 Ä‘áº¿n 1.0,
    "reasoning": "giáº£i thÃ­ch ngáº¯n gá»n lÃ½ do chá»n tool nÃ y",
    "should_execute": true hoáº·c false
}}

ğŸš¨ LÆ¯U Ã QUAN TRá»ŒNG:
1. Náº¾U user há»i cÃ¢u há»i chung (thá»i tiáº¿t, tin tá»©c...) â†’ KHÃ”NG cáº§n tool â†’ tool_name: null
2. Náº¾U user yÃªu cáº§u hÃ nh Ä‘á»™ng Cá»¤ THá»‚ â†’ tÃ¬m tool phÃ¹ há»£p
3. Náº¾U LLM Ä‘Ã£ nÃ³i "Ä‘Ã£ chuyá»ƒn bÃ i", "Ä‘Ã£ táº¡m dá»«ng" nhÆ°ng KHÃ”NG gá»i tool â†’ cáº§n gá»i tool
4. Confidence < 0.6 â†’ should_execute: false
5. CHá»ˆ tráº£ vá» JSON, khÃ´ng cÃ³ text khÃ¡c

VÃ Dá»¤:
- User: "phÃ¡t nháº¡c" â†’ {{"tool_name": "play_music", "arguments": {{}}, "confidence": 0.95, "reasoning": "user muá»‘n phÃ¡t nháº¡c", "should_execute": true}}
- User: "bÃ i tiáº¿p theo" â†’ {{"tool_name": "music_next", "arguments": {{}}, "confidence": 0.95, "reasoning": "user muá»‘n chuyá»ƒn bÃ i", "should_execute": true}}
- User: "má»Ÿ chrome" â†’ {{"tool_name": "open_application", "arguments": {{"app_name": "chrome"}}, "confidence": 0.95, "reasoning": "má»Ÿ trÃ¬nh duyá»‡t", "should_execute": true}}
- User: "hÃ´m nay thá»i tiáº¿t tháº¿ nÃ o?" â†’ {{"tool_name": null, "arguments": {{}}, "confidence": 0.0, "reasoning": "cÃ¢u há»i thÃ´ng thÆ°á»ng, khÃ´ng cáº§n tool", "should_execute": false}}

TRáº¢ Vá»€ JSON:"""

        try:
            # Thá»­ dÃ¹ng Gemini trÆ°á»›c
            if GEMINI_AVAILABLE and hasattr(genai, '_client') or os.getenv("GEMINI_API_KEY"):
                try:
                    api_key = os.getenv("GEMINI_API_KEY", "")
                    if api_key:
                        genai.configure(api_key=api_key)
                        model = genai.GenerativeModel('models/gemini-3-flash-preview')
                        response = model.generate_content(analysis_prompt)
                        ai_result = response.text.strip()
                        print(f"ğŸ¤– [AI Analysis] Gemini response: {ai_result[:200]}...")
                        return self._parse_ai_response(ai_result)
                except Exception as e:
                    print(f"âš ï¸ [AI Analysis] Gemini error: {e}")
            
            # Fallback: dÃ¹ng OpenAI
            if OPENAI_AVAILABLE:
                try:
                    api_key = os.getenv("OPENAI_API_KEY", "")
                    if api_key:
                        client = OpenAI(api_key=api_key)
                        response = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": analysis_prompt}],
                            temperature=0.1,
                            max_tokens=500
                        )
                        ai_result = response.choices[0].message.content.strip()
                        print(f"ğŸ¤– [AI Analysis] GPT-4 response: {ai_result[:200]}...")
                        return self._parse_ai_response(ai_result)
                except Exception as e:
                    print(f"âš ï¸ [AI Analysis] OpenAI error: {e}")
            
            # Fallback cuá»‘i: dÃ¹ng rule-based
            print("âš ï¸ [AI Analysis] No AI available, using rule-based analysis")
            return await self._rule_based_analysis(user_query, llm_response)
            
        except Exception as e:
            print(f"âŒ [AI Analysis] Error: {e}")
            return await self._rule_based_analysis(user_query, llm_response)
    
    def _parse_ai_response(self, ai_text: str) -> dict:
        """Parse JSON tá»« AI response"""
        try:
            # TÃ¬m JSON trong response
            import json
            
            # Thá»­ parse trá»±c tiáº¿p
            try:
                return json.loads(ai_text)
            except:
                pass
            
            # TÃ¬m JSON block
            json_match = re.search(r'\{[\s\S]*\}', ai_text)
            if json_match:
                return json.loads(json_match.group())
            
            # KhÃ´ng tÃ¬m Ä‘Æ°á»£c JSON
            return {
                "tool_name": None,
                "arguments": {},
                "confidence": 0.0,
                "reasoning": "Could not parse AI response",
                "should_execute": False
            }
        except Exception as e:
            print(f"âŒ [Parse] Error: {e}")
            return {
                "tool_name": None,
                "arguments": {},
                "confidence": 0.0,
                "reasoning": f"Parse error: {e}",
                "should_execute": False
            }
    
    async def _rule_based_analysis(self, user_query: str, llm_response: str) -> dict:
        """Fallback: phÃ¢n tÃ­ch báº±ng rules khi khÃ´ng cÃ³ AI"""
        query_lower = user_query.lower() if user_query else ""
        response_lower = llm_response.lower() if llm_response else ""
        combined = (query_lower + " " + response_lower).strip()
        
        print(f"ğŸ” [Rule-Based] Analyzing: '{combined}'")
        
        # Extended patterns cho Táº¤T Cáº¢ tools (Há»– TRá»¢ TIáº¾NG VIá»†T KHÃ”NG Dáº¤U)
        all_tool_patterns = {
            # === MUSIC CONTROLS ===
            "music_next": {
                "patterns": [
                    r"bÃ i tiáº¿p|bai tiep|next|skip|chuyá»ƒn bÃ i|chuyen bai",
                    r"bÃ i sau|bai sau|bÃ i káº¿|bai ke|sang bÃ i|sang bai",
                    r"tiep theo|tiáº¿p theo|ke tiep|káº¿ tiáº¿p"
                ],
                "keywords": ["next", "tiáº¿p", "tiep", "skip", "chuyá»ƒn", "chuyen", "sau", "káº¿", "ke"]
            },
            "music_previous": {
                "patterns": [
                    r"bÃ i trÆ°á»›c|bai truoc|previous|quay láº¡i|quay lai",
                    r"back|lÃ¹i|lui|trá»Ÿ láº¡i|tro lai|bai cu|bÃ i cÅ©"
                ],
                "keywords": ["previous", "trÆ°á»›c", "truoc", "back", "quay", "lÃ¹i", "lui"]
            },
            "pause_music": {
                "patterns": [r"táº¡m dá»«ng|tam dung|pause|dá»«ng láº¡i|dung lai|ngÆ°ng|ngung"],
                "keywords": ["pause", "táº¡m", "tam", "dá»«ng", "dung"]
            },
            "resume_music": {
                "patterns": [r"tiáº¿p tá»¥c|tiep tuc|resume|continue|phÃ¡t tiáº¿p|phat tiep|cháº¡y tiáº¿p|chay tiep"],
                "keywords": ["resume", "tiáº¿p tá»¥c", "tiep tuc", "continue"]
            },
            "stop_music": {
                "patterns": [r"dá»«ng háº³n|dung han|stop|táº¯t nháº¡c|tat nhac|ngá»«ng nháº¡c|ngung nhac"],
                "keywords": ["stop", "táº¯t", "tat", "dá»«ng háº³n", "dung han"]
            },
            "play_music": {
                "patterns": [
                    r"phÃ¡t nháº¡c|phat nhac|play music|báº­t nháº¡c|bat nhac",
                    r"má»Ÿ nháº¡c|mo nhac|nghe nháº¡c|nghe nhac"
                ],
                "keywords": ["phÃ¡t", "phat", "play", "báº­t", "bat", "má»Ÿ", "mo", "nghe"]
            },
            
            # === VOLUME CONTROLS ===
            "volume_up": {
                "patterns": [r"tÄƒng Ã¢m|tang am|volume up|to hÆ¡n|to hon|lá»›n hÆ¡n|lon hon"],
                "keywords": ["tÄƒng", "tang", "up", "to hÆ¡n", "to hon", "lá»›n", "lon"]
            },
            "volume_down": {
                "patterns": [r"giáº£m Ã¢m|giam am|volume down|nhá» hÆ¡n|nho hon|bá»›t to|bot to"],
                "keywords": ["giáº£m", "giam", "down", "nhá»", "nho", "bá»›t", "bot"]
            },
            "mute_volume": {
                "patterns": [r"táº¯t tiáº¿ng|tat tieng|mute|cÃ¢m|cam|im láº·ng|im lang"],
                "keywords": ["mute", "táº¯t tiáº¿ng", "tat tieng", "cÃ¢m", "cam"]
            },
            "set_volume": {
                "patterns": [r"Ã¢m lÆ°á»£ng \d+|am luong \d+|volume \d+|Ä‘áº·t Ã¢m|dat am|chá»‰nh Ã¢m|chinh am"],
                "keywords": ["Ã¢m lÆ°á»£ng", "am luong", "volume"]
            },
            
            # === APPLICATIONS ===
            "open_application": {
                "patterns": [
                    r"má»Ÿ á»©ng dá»¥ng|mo ung dung|open app|má»Ÿ chrome|mo chrome",
                    r"má»Ÿ word|mo word|má»Ÿ excel|mo excel|má»Ÿ notepad|mo notepad",
                    r"khá»Ÿi Ä‘á»™ng|khoi dong"
                ],
                "keywords": ["má»Ÿ", "mo", "open", "khá»Ÿi Ä‘á»™ng", "khoi dong", "cháº¡y", "chay"]
            },
            "kill_process": {
                "patterns": [r"táº¯t á»©ng dá»¥ng|tat ung dung|kill|Ä‘Ã³ng app|dong app|close app"],
                "keywords": ["táº¯t", "tat", "kill", "Ä‘Ã³ng", "dong", "close"]
            },
            
            # === SYSTEM ===
            "take_screenshot": {
                "patterns": [r"chá»¥p mÃ n hÃ¬nh|chup man hinh|screenshot|capture screen"],
                "keywords": ["chá»¥p", "chup", "screenshot", "capture"]
            },
            "get_system_resources": {
                "patterns": [r"tÃ i nguyÃªn|tai nguyen|system info|cpu|ram|memory"],
                "keywords": ["tÃ i nguyÃªn", "tai nguyen", "system", "cpu", "ram"]
            },
            "get_current_time": {
                "patterns": [r"máº¥y giá»|may gio|thá»i gian|thoi gian|time now|giá» hiá»‡n táº¡i|gio hien tai"],
                "keywords": ["giá»", "gio", "time", "thá»i gian", "thoi gian"]
            },
            
            # === FILES ===
            "create_file": {
                "patterns": [r"táº¡o file|tao file|create file|viáº¿t file|viet file"],
                "keywords": ["táº¡o file", "tao file", "create file", "viáº¿t", "viet"]
            },
            "read_file": {
                "patterns": [r"Ä‘á»c file|doc file|read file|xem file"],
                "keywords": ["Ä‘á»c", "doc", "read", "xem"]
            },
            "list_files": {
                "patterns": [r"liá»‡t kÃª file|liet ke file|list files|xem thÆ° má»¥c|xem thu muc"],
                "keywords": ["liá»‡t kÃª", "liet ke", "list", "thÆ° má»¥c", "thu muc"]
            },
            
            # === CALCULATOR ===
            "calculator": {
                "patterns": [r"tÃ­nh|tinh|calculate|bao nhiÃªu|bao nhieu|\d+\s*[\+\-\*\/]\s*\d+"],
                "keywords": ["tÃ­nh", "tinh", "calculate", "cá»™ng", "cong", "trá»«", "tru", "nhÃ¢n", "nhan", "chia"]
            },
            
            # === CLIPBOARD ===
            "get_clipboard": {
                "patterns": [r"clipboard|Ä‘Ã£ copy gÃ¬|da copy gi|láº¥y clipboard|lay clipboard"],
                "keywords": ["clipboard", "copy"]
            },
            "set_clipboard": {
                "patterns": [r"copy vÃ o clipboard|copy vao clipboard|set clipboard"],
                "keywords": ["copy vÃ o", "copy vao", "set clipboard"]
            },
            
            # === BROWSER ===
            "search_web": {
                "patterns": [r"tÃ¬m kiáº¿m google|tim kiem google|search google|má»Ÿ google tÃ¬m|mo google tim"],
                "keywords": ["google", "search web", "tÃ¬m kiáº¿m", "tim kiem"]
            },
            "open_youtube": {
                "patterns": [r"má»Ÿ youtube|mo youtube|youtube|xem video"],
                "keywords": ["youtube", "video"]
            },
            
            # === BRIGHTNESS ===
            "set_brightness": {
                "patterns": [r"Ä‘á»™ sÃ¡ng|do sang|brightness|sÃ¡ng hÆ¡n|sang hon|tá»‘i hÆ¡n|toi hon"],
                "keywords": ["sÃ¡ng", "sang", "brightness", "tá»‘i", "toi"]
            }
        }
        
        # TÃ¬m tool match nháº¥t
        best_match = None
        best_confidence = 0.0
        best_reason = ""
        
        for tool_name, tool_patterns in all_tool_patterns.items():
            # Check patterns
            for pattern in tool_patterns["patterns"]:
                if re.search(pattern, combined):
                    confidence = 0.85
                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_match = tool_name
                        best_reason = f"Pattern match: {pattern}"
                        print(f"âœ… [Rule-Based] Pattern matched: {tool_name} ({pattern})")
                    break
            
            # ALWAYS check keywords (khÃ´ng chá»‰ khi chÆ°a cÃ³ match)
            keyword_count = sum(1 for kw in tool_patterns["keywords"] if kw in combined)
            if keyword_count >= 1:
                confidence = 0.6 + (keyword_count * 0.1)
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = tool_name
                    best_reason = f"Keywords: {keyword_count} matches"
                    print(f"âœ… [Rule-Based] Keywords matched: {tool_name} ({keyword_count} keywords)")
        
        print(f"ğŸ“Š [Rule-Based] Result: {best_match} (confidence: {best_confidence:.2f})")
        
        # Extract arguments
        arguments = {}
        if best_match:
            # DÃ¹ng combined text Ä‘á»ƒ extract args náº¿u query trá»‘ng
            text_for_args = user_query if user_query else llm_response
            arguments = self._extract_arguments(best_match, text_for_args)
        
        return {
            "tool_name": best_match,
            "arguments": arguments,
            "confidence": best_confidence,
            "reasoning": best_reason,
            "should_execute": best_confidence >= 0.5
        }
    
    def _extract_arguments(self, tool_name: str, query: str) -> dict:
        """Extract arguments cho tool tá»« query"""
        args = {}
        query_lower = query.lower()
        
        # play_music â†’ extract filename
        if tool_name == "play_music":
            for kw in ["phÃ¡t", "play", "bÃ i", "song", "má»Ÿ", "báº­t", "nghe"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        filename = parts[1].strip()
                        filename = re.sub(r'\b(cho tÃ´i|giÃºp tÃ´i|nhÃ©|Ä‘i|nÃ o)\b', '', filename).strip()
                        if filename and len(filename) > 1:
                            args["filename"] = filename
                        break
        
        # open_application â†’ extract app_name
        elif tool_name == "open_application":
            for kw in ["má»Ÿ", "open", "khá»Ÿi Ä‘á»™ng", "cháº¡y"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        app = parts[1].strip()
                        app = re.sub(r'\b(cho tÃ´i|giÃºp|nhÃ©|Ä‘i|á»©ng dá»¥ng|app)\b', '', app).strip()
                        if app:
                            args["app_name"] = app
                        break
        
        # set_volume â†’ extract level
        elif tool_name == "set_volume":
            match = re.search(r'(\d+)\s*(%)?', query)
            if match:
                level = int(match.group(1))
                args["level"] = min(100, max(0, level))
        
        # calculator â†’ extract expression
        elif tool_name == "calculator":
            # TÃ¬m biá»ƒu thá»©c toÃ¡n
            expr_match = re.search(r'(\d+[\s\+\-\*\/\(\)]+\d+[\s\d\+\-\*\/\(\)]*)', query)
            if expr_match:
                args["expression"] = expr_match.group(1).strip()
        
        # set_brightness â†’ extract level
        elif tool_name == "set_brightness":
            match = re.search(r'(\d+)\s*(%)?', query)
            if match:
                level = int(match.group(1))
                args["level"] = min(100, max(0, level))
        
        # search_web â†’ extract query
        elif tool_name == "search_web":
            for kw in ["tÃ¬m", "search", "google"]:
                if kw in query_lower:
                    parts = query_lower.split(kw, 1)
                    if len(parts) > 1:
                        search_query = parts[1].strip()
                        search_query = re.sub(r'\b(vá»|cho tÃ´i|giÃºp|trÃªn)\b', '', search_query).strip()
                        if search_query:
                            args["query"] = search_query
                        break
        
        return args
    
    async def execute_tool(self, tool_name: str, arguments: dict) -> dict:
        """Thá»±c thi tool vá»›i arguments"""
        try:
            if tool_name not in TOOLS:
                return {"success": False, "error": f"Tool '{tool_name}' not found"}
            
            handler = TOOLS[tool_name]["handler"]
            if not handler:
                return {"success": False, "error": f"Tool '{tool_name}' has no handler"}
            
            # Gá»i tool
            result = await handler(**arguments)
            
            # LÆ°u láº¡i
            self.last_executed_tool = tool_name
            self.last_tool_result = result
            
            return {"success": True, "tool": tool_name, "result": result}
            
        except Exception as e:
            import traceback
            return {"success": False, "error": str(e), "traceback": traceback.format_exc()}


# Global instance
smart_analyzer = SmartConversationAnalyzer()


@app.post("/api/smart_analyze")
async def api_smart_analyze(data: dict):
    """
    ğŸ§  SMART CONVERSATION ANALYZER API
    
    PhÃ¢n tÃ­ch há»™i thoáº¡i thÃ´ng minh, tá»± Ä‘á»™ng Ä‘iá»u khiá»ƒn Má»ŒI tool.
    KhÃ´ng phá»¥ thuá»™c tá»« khÃ³a cá»©ng - dÃ¹ng AI Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh.
    
    Args:
        user_query: YÃªu cáº§u cá»§a user
        llm_response: Pháº£n há»“i tá»« LLM (optional)
        conversation_history: Lá»‹ch sá»­ há»™i thoáº¡i (optional, list of {role, content})
        auto_execute: Tá»± Ä‘á»™ng thá»±c thi tool (default: True)
        use_ai: DÃ¹ng AI Ä‘á»ƒ phÃ¢n tÃ­ch (default: True, fallback to rules)
    
    Returns:
        {
            "success": bool,
            "analysis": {
                "tool_name": str,
                "arguments": dict,
                "confidence": float,
                "reasoning": str,
                "should_execute": bool
            },
            "execution": {
                "executed": bool,
                "result": dict
            },
            "message": str
        }
    """
    try:
        user_query = data.get("user_query", data.get("query", "")).strip()
        llm_response = data.get("llm_response", data.get("response", "")).strip()
        conversation_history = data.get("conversation_history", [])
        auto_execute = data.get("auto_execute", True)
        use_ai = data.get("use_ai", True)
        
        print(f"\n{'='*70}")
        print(f"ğŸ§  [Smart Analyze] NEW REQUEST")
        print(f"{'='*70}")
        print(f"ğŸ“ User Query: '{user_query}'")
        print(f"ğŸ’¬ LLM Response: '{llm_response[:100]}...' " if llm_response else "")
        print(f"âš™ï¸  Auto Execute: {auto_execute} | Use AI: {use_ai}")
        print(f"ğŸ“œ History Length: {len(conversation_history)}")
        print(f"{'-'*70}")
        
        if not user_query and not llm_response:
            return {
                "success": False,
                "error": "user_query or llm_response is required"
            }
        
        # ThÃªm conversation history náº¿u cÃ³
        for msg in conversation_history:
            smart_analyzer.add_message(
                role=msg.get("role", "user"),
                content=msg.get("content", "")
            )
        
        # ThÃªm message hiá»‡n táº¡i
        if user_query:
            smart_analyzer.add_message("user", user_query)
        if llm_response:
            smart_analyzer.add_message("assistant", llm_response)
        
        # === PHÃ‚N TÃCH ===
        if use_ai:
            analysis = await smart_analyzer.analyze_with_ai(user_query, llm_response)
        else:
            analysis = await smart_analyzer._rule_based_analysis(user_query, llm_response)
        
        print(f"\nğŸ¯ [Analysis Result]")
        print(f"   - Tool: {analysis.get('tool_name')}")
        print(f"   - Arguments: {analysis.get('arguments')}")
        print(f"   - Confidence: {analysis.get('confidence', 0):.2f}")
        print(f"   - Should Execute: {analysis.get('should_execute')}")
        print(f"   - Reasoning: {analysis.get('reasoning')}")
        
        # === THá»°C THI ===
        execution = {"executed": False, "result": None}
        
        if auto_execute and analysis.get("should_execute") and analysis.get("tool_name"):
            tool_name = analysis["tool_name"]
            arguments = analysis.get("arguments", {})
            
            print(f"\nğŸš€ [Execute] Calling: {tool_name}({arguments})")
            
            exec_result = await smart_analyzer.execute_tool(tool_name, arguments)
            execution = {
                "executed": exec_result.get("success", False),
                "result": exec_result
            }
            
            # Cáº­p nháº­t history vá»›i tool Ä‘Ã£ gá»i
            smart_analyzer.add_message("system", f"Tool executed: {tool_name}", tool_called=tool_name)
            
            if exec_result.get("success"):
                print(f"âœ… [Execute] Success!")
            else:
                print(f"âŒ [Execute] Failed: {exec_result.get('error')}")
        
        print(f"{'='*70}\n")
        
        return {
            "success": True,
            "user_query": user_query,
            "llm_response": llm_response,
            "analysis": analysis,
            "execution": execution,
            "message": f"âœ… Tool: {analysis.get('tool_name')} | Executed: {execution['executed']}" if analysis.get('tool_name') else "âš ï¸ No tool needed"
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


# NOTE: ÄÃ£ xÃ³a duplicate endpoint /api/conversation/add (line 13967)
# Endpoint chÃ­nh náº±m á»Ÿ pháº§n CONVERSATION HISTORY API (line ~15208)
# Giá»¯ láº¡i Ä‘á»ƒ trÃ¡nh conflict vá»›i SmartConversationAnalyzer


@app.post("/api/smart_chat")
async def api_smart_chat(data: dict):
    """
    Smart Chat vá»›i Intent Detection tá»± Ä‘á»™ng + VLC MCP Integration + Google Search Grounding
    1. PhÃ¢n tÃ­ch intent
    2. Náº¿u cáº§n tool â†’ tá»± Ä‘á»™ng gá»i tool (REST) hoáº·c MCP (VLC)
    3. Gá»­i káº¿t quáº£ tool + query Ä‘áº¿n Gemini
    4. Tráº£ vá» response hoÃ n chá»‰nh
    
    ğŸ†• VLC MCP: Tá»± Ä‘á»™ng dÃ¹ng MCP protocol cho VLC commands
    ğŸ†• Google Search: Tá»± Ä‘á»™ng tra cá»©u Google cho cÃ¢u há»i realtime
    """
    query = data.get("query", data.get("prompt", data.get("text", "")))
    use_llm_intent = data.get("use_llm_intent", False)
    model = data.get("model", "gemini-2.0-flash")  # Default model há»— trá»£ grounding
    use_google_search = data.get("use_google_search", True)  # ğŸ†• Máº·c Ä‘á»‹nh Báº¬T Google Search
    
    if not query:
        raise HTTPException(400, "Query is required")
    
    try:
        # ğŸ†• STEP -1: Kiá»ƒm tra cÃ³ cáº§n Google Search khÃ´ng (cÃ¢u há»i thá»i sá»±, giÃ¡ cáº£, tin tá»©c)
        realtime_keywords = [
            'giÃ¡ vÃ ng', 'giÃ¡ usd', 'tá»· giÃ¡', 'giÃ¡ bitcoin', 'crypto', 'chá»©ng khoÃ¡n',
            'thá»i tiáº¿t', 'weather', 'tin tá»©c', 'news', 'má»›i nháº¥t', 'latest',
            'hÃ´m nay', 'bÃ¢y giá»', 'hiá»‡n nay', 'hiá»‡n táº¡i', 'today', 'now', 'current',
            'nÄƒm 2024', 'nÄƒm 2025', 'nÄƒm 2026', '2024', '2025', '2026',
            'vÃ´ Ä‘á»‹ch', 'champion', 'winner', 'káº¿t quáº£', 'score', 'result',
            'tá»•ng thá»‘ng', 'president', 'thá»§ tÆ°á»›ng', 'chá»§ tá»‹ch', 'ceo',
            'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft', 'ra máº¯t',
            'lÃ  ai', 'lÃ  gÃ¬', 'á»Ÿ Ä‘Ã¢u', 'what is', 'where is', 'how much', 'bao nhiÃªu',
            'sá»± kiá»‡n', 'event', 'lá»‹ch', 'schedule', 'khi nÃ o', 'when', 'giÃ¡ xÄƒng', 'giÃ¡ dáº§u',
            'covid', 'bÃ£o', 'Ä‘á»™ng Ä‘áº¥t', 'tai náº¡n', 'chÃ¡y', 'chiáº¿n tranh', 'xung Ä‘á»™t'
        ]
        query_lower = query.lower()
        needs_google_search = use_google_search and any(kw in query_lower for kw in realtime_keywords)
        
        # ğŸ” Náº¿u cáº§n Google Search, Æ°u tiÃªn dÃ¹ng Gemini + Google Search Grounding
        if needs_google_search:
            print(f"ğŸ” [Smart Chat] PhÃ¡t hiá»‡n cÃ¢u há»i cáº§n Google Search: {query[:50]}...")
            try:
                google_result = await ask_gemini_with_google_search(
                    prompt=query,
                    model="gemini-2.0-flash"  # Model há»— trá»£ grounding tá»‘t nháº¥t
                )
                
                if google_result.get("success"):
                    # LÆ°u vÃ o conversation history
                    add_to_conversation(role="user", content=query, metadata={"source": "smart_chat_google_search"})
                    add_to_conversation(
                        role="assistant", 
                        content=google_result.get("response", ""),
                        metadata={
                            "source": "smart_chat_google_search",
                            "model": google_result.get("model"),
                            "google_search_used": True,
                            "search_queries": google_result.get("search_queries", [])
                        }
                    )
                    
                    return {
                        "success": True,
                        "query": query,
                        "response": google_result.get("response"),
                        "intent": {"intent": "realtime_query", "needs_google_search": True},
                        "tool_used": "google_search_grounding",
                        "google_search_used": True,
                        "search_queries": google_result.get("search_queries", []),
                        "grounding_chunks": google_result.get("grounding_chunks", []),
                        "model": google_result.get("model"),
                        "message": google_result.get("message")
                    }
                else:
                    print(f"âš ï¸ [Smart Chat] Google Search failed, falling back to normal...")
            except Exception as e:
                print(f"âš ï¸ [Smart Chat] Google Search error: {e}, falling back...")
        
        # ğŸ†• STEP 0: Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ documents/database vá»›i Gemini
        doc_result = await auto_process_document_with_gemini(query, model=model)
        
        if doc_result.get("activated") and doc_result.get("success"):
            # ÄÃ£ xá»­ lÃ½ document thÃ nh cÃ´ng vá»›i Gemini
            print(f"ğŸ“š [Auto Document] Success! Documents: {len(doc_result.get('documents_found', []))}")
            
            return {
                "success": True,
                "query": query,
                "response": doc_result.get("gemini_response"),
                "intent": "document_query",
                "tool_used": "auto_process_document_with_gemini",
                "documents_found": doc_result.get("documents_found", []),
                "model": doc_result.get("model_used"),
                "message": doc_result.get("message"),
                "auto_document_processing": True
            }
        
        # Step 1: Detect intent
        if use_llm_intent:
            intent_result = await intent_detector.detect_with_llm(query, GEMINI_API_KEY)
        else:
            intent_result = intent_detector.detect_intent(query)
        
        print(f"ğŸ§  [Intent] {intent_result}")
        
        tool_result = None
        tool_used = None
        mcp_used = False
        
        # Step 2: Náº¿u cáº§n force tool, gá»i tool trÆ°á»›c
        if intent_result.get("should_force_tool") and intent_result.get("suggested_tool"):
            tool_name = intent_result["suggested_tool"]
            
            # ğŸ†• CHECK: Náº¿u lÃ  VLC command â†’ dÃ¹ng MCP
            vlc_commands = ["music_next", "music_previous", "pause_music", "resume_music", "stop_music", "play_music"]
            
            if VLC_MCP_AVAILABLE and tool_name in vlc_commands:
                print(f"ğŸ¯ [VLC MCP] Routing to MCP: {tool_name}")
                
                # Map tool name to MCP tool name
                mcp_tool_map = {
                    "music_next": "vlc.next",
                    "music_previous": "vlc.previous",
                    "pause_music": "vlc.pause",
                    "resume_music": "vlc.play",
                    "stop_music": "vlc.stop",
                    "play_music": "vlc.play"
                }
                
                mcp_tool_name = mcp_tool_map.get(tool_name)
                
                if mcp_tool_name:
                    try:
                        # Call via MCP protocol
                        mcp_request = {
                            "jsonrpc": "2.0",
                            "method": "tools/call",
                            "params": {
                                "name": mcp_tool_name,
                                "arguments": {}
                            },
                            "id": 1
                        }
                        
                        mcp_response = await vlc_mcp_server.handle_mcp_request(mcp_request)
                        
                        if "result" in mcp_response:
                            tool_result = mcp_response["result"]
                            tool_used = mcp_tool_name
                            mcp_used = True
                            print(f"âœ… [VLC MCP] Success: {mcp_tool_name}")
                        else:
                            print(f"âŒ [VLC MCP] Error: {mcp_response.get('error')}")
                            tool_result = {"error": mcp_response.get("error", {}).get("message", "Unknown error")}
                    except Exception as e:
                        print(f"âš ï¸ [VLC MCP] Exception: {e}")
                        tool_result = {"error": str(e)}
            
            # Fallback: REST API
            elif tool_name in TOOLS and TOOLS[tool_name]["handler"]:
                print(f"ğŸ”§ [Auto Tool] Calling {tool_name} for query: {query}")
                
                try:
                    # Táº¡o arguments dá»±a trÃªn intent
                    tool_args = {"query": query}
                    
                    # Gá»i tool
                    handler = TOOLS[tool_name]["handler"]
                    tool_result = await handler(**tool_args)
                    tool_used = tool_name
                    
                    print(f"âœ… [Auto Tool] {tool_name} result: {str(tool_result)[:200]}...")
                except Exception as e:
                    print(f"âš ï¸ [Auto Tool] Error calling {tool_name}: {e}")
                    tool_result = {"error": str(e)}
        
        # Step 3: Gá»­i Ä‘áº¿n Gemini vá»›i context tá»« tool
        final_prompt = query
        if tool_result and not tool_result.get("error"):
            # ThÃªm context tá»« tool result
            context = json.dumps(tool_result, ensure_ascii=False, indent=2)
            final_prompt = f"""Dá»±a trÃªn thÃ´ng tin tra cá»©u sau Ä‘Ã¢y, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a user.

ğŸ“Š THÃ”NG TIN TRA Cá»¨U (tá»« {tool_used}):
{context}

â“ CÃ‚U Há»I Cá»¦A USER:
{query}

ğŸ“ YÃŠU Cáº¦U:
- Tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c
- Dá»±a trÃªn thÃ´ng tin tra cá»©u á»Ÿ trÃªn
- Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§, nÃ³i rÃµ vÃ  Ä‘Æ°a ra nhá»¯ng gÃ¬ cÃ³"""
        
        # Gá»i Gemini
        gemini_result = await ask_gemini(prompt=final_prompt, model=model)
        
        # LÆ°u vÃ o conversation history
        add_to_conversation(
            role="user",
            content=query,
            metadata={
                "source": "smart_chat",
                "intent": intent_result.get("intent"),
                "tool_suggested": intent_result.get("suggested_tool")
            }
        )
        
        if gemini_result.get("success"):
            add_to_conversation(
                role="assistant",
                content=gemini_result.get("response", ""),
                metadata={
                    "source": "smart_chat",
                    "tool_used": tool_used,
                    "model": model
                }
            )
        
        return {
            "success": True,
            "query": query,
            "intent": intent_result,
            "tool_used": tool_used,
            "tool_result": tool_result,
            "response": gemini_result.get("response", ""),
            "model": model
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


# ===== ğŸ” GOOGLE SEARCH GROUNDING ENDPOINT =====

@app.post("/api/gemini/google_search")
async def api_gemini_google_search(data: dict):
    """
    ğŸ” Gemini vá»›i Google Search Grounding - Tra cá»©u Google tá»± Ä‘á»™ng
    
    TÃ­nh nÄƒng cho phÃ©p Gemini tá»± Ä‘á»™ng tÃ¬m kiáº¿m Google Ä‘á»ƒ tráº£ lá»i
    cÃ¡c cÃ¢u há»i cáº§n thÃ´ng tin má»›i nháº¥t, real-time.
    
    Args (JSON body):
        prompt (str): CÃ¢u há»i cáº§n Gemini tra cá»©u vÃ  tráº£ lá»i
        model (str, optional): Model Gemini (default: gemini-2.0-flash)
        
    Returns:
        success: True/False
        response: CÃ¢u tráº£ lá»i tá»« Gemini
        google_search_used: True náº¿u Ä‘Ã£ dÃ¹ng Google Search
        search_queries: CÃ¡c query Ä‘Ã£ search trÃªn Google
        grounding_chunks: Nguá»“n website Ä‘Æ°á»£c trÃ­ch dáº«n
    
    Example:
        POST /api/gemini/google_search
        {"prompt": "GiÃ¡ vÃ ng hÃ´m nay lÃ  bao nhiÃªu?"}
    """
    prompt = data.get("prompt", data.get("query", data.get("text", "")))
    model = data.get("model", "gemini-2.0-flash")
    
    if not prompt:
        raise HTTPException(400, "Prompt is required")
    
    print(f"ğŸ” [API Google Search] Query: {prompt[:100]}...")
    
    # LÆ°u user message vÃ o history
    add_to_conversation(
        role="user",
        content=prompt,
        metadata={"source": "google_search_api", "model": model}
    )
    
    try:
        # Gá»i Gemini vá»›i Google Search Grounding
        result = await ask_gemini_with_google_search(
            prompt=prompt,
            model=model
        )
        
        if result.get("success"):
            # LÆ°u assistant response vÃ o history
            add_to_conversation(
                role="assistant",
                content=result.get("response", ""),
                metadata={
                    "source": "google_search_api",
                    "model": result.get("model"),
                    "google_search_used": result.get("google_search_used", False),
                    "search_queries": result.get("search_queries", [])
                }
            )
            
            return {
                "success": True,
                "prompt": prompt,
                "response": result.get("response"),
                "response_text": result.get("response"),  # Alias
                "model": result.get("model"),
                "google_search_used": result.get("google_search_used", False),
                "search_queries": result.get("search_queries", []),
                "grounding_chunks": result.get("grounding_chunks", []),
                "message": result.get("message")
            }
        else:
            return {
                "success": False,
                "error": result.get("error", "Unknown error"),
                "prompt": prompt
            }
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "prompt": prompt
        }


# ===== 23 API ENDPOINTS Má»šI (Tool 8-30) =====

@app.post("/api/tool/ask_gemini")
async def api_ask_gemini(data: dict):
    """
    Gemini AI endpoint with Knowledge Base + Google Search integration
    
    Flow:
    1. Nháº­n query tá»« user
    2. ğŸ†• Kiá»ƒm tra cÃ³ cáº§n Google Search khÃ´ng (giÃ¡ cáº£, tin tá»©c, thá»i sá»±)
    3. Náº¿u cáº§n realtime â†’ dÃ¹ng Google Search Grounding
    4. Náº¿u khÃ´ng â†’ search Knowledge Base + Gemini
    5. Tráº£ vá» response
    """
    prompt = data.get("prompt", "")
    model = data.get("model", "gemini-2.0-flash")  # ğŸ†• Default model há»— trá»£ grounding
    use_google_search = data.get("use_google_search", True)  # ğŸ†• Máº·c Ä‘á»‹nh Báº¬T
    # ğŸ”’ Báº®T BUá»˜C search KB - KHÃ”NG cho user táº¯t
    use_knowledge_base = True  # LUÃ”N Báº¬T
    
    if not prompt:
        raise HTTPException(400, "Prompt is required")
    
    # LÆ°u user message vÃ o history
    add_to_conversation(
        role="user",
        content=prompt,
        metadata={
            "source": "web_ui",
            "model_requested": model,
            "ai_provider": "gemini"
        }
    )
    
    # ğŸ†• STEP 0: Kiá»ƒm tra cÃ³ cáº§n Google Search khÃ´ng
    realtime_keywords = [
        # GiÃ¡ cáº£, tÃ i chÃ­nh
        'giÃ¡ vÃ ng', 'giÃ¡ usd', 'tá»· giÃ¡', 'giÃ¡ bitcoin', 'crypto', 'chá»©ng khoÃ¡n',
        'gold price', 'exchange rate', 'giÃ¡ xÄƒng', 'giÃ¡ dáº§u', 'giÃ¡ cao nháº¥t', 'giÃ¡ má»›i nháº¥t',
        'stock', 'bitcoin', 'ethereum', 'btc', 'eth',
        
        # Thá»i tiáº¿t
        'thá»i tiáº¿t', 'weather', 'nhiá»‡t Ä‘á»™', 'temperature', 'mÆ°a', 'bÃ£o',
        
        # Tin tá»©c, sá»± kiá»‡n
        'tin tá»©c', 'news', 'má»›i nháº¥t', 'latest', 'breaking', 'sá»± kiá»‡n',
        
        # Thá»i gian thá»±c
        'hÃ´m nay', 'bÃ¢y giá»', 'hiá»‡n nay', 'hiá»‡n táº¡i', 'today', 'now', 'current',
        'nÄƒm 2024', 'nÄƒm 2025', 'nÄƒm 2026', '2024', '2025', '2026',
        
        # Thá»ƒ thao, cuá»™c thi
        'vÃ´ Ä‘á»‹ch', 'champion', 'winner', 'káº¿t quáº£', 'score', 'result',
        'world cup', 'euro', 'sea games', 'olympic', 'bÃ³ng Ä‘Ã¡', 'football',
        
        # NgÆ°á»i ná»•i tiáº¿ng, chÃ­nh trá»‹
        'tá»•ng thá»‘ng', 'president', 'thá»§ tÆ°á»›ng', 'chá»§ tá»‹ch', 'ceo',
        'ai lÃ ', 'who is', 'who won',
        
        # Sáº£n pháº©m, cÃ´ng nghá»‡
        'iphone', 'samsung', 'tesla', 'apple', 'google', 'microsoft',
        'ra máº¯t', 'launch', 'release', 'announced',
        
        # Tra cá»©u chung cáº§n thÃ´ng tin má»›i
        'lÃ  ai', 'lÃ  gÃ¬', 'á»Ÿ Ä‘Ã¢u', 'what is', 'where is', 'how much', 'bao nhiÃªu',
        'khi nÃ o', 'when', 'how many'
    ]
    prompt_lower = prompt.lower()
    needs_google_search = use_google_search and any(kw in prompt_lower for kw in realtime_keywords)
    
    # ğŸ” Náº¿u cáº§n Google Search, Æ°u tiÃªn dÃ¹ng Gemini + Google Search Grounding
    if needs_google_search:
        print(f"ğŸ” [ask_gemini] PhÃ¡t hiá»‡n cÃ¢u há»i cáº§n Google Search: {prompt[:50]}...")
        try:
            google_result = await ask_gemini_with_google_search(
                prompt=prompt,
                model="gemini-2.0-flash"  # Model há»— trá»£ grounding tá»‘t nháº¥t
            )
            
            if google_result.get("success"):
                response_text = google_result.get("response", "")
                
                # LÆ°u vÃ o conversation history
                add_to_conversation(
                    role="assistant",
                    content=response_text,
                    metadata={
                        "source": "web_ui_google_search",
                        "model": google_result.get("model"),
                        "google_search_used": True,
                        "search_queries": google_result.get("search_queries", [])
                    }
                )
                
                return {
                    "success": True,
                    "prompt": prompt,
                    "response": response_text,
                    "response_text": response_text,
                    "model": google_result.get("model"),
                    "google_search_used": True,
                    "search_queries": google_result.get("search_queries", []),
                    "grounding_chunks": google_result.get("grounding_chunks", []),
                    "message": f"âœ… Gemini Ä‘Ã£ tra cá»©u Google vÃ  tráº£ lá»i (model: {google_result.get('model')})"
                }
            else:
                print(f"âš ï¸ [ask_gemini] Google Search failed: {google_result.get('error')}, falling back to KB...")
        except Exception as e:
            print(f"âš ï¸ [ask_gemini] Google Search error: {e}, falling back to KB...")
    
    # ğŸ†• AUTO-READ ALL KNOWLEDGE BASE (Báº®T BUá»˜C) - Fallback náº¿u Google Search khÃ´ng dÃ¹ng/fail
    enhanced_prompt = prompt
    kb_context_used = False
    
    if use_knowledge_base:  # LuÃ´n = True
        try:
            # Äá»ŒC TOÃ€N Bá»˜ Knowledge Base - KHÃ”NG filter theo query
            kb_result = await get_knowledge_context(
                query="",  # Äá»‚ TRá»NG Ä‘á»ƒ láº¥y Táº¤T Cáº¢ documents
                max_chars=50000,  # TÄƒng giá»›i háº¡n Ä‘á»ƒ Ä‘á»c nhiá»u hÆ¡n
                use_gemini_summary=True  # Báº­t Gemini tÃ³m táº¯t
            )
            
            if kb_result.get("success") and kb_result.get("context"):
                kb_context = kb_result["context"]
                docs_count = kb_result.get("documents_included", 0)
                
                # ThÃªm context vÃ o prompt
                enhanced_prompt = f"""ğŸ“š KNOWLEDGE BASE - TOÃ€N Bá»˜ CÆ  Sá» Dá»® LIá»†U ({docs_count} tÃ i liá»‡u):
{kb_context}

{'='*60}
â“ CÃ‚U Há»I Cá»¦A USER:
{prompt}

{'='*60}
ğŸ’¡ HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
- Báº¡n Ä‘Ã£ cÃ³ TOÃ€N Bá»˜ ná»™i dung Knowledge Base á»Ÿ trÃªn
- PhÃ¢n tÃ­ch vÃ  tÃ³m táº¯t thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i
- Tráº£ lá»i Dá»°A TRÃŠN dá»¯ liá»‡u cÃ³ sáºµn, KHÃ”NG Ä‘oÃ¡n mÃ²
- TrÃ­ch dáº«n nguá»“n cá»¥ thá»ƒ (tÃªn file, pháº§n ná»™i dung)
- Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, hÃ£y nÃ³i rÃµ "KhÃ´ng cÃ³ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u"
"""
                kb_context_used = True
                print(f"âœ… [KB] Loaded ALL Knowledge Base: {docs_count} documents, {len(kb_context)} chars")
            else:
                print(f"âš ï¸ [KB] Knowledge Base is empty or not indexed yet")
        except Exception as e:
            print(f"âš ï¸ [KB] Error getting context: {e}")
            # KhÃ´ng cÃ³ context, dÃ¹ng prompt gá»‘c
    
    # Gá»i Gemini vá»›i enhanced prompt
    result = await ask_gemini(prompt=enhanced_prompt, model=model)
    
    # ThÃªm metadata vá» KB usage
    if kb_context_used and result.get("success"):
        result["knowledge_base_used"] = True
        result["message"] = result.get("response", "") + "\n\nğŸ“š *Tráº£ lá»i dá»±a trÃªn Knowledge Base cá»§a báº¡n*"
    
    # LÆ°u AI response vÃ o history
    if result.get("success"):
        add_to_conversation(
            role="assistant",
            content=result.get("response", ""),
            metadata={
                "source": "web_ui",
                "model": model,
                "ai_provider": "gemini",
                "knowledge_base_used": kb_context_used,
                "token_count": result.get("token_count", 0) if "token_count" in result else None
            }
        )
    
    return result


# ===== TTS (Text-to-Speech) API =====
# Global variable Ä‘á»ƒ track tráº¡ng thÃ¡i TTS
tts_is_playing = False
tts_stop_requested = False

@app.post("/api/tts")
async def api_text_to_speech(data: dict):
    """
    API Ä‘á»c to vÄƒn báº£n - Æ¯u tiÃªn Gemini TTS, fallback to gTTS/SAPI
    âš¡ FAST MODE: Chá»‰ Ä‘á»c 500 kÃ½ tá»± Ä‘áº§u Ä‘á»ƒ response nhanh
    """
    global tts_is_playing, tts_stop_requested
    
    print(f"ğŸ”Š [TTS API] Received request")
    
    text = data.get("text", "")
    if not text:
        print("âŒ [TTS API] No text provided")
        return {"success": False, "error": "KhÃ´ng cÃ³ vÄƒn báº£n Ä‘á»ƒ Ä‘á»c"}
    
    # âš¡ FAST MODE: Giá»›i háº¡n 500 kÃ½ tá»± Ä‘á»ƒ TTS nhanh (real-time feel)
    max_chars = 500
    original_length = len(text)
    if len(text) > max_chars:
        # Cáº¯t táº¡i dáº¥u cÃ¢u gáº§n nháº¥t Ä‘á»ƒ khÃ´ng bá»‹ cáº¯t giá»¯a tá»«
        cut_text = text[:max_chars]
        last_sentence = max(
            cut_text.rfind('.'),
            cut_text.rfind('!'),
            cut_text.rfind('?'),
            cut_text.rfind('ã€‚')
        )
        if last_sentence > max_chars // 2:
            text = text[:last_sentence + 1]
        else:
            text = cut_text
        print(f"ğŸ”Š [TTS API] Truncated from {original_length} to {len(text)} chars for fast response")
    
    # Loáº¡i bá» markdown formatting
    text = clean_markdown_for_tts(text)
    
    tts_is_playing = True
    tts_stop_requested = False
    
    try:
        # Æ¯u tiÃªn Gemini TTS (cháº¥t lÆ°á»£ng cao)
        print(f"ğŸ™ï¸ [TTS API] Trying Gemini TTS ({len(text)} chars)...")
        voice = data.get("voice", "Aoede")  # Default female voice
        result = await gemini_text_to_speech(text, voice=voice, save_audio=False)
        
        if result.get("success"):
            print(f"âœ… [TTS API] Gemini TTS success!")
            tts_is_playing = False
            return result
        
        # Fallback to gTTS/SAPI
        print(f"âš ï¸ [TTS API] Gemini TTS failed, falling back to gTTS/SAPI...")
        result = await text_to_speech(text, save_audio=False)
        print(f"ğŸ”Š [TTS API] Result: {result}")
        tts_is_playing = False
        return result
    except Exception as e:
        print(f"âŒ [TTS API] Error: {e}")
        import traceback
        traceback.print_exc()
        tts_is_playing = False
        return {"success": False, "error": str(e)}


@app.post("/api/tts/stop")
async def api_tts_stop():
    """
    Dá»«ng TTS Ä‘ang phÃ¡t
    """
    global tts_is_playing, tts_stop_requested
    
    tts_stop_requested = True
    
    try:
        import pygame
        if pygame.mixer.get_init():
            pygame.mixer.music.stop()
            pygame.mixer.quit()
        tts_is_playing = False
        return {"success": True, "message": "ÄÃ£ dá»«ng TTS"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/tts/status")
async def api_tts_status():
    """
    Kiá»ƒm tra tráº¡ng thÃ¡i TTS
    """
    global tts_is_playing
    return {"is_playing": tts_is_playing}


@app.post("/api/tool/open_application")
async def api_open_app(data: dict):
    result = await open_application(data.get("app_name", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

# MEDIA PLAYER CONTROL ENDPOINTS
@app.post("/api/tool/media_play_pause")
async def api_media_play_pause(data: dict):
    result = await media_play_pause()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_next_track")
async def api_media_next(data: dict):
    result = await media_next_track()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_previous_track")
async def api_media_previous(data: dict):
    result = await media_previous_track()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_stop")
async def api_media_stop(data: dict):
    result = await media_stop()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/media_control")
async def api_media_control(data: dict):
    result = await media_control(data.get("action", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_active_media_players")
async def api_get_active_media(data: dict):
    result = await get_active_media_players()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/list_running_processes")
async def api_list_procs(data: dict):
    result = await list_running_processes(data.get("limit", 10))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/kill_process")
async def api_kill_proc(data: dict):
    result = await kill_process(data.get("identifier", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/create_file")
async def api_create_file(data: dict):
    result = await create_file(data.get("path", ""), data.get("content", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/read_file")
async def api_read_file(data: dict):
    result = await read_file(data.get("path", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/list_files")
async def api_list_files(data: dict):
    result = await list_files(data.get("directory", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_disk_usage")
async def api_disk_usage():
    result = await get_disk_usage()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_network_info")
async def api_network():
    result = await get_network_info()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_battery_status")
async def api_battery():
    result = await get_battery_status()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/search_web")
async def api_search(data: dict):
    result = await search_web(data.get("query", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/get_clipboard")
async def api_get_clip():
    result = await get_clipboard()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_clipboard")
async def api_set_clip(data: dict):
    result = await set_clipboard(data.get("text", ""))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/play_sound")
async def api_sound(data: dict):
    result = await play_sound(data.get("frequency", 1000), data.get("duration", 500))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_volume")
async def api_tool_set_volume(data: dict):
    result = await set_volume(data.get("level", 50))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_brightness")
async def api_brightness(data: dict):
    result = await set_brightness(data.get("level", 50))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/mute_volume")
async def api_mute_volume(data: dict):
    result = await mute_volume()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/unmute_volume")
async def api_unmute_volume(data: dict):
    result = await unmute_volume()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/volume_up")
async def api_volume_up(data: dict):
    result = await volume_up(data.get("steps", 5))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/volume_down")
async def api_volume_down(data: dict):
    result = await volume_down(data.get("steps", 5))
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/minimize_all_windows")
async def api_minimize():
    result = await show_desktop()  # Sá»­ dá»¥ng show_desktop thay vÃ¬ minimize_all_windows
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/undo_action")
async def api_undo():
    result = await undo_operation()  # Sá»­ dá»¥ng undo_operation thay vÃ¬ undo_action
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/toggle_dark_mode")
async def api_theme():
    result = await set_theme(dark_mode=None)  # Toggle báº±ng cÃ¡ch Ä‘á»ƒ None, hÃ m set_theme sáº½ xá»­ lÃ½
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/change_wallpaper")
async def api_change_wallpaper(data: dict):
    """Äá»•i hÃ¬nh ná»n - endpoint cho Web UI"""
    keyword = data.get("keyword", "")
    path = data.get("path", "")
    result = await change_wallpaper(keyword=keyword, custom_path=path)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/set_wallpaper")
async def api_wallpaper(data: dict):
    """Alias cá»§a change_wallpaper"""
    path = data.get("path", "")
    keyword = data.get("keyword", "")
    result = await change_wallpaper(keyword=keyword, custom_path=path)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/paste_text")
async def api_paste():
    result = await paste_content(content="")  # paste_content vá»›i clipboard hiá»‡n táº¡i
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/press_enter")
async def api_enter():
    result = await press_enter()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/find_on_screen")
async def api_find(data: dict):
    result = await find_in_document(data.get("text", ""))  # Sá»­ dá»¥ng find_in_document
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/lock_computer")
async def api_lock():
    result = await lock_computer()
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result

@app.post("/api/tool/shutdown_computer")
async def api_shutdown(data: dict):
    delay = data.get("delay", 0)
    # Sá»­ dá»¥ng shutdown_schedule vá»›i action="shutdown"
    result = await shutdown_schedule(action="shutdown", delay=delay)
    if not result["success"]:
        raise HTTPException(500, result["error"])
    return result


@app.get("/logo.png")
async def get_logo():
    from fastapi.responses import FileResponse
    import os
    import sys
    
    # TÃ¬m logo theo thá»© tá»± Æ°u tiÃªn
    possible_paths = []
    
    # 1. PyInstaller frozen EXE - trong thÆ° má»¥c _internal hoáº·c cÃ¹ng thÆ° má»¥c EXE
    if getattr(sys, 'frozen', False):
        exe_dir = os.path.dirname(sys.executable)
        possible_paths.extend([
            os.path.join(exe_dir, "_internal", "logo.png"),
            os.path.join(exe_dir, "logo.png"),
            os.path.join(getattr(sys, '_MEIPASS', exe_dir), "logo.png"),
        ])
    
    # 2. ThÆ° má»¥c script
    possible_paths.append(os.path.join(os.path.dirname(__file__), "logo.png"))
    
    # 3. ThÆ° má»¥c lÃ m viá»‡c hiá»‡n táº¡i
    possible_paths.append(os.path.join(os.getcwd(), "logo.png"))
    
    # TÃ¬m file Ä‘áº§u tiÃªn tá»“n táº¡i
    for logo_path in possible_paths:
        if os.path.exists(logo_path):
            return FileResponse(logo_path, media_type="image/png")
    
    # Log Ä‘á»ƒ debug
    print(f"âš ï¸ Logo not found. Checked paths: {possible_paths}")
    raise HTTPException(404, "Logo not found")

@app.get("/api/endpoints")
async def get_endpoints():
    global GEMINI_API_KEY, OPENAI_API_KEY, SERPER_API_KEY
    return {
        "endpoints": endpoints_config,
        "active_index": active_endpoint_index,
        "gemini_api_key": GEMINI_API_KEY,
        "openai_api_key": OPENAI_API_KEY,
        "serper_api_key": SERPER_API_KEY
    }

@app.get("/api/endpoints/status")
async def get_endpoints_status():
    """ğŸ”¥ NEW: Get detailed endpoint connection status with stats"""
    status = {
        "endpoints": [],
        "active_index": active_endpoint_index,
        "total_connected": sum(1 for v in xiaozhi_connected.values() if v)
    }
    
    # Add detailed info for each endpoint
    for i, ep in enumerate(endpoints_config):
        endpoint_status = {
            "index": i,
            "name": ep.get("name", f"Thiáº¿t bá»‹ {i+1}"),
            "enabled": ep.get("enabled", False),
            "has_token": bool(ep.get("token")),
            "connected": xiaozhi_connected.get(i, False),
            "is_active": i == active_endpoint_index
        }
        
        # ThÃªm stats tá»« EndpointManager náº¿u cÃ³
        if ENDPOINT_MANAGER_AVAILABLE:
            try:
                manager = get_endpoint_manager()
                stats = manager.stats.get(i)
                if stats:
                    endpoint_status["stats"] = {
                        "total_connects": stats.total_connects,
                        "total_disconnects": stats.total_disconnects,
                        "total_errors": stats.total_errors,
                        "last_connected": stats.last_connected,
                        "last_error": stats.last_error,
                        "uptime_seconds": stats.uptime_seconds
                    }
            except Exception:
                pass
        
        status["endpoints"].append(endpoint_status)
    
    return status

@app.post("/api/endpoints/reconnect/{index}")
async def reconnect_endpoint(index: int):
    """ğŸ”¥ NEW: Force reconnect an endpoint"""
    global should_reconnect
    
    if index < 0 or index >= len(endpoints_config):
        return {"success": False, "error": f"Invalid index: {index}"}
    
    ep = endpoints_config[index]
    if not ep.get("token"):
        return {"success": False, "error": "Endpoint has no token"}
    
    # Trigger reconnect
    should_reconnect[index] = True
    
    # Cáº­p nháº­t EndpointManager náº¿u cÃ³
    if ENDPOINT_MANAGER_AVAILABLE:
        try:
            manager = get_endpoint_manager()
            manager.should_reconnect[index] = True
        except Exception:
            pass
    
    return {
        "success": True,
        "message": f"Äang reconnect {ep.get('name', f'Thiáº¿t bá»‹ {index+1}')}..."
    }

# YouTube Playlists API
@app.get("/api/youtube_playlists")
async def api_get_youtube_playlists():
    """Láº¥y danh sÃ¡ch playlist YouTube"""
    return await get_youtube_playlists()

@app.post("/api/youtube_playlists/add")
async def api_add_youtube_playlist(data: dict):
    """ThÃªm playlist YouTube má»›i"""
    name = data.get("name", "").strip()
    url = data.get("url", "").strip()
    
    if not name or not url:
        return {"success": False, "error": "TÃªn vÃ  URL khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng"}
    
    return await add_youtube_playlist(name, url)

@app.post("/api/youtube_playlists/remove")
async def api_remove_youtube_playlist(data: dict):
    """XÃ³a playlist YouTube"""
    name = data.get("name", "").strip()
    
    if not name:
        return {"success": False, "error": "TÃªn playlist khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng"}
    
    return await remove_youtube_playlist(name)

# ============================================================
# KNOWLEDGE BASE API - Quáº£n lÃ½ dá»¯ liá»‡u cho LLM
# ============================================================

# File lÆ°u cáº¥u hÃ¬nh knowledge base - LÆ°u vÃ o AppData Ä‘á»ƒ trÃ¡nh Permission denied
def get_knowledge_data_dir():
    """Láº¥y thÆ° má»¥c lÆ°u trá»¯ knowledge base data trong AppData"""
    if os.name == 'nt':  # Windows
        appdata = os.environ.get('LOCALAPPDATA', os.path.expanduser('~\\AppData\\Local'))
        data_dir = Path(appdata) / "miniZ_MCP" / "knowledge"
    else:  # Linux/Mac
        data_dir = Path.home() / ".miniz_mcp" / "knowledge"
    data_dir.mkdir(parents=True, exist_ok=True)
    return data_dir

KNOWLEDGE_DATA_DIR = get_knowledge_data_dir()
KNOWLEDGE_CONFIG_FILE = KNOWLEDGE_DATA_DIR / "knowledge_config.json"
KNOWLEDGE_INDEX_FILE = KNOWLEDGE_DATA_DIR / "knowledge_index.json"

# CÃ¡c extension Ä‘Æ°á»£c há»— trá»£
SUPPORTED_EXTENSIONS = {'.pdf', '.txt', '.docx', '.doc', '.md', '.json', '.csv', '.xlsx', '.xls', '.rtf'}

def load_knowledge_config():
    """Load cáº¥u hÃ¬nh knowledge base"""
    if KNOWLEDGE_CONFIG_FILE.exists():
        try:
            # Sá»­ dá»¥ng utf-8-sig Ä‘á»ƒ tá»± Ä‘á»™ng xá»­ lÃ½ BOM
            with open(KNOWLEDGE_CONFIG_FILE, 'r', encoding='utf-8-sig') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ [Knowledge] Error loading config: {e}")
    return {"folder_path": "", "indexed_files": [], "last_update": ""}

def save_knowledge_config(config: dict):
    """LÆ°u cáº¥u hÃ¬nh knowledge base"""
    try:
        with open(KNOWLEDGE_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ [Knowledge] Error saving config: {e}")
        return False

def load_knowledge_index():
    """Load index Ä‘Ã£ lÆ°u"""
    if KNOWLEDGE_INDEX_FILE.exists():
        try:
            # Sá»­ dá»¥ng utf-8-sig Ä‘á»ƒ tá»± Ä‘á»™ng xá»­ lÃ½ BOM
            with open(KNOWLEDGE_INDEX_FILE, 'r', encoding='utf-8-sig') as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸ [Knowledge] Error loading index: {e}")
    return {"documents": [], "total_chunks": 0, "last_update": ""}

# ============================================================
# VECTOR SEARCH ENGINE - Global Instance
# ============================================================

_vector_engine = None

def get_vector_engine():
    """Láº¥y hoáº·c khá»Ÿi táº¡o VectorSearchEngine"""
    global _vector_engine
    if _vector_engine is None and VECTOR_SEARCH_AVAILABLE:
        _vector_engine = VectorSearchEngine()
        
        # Try loading existing index - kiá»ƒm tra nhiá»u vá»‹ trÃ­
        vector_paths = [
            Path("test_vector.faiss"),  # Trong thÆ° má»¥c gá»‘c
            KNOWLEDGE_DATA_DIR / "vector_index.faiss",  # Trong AppData
            Path("vector_index.faiss")  # Backup trong gá»‘c
        ]
        
        for vector_index_path in vector_paths:
            if vector_index_path.exists():
                try:
                    # Remove .faiss extension for load_index
                    base_path = str(vector_index_path.with_suffix(''))
                    _vector_engine.load_index(base_path)
                    print(f"âœ… [VectorSearch] Loaded index from: {vector_index_path}")
                    print(f"   Statistics: {_vector_engine.get_statistics()}")
                    break
                except Exception as e:
                    print(f"âš ï¸ [VectorSearch] Failed to load {vector_index_path}: {e}")
                    continue
        else:
            print(f"âš ï¸ [VectorSearch] No valid index found in any location")
            
    return _vector_engine

def save_knowledge_index(index_data: dict):
    """LÆ°u index"""
    try:
        with open(KNOWLEDGE_INDEX_FILE, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"âŒ [Knowledge] Error saving index: {e}")
        return False

async def summarize_with_gemini(text: str, filename: str) -> dict:
    """TÃ³m táº¯t document báº±ng Gemini Flash (optimized)"""
    try:
        import google.generativeai as genai
        
        # Configure Gemini
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-3-flash-preview')
        
        # âš¡ PROMPT NGáº®N Gá»ŒN - pháº£n há»“i nhanh hÆ¡n
        prompt = f"""TÃ³m táº¯t tÃ i liá»‡u:

File: {filename}
Ná»™i dung: {text[:6000]}

Tráº£ vá» JSON:
{{
  "summary": "[2-3 cÃ¢u chÃ­nh]",
  "keywords": ["5-7 tá»« khÃ³a"],
  "key_quotes": ["2 trÃ­ch dáº«n quan trá»ng"],
  "category": "[loáº¡i: technical/business/etc]"
}}"""
        
        print(f"âš¡ [Gemini] TÃ³m táº¯t: {filename[:30]}...")
        
        # â±ï¸ Timeout 12 giÃ¢y
        loop = asyncio.get_event_loop()
        response = await asyncio.wait_for(
            loop.run_in_executor(None, lambda: model.generate_content(prompt)),
            timeout=12.0
        )
        
        # Parse JSON response
        import json
        result_text = response.text.strip()
        if result_text.startswith("```json"):
            result_text = result_text[7:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        result_text = result_text.strip()
        
        result = json.loads(result_text)
        print(f"âœ… [Gemini] Done: {filename[:30]}")
        return result
        
    except asyncio.TimeoutError:
        print(f"â±ï¸ [Gemini] Timeout: {filename}")
        return {
            "summary": text[:400] + "...",
            "keywords": [],
            "key_quotes": [],
            "category": "unknown"
        }
    except Exception as e:
        print(f"âš ï¸ [Gemini] Error {filename}: {e}")
        return {
            "summary": text[:400] + "...",
            "keywords": [],
            "key_quotes": [],
            "category": "unknown"
        }

def extract_text_from_file(file_path: str) -> str:
    """TrÃ­ch xuáº¥t text tá»« file"""
    ext = Path(file_path).suffix.lower()
    text = ""
    
    try:
        if ext == '.txt' or ext == '.md':
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                text = f.read()
        
        elif ext == '.json':
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                text = json.dumps(data, ensure_ascii=False, indent=2)
        
        elif ext == '.csv':
            import csv
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                reader = csv.reader(f)
                rows = [', '.join(row) for row in reader]
                text = '\n'.join(rows)
        
        elif ext == '.pdf':
            try:
                import PyPDF2
                with open(file_path, 'rb') as f:
                    reader = PyPDF2.PdfReader(f)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
            except ImportError:
                # Fallback: Read as binary and extract text using basic regex
                print(f"âš ï¸ [Extract] PyPDF2 not installed, using fallback for {file_path}")
                try:
                    with open(file_path, 'rb') as f:
                        content = f.read()
                        import re
                        # Simple extraction: find readable ASCII/Unicode text
                        text = re.sub(r'[\x00-\x08\x0b-\x0c\x0e-\x1f]+', ' ', 
                                     content.decode('latin1', errors='ignore'))
                        text = ' '.join(text.split())  # Clean whitespace
                except:
                    text = f"[PDF file - Cáº§n cÃ i PyPDF2: pip install PyPDF2]"
            except Exception as e:
                text = f"[Lá»—i Ä‘á»c PDF: {str(e)}]"
        
        elif ext in ['.docx', '.doc']:
            try:
                from docx import Document
                doc = Document(file_path)
                for para in doc.paragraphs:
                    text += para.text + "\n"
            except ImportError:
                # Fallback: Try reading docx as zip
                print(f"âš ï¸ [Extract] python-docx not installed, using fallback for {file_path}")
                try:
                    import zipfile
                    import xml.etree.ElementTree as ET
                    with zipfile.ZipFile(file_path) as docx:
                        xml_content = docx.read('word/document.xml')
                        tree = ET.XML(xml_content)
                        paragraphs = []
                        for paragraph in tree.iter('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}t'):
                            if paragraph.text:
                                paragraphs.append(paragraph.text)
                        text = '\n'.join(paragraphs)
                except:
                    text = f"[Word file - Cáº§n cÃ i python-docx: pip install python-docx]"
            except Exception as e:
                text = f"[Lá»—i Ä‘á»c Word: {str(e)}]"
        
        elif ext in ['.xlsx', '.xls']:
            try:
                import openpyxl
                print(f"âœ… [Extract] openpyxl loaded, reading: {file_path}")
                wb = openpyxl.load_workbook(file_path, data_only=True)
                rows_read = 0
                for sheet in wb.worksheets:
                    for row in sheet.iter_rows():
                        row_text = ', '.join([str(cell.value) if cell.value else '' for cell in row])
                        if row_text.strip():
                            text += row_text + "\n"
                            rows_read += 1
                print(f"âœ… [Extract] Excel read complete: {rows_read} rows")
            except ImportError as ie:
                print(f"âŒ [Extract] openpyxl ImportError: {ie}")
                text = f"[Excel file - Cáº§n cÃ i openpyxl: pip install openpyxl]"
            except Exception as e:
                print(f"âŒ [Extract] Excel error: {type(e).__name__}: {e}")
                text = f"[Lá»—i Ä‘á»c Excel: {str(e)}]"
        
        elif ext == '.rtf':
            try:
                from striprtf.striprtf import rtf_to_text
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    rtf_content = f.read()
                text = rtf_to_text(rtf_content)
            except ImportError:
                text = f"[RTF file - Cáº§n cÃ i striprtf: pip install striprtf]"
            except Exception as e:
                text = f"[Lá»—i Ä‘á»c RTF: {str(e)}]"
        
    except Exception as e:
        text = f"[Lá»—i Ä‘á»c file: {str(e)}]"
    
    return text.strip()

def scan_folder_for_files(folder_path: str) -> list:
    """QuÃ©t thÆ° má»¥c vÃ  tráº£ vá» danh sÃ¡ch files Ä‘Æ°á»£c há»— trá»£"""
    files = []
    folder = Path(folder_path)
    
    if not folder.exists():
        print(f"âŒ [Scan] Folder not exists: {folder_path}")
        return files
    
    print(f"ğŸ“‚ [Scan] Scanning folder: {folder_path}")
    total_checked = 0
    
    for file_path in folder.rglob('*'):
        if file_path.is_file():
            total_checked += 1
            ext = file_path.suffix.lower()
            if ext in SUPPORTED_EXTENSIONS:
                try:
                    stat = file_path.stat()
                    files.append({
                        "name": file_path.name,
                        "path": str(file_path),
                        "size": stat.st_size,
                        "modified": datetime.fromtimestamp(stat.st_mtime).strftime("%Y-%m-%d %H:%M"),
                        "extension": ext,
                        "indexed": False
                    })
                    print(f"  âœ… Added: {file_path.name} ({ext})")
                except Exception as e:
                    print(f"  âš ï¸ Error scanning file {file_path}: {e}")
            else:
                print(f"  â­ï¸ Skipped: {file_path.name} ({ext}) - Not supported")
    
    print(f"ğŸ“Š [Scan] Result: {len(files)} files found (checked {total_checked} files)")
    return files

@app.get("/api/knowledge/status")
async def api_knowledge_status():
    """Láº¥y tráº¡ng thÃ¡i Knowledge Base"""
    config = load_knowledge_config()
    index = load_knowledge_index()
    
    folder_path = config.get("folder_path", "")
    files = []
    total_size = 0
    
    if folder_path and Path(folder_path).exists():
        files = scan_folder_for_files(folder_path)
        total_size = sum(f["size"] for f in files)
        
        # ÄÃ¡nh dáº¥u cÃ¡c file Ä‘Ã£ Ä‘Æ°á»£c index
        indexed_paths = set(config.get("indexed_files", []))
        for f in files:
            f["indexed"] = f["path"] in indexed_paths
    
    return {
        "success": True,
        "folder_path": folder_path,
        "total_files": len(files),
        "indexed_files": len(config.get("indexed_files", [])),
        "total_size": total_size,
        "last_update": config.get("last_update", "--"),
        "files": files
    }

@app.post("/api/knowledge/set_folder")
async def api_knowledge_set_folder(data: dict):
    """Cáº¥u hÃ¬nh thÆ° má»¥c knowledge base"""
    folder_path = data.get("folder_path", "").strip()
    
    if not folder_path:
        return {"success": False, "error": "ÄÆ°á»ng dáº«n khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng"}
    
    # Kiá»ƒm tra thÆ° má»¥c tá»“n táº¡i
    if not Path(folder_path).exists():
        return {"success": False, "error": f"ThÆ° má»¥c khÃ´ng tá»“n táº¡i: {folder_path}"}
    
    if not Path(folder_path).is_dir():
        return {"success": False, "error": "ÄÆ°á»ng dáº«n pháº£i lÃ  thÆ° má»¥c, khÃ´ng pháº£i file"}
    
    config = load_knowledge_config()
    config["folder_path"] = folder_path
    config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
    
    if save_knowledge_config(config):
        return {"success": True, "message": f"ÄÃ£ lÆ°u thÆ° má»¥c: {folder_path}"}
    else:
        return {"success": False, "error": "Lá»—i khi lÆ°u cáº¥u hÃ¬nh"}

@app.post("/api/knowledge/scan")
async def api_knowledge_scan(data: dict):
    """QuÃ©t thÆ° má»¥c Ä‘á»ƒ tÃ¬m files"""
    folder_path = data.get("folder_path", "").strip()
    
    if not folder_path:
        config = load_knowledge_config()
        folder_path = config.get("folder_path", "")
    
    if not folder_path:
        return {"success": False, "error": "ChÆ°a cáº¥u hÃ¬nh thÆ° má»¥c"}
    
    if not Path(folder_path).exists():
        return {"success": False, "error": f"ThÆ° má»¥c khÃ´ng tá»“n táº¡i: {folder_path}"}
    
    files = scan_folder_for_files(folder_path)
    total_size = sum(f["size"] for f in files)
    
    # Cáº­p nháº­t config
    config = load_knowledge_config()
    config["folder_path"] = folder_path
    indexed_paths = set(config.get("indexed_files", []))
    for f in files:
        f["indexed"] = f["path"] in indexed_paths
    save_knowledge_config(config)
    
    return {
        "success": True,
        "total_files": len(files),
        "total_size": total_size,
        "files": files
    }

@app.post("/api/knowledge/index_all")
async def api_knowledge_index_all():
    """Index táº¥t cáº£ files trong thÆ° má»¥c (parallel processing)"""
    config = load_knowledge_config()
    folder_path = config.get("folder_path", "")
    
    if not folder_path or not Path(folder_path).exists():
        return {"success": False, "error": "ChÆ°a cáº¥u hÃ¬nh thÆ° má»¥c hoáº·c thÆ° má»¥c khÃ´ng tá»“n táº¡i"}
    
    files = scan_folder_for_files(folder_path)
    print(f"âš¡ [Index] Starting parallel indexing of {len(files)} files...")
    
    # âš¡ PARALLEL PROCESSING: Index nhiá»u files cÃ¹ng lÃºc
    async def index_single_file(file_info):
        try:
            text = extract_text_from_file(file_info["path"])
            
            # Check if extraction failed
            if not text or len(text.strip()) < 10:
                print(f"âš ï¸ [Index] Skipped {file_info['name']}: No text extracted")
                return None
                
            if text.startswith("["):  # Error message from extract_text_from_file
                print(f"âš ï¸ [Index] Skipped {file_info['name']}: {text}")
                return None
            
            print(f"ğŸ“„ [Index] Processing {file_info['name']} ({len(text)} chars)...")
            
            # TÃ³m táº¯t báº±ng Gemini Flash
            ai_summary = await summarize_with_gemini(text, file_info["name"])
            
            if not ai_summary or not ai_summary.get("summary"):
                print(f"âš ï¸ [Index] No summary for {file_info['name']}")
                # Still index with basic info
                ai_summary = {
                    "summary": text[:400] + "...",
                    "keywords": [],
                    "key_quotes": [],
                    "category": "general"
                }
            
            result = {
                "file_path": file_info["path"],
                "file_name": file_info["name"],
                "content": text[:50000],  # Giá»›i háº¡n 50k kÃ½ tá»± má»—i file
                "summary": ai_summary.get("summary", ""),
                "keywords": ai_summary.get("keywords", []),
                "key_quotes": ai_summary.get("key_quotes", []),
                "category": ai_summary.get("category", "general"),
                "indexed_at": datetime.now().isoformat()
            }
            print(f"âœ… [Index] Indexed {file_info['name']}")
            return result
            
        except Exception as e:
            print(f"âŒ [Index] Error indexing {file_info['name']}: {e}")
            return None
    
    # Process files in parallel (batch of 5 at a time to avoid API rate limits)
    documents = []
    batch_size = 5
    for i in range(0, len(files), batch_size):
        batch = files[i:i+batch_size]
        results = await asyncio.gather(*[index_single_file(f) for f in batch], return_exceptions=True)
        documents.extend([r for r in results if r and not isinstance(r, Exception)])
        print(f"âš¡ [Index] Processed {min(i+batch_size, len(files))}/{len(files)} files...")
    
    indexed_count = len(documents)
    
    # LÆ°u index
    index_data = {
        "documents": documents,
        "total_chunks": indexed_count,
        "last_update": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    save_knowledge_index(index_data)
    
    # ğŸ†• BUILD VECTOR INDEX with FAISS
    if VECTOR_SEARCH_AVAILABLE and documents:
        try:
            print(f"ğŸ”¨ [VectorSearch] Building vector index for {len(documents)} documents...")
            vector_engine = get_vector_engine()
            
            # Prepare documents in correct format: [{"id": str, "text": str, "metadata": dict}]
            documents_data = [
                {
                    "id": f"doc_{i}",
                    "text": doc["content"],
                    "metadata": {
                        "file_name": doc["file_name"],
                        "file_path": doc["file_path"],
                        "index": i
                    }
                }
                for i, doc in enumerate(documents)
            ]
            
            # Build and save index
            vector_engine.build_index(documents_data)
            vector_engine.save_index()
            
            stats = vector_engine.get_statistics()
            print(f"âœ… [VectorSearch] Index built: {stats['num_vectors']} vectors, {stats['embedding_dim']} dims")
        except Exception as e:
            print(f"âš ï¸ [VectorSearch] Failed to build index: {e}")
    
    # Cáº­p nháº­t config
    config["indexed_files"] = [f["path"] for f in files if any(d["file_path"] == f["path"] for d in documents)]
    config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
    save_knowledge_config(config)
    
    return {
        "success": True,
        "message": f"ÄÃ£ index {indexed_count}/{len(files)} files",
        "indexed_count": indexed_count,
        "last_update": index_data["last_update"]
    }

@app.post("/api/knowledge/index_file")
async def api_knowledge_index_file(data: dict):
    """Index má»™t file cá»¥ thá»ƒ"""
    file_path = data.get("file_path", "").strip()
    
    if not file_path or not Path(file_path).exists():
        return {"success": False, "error": "File khÃ´ng tá»“n táº¡i"}
    
    try:
        file_name = Path(file_path).name
        print(f"ğŸ“„ [Index] Starting index: {file_name}")
        
        text = extract_text_from_file(file_path)
        if not text or text.startswith("["):
            print(f"âŒ [Index] Failed to extract: {file_name} - {text[:100] if text else 'Empty'}")
            return {"success": False, "error": f"KhÃ´ng thá»ƒ Ä‘á»c file: {text}"}
        
        print(f"ğŸ“ [Index] Extracted {len(text)} chars from {file_name}")
        
        # Load existing index
        index_data = load_knowledge_index()
        
        # Remove existing entry for this file
        index_data["documents"] = [d for d in index_data["documents"] if d["file_path"] != file_path]
        
        # ğŸ†• TRY summarize, nhÆ°ng fallback náº¿u fail
        ai_summary = {"summary": "", "keywords": [], "key_quotes": [], "category": "general"}
        try:
            ai_summary = await asyncio.wait_for(
                summarize_with_gemini(text, file_name),
                timeout=30.0  # 30s timeout
            )
            print(f"âœ… [Index] AI Summary done for {file_name}")
        except asyncio.TimeoutError:
            print(f"âš ï¸ [Index] AI Summary timeout for {file_name}, using basic index")
            ai_summary["summary"] = text[:500] + "..."
        except Exception as e:
            print(f"âš ï¸ [Index] AI Summary error for {file_name}: {e}, using basic index")
            ai_summary["summary"] = text[:500] + "..."
        
        # Add new entry
        index_data["documents"].append({
            "file_path": file_path,
            "file_name": file_name,
            "content": text[:50000],
            "summary": ai_summary.get("summary", ""),
            "keywords": ai_summary.get("keywords", []),
            "key_quotes": ai_summary.get("key_quotes", []),
            "category": ai_summary.get("category", "general"),
            "indexed_at": datetime.now().isoformat()
        })
        index_data["total_chunks"] = len(index_data["documents"])
        index_data["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        save_knowledge_index(index_data)
        print(f"âœ… [Index] Saved: {file_name} (total: {index_data['total_chunks']} docs)")
        
        # Update config
        config = load_knowledge_config()
        if file_path not in config.get("indexed_files", []):
            config.setdefault("indexed_files", []).append(file_path)
        config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        save_knowledge_config(config)
        
        return {"success": True, "message": f"ÄÃ£ index: {file_name}"}
    
    except Exception as e:
        print(f"âŒ [Index] Error indexing {file_path}: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/knowledge/clear")
async def api_knowledge_clear():
    """XÃ³a toÃ n bá»™ index"""
    try:
        # Clear index file
        save_knowledge_index({"documents": [], "total_chunks": 0, "last_update": ""})
        
        # Update config
        config = load_knowledge_config()
        config["indexed_files"] = []
        config["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M")
        save_knowledge_config(config)
        
        return {"success": True, "message": "ÄÃ£ xÃ³a toÃ n bá»™ index"}
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api/knowledge/search")
async def api_knowledge_search(query: str = ""):
    """TÃ¬m kiáº¿m trong knowledge base"""
    if not query:
        return {"success": False, "error": "Vui lÃ²ng nháº­p tá»« khÃ³a tÃ¬m kiáº¿m"}
    
    index_data = load_knowledge_index()
    documents = index_data.get("documents", [])
    
    if not documents:
        return {"success": False, "error": "Knowledge base chÆ°a cÃ³ dá»¯ liá»‡u. Vui lÃ²ng index files trÆ°á»›c."}
    
    # AI-powered search - tÃ¬m trong summary, keywords vÃ  content
    query_lower = query.lower()
    results = []
    
    for doc in documents:
        score = 0
        matched_in = []
        
        # TÃ¬m trong summary (Ä‘iá»ƒm cao nháº¥t)
        summary = doc.get("summary", "")
        if query_lower in summary.lower():
            score += 10
            matched_in.append("summary")
        
        # TÃ¬m trong keywords (Ä‘iá»ƒm trung bÃ¬nh)
        keywords = doc.get("keywords", [])
        for keyword in keywords:
            if query_lower in keyword.lower():
                score += 5
                matched_in.append("keywords")
                break
        
        # TÃ¬m trong content (Ä‘iá»ƒm tháº¥p nháº¥t)
        content = doc.get("content", "")
        if query_lower in content.lower():
            score += 1
            matched_in.append("content")
            
            # TÃ¬m Ä‘oáº¡n text chá»©a query
            idx = content.lower().find(query_lower)
            start = max(0, idx - 200)
            end = min(len(content), idx + 200)
            snippet = content[start:end]
        else:
            snippet = summary[:400] if summary else content[:400]
        
        # Chá»‰ thÃªm vÃ o results náº¿u cÃ³ match
        if score > 0:
            results.append({
                "file_name": doc.get("file_name", ""),
                "file_path": doc.get("file_path", ""),
                "summary": summary,
                "keywords": keywords,
                "category": doc.get("category", "general"),
                "snippet": "..." + snippet + "...",
                "score": score,
                "matched_in": matched_in,
                "indexed_at": doc.get("indexed_at", "")
            })
    
    # Sáº¯p xáº¿p theo score
    results.sort(key=lambda x: x["score"], reverse=True)
    
    return {
        "success": True,
        "query": query,
        "total_results": len(results),
        "results": results[:20]  # Giá»›i háº¡n 20 káº¿t quáº£
    }

@app.get("/api/knowledge/context")
async def api_knowledge_get_context(query: str = "", max_chars: int = 10000, use_gemini_summary: bool = True):
    """Láº¥y context tá»« knowledge base Ä‘á»ƒ cung cáº¥p cho LLM - vá»›i Gemini summarization"""
    result = await get_knowledge_context(query, max_chars, use_gemini_summary)
    return result
    
@app.get("/api/knowledge/context_legacy")
async def api_knowledge_get_context_legacy(query: str = "", max_chars: int = 10000):
    """Legacy endpoint - khÃ´ng dÃ¹ng Gemini summarization"""
    index_data = load_knowledge_index()
    documents = index_data.get("documents", [])
    
    if not documents:
        return {"success": False, "context": "", "message": "Knowledge base trá»‘ng"}
    
    context_parts = []
    total_chars = 0
    
    # Náº¿u cÃ³ query, Æ°u tiÃªn cÃ¡c document liÃªn quan
    if query:
        query_lower = query.lower()
        # Sáº¯p xáº¿p theo Ä‘á»™ liÃªn quan
        scored_docs = []
        for doc in documents:
            content = doc.get("content", "")
            score = content.lower().count(query_lower)
            scored_docs.append((score, doc))
        scored_docs.sort(key=lambda x: x[0], reverse=True)
        documents = [d for _, d in scored_docs]
    
    for doc in documents:
        file_name = doc.get("file_name", "unknown")
        summary = doc.get("summary", "")
        keywords = doc.get("keywords", [])
        key_quotes = doc.get("key_quotes", [])
        category = doc.get("category", "general")
        
        # Æ¯u tiÃªn dÃ¹ng summary vÃ  key_quotes thay vÃ¬ full content
        # Äiá»u nÃ y giáº£m Ä‘Ã¡ng ká»ƒ token vÃ  tÄƒng cháº¥t lÆ°á»£ng context
        
        # Build compact context
        compact_content = f"ğŸ“ {summary}\n"
        if keywords:
            compact_content += f"ğŸ”‘ Keywords: {', '.join(keywords[:5])}\n"
        if key_quotes:
            compact_content += f"ğŸ’¬ TrÃ­ch dáº«n:\n"
            for quote in key_quotes[:3]:
                compact_content += f"  â€¢ {quote}\n"
        
        # ThÃªm header cho má»—i document
        header = f"\n\n=== [{category.upper()}] {file_name} ===\n"
        full_entry = header + compact_content
        
        if total_chars + len(full_entry) > max_chars:
            break
        else:
            context_parts.append(full_entry)
            total_chars += len(full_entry)
    
    full_context = "".join(context_parts)
    
    return {
        "success": True,
        "context": full_context,
        "total_documents": len(documents),
        "context_length": len(full_context)
    }

# ============================================================
# TASK MEMORY API - Ghi nhá»› tÃ¡c vá»¥ Ä‘Ã£ thá»±c hiá»‡n
# ============================================================

@app.get("/api/tasks/recent")
async def api_get_recent_tasks(limit: int = 10):
    """Láº¥y cÃ¡c tÃ¡c vá»¥ gáº§n Ä‘Ã¢y"""
    tasks = get_recent_tasks(limit)
    return {
        "success": True,
        "count": len(tasks),
        "tasks": tasks
    }

@app.get("/api/tasks/search/{keyword}")
async def api_search_tasks(keyword: str):
    """TÃ¬m kiáº¿m tÃ¡c vá»¥ theo tá»« khÃ³a"""
    results = search_task_memory(keyword)
    return {
        "success": True,
        "count": len(results),
        "tasks": results
    }

@app.get("/api/tasks/all")
async def api_get_all_tasks():
    """Láº¥y toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥"""
    tasks = load_task_memory()
    return {
        "success": True,
        "total": len(tasks),
        "tasks": tasks
    }

@app.post("/api/tasks/clear")
async def api_clear_tasks():
    """XÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥"""
    success = clear_task_memory()
    return {
        "success": success,
        "message": "ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­ tÃ¡c vá»¥" if success else "Lá»—i khi xÃ³a"
    }

@app.get("/api/tasks/summary")
async def api_get_task_summary():
    """Láº¥y tá»•ng há»£p thá»‘ng kÃª tÃ¡c vá»¥"""
    tasks = load_task_memory()
    
    if not tasks:
        return {
            "success": True,
            "total_tasks": 0,
            "by_tool": {},
            "success_rate": 0,
            "recent_tools": []
        }
    
    # Äáº¿m theo tool
    tool_counts = {}
    success_count = 0
    
    for task in tasks:
        tool = task.get('tool', 'unknown')
        tool_counts[tool] = tool_counts.get(tool, 0) + 1
        if task.get('result_success'):
            success_count += 1
    
    # Sáº¯p xáº¿p theo sá»‘ láº§n sá»­ dá»¥ng
    sorted_tools = sorted(tool_counts.items(), key=lambda x: x[1], reverse=True)
    
    return {
        "success": True,
        "total_tasks": len(tasks),
        "by_tool": dict(sorted_tools[:20]),
        "success_rate": round(success_count / len(tasks) * 100, 1),
        "recent_tools": [t.get('tool') for t in tasks[-5:]]
    }

# ============================================================
# CONVERSATION HISTORY API
# ============================================================

@app.get("/api/conversation/history")
async def api_get_conversation_history():
    """Láº¥y toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i"""
    return {
        "success": True,
        "total_messages": len(conversation_history),
        "messages": conversation_history
    }

@app.get("/api/conversation/recent/{count}")
async def api_get_recent_conversation(count: int = 10):
    """Láº¥y N messages gáº§n nháº¥t"""
    recent = conversation_history[-count:] if len(conversation_history) > count else conversation_history
    return {
        "success": True,
        "count": len(recent),
        "messages": recent
    }

@app.post("/api/conversation/clear")
async def api_clear_conversation():
    """XÃ³a toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i"""
    global conversation_history
    conversation_history = []
    save_conversation_history()
    return {
        "success": True,
        "message": "ÄÃ£ xÃ³a toÃ n bá»™ lá»‹ch sá»­ há»™i thoáº¡i"
    }

@app.post("/api/conversation/export")
async def api_export_conversation(data: dict = None):
    """Export lá»‹ch sá»­ há»™i thoáº¡i ra file"""
    filename = data.get("filename", "") if data else ""
    return await export_conversation_to_file(filename)

@app.post("/api/conversation/add")
async def api_add_conversation_message(data: dict):
    """ThÃªm message tá»« Web UI vÃ o history"""
    role = data.get("role", "user")
    content = data.get("content", "")
    metadata = data.get("metadata", {})
    
    if not content:
        return {"success": False, "error": "Content khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng"}
    
    add_to_conversation(role, content, metadata)
    
    return {
        "success": True,
        "message": "ÄÃ£ thÃªm message vÃ o history"
    }

@app.post("/api/chat/log")
async def api_log_chat_message(data: dict):
    """
    Endpoint Ä‘áº·c biá»‡t Ä‘á»ƒ Web UI log TOÃ€N Bá»˜ cuá»™c há»™i thoáº¡i
    DÃ¹ng cho cÃ¡c chat khÃ´ng qua MCP
    """
    messages = data.get("messages", [])
    
    if not messages:
        return {"success": False, "error": "KhÃ´ng cÃ³ messages Ä‘á»ƒ log"}
    
    # Log tá»«ng message
    for msg in messages:
        role = msg.get("role", "user")
        content = msg.get("content", "")
        metadata = msg.get("metadata", {})
        
        if content:
            add_to_conversation(role, content, metadata)
    
    return {
        "success": True,
        "message": f"ÄÃ£ log {len(messages)} messages vÃ o history",
        "total_messages": len(conversation_history)
    }

# ============================================================
# USER PROFILE API - Hiá»ƒu ngÆ°á»i dÃ¹ng
# ============================================================

@app.get("/api/user/profile")
async def api_get_user_profile():
    """Láº¥y user profile"""
    return {
        "success": True,
        "profile": load_user_profile(),
        "summary": get_user_profile_summary()
    }

@app.get("/api/user/context")
async def api_get_user_context(max_messages: int = 10):
    """Láº¥y context tá»« lá»‹ch sá»­ há»™i thoáº¡i + user profile"""
    return {
        "success": True,
        "user_profile": get_user_profile_summary(),
        "recent_conversation": get_conversation_context(max_messages),
        "hint": "DÃ¹ng thÃ´ng tin nÃ y Ä‘á»ƒ hiá»ƒu ngÆ°á»i dÃ¹ng tá»‘t hÆ¡n"
    }

@app.get("/api/conversation/files")
async def api_list_conversation_files():
    """Liá»‡t kÃª cÃ¡c file há»™i thoáº¡i Ä‘Ã£ lÆ°u"""
    files = list_conversation_files()
    return {
        "success": True,
        "storage_path": str(CONVERSATION_BASE_DIR),
        "total_files": len(files),
        "files": files
    }

# NOTE: Endpoint /api/conversation/today Ä‘Ã£ bá»‹ xÃ³a (khÃ´ng cÃ²n file theo ngÃ y)

@app.post("/api/endpoints/switch/{index}")
async def switch_endpoint(index: int):
    global active_endpoint_index, should_reconnect
    if index < 0 or index >= len(endpoints_config):
        return {"success": False, "error": "Thiáº¿t bá»‹ khÃ´ng tá»“n táº¡i"}
    
    device = endpoints_config[index]
    if not device.get("token"):
        return {"success": False, "error": "Thiáº¿t bá»‹ chÆ°a cÃ³ token. HÃ£y nháº­p token vÃ  lÆ°u láº¡i!"}
    
    # Thay Ä‘á»•i endpoint vÃ  trigger reconnect
    old_index = active_endpoint_index
    active_endpoint_index = index
    should_reconnect = True  # Trigger reconnect trong xiaozhi_websocket_client
    
    # LÆ°u vÃ o file
    save_endpoints_to_file(endpoints_config, active_endpoint_index)
    
    print(f"ğŸ”„ [Endpoint] Switching from device {old_index} to {index} ({device['name']})")
    
    return {"success": True, "message": f"ÄÃ£ chuyá»ƒn sang {device['name']}. Äang káº¿t ná»‘i láº¡i..."}

@app.post("/api/endpoints/save")
async def save_endpoints(data: dict):
    global endpoints_config, should_reconnect
    try:
        devices = data.get('devices', [])
        if not devices:
            return {"success": False, "error": "KhÃ´ng cÃ³ dá»¯ liá»‡u"}
        
        # LÆ°u token cÅ© cá»§a thiáº¿t bá»‹ Ä‘ang active Ä‘á»ƒ so sÃ¡nh
        old_active_token = endpoints_config[active_endpoint_index].get('token', '') if active_endpoint_index < len(endpoints_config) else ''
        
        # Cáº­p nháº­t endpoints_config
        endpoints_config = []
        for dev in devices:
            token = dev.get('token', '').strip()  # Strip whitespace
            endpoints_config.append({
                'name': dev.get('name', 'Thiáº¿t bá»‹'),
                'token': token,
                'enabled': bool(token)  # Only enabled if token not empty
            })
        
        # ğŸ”¥ FIX: FORCE SAVE khi user báº¥m Save - khÃ´ng skip
        if save_endpoints_to_file(endpoints_config, active_endpoint_index, force_save=True):
            print(f"âœ… [Endpoint] User saved {len(devices)} devices (forced)")
        else:
            print(f"âš ï¸ [Endpoint] Failed to save to file, but config updated in memory")
        
        # CHá»ˆ reconnect náº¿u token thay Ä‘á»•i VÃ€ cÃ³ giÃ¡ trá»‹ má»›i khÃ¡c rá»—ng
        new_active_token = endpoints_config[active_endpoint_index].get('token', '') if active_endpoint_index < len(endpoints_config) else ''
        if old_active_token != new_active_token and new_active_token and old_active_token:
            # Token Ä‘Ã£ thay Ä‘á»•i (khÃ´ng pháº£i láº§n Ä‘áº§u nháº­p)
            should_reconnect = True
            print(f"ğŸ”„ [Endpoint] Token changed for active device {active_endpoint_index}. Triggering reconnect...")
        
        return {"success": True, "message": "ÄÃ£ lÆ°u cáº¥u hÃ¬nh"}
    except Exception as e:
        print(f"âŒ [Endpoint] Error saving: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}

@app.post("/api/gemini-key")
async def save_gemini_key(data: dict):
    """Save Gemini API key - Auto-save endpoint"""
    global GEMINI_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # ğŸ”¥ FIX: Cho phÃ©p empty string (user xÃ³a key)
        if api_key:
            # Validate format only if key is provided
            if not api_key.startswith('AIzaSy'):
                return {"success": False, "error": "API key khÃ´ng há»£p lá»‡ (pháº£i báº¯t Ä‘áº§u vá»›i 'AIzaSy')"}
        
        # Update global variable (allow empty)
        GEMINI_API_KEY = api_key
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"âœ… [Gemini] API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ lÆ°u Gemini API key",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("âœ… [Gemini] API key cleared")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ xÃ³a Gemini API key"
                }
        else:
            return {"success": False, "error": "Lá»—i lÆ°u file config"}
    except Exception as e:
        print(f"âŒ [Gemini] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/openai-key")
async def save_openai_key(data: dict):
    """Save OpenAI API key - Auto-save endpoint"""
    global OPENAI_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # ğŸ”¥ FIX: Cho phÃ©p empty string (user xÃ³a key)
        if api_key:
            # Validate format only if key is provided
            if not api_key.startswith('sk-'):
                return {"success": False, "error": "API key khÃ´ng há»£p lá»‡ (pháº£i báº¯t Ä‘áº§u vá»›i 'sk-')"}
        
        # Update global variable (allow empty)
        OPENAI_API_KEY = api_key
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"âœ… [OpenAI] API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ lÆ°u OpenAI API key",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("âœ… [OpenAI] API key cleared")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ xÃ³a OpenAI API key"
                }
        else:
            return {"success": False, "error": "Lá»—i lÆ°u file config"}
    except Exception as e:
        print(f"âŒ [OpenAI] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.post("/api/serper-key")
async def save_serper_key(data: dict):
    """Save Serper API key (Google Search) - Auto-save endpoint"""
    global SERPER_API_KEY
    try:
        api_key = data.get('api_key', '').strip()
        
        # ğŸ”¥ FIX: Cho phÃ©p empty string (user xÃ³a key)
        # Update global variable (allow empty)
        SERPER_API_KEY = api_key
        
        # Cáº­p nháº­t environment variable Ä‘á»ƒ rag_system.py cÃ³ thá»ƒ dÃ¹ng
        if api_key:
            os.environ['SERPER_API_KEY'] = api_key
        else:
            os.environ.pop('SERPER_API_KEY', None)  # Remove if empty
        
        # Save to file
        if save_endpoints_to_file(endpoints_config, active_endpoint_index):
            if api_key:
                print(f"âœ… [Serper] Google Search API key saved (ends with ...{api_key[-8:]})")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ lÆ°u Serper API key - Google Search sáºµn sÃ ng!",
                    "key_preview": f"...{api_key[-8:]}"
                }
            else:
                print("âœ… [Serper] API key cleared")
                return {
                    "success": True,
                    "message": "âœ“ ÄÃ£ xÃ³a Serper API key"
                }
        else:
            return {"success": False, "error": "Lá»—i lÆ°u file config"}
    except Exception as e:
        print(f"âŒ [Serper] Error saving API key: {e}")
        return {"success": False, "error": str(e)}

@app.get("/api/serper-key")
async def get_serper_key():
    """Get current Serper API key status"""
    if SERPER_API_KEY:
        return {
            "success": True,
            "has_key": True,
            "key_preview": f"...{SERPER_API_KEY[-8:]}"
        }
    return {"success": True, "has_key": False}


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    active_connections.append(websocket)
    try:
        await websocket.send_json({"type": "xiaozhi_status", "connected": xiaozhi_connected})
        while True:
            data = await websocket.receive_text()
            
            # Parse vÃ  log WebSocket messages
            try:
                msg_data = json.loads(data)
                msg_type = msg_data.get("type", "")
                
                # LÆ°u user messages tá»« Web UI
                if msg_type == "chat_message":
                    user_msg = msg_data.get("message", "")
                    if user_msg:
                        add_to_conversation(
                            role="user",
                            content=user_msg,
                            metadata={
                                "source": "websocket",
                                "msg_type": msg_type
                            }
                        )
                
                # LÆ°u AI responses tá»« Web UI
                elif msg_type == "ai_response":
                    ai_msg = msg_data.get("response", "")
                    if ai_msg:
                        add_to_conversation(
                            role="assistant",
                            content=ai_msg,
                            metadata={
                                "source": "websocket",
                                "msg_type": msg_type,
                                "model": msg_data.get("model", "unknown")
                            }
                        )
                
                # ğŸ†• SMART ANALYZE - PhÃ¢n tÃ­ch thÃ´ng minh vá»›i AI (Má»šI - Æ¯U TIÃŠN)
                elif msg_type == "smart_analyze":
                    user_query = msg_data.get("query", "")
                    llm_response = msg_data.get("response", "")
                    auto_execute = msg_data.get("auto_execute", True)
                    use_ai = msg_data.get("use_ai", True)
                    conversation_history = msg_data.get("history", [])
                    
                    print(f"ğŸ§  [WebSocket] Smart Analyze: query='{user_query[:50]}...'")
                    
                    # Gá»i Smart Analyzer API
                    analyze_result = await api_smart_analyze({
                        "user_query": user_query,
                        "llm_response": llm_response,
                        "conversation_history": conversation_history,
                        "auto_execute": auto_execute,
                        "use_ai": use_ai
                    })
                    
                    # Gá»­i káº¿t quáº£ vá» client
                    await websocket.send_json({
                        "type": "smart_analyze_result",
                        **analyze_result
                    })
                    
                    print(f"âœ… [WebSocket] Smart analyze result sent")
                
                # ğŸ”„ AUTO TOOL EXECUTION (Legacy - váº«n giá»¯ Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch)
                elif msg_type == "llm_response_check":
                    llm_response = msg_data.get("response", "")
                    original_query = msg_data.get("query", "")
                    auto_execute = msg_data.get("auto_execute", True)
                    use_smart = msg_data.get("use_smart", True)  # Máº·c Ä‘á»‹nh dÃ¹ng Smart Analyzer
                    
                    if llm_response or original_query:
                        print(f"ğŸ¤– [WebSocket] Processing: '{(original_query or llm_response)[:50]}...'")
                        
                        if use_smart:
                            # ğŸ§  DÃ¹ng Smart Analyzer (má»›i - thÃ´ng minh hÆ¡n)
                            result = await api_smart_analyze({
                                "user_query": original_query,
                                "llm_response": llm_response,
                                "auto_execute": auto_execute,
                                "use_ai": True
                            })
                            result["type"] = "smart_analyze_result"
                        else:
                            # Legacy: dÃ¹ng pattern matching
                            result = await api_auto_execute({
                                "llm_response": llm_response,
                                "original_query": original_query,
                                "auto_execute": auto_execute
                            })
                            result["type"] = "auto_execute_result"
                        
                        # Gá»­i káº¿t quáº£ vá» client
                        await websocket.send_json(result)
                        
                        print(f"âœ… [WebSocket] Result sent to client")
                
            except json.JSONDecodeError:
                pass  # Not JSON, skip logging
            
            await websocket.send_text(f"Echo: {data}")
    except Exception as e:
        print(f"âš ï¸ WebSocket client error: {e}")
    finally:
        if websocket in active_connections:
            active_connections.remove(websocket)

@app.on_event("startup")
async def startup():
    """Khá»Ÿi Ä‘á»™ng server vá»›i endpoint manager cáº£i tiáº¿n - ghi nhá»› endpoint má»—i láº§n khá»Ÿi Ä‘á»™ng"""
    global endpoints_config, active_endpoint_index
    
    # Check music folder config and notify
    config_info = check_music_folder_config()
    if config_info.get("has_config"):
        folder_path = config_info.get("folder_path", "")
        print(f"ğŸµ [Music Config] User music folder configured: {folder_path}")
        print(f"â­ [Music Priority] Will use play_music_from_user_folder for music requests")
    else:
        print(f"âš ï¸ [Music Config] No user music folder configured. Will use VLC music_library as fallback.")
    
    # ğŸ”¥ NEW: Sá»­ dá»¥ng MCPEndpointManager Ä‘á»ƒ quáº£n lÃ½ káº¿t ná»‘i
    if ENDPOINT_MANAGER_AVAILABLE:
        try:
            manager = get_endpoint_manager()
            
            # Äá»“ng bá»™ config tá»« manager (Ä‘Ã£ Ä‘Æ°á»£c load vÃ  ghi nhá»› tá»« láº§n trÆ°á»›c)
            endpoints_config = manager.endpoints
            active_endpoint_index = manager.active_index
            
            print(f"ğŸ“‹ [Startup] Loaded {len(endpoints_config)} endpoints from saved config")
            print(f"ğŸ“ [Startup] Active endpoint: {active_endpoint_index} ({endpoints_config[active_endpoint_index].get('name', 'Unknown')})")
            
            # Register callbacks Ä‘á»ƒ Ä‘á»“ng bá»™ tráº¡ng thÃ¡i
            def on_connect_callback(index, name):
                global xiaozhi_connected
                xiaozhi_connected[index] = True
                print(f"ğŸ”” [Manager] Device {index + 1} ({name}) connected")
            
            def on_disconnect_callback(index):
                global xiaozhi_connected, xiaozhi_connections
                xiaozhi_connected[index] = False
                xiaozhi_connections[index] = None
                print(f"ğŸ”Œ [Manager] Device {index + 1} disconnected")
            
            def on_error_callback(index, error):
                print(f"âŒ [Manager] Device {index + 1} error: {error}")
            
            manager.on_connect(on_connect_callback)
            manager.on_disconnect(on_disconnect_callback)
            manager.on_error(on_error_callback)
            
            # Váº«n dÃ¹ng websocket client cÅ© Ä‘á»ƒ xá»­ lÃ½ messages, nhÆ°ng thÃ´ng tin Ä‘Æ°á»£c ghi nhá»›
            print(f"ğŸš€ [Startup] Starting WebSocket clients with remembered endpoints...")
            
        except Exception as e:
            print(f"âš ï¸ [Startup] EndpointManager error: {e}")
    
    # Enable WebSocket client with error handling
    try:
        # Khá»Ÿi táº¡o 3 Xiaozhi clients Ä‘á»“ng thá»i
        for i in range(3):
            asyncio.create_task(xiaozhi_websocket_client(device_index=i))
        print(f"âœ… [Startup] WebSocket clients started for {len(endpoints_config)} devices")
    except Exception as e:
        print(f"âš ï¸ Failed to start WebSocket clients: {e}")

@app.on_event("shutdown")
async def shutdown():
    """Save conversation history vÃ  endpoint state on shutdown - trÃ¡nh máº¥t data"""
    try:
        print("ğŸ’¾ [Shutdown] Saving conversation history...")
        save_conversation_history()
        print(f"âœ… [Shutdown] Saved {len(conversation_history)} messages")
        
        # ğŸ”¥ NEW: LÆ°u endpoint state Ä‘á»ƒ ghi nhá»› cho láº§n khá»Ÿi Ä‘á»™ng sau
        if ENDPOINT_MANAGER_AVAILABLE:
            try:
                manager = get_endpoint_manager()
                # Äá»“ng bá»™ config hiá»‡n táº¡i trÆ°á»›c khi lÆ°u
                manager.endpoints = endpoints_config
                manager.active_index = active_endpoint_index
                manager.save_config()
                print(f"ğŸ’¾ [Shutdown] Saved endpoint config (active: {active_endpoint_index})")
            except Exception as e:
                print(f"âš ï¸ [Shutdown] Error saving endpoint config: {e}")
        
        # LÆ°u endpoints vÃ o file cÅ© Ä‘á»ƒ backward compatible
        save_endpoints_to_file(endpoints_config, active_endpoint_index)
        print(f"ğŸ’¾ [Shutdown] Saved {len(endpoints_config)} endpoints")
        
    except Exception as e:
        print(f"âš ï¸ [Shutdown] Error saving: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import uvicorn
    import webbrowser
    import threading
    import time
    
    # ============================================================
    # UNIFIED STARTUP BANNER - PROFESSIONAL EDITION
    # ============================================================
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                            â•‘")
    print("â•‘          ğŸ” miniZ MCP v4.3.0 - PROFESSIONAL EDITION        â•‘")
    print("â•‘                                                            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # Step 1: FREE EDITION - No License Check
    print("ğŸ” [1/4] Kiá»ƒm tra phiÃªn báº£n...")
    print("    âœ… miniZ MCP FREE EDITION")
    print("    ğŸ“¦ Loáº¡i: FREE (KhÃ´ng giá»›i háº¡n)")
    print("    ğŸ‘¤ NgÆ°á»i dÃ¹ng: Community User")
    
    # Auto-startup check - Láº§n Ä‘áº§u cháº¡y thÃ¬ báº­t auto-start
    marker_file = os.path.join(os.path.expanduser("~"), ".miniz_mcp_installed")
    if not os.path.exists(marker_file):
        print("    âš™ï¸ CÃ i Ä‘áº·t khá»Ÿi Ä‘á»™ng cÃ¹ng Windows...")
        AutoStartupManager.enable_autostart()
        try:
            with open(marker_file, 'w') as f:
                f.write("installed=true\\nversion=4.3.0\\nedition=FREE")
        except:
            pass
    else:
        if AutoStartupManager.is_autostart_enabled():
            print("    ğŸ”„ Khá»Ÿi Ä‘á»™ng cÃ¹ng Windows: Báº¬T")
    
    print()
    
    # Step 2: Check Firewall/Internet Permission
    print("ğŸ”¥ [2/4] Kiá»ƒm tra quyá»n káº¿t ná»‘i máº¡ng...")
    firewall_status = FirewallChecker.check_firewall_rules()
    internet_status = FirewallChecker.check_internet_connection()
    
    if firewall_status['rules_found']:
        print("    âœ… Firewall: ÄÃ£ cáº¥p quyá»n")
        print(f"    ğŸ“Œ Rules: {', '.join(firewall_status['rules_found'][:3])}")
    else:
        print("    âš ï¸ Firewall: ChÆ°a cÃ³ rule (Windows sáº½ há»i khi cáº§n)")
        print("    ğŸ’¡ Tip: Nháº¥n 'Allow' khi Windows há»i cho phÃ©p truy cáº­p máº¡ng")
    
    if internet_status['connected']:
        latency = internet_status.get('latency_ms', '?')
        print(f"    âœ… Internet: ÄÃ£ káº¿t ná»‘i ({latency}ms)")
    else:
        print("    âš ï¸ Internet: KhÃ´ng káº¿t ná»‘i hoáº·c Ä‘ang kiá»ƒm tra...")
        print("    ğŸ’¡ Äáº£m báº£o mÃ¡y tÃ­nh cÃ³ káº¿t ná»‘i máº¡ng Ä‘á»ƒ sá»­ dá»¥ng AI")
    
    print()
    
    # Step 3: Initialize Server
    print("ğŸš€ [3/4] Khá»Ÿi Ä‘á»™ng Server...")
    print("    ğŸŒ Web Dashboard: http://localhost:8000")
    print("    ğŸ“¡ WebSocket MCP: Multi-device support")
    print("    ğŸ› ï¸  Tools: 141 cÃ´ng cá»¥ AI sáºµn sÃ ng")
    print("    âœ… Server initialized")
    
    print()
    
    # Step 4: Open Browser
    print("ğŸŒ [4/4] Má»Ÿ giao diá»‡n...")
    print("    â³ Browser sáº½ tá»± Ä‘á»™ng má»Ÿ sau 2 giÃ¢y...")
    
    def open_browser():
        """Mo browser sau 2 giay"""
        time.sleep(2)
        webbrowser.open("http://localhost:8000")
    
    # Khoi dong thread mo browser
    threading.Thread(target=open_browser, daemon=True).start()
    
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                            â•‘")
    print("â•‘              âœ… miniZ MCP READY TO USE                      â•‘")
    print("â•‘                                                            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # Fix logging error when running as frozen EXE
    import sys
    if getattr(sys, 'frozen', False):
        # Disable uvicorn's default logging config when frozen
        uvicorn.run(app, host="0.0.0.0", port=8000, log_config=None)
    else:
        uvicorn.run(app, host="0.0.0.0", port=8000)

